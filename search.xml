<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>CUDA|GPU的内存结构</title>
      <link href="/2024/11/18/cuda-zhi-shi/gpu-de-nei-cun-jie-gou/"/>
      <url>/2024/11/18/cuda-zhi-shi/gpu-de-nei-cun-jie-gou/</url>
      
        <content type="html"><![CDATA[<h1 id="GPU的内存结构"><a href="#GPU的内存结构" class="headerlink" title="GPU的内存结构"></a>GPU的内存结构</h1><p>内存的本地化原则：</p><ol><li>时间本地化：内存地址在某个时间被访问，该内存地址有较大概率在短时间内再次被访问，此概率随时间间隔增加而逐渐减小。</li><li>空间本地化：某个内存地址被访问，该内存附近的内存有较大概率被访问</li></ol><p>内存分类：</p><ol><li>非可编程内存</li><li>可编程内存，重点关注可编程内存即可</li></ol><p>内存层次和类型：</p><p>CUDA内存模型将独立的<strong>主机内存</strong>和<strong>GPU设备内存</strong>作为整体形成完整的内存层次结构。为了获得更好的性能，内存层次结构遵循渐进的低延迟、低容量特点：<br><img src="/images/cuda_imgs/memory_arch.png"></p><p><img src="/images/cuda_imgs/memory_vis.png"></p><h2 id="寄存器"><a href="#寄存器" class="headerlink" title="寄存器"></a>寄存器</h2><p>寄存器的特点是速度快，容量小，它是最快的一种内存。如上图所示，寄存器中的数据是被每个线程所独有，具有与内核函数相同的生命周期。<br>寄存器中保存的数据：</p><ol><li>内核函数中无修饰符的自动变量，由系统自动为其分配空间</li><li>数组索引为常量或在编译时有确定值时，数组可以保存在寄存器</li></ol><p>每个线程使用的寄存器数量是有限的，对于Fermi架构而言，每个线程最多可用63个寄存器，Kepler架构最多可用255个寄存器。</p><h3 id="寄存器溢出"><a href="#寄存器溢出" class="headerlink" title="寄存器溢出"></a>寄存器溢出</h3><p>当内核函数使用的寄存器数量超过硬件限制时，数据会被保存到线程的本地内存（local memory）中。这种现象就是寄存器溢出，溢出会降低程序运行性能。</p><p>为了避免寄存器溢出，需要对其进行控制。可在内核函数前面加上标识符<code>__launch_bounds__</code>，如此在内核函数编译时，编译器会对可能使用的寄存器数量进行限制。</p><pre class="line-numbers language-cpp"><code class="language-cpp">__global__ <span class="token keyword">void</span> <span class="token function">__launch_bounds__</span><span class="token punctuation">(</span>maxThreadsPerBlock<span class="token punctuation">,</span> minBlocksPerMultiprocessor<span class="token punctuation">)</span><span class="token function">kernel</span><span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token punctuation">{</span>    <span class="token comment" spellcheck="true">// kernel body</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>其中<code>maxThreadsPerBlock</code>用于设置每个线程块的最大线程数量，<code>minBlocksPerMultiprocessor</code>用于设置每个SM流处理器的最小线程块数量。nvcc编译器会根据这两个参数推算出每个内核函数所需要的寄存器数量，如果推算数量多余硬件限制的数量，则会降低每个内核函数所使用的寄存器数量。</p><h2 id="本地内存"><a href="#本地内存" class="headerlink" title="本地内存"></a>本地内存</h2><p>如上图，本地内存（local memory）是被每个线程所独有，延迟比寄存器大，但是容量也比寄存器大。当寄存器发生溢出时，溢出的数据会被保存到本地内存。</p><p>本地内存中保存的数据：</p><ol><li>内核代码中存在无法确定索引的数组，则该数组保存在本地内存</li><li>寄存器发生溢出时，溢出的数据会被保存到本地内存</li><li>结构体和大数组</li><li>无法保存在寄存器中的其他数据</li></ol><h2 id="共享内存"><a href="#共享内存" class="headerlink" title="共享内存"></a>共享内存</h2><p>共享内存的特点是低延迟、高带宽，可以被线程块中的所有线程所访问，具有与线程块相同的生命周期；由于可被线程块中的所有线程访问，因此可以作为一种线程间的通信机制，且对共享内存的访问必须要做同步处理：<code>__syncthreads()</code>。</p><p>共享内存需要用<code>__share__</code>关键字来修饰。</p><p>流处理器SM中的L1缓存和共享内存共享GPU上的64K存储区域。可以通过动态配置的方式控制共享内存的大小，动态配置函数为<code>cudaFuncSetCacheConfig()</code>，控制共享内存大小的参数有如下几种：</p><ol><li><code>cudaFuncCachePerferNone</code>，默认配置</li><li><code>cudaFuncCachePerferShared</code>，48K共享内存，16K L1缓存</li><li><code>cudaFuncCachePerferL1</code>，48K L1内存，16K 共享缓存</li><li><code>cudaFuncCachePerferEqual</code>，各32K</li></ol><pre class="line-numbers language-c"><code class="language-c">__host__ cudaError_t <span class="token function">cudaFuncSetCacheConfig</span><span class="token punctuation">(</span><span class="token keyword">const</span> <span class="token keyword">void</span> <span class="token operator">*</span>func<span class="token punctuation">,</span> cudaFuncCache cacheConfig<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>其中<code>func</code>即表示内核函数，<code>cacheConfig</code>即表示配置参数。</p><h2 id="常量内存"><a href="#常量内存" class="headerlink" title="常量内存"></a>常量内存</h2><p>常量内存（constant memory）是GPU上的内存区域，每个流处理器SM均有独立的常量内存。常量变量必须由<code>__constant__</code>关键字修饰，且必须声明在全局域中（不能声明在内核函数中）。常量内存大小为64K，其对程序中的所有内核函数可见，且内核函数只能读取常量内存中的数据。</p><p>常量内存必须在主机程序中完成初始化：<code>cudaMemcpyToSymbol()</code>。</p><pre class="line-numbers language-c"><code class="language-c">__constant__ <span class="token keyword">float</span> factor<span class="token punctuation">;</span>__host__ <span class="token keyword">void</span> <span class="token function">constantMemory</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">{</span>    <span class="token function">printf</span><span class="token punctuation">(</span><span class="token string">"get constant memory: %.2f"</span><span class="token punctuation">,</span>factor<span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token punctuation">}</span><span class="token keyword">int</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token keyword">int</span> argc<span class="token punctuation">,</span> <span class="token keyword">char</span><span class="token operator">*</span><span class="token operator">*</span> argv<span class="token punctuation">)</span><span class="token punctuation">{</span>    <span class="token comment" spellcheck="true">// gpu设备初始化</span>    <span class="token comment" spellcheck="true">// 网格设置、线程块设置</span>    <span class="token comment" spellcheck="true">// ....</span>    <span class="token comment" spellcheck="true">////////////</span>        <span class="token keyword">float</span> h_factor<span class="token operator">=</span> <span class="token number">2.3</span><span class="token punctuation">;</span> <span class="token comment" spellcheck="true">// 主机上的变量</span>    <span class="token comment" spellcheck="true">// 常量内存初始化</span>    <span class="token function">cudaMemcpyToSymbol</span><span class="token punctuation">(</span>factor<span class="token punctuation">,</span> <span class="token operator">&amp;</span>h_factor<span class="token punctuation">,</span> <span class="token keyword">sizeof</span><span class="token punctuation">(</span><span class="token keyword">float</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> cudaMemcpyHostToDevice<span class="token punctuation">)</span><span class="token punctuation">;</span>    constantMemory<span class="token operator">&lt;&lt;</span><span class="token operator">&lt;</span>grid<span class="token punctuation">,</span> block<span class="token operator">>></span><span class="token operator">></span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token function">cudaDeviceReset</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">return</span> <span class="token number">0</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>从上面可以看到，第一个参数<code>factor</code>是常量内存的符号，而不是传入其地址，切记不要使用取地址符<code>&amp;factor</code>，否则编译会报错。</p><h2 id="全局内存"><a href="#全局内存" class="headerlink" title="全局内存"></a>全局内存</h2><p>全局内存是GPU上容量最大，延迟最大、使用最多的内存空间，其具有与程序相同的生命周期，可以被所有流处理器SM访问。同时对程序中的所有内核函数可见。</p><p>全局内存的首地址必须是32字节、64字节、128字节的整数倍。</p><p>全局内存的初始化方式有两种：</p><ol><li>静态初始化：使用<code>__device__</code>关键字静态声明全局内存</li><li>动态初始化：主机代码中使用<code>cudaMalloc()</code>动态初始化全局内存，使用<code>cudaFree()</code>释放全局内存。</li></ol><pre class="line-numbers language-c"><code class="language-c">__device__ <span class="token keyword">float</span> factor <span class="token operator">=</span> <span class="token number">2.3</span><span class="token punctuation">;</span> <span class="token comment" spellcheck="true">// 静态初始化</span>__global__ <span class="token keyword">void</span> <span class="token function">globalMemory</span><span class="token punctuation">(</span><span class="token keyword">float</span><span class="token operator">*</span> out<span class="token punctuation">)</span><span class="token punctuation">{</span>    <span class="token function">printf</span><span class="token punctuation">(</span><span class="token string">"get global memory: %.2f"</span><span class="token punctuation">,</span>factor<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token operator">*</span>out <span class="token operator">=</span> factor<span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token keyword">int</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token keyword">int</span> argc<span class="token punctuation">,</span> <span class="token keyword">char</span><span class="token operator">*</span><span class="token operator">*</span> argv<span class="token punctuation">)</span><span class="token punctuation">{</span>    <span class="token comment" spellcheck="true">// gpu设备初始化</span>    <span class="token comment" spellcheck="true">// 网格设置、线程块设置</span>    <span class="token comment" spellcheck="true">// ....</span>    <span class="token comment" spellcheck="true">////////////</span>    <span class="token keyword">float</span> h_factor<span class="token punctuation">;</span>    <span class="token keyword">float</span><span class="token operator">*</span> d_factor<span class="token punctuation">;</span>    <span class="token function">cudaMalloc</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token keyword">void</span><span class="token operator">*</span><span class="token operator">*</span><span class="token punctuation">)</span><span class="token operator">&amp;</span>d_factor<span class="token punctuation">,</span> <span class="token keyword">sizeof</span><span class="token punctuation">(</span><span class="token keyword">float</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment" spellcheck="true">// 动态初始化</span>    globalMemory<span class="token operator">&lt;&lt;</span><span class="token operator">&lt;</span>grid<span class="token punctuation">,</span> block<span class="token operator">>></span><span class="token operator">></span><span class="token punctuation">(</span>d_factor<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">// 将gpu数据拷贝至cpu内存里</span>    <span class="token function">cudaMemcpy</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>h_factor<span class="token punctuation">,</span> d_factor<span class="token punctuation">,</span> <span class="token keyword">sizeof</span><span class="token punctuation">(</span><span class="token keyword">float</span><span class="token punctuation">)</span><span class="token punctuation">,</span> cudaMemcpyDeviceToHost<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token function">printf</span><span class="token punctuation">(</span><span class="token string">"host memory: %.2f"</span><span class="token punctuation">,</span>h_factor<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token function">cudaFree</span><span class="token punctuation">(</span>d_factor<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token function">cudaDeviceReset</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">return</span> <span class="token number">0</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="静态全局内存"><a href="#静态全局内存" class="headerlink" title="静态全局内存"></a>静态全局内存</h3><p>静态全局内存使用<code>__device__</code>修饰符来声明，所声明的静态全局内存不能在主机代码中直接访问。</p><p>如果要为静态全局内存赋值，使用<code>cudaMemcpyToSymbol()</code>，如果要获取静态全局内存的值，使用<code>cudaMemcpyFromSymbol()</code>。</p><p>静态全局内存只是GPU上内存块的符号，不能直接使用<code>&amp;</code>获取其内存地址，如果要获取静态全局内存地址，使用<code>cudaGetSymbolAddress()</code>。</p><pre class="line-numbers language-c"><code class="language-c">__device__ <span class="token keyword">float</span> factor <span class="token operator">=</span> <span class="token number">0.0</span><span class="token punctuation">;</span> <span class="token comment" spellcheck="true">// 静态初始化</span>__global__ <span class="token keyword">void</span> <span class="token function">globalMemory</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">{</span>    <span class="token function">printf</span><span class="token punctuation">(</span><span class="token string">"get global memory: %.2f"</span><span class="token punctuation">,</span>factor<span class="token punctuation">)</span><span class="token punctuation">;</span>    factor <span class="token operator">+</span><span class="token operator">=</span> <span class="token number">1.2</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token keyword">int</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token keyword">int</span> argc<span class="token punctuation">,</span> <span class="token keyword">char</span><span class="token operator">*</span><span class="token operator">*</span> argv<span class="token punctuation">)</span><span class="token punctuation">{</span>    <span class="token comment" spellcheck="true">// gpu设备初始化</span>    <span class="token comment" spellcheck="true">// 网格设置、线程块设置</span>    <span class="token comment" spellcheck="true">// ....</span>    <span class="token comment" spellcheck="true">////////////</span>    <span class="token keyword">float</span> h_factor <span class="token operator">=</span> <span class="token number">3.6</span><span class="token punctuation">;</span>    <span class="token function">cudaMemcpyToSymbol</span><span class="token punctuation">(</span>factor<span class="token punctuation">,</span> <span class="token operator">&amp;</span>h_factor<span class="token punctuation">,</span> <span class="token keyword">sizeof</span><span class="token punctuation">(</span><span class="token keyword">float</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> cudaMemcpyHostToDevice<span class="token punctuation">)</span><span class="token punctuation">;</span>        globalMemory<span class="token operator">&lt;&lt;</span><span class="token operator">&lt;</span>grid<span class="token punctuation">,</span> block<span class="token operator">>></span><span class="token operator">></span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token function">cudaDeviceSynchronize</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token function">cudaMemcpyFromSymbol</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>h_factor<span class="token punctuation">,</span> factor<span class="token punctuation">,</span> <span class="token keyword">sizeof</span><span class="token punctuation">(</span><span class="token keyword">float</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> cudaMemcpyDeviceToHost<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token function">printf</span><span class="token punctuation">(</span><span class="token string">"cudaMemcpyFromSymbol: %.2f"</span><span class="token punctuation">,</span>h_factor<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// 第二种通过地址获取值</span>    <span class="token keyword">float</span><span class="token operator">*</span> d_factor<span class="token punctuation">;</span>    <span class="token function">cudaGetSymbolAddress</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token keyword">void</span><span class="token operator">*</span><span class="token operator">*</span><span class="token punctuation">)</span><span class="token operator">&amp;</span>d_factor<span class="token punctuation">,</span> factor<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token function">cudaMemcpy</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>h_factor<span class="token punctuation">,</span> d_factor<span class="token punctuation">,</span> <span class="token keyword">sizeof</span><span class="token punctuation">(</span><span class="token keyword">float</span><span class="token punctuation">)</span><span class="token punctuation">,</span> cudaMemcpyDeviceToHost<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token function">printf</span><span class="token punctuation">(</span><span class="token string">"cudaGetSymbolAddress: %.2f"</span><span class="token punctuation">,</span>h_factor<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token function">cudaDeviceReset</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">return</span> <span class="token number">0</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="缓存和变量作用域"><a href="#缓存和变量作用域" class="headerlink" title="缓存和变量作用域"></a>缓存和变量作用域</h2><p>缓存的特点是访问速度快、容量小。CPU上有一级缓存、二级缓存，GPU上同样有缓存，GPU上的缓存是非可编程存储区域</p><h3 id="缓存类型"><a href="#缓存类型" class="headerlink" title="缓存类型"></a>缓存类型</h3><p>GPU包含4类缓存：</p><ol><li>L1缓存，每个流处理器SM拥有一个</li><li>L2缓存，所有流处理器SM共享一个</li><li>只读常量缓存，每个流处理器SM拥有一个</li><li>只读纹理缓存，每个流处理器SM拥有一个</li></ol><p>L1缓存和L2缓存都可用于存储本地内存和全局内存中的数据，包括寄存器溢出的数据</p><h3 id="变量作用域"><a href="#变量作用域" class="headerlink" title="变量作用域"></a>变量作用域</h3><p>声明的变量在不同修饰符下的存储区域、作用域和生命周期如下图所示。下图中✝表示即可保存标量，又可保存数组</p><p><img src="/images/cuda_imgs/var_scope1.png"></p><p>可对应查看上述介绍不同类型内存的小节。</p><p>下图介绍了上述小节中各个类型内存的细节。<code>ON/OFF CHIP</code>表示是否在片上，<code>CACHED</code>表示是否带有缓存，<code>ACCESS</code>表示读写类型。</p><p><img src="/images/cuda_imgs/var_scope.png"></p>]]></content>
      
      
      <categories>
          
          <category> 编程语言 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> CUDA </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>详解扩散模型DDIM</title>
      <link href="/2024/10/18/suan-fa/xiang-jie-kuo-san-mo-xing-ddim/"/>
      <url>/2024/10/18/suan-fa/xiang-jie-kuo-san-mo-xing-ddim/</url>
      
        <content type="html"><![CDATA[<h1 id="扩散模型DDIM"><a href="#扩散模型DDIM" class="headerlink" title="扩散模型DDIM"></a>扩散模型DDIM</h1><p>之前的文章介绍了扩散模型DDPM算法，但是DDPM算法采样过程很慢，必须要从时间步T开始，一步一步迭代到时间步1（DDPM 的反向过程利用了马尔可夫假设，所以每次都必须在相邻的时间步之间进行去噪，而不能跳过中间步骤。），而时间步T往往非常大，一般是1000，所以这个过程是非常慢的。因此DDIM算法横空出世，来解决DDPM采样过慢的问题。</p><h2 id="DDIM算法原理"><a href="#DDIM算法原理" class="headerlink" title="DDIM算法原理"></a>DDIM算法原理</h2><p>为了加速 DDPM 的采样过程，DDIM 在不利用马尔可夫假设的情况下推导出了扩散的反向过程，最终可以实现仅采样 20～100 步的情况下达到和 DDPM 采样 1000 步相近的生成效果。即提速 10～50 倍。首先来回顾一下DDPM反向去噪过程。</p><h3 id="DDPM的反向去噪过程"><a href="#DDPM的反向去噪过程" class="headerlink" title="DDPM的反向去噪过程"></a>DDPM的反向去噪过程</h3><p>DDPM算法中，我们希望求出反向过程的每一步的真实分布$q(x_{t-1}|x_t)$，但是直接求该分布较为困难，于是DDPM 通过向条件中加入$x_0$，利用贝叶斯公式将该分布转换为已知分布的组合：</p><p>$$\begin{aligned}q(x_{t-1}|x_t,x_0) &amp;&#x3D; \frac{q(x_t,x_0,x_{t-1})}{q(x_t,x_0)} \\ &amp;&#x3D; \frac{q(x_0)q(x_{t-1}|x_0)q(x_t|x_0,x_{t-1})}{q(x_0)q(x_t|x_0)} \\ &amp;&#x3D; q(x_t|x_0,x_{t-1}) \frac{q(x_{t-1}|x_0)}{q(x_t|x_0)} \end{aligned}$$</p><p>在上述等式右侧，$q(x_t|x_0)$和$q(x_{t-1}|x_0)$都是已知的，需要求解的只有$q(x_t|x_0,x_{t-1})$，而DDPM把前向过程和反向过程均看作是马尔可夫链，认为$x_t$只与$x_{t-1}$有关，则$q(x_t|x_0,x_{t-1})$转变为$q(x_t|x_{t-1})$，最终通过一系列推导，得出反向去噪过程的分布为：</p><p>$$q(x_{t-1}|x_t)&#x3D;N(x_{t-1}; \mu_{\theta}(x_t, t), \sigma_t^2I)$$</p><p>通过对DDPM算法的回顾，可以看到DDPM之所以采样很慢，是因为反向过程也看作是一个马尔科夫链，使得去噪只能在相邻时间步之间进行。</p><p>如果可以在不假设反向过程是一个马尔科夫链的情况下推导出$q(x_{t-1}|x_t,x_0)$，就可以将该式子中的$t-1$替换为任意的中间时间步$\tau$，从而实现加速采样。总结来说，DDIM算法优化有两个出发点：</p><ol><li>保持前向过程的分布$q(x_t|x_0) &#x3D; N(x_t; \sqrt{\bar \alpha_t}x_0, (1- \bar \alpha_t)I)$不变。</li><li>在不假设反向过程是一个马尔科夫链的情况下推导出$q(x_\tau|x_t,x_0)$分布。</li></ol><h3 id="DDIM的反向去噪过程"><a href="#DDIM的反向去噪过程" class="headerlink" title="DDIM的反向去噪过程"></a>DDIM的反向去噪过程</h3><p>DDIM算法的目的是推导出$q(x_\tau|x_t,x_0)$，实际就是上述$q(x_{t-1}|x_t,x_0)$，不过因为不再假设反向过程是一个马尔科夫链，所以$t-1$可以替换为任意的$\tau \in (0,t)$，这里用一个通用的符号$\tau \in (0,t)$表示时间步0和t中间的时间步。</p><p>这里推导依然使用 DDPM 的符号约定，${\alpha_t}^T_{t&#x3D;1}&#x3D;1-\beta_t$表示不同时间步要添加的噪声大小；$\bar \alpha_t &#x3D; \prod_{i&#x3D;1}^t \alpha_i$ 表示从$i&#x3D;1$开始的$\alpha_i$累乘。在DDPM中已经推导出后验分布$q(x_{t-1}|x_t,x_0)$是一个高斯分布，其均值和方差为：</p><p>$$\begin{aligned} \mu_t &#x3D; \frac{\sqrt{\alpha_t}(1-\bar\alpha_{t-1})}{1-\bar\alpha_t}x_t + \frac{\sqrt{\bar \alpha_{t-1}}\beta_t}{1-\bar\alpha_t}x_0 \end{aligned}$$</p><p>$$\begin{aligned} \sigma_t &#x3D; \frac{1-\bar\alpha_{t-1}}{1-\bar\alpha_t}\beta_t \end{aligned}$$</p><p>可以看到均值是$x_t$与$x_0$的线性组合，方差是时间步$t$的函数。DDIM 基于这样的规律，使用待定系数法假设$q(x_{\tau}|x_t,x_0)$是一个如下的高斯分布：</p><p>$$q(x_{\tau}|x_t,x_0)&#x3D;N(x_\tau; \lambda x_0+ kx_t, \sigma_t I)$$</p><p>则得到</p><p>$$x_\tau&#x3D;\lambda x_0+ kx_t + \sqrt\sigma_t \epsilon_\tau$$</p><p>又因为前向过程满足$x_t&#x3D;\sqrt{\bar \alpha_t} x_0 + \sqrt{1- \bar\alpha_t} \epsilon_t$，代入上式得到：</p><p>$$\begin{aligned} x_\tau &amp;&#x3D; \lambda x_0+ kx_t + \sqrt\sigma_t \epsilon_\tau \\  &amp;&#x3D; \lambda x_0+ k(\sqrt{\bar \alpha_t} x_0 + \sqrt{1- \bar\alpha_t} \epsilon_t) + \sqrt\sigma_t \epsilon_\tau  \\ &amp;&#x3D; (\lambda+k\sqrt{\bar \alpha_t})x_0+(k\sqrt{1- \bar\alpha_t}\epsilon_t+\sqrt\sigma_t \epsilon_\tau) \\ &amp;&#x3D;(\lambda+k\sqrt{\bar \alpha_t})x_0 + \sqrt{k^2(1-\bar \alpha_t)+\sigma_t}\epsilon_t \end{aligned}$$</p><p>上述的推导过程，由于$\epsilon_t$和$\epsilon_\tau$均服从标准正态分布，由两个相互独立的高斯分布的相加性可知，两项可以合并。又$x_\tau&#x3D;\sqrt{\bar \alpha_\tau} x_0 + \sqrt{1- \bar\alpha_\tau} \epsilon_\tau$，将两个式子的系数对比，可以得到方程组：</p><p>$$\begin{aligned} \lambda+k\sqrt{\bar \alpha_t} &amp;&#x3D; \sqrt{\bar \alpha_\tau} \\ \sqrt{k^2(1-\bar \alpha_t)+\sigma_t} &amp;&#x3D; \sqrt{1- \bar\alpha_\tau} \end{aligned}$$</p><p>解方程组得到$\lambda$和$k$：</p><p>$$\begin{aligned} \lambda &amp;&#x3D; \sqrt{\bar \alpha_\tau}- \sqrt{\frac{(1-\bar \alpha_\tau - \sigma_t)\bar \alpha_t}{1-\bar \alpha_t}}\\ k &amp;&#x3D;  \sqrt{\frac{1-\bar \alpha_\tau - \sigma_t}{1-\bar \alpha_t}} \end{aligned}$$</p><p>由此可以得到$q(x_{\tau}|x_t,x_0)$分布的均值中的两个参数，而方差$\sigma_t$没有唯一确定值，因此该方程组的结果对应于一组解，通过规定不同的方差，可以得到不同的采样过程。</p><p>由前向扩散过程的推导公式可得，$x_0 &#x3D; (x_t - \sqrt{1-\bar \alpha_t}\epsilon_t)&#x2F;\sqrt{\bar \alpha_t}$，将其代入$q(x_{\tau}|x_t,x_0)$分布的均值公式中可得：</p><p>$$\begin{aligned} \mu_t &amp;&#x3D;\lambda x_0+ kx_t \\ &amp;&#x3D;(\sqrt{\bar \alpha_\tau}- \sqrt{\frac{(1-\bar \alpha_\tau - \sigma_t)\bar \alpha_t}{1-\bar \alpha_t}})(\frac{x_t-\sqrt{1-\bar\alpha_t}\epsilon_t}{\sqrt{\bar\alpha_t}}) + \sqrt{\frac{1-\bar \alpha_\tau - \sigma_t}{1-\bar \alpha_t}}x_t \\ &amp;&#x3D;\sqrt {\bar\alpha_\tau}\frac{x_t-\sqrt{1-\bar \alpha_t}\epsilon_t}{\sqrt{\bar \alpha_t}}+\sqrt{1-\bar\alpha_\tau-\sigma_t}\epsilon_t \end{aligned}$$</p><p>则我们可以得到$x_\tau$的表达式：</p><p>$$\begin{aligned} x_\tau &amp;&#x3D; \mu_t + \sqrt{\sigma_t} \epsilon \\ &amp;&#x3D;\sqrt {\bar\alpha_\tau}\frac{x_t-\sqrt{1-\bar \alpha_t}\epsilon_t}{\sqrt{\bar \alpha_t}}+\sqrt{1-\bar\alpha_\tau-\sigma_t}\epsilon_t + \sqrt{\sigma_t} \epsilon\end{aligned}$$</p><p>在DDPM推导中我们得知，我们使用神经网络去估计每一时间步的噪声，上述公式中的$\epsilon_t$其实正是使用神经网络估计的第t时间步的噪声，可以用$\epsilon_\theta(x_t,t)$替换：</p><p><img src="/images/DDIM%E9%87%87%E6%A0%B7%E5%85%AC%E5%BC%8F.png"></p><h3 id="DDIM中的方差"><a href="#DDIM中的方差" class="headerlink" title="DDIM中的方差"></a>DDIM中的方差</h3><p>正如我们前文中所说，我们得到的实际上是$x_\tau$的一组解，其中的$\sigma_t$并没有固定的取值。在论文中，作者参照 DDPM 的方差的形式给出了一个$\sigma_t$的形式：</p><p>$$\begin{aligned} \sigma_t&#x3D;\eta\sqrt{\frac{1-\bar\alpha_\tau}{1-\bar\alpha_t}}\sqrt{1-\alpha_t} \end{aligned}$$</p><ol><li>当$\eta&#x3D;1$时，生成过程与 DDPM 一致。</li><li>当$\eta&#x3D;0$时，此时生成过程不再添加随机噪声项，唯一带有随机性的因素就是采样初始的$x_T \sim N(0,1)$，因此采样的过程是确定的，每个$x_T$对应唯一的$x_0$。该算法就是DDIM（Denoising Diffusion Implicit Models）算法。</li></ol><h2 id="DDIM加速采样"><a href="#DDIM加速采样" class="headerlink" title="DDIM加速采样"></a>DDIM加速采样</h2><p>由于在DDIM算法中不再将反向去噪过程看作马尔科夫链，因此去噪的过程并不需要在相邻的时间步之间进行，也就是跳过一些中间的步骤。</p><p>DDPM算法的采样时间步为$[T,T-1,…,2,1]$，而DDIM算法的采样时间步可以直接从$[T,T-1,…,2,1]$中抽取一个子序列：$[\tau_s, \tau_{s-1},…,\tau_2,\tau_1]$。</p>]]></content>
      
      
      <categories>
          
          <category> 算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 算法知识 </tag>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>C++|C++中的多态和虚函数</title>
      <link href="/2024/08/16/c-zhi-shi/c-zhong-de-duo-tai-he-xu-han-shu/"/>
      <url>/2024/08/16/c-zhi-shi/c-zhong-de-duo-tai-he-xu-han-shu/</url>
      
        <content type="html"><![CDATA[<h1 id="C-中的多态和虚函数"><a href="#C-中的多态和虚函数" class="headerlink" title="C++中的多态和虚函数"></a>C++中的多态和虚函数</h1><h2 id="多态"><a href="#多态" class="headerlink" title="多态"></a>多态</h2><p><strong>多态</strong>（Polymorphism）按字面的意思就是某个事物有多种形态，当类之间存在层次结构，并且类之间是通过继承关联时，就会用到多态。</p><p>C++ 中，多态是面向对象编程的重要特性之一。<strong>多态允许使用基类指针或引用来调用子类的重写方法</strong>，从而使得同一接口可以表现不同的行为。多态使得代码更加灵活和通用，程序可以通过基类指针或引用来操作不同类型的对象，而不需要显式区分对象类型。这样可以使代码更具扩展性，在增加新的形状类时不需要修改主程序。</p><p>我们编写如下代码，这是一个普通的关于继承的代码，类Player继承了类Entity，且类Player重写了父类Entity的GetName()方法。</p><pre class="line-numbers language-cpp"><code class="language-cpp"><span class="token keyword">class</span> <span class="token class-name">Entity</span><span class="token punctuation">{</span><span class="token keyword">public</span><span class="token operator">:</span>    std<span class="token operator">::</span>string <span class="token function">GetName</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">{</span>        <span class="token keyword">return</span> <span class="token string">"Entity"</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token punctuation">;</span><span class="token keyword">class</span> <span class="token class-name">Player</span><span class="token operator">:</span> <span class="token keyword">public</span> Entity<span class="token punctuation">{</span><span class="token keyword">private</span><span class="token operator">:</span>    std<span class="token operator">::</span>string m_Name<span class="token punctuation">;</span><span class="token keyword">public</span><span class="token operator">:</span>    <span class="token function">Player</span><span class="token punctuation">(</span><span class="token keyword">const</span> std<span class="token operator">::</span>string<span class="token operator">&amp;</span> name<span class="token punctuation">)</span><span class="token punctuation">{</span>        m_Name <span class="token operator">=</span> name<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    std<span class="token operator">::</span>string <span class="token function">GetName</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">{</span>        <span class="token keyword">return</span> m_Name<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token punctuation">}</span>；<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>使用如下方式调用，输出分别为“Entity”和“Cherno”，这是我们期望的正常结果。</p><pre class="line-numbers language-cpp"><code class="language-cpp"><span class="token keyword">int</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">{</span>    Entity<span class="token operator">*</span> e <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token function">Entity</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    std<span class="token operator">::</span>cout <span class="token operator">&lt;&lt;</span> e<span class="token operator">-</span><span class="token operator">></span><span class="token function">GetName</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&lt;&lt;</span> std<span class="token operator">::</span>endl<span class="token punctuation">;</span> <span class="token comment" spellcheck="true">// Entity</span>    Player<span class="token operator">*</span> p <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token function">Player</span><span class="token punctuation">(</span><span class="token string">"Cherno"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    std<span class="token operator">::</span>cout <span class="token operator">&lt;&lt;</span> p<span class="token operator">-</span><span class="token operator">></span><span class="token function">GetName</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&lt;&lt;</span> std<span class="token operator">::</span>endl<span class="token punctuation">;</span> <span class="token comment" spellcheck="true">// Cherno</span>    <span class="token keyword">return</span> <span class="token number">0</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>如果我们使用多态的方式调用，即当父类Entity的指针指向了子类Player时，就会遇到问题：最后的输出为“Entity”。这不是我们期望的，我们希望是由Player调用GetName()，即使是父类Entity的指针，但实际上它是指向Player实例对象。</p><pre class="line-numbers language-cpp"><code class="language-cpp"><span class="token keyword">int</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">{</span>    Entity<span class="token operator">*</span> e <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token function">Entity</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    std<span class="token operator">::</span>cout <span class="token operator">&lt;&lt;</span> e<span class="token operator">-</span><span class="token operator">></span><span class="token function">GetName</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&lt;&lt;</span> std<span class="token operator">::</span>endl<span class="token punctuation">;</span> <span class="token comment" spellcheck="true">// Entity</span>    Player<span class="token operator">*</span> p <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token function">Player</span><span class="token punctuation">(</span><span class="token string">"Cherno"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    std<span class="token operator">::</span>cout <span class="token operator">&lt;&lt;</span> p<span class="token operator">-</span><span class="token operator">></span><span class="token function">GetName</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&lt;&lt;</span> std<span class="token operator">::</span>endl<span class="token punctuation">;</span> <span class="token comment" spellcheck="true">// Cherno</span>    <span class="token comment" spellcheck="true">// 多态</span>    Entity<span class="token operator">*</span> entity <span class="token operator">=</span> p<span class="token punctuation">;</span>    std<span class="token operator">::</span>cout <span class="token operator">&lt;&lt;</span> entity<span class="token operator">-</span><span class="token operator">></span><span class="token function">GetName</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&lt;&lt;</span> std<span class="token operator">::</span>endl<span class="token punctuation">;</span> <span class="token comment" spellcheck="true">// Entity</span>    <span class="token keyword">return</span> <span class="token number">0</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>为什么会出现这种情况？这是因为使用了父类Entity的指针，当调用GetName()时，它会先去Entity找这个函数。但是我们希望C++ 能够意识到，虽然使用了父类Entity的指针，但我们实际使用的是Player对象，所以应该调用Player的GetName()。</p><p>这就引出了虚函数。</p><h2 id="虚函数"><a href="#虚函数" class="headerlink" title="虚函数"></a>虚函数</h2><p>虚函数是指加了<code>virtual</code>修饰符的类的成员函数，<code>virtual</code>关键字只能出现在类内部的函数声明中，不能用于类外部的函数定义。如下所示：</p><pre class="line-numbers language-cpp"><code class="language-cpp"><span class="token keyword">class</span> <span class="token class-name">Entity</span><span class="token punctuation">{</span><span class="token keyword">public</span><span class="token operator">:</span>    <span class="token keyword">virtual</span> std<span class="token operator">::</span>string <span class="token function">GetName</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">{</span> <span class="token comment" spellcheck="true">//标记为virtual</span>        <span class="token keyword">return</span> <span class="token string">"Entity"</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>虽然只加了一个关键词<code>virtual</code>，但此时使用前文多态的方式调用，即可得到我们期望的结果：</p><pre class="line-numbers language-cpp"><code class="language-cpp"><span class="token keyword">int</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">{</span>    Entity<span class="token operator">*</span> e <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token function">Entity</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    std<span class="token operator">::</span>cout <span class="token operator">&lt;&lt;</span> e<span class="token operator">-</span><span class="token operator">></span><span class="token function">GetName</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&lt;&lt;</span> std<span class="token operator">::</span>endl<span class="token punctuation">;</span> <span class="token comment" spellcheck="true">// Entity</span>    Player<span class="token operator">*</span> p <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token function">Player</span><span class="token punctuation">(</span><span class="token string">"Cherno"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    std<span class="token operator">::</span>cout <span class="token operator">&lt;&lt;</span> p<span class="token operator">-</span><span class="token operator">></span><span class="token function">GetName</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&lt;&lt;</span> std<span class="token operator">::</span>endl<span class="token punctuation">;</span> <span class="token comment" spellcheck="true">// Cherno</span>    <span class="token comment" spellcheck="true">// 多态</span>    Entity<span class="token operator">*</span> entity <span class="token operator">=</span> p<span class="token punctuation">;</span>    std<span class="token operator">::</span>cout <span class="token operator">&lt;&lt;</span> entity<span class="token operator">-</span><span class="token operator">></span><span class="token function">GetName</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&lt;&lt;</span> std<span class="token operator">::</span>endl<span class="token punctuation">;</span> <span class="token comment" spellcheck="true">// Cherno</span>    <span class="token keyword">return</span> <span class="token number">0</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>在C++11之后，可以将被重写的子类方法标记为<code>override</code>，但这不是必需的：</p><pre class="line-numbers language-cpp"><code class="language-cpp"><span class="token keyword">class</span> <span class="token class-name">Entity</span><span class="token punctuation">{</span><span class="token keyword">public</span><span class="token operator">:</span>    <span class="token keyword">virtual</span> std<span class="token operator">::</span>string <span class="token function">GetName</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">{</span>        <span class="token keyword">return</span> <span class="token string">"Entity"</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token punctuation">;</span><span class="token keyword">class</span> <span class="token class-name">Player</span><span class="token operator">:</span> <span class="token keyword">public</span> Entity<span class="token punctuation">{</span><span class="token keyword">private</span><span class="token operator">:</span>    std<span class="token operator">::</span>string m_Name<span class="token punctuation">;</span><span class="token keyword">public</span><span class="token operator">:</span>    <span class="token function">Player</span><span class="token punctuation">(</span><span class="token keyword">const</span> std<span class="token operator">::</span>string<span class="token operator">&amp;</span> name<span class="token punctuation">)</span><span class="token punctuation">{</span>        m_Name <span class="token operator">=</span> name<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    std<span class="token operator">::</span>string <span class="token function">GetName</span><span class="token punctuation">(</span><span class="token punctuation">)</span> override <span class="token punctuation">{</span> <span class="token comment" spellcheck="true">// 标记为override</span>        <span class="token keyword">return</span> m_Name<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token punctuation">}</span>；<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="多态的实现机制"><a href="#多态的实现机制" class="headerlink" title="多态的实现机制"></a>多态的实现机制</h3><ul><li>虚函数表（V-Table）：C++运行时使用虚函数表来实现多态。每个包含虚函数的类都有一个虚函数表，表中存储了指向类中所有虚函数的指针。</li><li>虚函数指针（V-Ptr）：对象中包含一个指向该类的虚函数表的指针。</li></ul><p>虚函数表使得我们在运行时，可以找到正确的重写函数，实现多态。即如果要重写子类的方法，需要将父类的函数标记为虚函数，</p><p>虚函数允许我们在子类中重写方法，但是这是有额外开销的：首先，需要额外的内存来存储虚函数表和虚函数指针；其次，每次调用虚函数时，需要遍历虚函数表方便找到正确的函数。</p><p><strong>注意事项</strong>：</p><ul><li>只有通过基类的指针或引用调用虚函数时，才会发生多态。</li><li>如果直接使用派生类的对象调用函数，那么调用的是派生类中的版本，而不是基类中的版本。（如多态一节的代码结果）</li></ul><h2 id="纯虚函数"><a href="#纯虚函数" class="headerlink" title="纯虚函数"></a>纯虚函数</h2><p>纯虚函数是一种特殊的虚函数，其与Java中的抽象方法或接口类似。纯虚函数允许在基类中定义一个没有实现的函数，然后强制子类去实现该函数。</p><p>纯虚函数没有函数体，声明时使用<code>函数名() = 0</code>。一个包含纯虚函数的类被称为抽象类（Abstract Class），因为类内方法没有实现，所以它<strong>不可能被直接实例化</strong>。必须要重写基类的纯虚函数。</p><pre class="line-numbers language-cpp"><code class="language-cpp"><span class="token keyword">class</span> <span class="token class-name">Entity</span><span class="token punctuation">{</span> <span class="token comment" spellcheck="true">// 抽象类</span><span class="token keyword">public</span><span class="token operator">:</span>    <span class="token keyword">virtual</span> std<span class="token operator">::</span>string <span class="token function">GetName</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> <span class="token comment" spellcheck="true">// 纯虚函数</span><span class="token punctuation">}</span><span class="token punctuation">;</span><span class="token keyword">class</span> <span class="token class-name">Player</span><span class="token operator">:</span> <span class="token keyword">public</span> Entity<span class="token punctuation">{</span><span class="token keyword">private</span><span class="token operator">:</span>    std<span class="token operator">::</span>string m_Name<span class="token punctuation">;</span><span class="token keyword">public</span><span class="token operator">:</span>    <span class="token function">Player</span><span class="token punctuation">(</span><span class="token keyword">const</span> std<span class="token operator">::</span>string<span class="token operator">&amp;</span> name<span class="token punctuation">)</span><span class="token punctuation">{</span>        m_Name <span class="token operator">=</span> name<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    std<span class="token operator">::</span>string <span class="token function">GetName</span><span class="token punctuation">(</span><span class="token punctuation">)</span> override <span class="token punctuation">{</span> <span class="token comment" spellcheck="true">// 标记为override</span>        <span class="token keyword">return</span> m_Name<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token punctuation">}</span>；<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>我们通过如下方式调用：</p><pre class="line-numbers language-cpp"><code class="language-cpp"><span class="token keyword">void</span> <span class="token function">Print</span><span class="token punctuation">(</span>Entity<span class="token operator">*</span> obj<span class="token punctuation">)</span><span class="token punctuation">{</span>    std<span class="token operator">::</span>cout <span class="token operator">&lt;&lt;</span> obj<span class="token operator">-</span><span class="token operator">></span><span class="token function">GetName</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&lt;&lt;</span> std<span class="token operator">::</span>endl<span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token keyword">int</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">{</span>     Entity<span class="token operator">*</span> entity <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token function">Player</span><span class="token punctuation">(</span><span class="token string">"Cherno"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token function">Print</span><span class="token punctuation">(</span>entity<span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment" spellcheck="true">// Cherno</span>    <span class="token keyword">return</span> <span class="token number">0</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="虚析构函数"><a href="#虚析构函数" class="headerlink" title="虚析构函数"></a>虚析构函数</h2><p>析构函数是在对象销毁时运行，当对象生命周期结束被销毁时，将调用析构函数。该函数主要用于清理内存，同时适用于栈内存和堆内存。而虚析构函数，顾名思义是虚函数和析构函数的组合。</p><p>虚析构函数是用于处理多态为问题的，如下面的代码，当执行<code>delete entity</code>，调用了基类Entity的析构函数，只是销毁Entity指针（在栈上）；而子类Player对象（在堆上）还没有释放，这就会导致内存泄露。</p><pre class="line-numbers language-cpp"><code class="language-cpp"><span class="token keyword">int</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">{</span>     Entity<span class="token operator">*</span> entity <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token function">Player</span><span class="token punctuation">(</span><span class="token string">"Cherno"</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment" spellcheck="true">//多态</span>    <span class="token keyword">delete</span> entity<span class="token punctuation">;</span> <span class="token comment" spellcheck="true">// 这里销毁Entity指针，但是没有释放Player对象</span>    <span class="token keyword">return</span> <span class="token number">0</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>这时需要虚析构函数。</p><p>虚析构函数即在析构函数前加<code>virtual</code>关键字，但是它和普通虚函数不同，<strong>不是去覆写析构函数，而是再加上一个析构函数</strong>。即，如果基类的析构函数改为虚函数，实际会调用两个析构函数，先调用子类的，再调用基类的。</p><pre class="line-numbers language-cpp"><code class="language-cpp"><span class="token keyword">class</span> <span class="token class-name">Entity</span><span class="token punctuation">{</span><span class="token keyword">public</span><span class="token operator">:</span>    <span class="token function">Entity</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">{</span>        std<span class="token operator">::</span>cout <span class="token operator">&lt;&lt;</span> <span class="token string">"Entity constructed"</span> <span class="token operator">&lt;&lt;</span> std<span class="token operator">::</span>endl<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">virtual</span> <span class="token operator">~</span><span class="token function">Entity</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">{</span>        std<span class="token operator">::</span>cout <span class="token operator">&lt;&lt;</span> <span class="token string">"Entity destroyed"</span> <span class="token operator">&lt;&lt;</span> std<span class="token operator">::</span>endl<span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token punctuation">;</span><span class="token keyword">class</span> <span class="token class-name">Player</span><span class="token operator">:</span> <span class="token keyword">public</span> Entity<span class="token punctuation">{</span><span class="token keyword">public</span><span class="token operator">:</span>    <span class="token function">Player</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">{</span>        std<span class="token operator">::</span>cout <span class="token operator">&lt;&lt;</span> <span class="token string">"Player constructed"</span> <span class="token operator">&lt;&lt;</span> std<span class="token operator">::</span>endl<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token operator">~</span><span class="token function">Player</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">{</span>        std<span class="token operator">::</span>cout <span class="token operator">&lt;&lt;</span> <span class="token string">"Player destroyed"</span> <span class="token operator">&lt;&lt;</span> std<span class="token operator">::</span>endl<span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span>；<span class="token keyword">int</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">{</span>     Entity<span class="token operator">*</span> entity <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token function">Player</span><span class="token punctuation">(</span><span class="token string">"Cherno"</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment" spellcheck="true">//多态</span>    <span class="token keyword">delete</span> entity<span class="token punctuation">;</span>     <span class="token keyword">return</span> <span class="token number">0</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token comment" spellcheck="true">// 输出</span><span class="token comment" spellcheck="true">// Entity constructed</span><span class="token comment" spellcheck="true">// Player constructed</span><span class="token comment" spellcheck="true">// Player destroyed</span><span class="token comment" spellcheck="true">// Entity destroyed</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> 编程语言 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> C++ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>C++|C++中的static</title>
      <link href="/2024/08/06/c-zhi-shi/static-yong-fa/"/>
      <url>/2024/08/06/c-zhi-shi/static-yong-fa/</url>
      
        <content type="html"><![CDATA[<h1 id="C-中的static"><a href="#C-中的static" class="headerlink" title="C++中的static"></a>C++中的static</h1><p>C++中的static有两种用法：一种是在类或结构体<strong>外部</strong>使用static关键字；第二种是在类或结构体<strong>内部</strong>使用static关键字。</p><ol><li>类或结构体<strong>外部</strong>使用：声明为static的符号，只是在编译单元内部进行链接，即只对定义该符号的编译单元可见。</li><li>类或结构体<strong>内部</strong>使用：声明为static的符号，将被该类的所有实例对象共享内存</li></ol><h2 id="外部使用的static"><a href="#外部使用的static" class="headerlink" title="外部使用的static"></a>外部使用的static</h2><h3 id="问题起源"><a href="#问题起源" class="headerlink" title="问题起源"></a>问题起源</h3><p>如果我们在main.cpp中定义一个变量<code>s_var</code>，同时在另一个a.cpp中定义同名变量（值得注意的是，这是一个全局声明的变量），如下所示：</p><pre class="line-numbers language-cpp"><code class="language-cpp"><span class="token comment" spellcheck="true">// main.cpp</span><span class="token macro property">#<span class="token directive keyword">include</span> <span class="token string">&lt;iostream></span></span><span class="token keyword">int</span> s_var <span class="token operator">=</span> <span class="token number">10</span><span class="token punctuation">;</span><span class="token keyword">int</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">{</span>    std<span class="token operator">::</span>cout <span class="token operator">&lt;&lt;</span> s_var <span class="token operator">&lt;&lt;</span> std<span class="token operator">::</span>endl<span class="token punctuation">;</span>    <span class="token keyword">return</span> <span class="token number">0</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token comment" spellcheck="true">// a.cpp</span><span class="token keyword">int</span> s_var <span class="token operator">=</span> <span class="token number">10</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>此时编译并链接main.cpp和a.cpp，则会报一个链接错误：s_var已经在main.cpp中被定义了。编译器告诉我们不能有两个同名的全局变量，所以编译器报错了。</p><h3 id="static全局使用"><a href="#static全局使用" class="headerlink" title="static全局使用"></a>static全局使用</h3><p>但是如果我们在a.cpp中把<code>s_var</code>声明为static变量，则可以编译通过，程序输出为10 ，这意味着<code>s_var</code>变量只在a.cpp中进行链接，</p><pre class="line-numbers language-cpp"><code class="language-cpp"><span class="token comment" spellcheck="true">// a.cpp</span><span class="token keyword">static</span> <span class="token keyword">int</span> s_var <span class="token operator">=</span> <span class="token number">5</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>这种方式类似于在类中声明一个私有变量，其他所有翻译单元都不能看到<code>s_var</code>这个变量。这里以变量举例，实际上声明函数为static，也有相似的效果。</p><p>总结：全局情况下，如果声明的变量或函数没有被static修饰，则链接器会跨编译单元进行链接，而static修饰的变量或函数则只会在被定义的编译单元内链接。</p><h3 id="static局部使用"><a href="#static局部使用" class="headerlink" title="static局部使用"></a>static局部使用</h3><p>静态局部变量允许我们声明一个变量，它的<strong>生命周期是整个程序的生命周期，但是其作用域被限制在局部范围内</strong>。</p><p>如下代码所示，在函数func内部定义了变量i，当第一次调用函数func()时，变量i会被初始化为0，后续函数调用时，则不会创建新的变量，而是直接使用。</p><pre class="line-numbers language-cpp"><code class="language-cpp"><span class="token macro property">#<span class="token directive keyword">include</span> <span class="token string">&lt;iostream></span></span><span class="token keyword">void</span> <span class="token function">func</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">{</span>    <span class="token keyword">static</span> <span class="token keyword">int</span> i<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">;</span>    i<span class="token operator">++</span><span class="token punctuation">;</span>    std<span class="token operator">::</span>cout <span class="token operator">&lt;&lt;</span> i <span class="token operator">&lt;&lt;</span> std<span class="token operator">::</span>endl<span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token keyword">int</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">{</span>    <span class="token function">func</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//输出 1</span>    <span class="token function">func</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//输出 2</span>    <span class="token function">func</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//输出 3</span>    <span class="token function">func</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//输出 4</span>    <span class="token function">func</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//输出 5</span>    <span class="token keyword">return</span> <span class="token number">0</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>可以通过静态局部变量这种方式，实现一个单例模式：</p><pre class="line-numbers language-cpp"><code class="language-cpp"><span class="token keyword">class</span> <span class="token class-name">Singleton</span><span class="token punctuation">{</span><span class="token keyword">public</span><span class="token operator">:</span>    <span class="token keyword">static</span> Singleton<span class="token operator">&amp;</span> <span class="token function">Get</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">{</span>        <span class="token keyword">static</span> Singleton instance<span class="token punctuation">;</span>        <span class="token keyword">return</span> instance<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">void</span> <span class="token function">Hello</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">{</span><span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token punctuation">;</span><span class="token keyword">int</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">{</span>    Singleton<span class="token operator">::</span><span class="token function">Get</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">Hello</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">return</span> <span class="token number">0</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="类和结构体中的static"><a href="#类和结构体中的static" class="headerlink" title="类和结构体中的static"></a>类和结构体中的static</h2><p>在类或结构体内声明为static的变量，将被该类的所有实例对象共享该变量，即该类的所有实例对象中，该变量只有一个，是内存共享的。类内声明为static的方法也是类似。</p><p>故通过类的实例对象引用static变量或方法是无意义的，可以通过类来引用，如下代码<code>Entity::var</code>或<code>Entity::func()</code>。</p><pre class="line-numbers language-cpp"><code class="language-cpp"><span class="token macro property">#<span class="token directive keyword">include</span> <span class="token string">&lt;iostream></span></span><span class="token keyword">struct</span> Entity<span class="token punctuation">{</span>    <span class="token keyword">static</span> <span class="token keyword">int</span> x<span class="token punctuation">,</span>y<span class="token punctuation">;</span>      <span class="token keyword">void</span> <span class="token function">Print</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">{</span>        std<span class="token operator">::</span>cout <span class="token operator">&lt;&lt;</span> x <span class="token operator">&lt;&lt;</span> <span class="token string">","</span> <span class="token operator">&lt;&lt;</span> y <span class="token operator">&lt;&lt;</span> std<span class="token operator">::</span>endl<span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token punctuation">;</span><span class="token keyword">int</span> Entity<span class="token operator">::</span>x<span class="token punctuation">;</span><span class="token keyword">int</span> Entity<span class="token operator">::</span>y<span class="token punctuation">;</span><span class="token keyword">int</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">{</span>    Entity e<span class="token punctuation">;</span>    e<span class="token punctuation">.</span>x<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">;</span> <span class="token comment" spellcheck="true">//等价于Entity::x</span>    e<span class="token punctuation">.</span>y<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">;</span> <span class="token comment" spellcheck="true">//等价于Entity::y</span>    Entity e1<span class="token punctuation">;</span>    e1<span class="token punctuation">.</span>x<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">;</span>    e1<span class="token punctuation">.</span>y<span class="token operator">=</span><span class="token number">8</span><span class="token punctuation">;</span>       e<span class="token punctuation">.</span><span class="token function">Print</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment" spellcheck="true">//输出 5,8</span>    e1<span class="token punctuation">.</span><span class="token function">Print</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//输出 5,8</span>    <span class="token keyword">return</span> <span class="token number">0</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>可以看到，程序输出两次都是“5,8”，对应我们上面所述：类的<strong>所有实例对象共享静态变量（static修饰）</strong>，上面代码是将同一个静态变量x和y输出了两次。实例对象e将静态变量x和y设置为2和3，但是e1又将x和y设置为5和8，因此最终两次输出均为5和8。</p><p>当类内的方法被static修饰，<strong>静态方法是不能访问非静态变量的</strong>，如下代码。这是因为静态方法没有类实例对象，这里涉及类的运行原理：类中每个非静态方法被调用时，会获得当前类的一个实例对象作为参数。因此静态方法没有实例对象作为参数，就找不到该对象的非静态变量的位置，自然无法访问。</p><pre class="line-numbers language-cpp"><code class="language-cpp"><span class="token macro property">#<span class="token directive keyword">include</span> <span class="token string">&lt;iostream></span></span><span class="token keyword">struct</span> Entity<span class="token punctuation">{</span>    <span class="token keyword">int</span> x<span class="token punctuation">,</span>y<span class="token punctuation">;</span>      <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">Print</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">{</span>        std<span class="token operator">::</span>cout <span class="token operator">&lt;&lt;</span> x <span class="token operator">&lt;&lt;</span> <span class="token string">","</span> <span class="token operator">&lt;&lt;</span> y <span class="token operator">&lt;&lt;</span> std<span class="token operator">::</span>endl<span class="token punctuation">;</span> <span class="token comment" spellcheck="true">// 编译报错</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token punctuation">;</span><span class="token keyword">int</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">{</span>    Entity e<span class="token punctuation">;</span>    e<span class="token punctuation">.</span>x<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">;</span>     e<span class="token punctuation">.</span>y<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">;</span>     Entity e1<span class="token punctuation">;</span>    e1<span class="token punctuation">.</span>x<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">;</span>    e1<span class="token punctuation">.</span>y<span class="token operator">=</span><span class="token number">8</span><span class="token punctuation">;</span>       Entity<span class="token operator">::</span><span class="token function">Print</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>     Entity<span class="token operator">::</span><span class="token function">Print</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">return</span> <span class="token number">0</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>类内部的静态变量，通过这种方式可以实现一个单例模式：</p><pre class="line-numbers language-cpp"><code class="language-cpp"><span class="token keyword">class</span> <span class="token class-name">Singleton</span><span class="token punctuation">{</span><span class="token keyword">private</span><span class="token operator">:</span>    <span class="token keyword">static</span> Singleton<span class="token operator">*</span> instance<span class="token punctuation">;</span><span class="token keyword">public</span><span class="token operator">:</span>    <span class="token keyword">static</span> Singleton<span class="token operator">&amp;</span> <span class="token function">Get</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">{</span>        <span class="token keyword">return</span> <span class="token operator">*</span>instance<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">void</span> <span class="token function">Hello</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">{</span><span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token punctuation">;</span>Singleton<span class="token operator">*</span> Singleton<span class="token operator">::</span>instance <span class="token operator">=</span> <span class="token keyword">nullptr</span><span class="token punctuation">;</span><span class="token keyword">int</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">{</span>    Singleton<span class="token operator">::</span><span class="token function">Get</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">Hello</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">return</span> <span class="token number">0</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> 编程语言 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> C++ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Python多进程的注意事项</title>
      <link href="/2024/07/11/python-zhi-shi/python-duo-jin-cheng-de-zhu-yi-shi-xiang/"/>
      <url>/2024/07/11/python-zhi-shi/python-duo-jin-cheng-de-zhu-yi-shi-xiang/</url>
      
        <content type="html"><![CDATA[<h1 id="Python多进程注意事项"><a href="#Python多进程注意事项" class="headerlink" title="Python多进程注意事项"></a>Python多进程注意事项</h1><h2 id="主进程函数最好写在程序入口内"><a href="#主进程函数最好写在程序入口内" class="headerlink" title="主进程函数最好写在程序入口内"></a>主进程函数最好写在程序入口内</h2><p>看下面的例子</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> multiprocessing <span class="token keyword">import</span> Process<span class="token comment" spellcheck="true"># 这里是子进程调用的函数</span><span class="token keyword">def</span> <span class="token function">function1</span><span class="token punctuation">(</span>id<span class="token punctuation">)</span><span class="token punctuation">:</span>      <span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">'id {id}'</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 这里是主进程调用函数</span><span class="token keyword">def</span> <span class="token function">run__process</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>      process <span class="token operator">=</span> <span class="token punctuation">[</span>mp<span class="token punctuation">.</span>Process<span class="token punctuation">(</span>target<span class="token operator">=</span>function1<span class="token punctuation">,</span> args<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>               mp<span class="token punctuation">.</span>Process<span class="token punctuation">(</span>target<span class="token operator">=</span>function1<span class="token punctuation">,</span> args<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">]</span>    <span class="token comment" spellcheck="true"># 开启了两个进程</span>    <span class="token punctuation">[</span>p<span class="token punctuation">.</span>start<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">for</span> p <span class="token keyword">in</span> process<span class="token punctuation">]</span>    <span class="token comment" spellcheck="true"># 等待两个进程依次结束</span>    <span class="token punctuation">[</span>p<span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">for</span> p <span class="token keyword">in</span> process<span class="token punctuation">]</span>   <span class="token comment" spellcheck="true"># 主进程函数调用不建议写在if外部。当然你强行这么做可能不会报错</span><span class="token comment" spellcheck="true"># run__process()  </span><span class="token keyword">if</span> __name__ <span class="token operator">==</span><span class="token string">'__main__'</span><span class="token punctuation">:</span>    <span class="token comment" spellcheck="true"># 正确做法：写在if内部</span>    run__process<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>在这个简单的例子里，把主进程函数<code>run__process()</code>写在程序入口外部可能不会报错，但是最好还是按照正确写法去做。因为<code>multiprocessing</code>模块通过主进程创建多个新的Python子进程来运行，如果没有写在<code>if __name__ ==&#39;__main__&#39;:</code>里，则该段程序会进入一个永无止境的创建新进程的循环：</p><blockquote><p>主进程运行run__process()生成 2 个子进程。</p><p>这2个子进程依次导入模块，并在导入过程中运行run__process()，导致多进程产生4个新进程。</p><p>这4个新进程依次导入模块，并在导入过程中运行run__process()，从而导致启动8个新进程。</p><p>……</p></blockquote><p>而写在程序入口内部则不会有这种问题。因为<code>if __name__ ==&#39;__main__&#39;:</code>是一种保护机制，即当该Python文件被其他进程调用时，不会执行入口<code>if __name__ ==&#39;__main__&#39;:</code>内的代码，而不在入口内部的代码则会被执行。正如上面的代码，在多进程中主进程创建子进程时，本质是自己在调用自己，子进程会导入该Python文件（即导入自身），由于有程序入口<code>if __name__ ==&#39;__main__&#39;:</code>，创建的子进程不会执行入口内的<code>run__process</code>，避免陷入创建进程的死循环。</p><h2 id="两种创建进程的方式"><a href="#两种创建进程的方式" class="headerlink" title="两种创建进程的方式"></a>两种创建进程的方式</h2><p>Python的两种创建进程的方式</p><ul><li><strong>fork</strong>：会直接复制一份自己给子进程运行，并把自己所有资源的handle都让子进程继承，因而创建速度很快，但更占用内存资源。</li><li><strong>spawn</strong>：只会把必要的资源的handle交给子进程，因此创建速度稍慢。</li></ul><pre class="line-numbers language-python"><code class="language-python">multiprocessing<span class="token punctuation">.</span>set_start_method<span class="token punctuation">(</span><span class="token string">'spawn'</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># default on WinOS or MacOS</span>multiprocessing<span class="token punctuation">.</span>set_start_method<span class="token punctuation">(</span><span class="token string">'fork'</span><span class="token punctuation">)</span>   <span class="token comment" spellcheck="true"># default on Linux (UnixOS)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>使用<code>fork()</code> 生成新进程，这样做有两个<strong>好处</strong>：</p><ol><li>子进程可以看到主程序中的所有数据结构。它们实际上是把主程序的数据复制了一份，在数据<strong>副本</strong>上工作。</li><li>子进程从主程序中<code>fork()</code>之后的指令开始执行，因此模块中已执行的任何模块级代码都不会再被执行。</li></ol><p>在 Windows 中无法执行<code>fork()</code>，因此在Windows中，每个子进程都要重新导入每个模块。所以</p><ol><li>在 Windows 系统中，子进程看不到主程序中的任何数据结构；</li><li>所有模块级代码都在每个子进程中执行。（<strong>因此主进程调用函数一定要写在程序入口内部，而不是写在外面成为模块级代码被子进程执行</strong>）</li></ol>]]></content>
      
      
      <categories>
          
          <category> 编程语言 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 基础知识 </tag>
            
            <tag> 进程和线程 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>C++手撕GPT2|交叉熵损失</title>
      <link href="/2024/04/18/suan-fa/c-shou-si-gpt2-jiao-cha-shang-sun-shi/"/>
      <url>/2024/04/18/suan-fa/c-shou-si-gpt2-jiao-cha-shang-sun-shi/</url>
      
        <content type="html"><![CDATA[<h1 id="C-手撕GPT2-交叉熵损失"><a href="#C-手撕GPT2-交叉熵损失" class="headerlink" title="C++手撕GPT2|交叉熵损失"></a>C++手撕GPT2|交叉熵损失</h1><p>Karpathy大佬（OpenAI创始人之一）用1000行纯C语言实现了GPT2模型，认真拜读了其代码，受益匪浅。因此想使用C++来复刻，以向大佬致敬。当然使用基于Numpy的Python来实现会更简单，使用C++是想以此来练手，重点是理解GPT2的模型结构、前向流和梯度反向过程。手撕GPT2是基于C++实现，以vector作为数据容器。</p><p>本文是<strong>C++手撕GPT2系列</strong>的第一篇：实现交叉熵损失函数的前向和反向过程。</p><h2 id="交叉熵损失简单回顾"><a href="#交叉熵损失简单回顾" class="headerlink" title="交叉熵损失简单回顾"></a>交叉熵损失简单回顾</h2><p>交叉熵损失是分类问题中最常用的损失函数。模型输出的数据$X &#x3D; {x_1,x_2,…,x_N}$经过softmax转换为归属每一类的概率，所有类别的概率和为1。</p><p>$$\begin{aligned} Prob_i &amp;&#x3D; \frac{e^{x_i}}{\sum_{i&#x3D;1}^N e^{x_i}} \\ Loss &amp;&#x3D; -log Prob_i \\ &amp;&#x3D; -log\frac{e^{x_i}}{\sum_{i&#x3D;1}^N e^{x_i}}\end{aligned}$$</p><p>其中，$Prob_i$表示归属于第$i$类的概率；$Loss$即为交叉熵损失，其只对归属与目标类别的概率计算对数（如目标类别为第k类，则loss计算为$-logProb_k$。</p><p>交叉熵损失$Loss$对模型输出数据$X$的导数算需要分两部分完成，对于目标类别$x_k$的导数：</p><p>$$\begin{aligned} \frac{\partial Loss}{\partial x_k} &amp;&#x3D; - \frac{\sum_{i&#x3D;1}^N e^{x_i}}{e^{x_k}} \frac{e^{x_k} \sum_{i&#x3D;1}^N e^{x_i} - e^{x_k} e^{x_k}}{(\sum_{i&#x3D;1}^N e^{x_i})^2} \\ &amp;&#x3D; -\frac{e^{x_k} \sum_{i&#x3D;1}^N e^{x_i}  - e^{x_k} e^{x_k}}{e^{x_k} \sum_{i&#x3D;1}^N e^{x_i}} \\ &amp;&#x3D; \frac{e^{x_k}}{\sum_{i&#x3D;1}^N e^{x_i}} - 1 \\ &amp; &#x3D; Prob_k -1 \end{aligned}$$</p><p>对于非目标类别$x_j$的导数计算为：</p><p>$$\begin{aligned} \frac{\partial Loss}{\partial x_j} &amp;&#x3D; - \frac{\sum_{i&#x3D;1}^N e^{x_i}}{e^{x_j}} \frac{0 - e^{x_j} e^{x_j}}{(\sum_{i&#x3D;1}^N e^{x_i})^2} \\ &amp;&#x3D; \frac{e^{x_j}}{\sum_{i&#x3D;1}^N e^{x_i}} \\ &amp; &#x3D; Prob_j \end{aligned}$$</p><h2 id="交叉熵损失实现"><a href="#交叉熵损失实现" class="headerlink" title="交叉熵损失实现"></a>交叉熵损失实现</h2><p>GPT2是一个基于transformer的序列模型，输入是一个句子，GPT2预测该句子的下一个单词是什么，也即计算下一个单词的概率。经过交叉熵计算前GPT2模型输出的张量大小为$(B,T,V)$，$B$表示batch size，$T$表示句子的长度，V表示要预测的所有单词的数量。</p><p>首先实现交叉熵的前向计算过程。实现softmax函数</p><pre class="line-numbers language-cpp"><code class="language-cpp">vector<span class="token operator">&lt;</span>vector<span class="token operator">&lt;</span>vector<span class="token operator">&lt;</span><span class="token keyword">float</span><span class="token operator">>></span><span class="token operator">></span> <span class="token function">softmax</span><span class="token punctuation">(</span>vector<span class="token operator">&lt;</span>vector<span class="token operator">&lt;</span>vector<span class="token operator">&lt;</span><span class="token keyword">float</span><span class="token operator">>></span><span class="token operator">></span><span class="token operator">&amp;</span> logits<span class="token punctuation">)</span><span class="token punctuation">{</span>    <span class="token comment" spellcheck="true">// input: logits is (B,T,V) of the unnormalized log probabilities</span>    <span class="token keyword">int</span> B <span class="token operator">=</span> logits<span class="token punctuation">.</span><span class="token function">size</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">int</span> T <span class="token operator">=</span> logits<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token function">size</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">int</span> V <span class="token operator">=</span> logits<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token function">size</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>       vector<span class="token operator">&lt;</span>vector<span class="token operator">&lt;</span>vector<span class="token operator">&lt;</span><span class="token keyword">float</span><span class="token operator">>></span><span class="token operator">></span> <span class="token function">probs</span><span class="token punctuation">(</span>B<span class="token punctuation">,</span> vector<span class="token operator">&lt;</span>vector<span class="token operator">&lt;</span><span class="token keyword">float</span><span class="token operator">>></span><span class="token punctuation">(</span>T<span class="token punctuation">,</span> vector<span class="token operator">&lt;</span><span class="token keyword">float</span><span class="token operator">></span><span class="token punctuation">(</span>V<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">for</span><span class="token punctuation">(</span><span class="token keyword">int</span> b <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> b <span class="token operator">&lt;</span> B<span class="token punctuation">;</span> b<span class="token operator">++</span><span class="token punctuation">)</span><span class="token punctuation">{</span>        <span class="token keyword">for</span><span class="token punctuation">(</span><span class="token keyword">int</span> t <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> t <span class="token operator">&lt;</span> T<span class="token punctuation">;</span> t<span class="token operator">++</span><span class="token punctuation">)</span><span class="token punctuation">{</span>            <span class="token comment" spellcheck="true">// maxval is only calculated and subtracted for numerical stability</span>            <span class="token keyword">float</span> maxval <span class="token operator">=</span> <span class="token operator">-</span><span class="token number">10000.0f</span><span class="token punctuation">;</span> <span class="token comment" spellcheck="true">// TODO something better</span>            <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> V<span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>                <span class="token keyword">if</span> <span class="token punctuation">(</span>logits<span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">[</span>t<span class="token punctuation">]</span><span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">></span> maxval<span class="token punctuation">)</span> <span class="token punctuation">{</span>                    maxval <span class="token operator">=</span> logits<span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">[</span>t<span class="token punctuation">]</span><span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">;</span>                <span class="token punctuation">}</span>            <span class="token punctuation">}</span>            <span class="token keyword">float</span> sum <span class="token operator">=</span> <span class="token number">0.0f</span><span class="token punctuation">;</span>            <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> V<span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>                probs<span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">[</span>t<span class="token punctuation">]</span><span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token function">expf</span><span class="token punctuation">(</span>logits<span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">[</span>t<span class="token punctuation">]</span><span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">-</span> maxval<span class="token punctuation">)</span><span class="token punctuation">;</span>                sum <span class="token operator">+</span><span class="token operator">=</span> probs<span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">[</span>t<span class="token punctuation">]</span><span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">;</span>            <span class="token punctuation">}</span>            <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> V<span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>                probs<span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">[</span>t<span class="token punctuation">]</span><span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">/</span><span class="token operator">=</span> sum<span class="token punctuation">;</span>            <span class="token punctuation">}</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span>            <span class="token keyword">return</span> probs<span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>通过softmax获得句子中每个位置的预测的单词的概率，计算得到的概率的张量大小为$(B,T,V)$。接着计算损失。</p><pre class="line-numbers language-cpp"><code class="language-cpp">vector<span class="token operator">&lt;</span>vector<span class="token operator">&lt;</span><span class="token keyword">float</span><span class="token operator">>></span> <span class="token function">forward</span><span class="token punctuation">(</span>vector<span class="token operator">&lt;</span>vector<span class="token operator">&lt;</span>vector<span class="token operator">&lt;</span><span class="token keyword">float</span><span class="token operator">>></span><span class="token operator">></span><span class="token operator">&amp;</span> logits<span class="token punctuation">,</span>                                vector<span class="token operator">&lt;</span>vector<span class="token operator">&lt;</span><span class="token keyword">int</span><span class="token operator">>></span><span class="token operator">&amp;</span> targets<span class="token punctuation">)</span><span class="token punctuation">{</span>    <span class="token comment" spellcheck="true">// targets is (B,T) of integers giving the correct index in logits</span>    <span class="token keyword">int</span> B <span class="token operator">=</span> logits<span class="token punctuation">.</span><span class="token function">size</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">int</span> T <span class="token operator">=</span> logits<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token function">size</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">this</span><span class="token operator">-</span><span class="token operator">></span>probs <span class="token operator">=</span> <span class="token function">softmax</span><span class="token punctuation">(</span>logits<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">this</span><span class="token operator">-</span><span class="token operator">></span>targets <span class="token operator">=</span> targets<span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">// output: losses is (B,T) of the individual losses at each position</span>    vector<span class="token operator">&lt;</span>vector<span class="token operator">&lt;</span><span class="token keyword">float</span><span class="token operator">>></span> <span class="token function">losses</span><span class="token punctuation">(</span>B<span class="token punctuation">,</span> vector<span class="token operator">&lt;</span><span class="token keyword">float</span><span class="token operator">></span><span class="token punctuation">(</span>T<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">for</span><span class="token punctuation">(</span><span class="token keyword">int</span> b <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> b <span class="token operator">&lt;</span> B<span class="token punctuation">;</span> b<span class="token operator">++</span><span class="token punctuation">)</span><span class="token punctuation">{</span>        <span class="token keyword">for</span><span class="token punctuation">(</span><span class="token keyword">int</span> t <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> t <span class="token operator">&lt;</span> T<span class="token punctuation">;</span> t<span class="token operator">++</span><span class="token punctuation">)</span><span class="token punctuation">{</span>            <span class="token keyword">int</span> idx <span class="token operator">=</span> targets<span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">[</span>t<span class="token punctuation">]</span><span class="token punctuation">;</span>            losses<span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">[</span>t<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token operator">-</span><span class="token function">logf</span><span class="token punctuation">(</span>probs<span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">[</span>t<span class="token punctuation">]</span><span class="token punctuation">[</span>idx<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span>    <span class="token keyword">return</span> losses<span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>计算完损失后，开始计算梯度进行反向传播。</p><pre class="line-numbers language-cpp"><code class="language-cpp">vector<span class="token operator">&lt;</span>vector<span class="token operator">&lt;</span>vector<span class="token operator">&lt;</span><span class="token keyword">float</span><span class="token operator">>></span><span class="token operator">></span> <span class="token function">backward</span><span class="token punctuation">(</span>vector<span class="token operator">&lt;</span>vector<span class="token operator">&lt;</span><span class="token keyword">float</span><span class="token operator">>></span><span class="token operator">&amp;</span> dlosses<span class="token punctuation">)</span><span class="token punctuation">{</span>    <span class="token keyword">int</span> B <span class="token operator">=</span> <span class="token keyword">this</span><span class="token operator">-</span><span class="token operator">></span>probs<span class="token punctuation">.</span><span class="token function">size</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">int</span> T <span class="token operator">=</span> <span class="token keyword">this</span><span class="token operator">-</span><span class="token operator">></span>probs<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token function">size</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">int</span> V <span class="token operator">=</span> <span class="token keyword">this</span><span class="token operator">-</span><span class="token operator">></span>probs<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token function">size</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            vector<span class="token operator">&lt;</span>vector<span class="token operator">&lt;</span>vector<span class="token operator">&lt;</span><span class="token keyword">float</span><span class="token operator">>></span><span class="token operator">></span> <span class="token function">dlogits</span><span class="token punctuation">(</span>B<span class="token punctuation">,</span> vector<span class="token operator">&lt;</span>vector<span class="token operator">&lt;</span><span class="token keyword">float</span><span class="token operator">>></span><span class="token punctuation">(</span>T<span class="token punctuation">,</span> vector<span class="token operator">&lt;</span><span class="token keyword">float</span><span class="token operator">></span><span class="token punctuation">(</span>V<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> b <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> b <span class="token operator">&lt;</span> B<span class="token punctuation">;</span> b<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> t <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> t <span class="token operator">&lt;</span> T<span class="token punctuation">;</span> t<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            <span class="token keyword">float</span> dloss <span class="token operator">=</span> dlosses<span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">[</span>t<span class="token punctuation">]</span><span class="token punctuation">;</span>            <span class="token keyword">int</span> idx <span class="token operator">=</span> <span class="token keyword">this</span><span class="token operator">-</span><span class="token operator">></span>targets<span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">[</span>t<span class="token punctuation">]</span><span class="token punctuation">;</span>            <span class="token keyword">for</span><span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> V<span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span><span class="token punctuation">{</span>                <span class="token keyword">float</span> indicator <span class="token operator">=</span> i <span class="token operator">==</span> idx <span class="token operator">?</span> <span class="token number">1.0f</span> <span class="token operator">:</span> <span class="token number">0.0f</span><span class="token punctuation">;</span>                dlogits<span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">[</span>t<span class="token punctuation">]</span><span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">+</span><span class="token operator">=</span> <span class="token punctuation">(</span><span class="token keyword">this</span><span class="token operator">-</span><span class="token operator">></span>probs<span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">[</span>t<span class="token punctuation">]</span><span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">-</span> indicator<span class="token punctuation">)</span> <span class="token operator">*</span> dloss<span class="token punctuation">;</span>            <span class="token punctuation">}</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span>    <span class="token keyword">return</span> dlogits<span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>完整的代码实现：</p><pre class="line-numbers language-cpp"><code class="language-cpp"><span class="token keyword">class</span> <span class="token class-name">CrossEntropy</span><span class="token punctuation">{</span><span class="token keyword">private</span><span class="token operator">:</span>    vector<span class="token operator">&lt;</span>vector<span class="token operator">&lt;</span>vector<span class="token operator">&lt;</span><span class="token keyword">float</span><span class="token operator">>></span><span class="token operator">></span> probs<span class="token punctuation">;</span>    vector<span class="token operator">&lt;</span>vector<span class="token operator">&lt;</span><span class="token keyword">int</span><span class="token operator">>></span> targets<span class="token punctuation">;</span><span class="token keyword">public</span><span class="token operator">:</span>    <span class="token function">CrossEntropy</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">{</span><span class="token punctuation">}</span>    vector<span class="token operator">&lt;</span>vector<span class="token operator">&lt;</span>vector<span class="token operator">&lt;</span><span class="token keyword">float</span><span class="token operator">>></span><span class="token operator">></span> <span class="token function">softmax</span><span class="token punctuation">(</span>vector<span class="token operator">&lt;</span>vector<span class="token operator">&lt;</span>vector<span class="token operator">&lt;</span><span class="token keyword">float</span><span class="token operator">>></span><span class="token operator">></span><span class="token operator">&amp;</span> logits<span class="token punctuation">)</span><span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">// input: logits is (B,T,V) of the unnormalized log probabilities</span>        <span class="token keyword">int</span> B <span class="token operator">=</span> logits<span class="token punctuation">.</span><span class="token function">size</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">int</span> T <span class="token operator">=</span> logits<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token function">size</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">int</span> V <span class="token operator">=</span> logits<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token function">size</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>           vector<span class="token operator">&lt;</span>vector<span class="token operator">&lt;</span>vector<span class="token operator">&lt;</span><span class="token keyword">float</span><span class="token operator">>></span><span class="token operator">></span> <span class="token function">probs</span><span class="token punctuation">(</span>B<span class="token punctuation">,</span> vector<span class="token operator">&lt;</span>vector<span class="token operator">&lt;</span><span class="token keyword">float</span><span class="token operator">>></span><span class="token punctuation">(</span>T<span class="token punctuation">,</span> vector<span class="token operator">&lt;</span><span class="token keyword">float</span><span class="token operator">></span><span class="token punctuation">(</span>V<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">for</span><span class="token punctuation">(</span><span class="token keyword">int</span> b <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> b <span class="token operator">&lt;</span> B<span class="token punctuation">;</span> b<span class="token operator">++</span><span class="token punctuation">)</span><span class="token punctuation">{</span>            <span class="token keyword">for</span><span class="token punctuation">(</span><span class="token keyword">int</span> t <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> t <span class="token operator">&lt;</span> T<span class="token punctuation">;</span> t<span class="token operator">++</span><span class="token punctuation">)</span><span class="token punctuation">{</span>                <span class="token comment" spellcheck="true">// maxval is only calculated and subtracted for numerical stability</span>                <span class="token keyword">float</span> maxval <span class="token operator">=</span> <span class="token operator">-</span><span class="token number">10000.0f</span><span class="token punctuation">;</span> <span class="token comment" spellcheck="true">// TODO something better</span>                <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> V<span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>                    <span class="token keyword">if</span> <span class="token punctuation">(</span>logits<span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">[</span>t<span class="token punctuation">]</span><span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">></span> maxval<span class="token punctuation">)</span> <span class="token punctuation">{</span>                        maxval <span class="token operator">=</span> logits<span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">[</span>t<span class="token punctuation">]</span><span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">;</span>                    <span class="token punctuation">}</span>                <span class="token punctuation">}</span>                <span class="token keyword">float</span> sum <span class="token operator">=</span> <span class="token number">0.0f</span><span class="token punctuation">;</span>                <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> V<span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>                    probs<span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">[</span>t<span class="token punctuation">]</span><span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token function">expf</span><span class="token punctuation">(</span>logits<span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">[</span>t<span class="token punctuation">]</span><span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">-</span> maxval<span class="token punctuation">)</span><span class="token punctuation">;</span>                    sum <span class="token operator">+</span><span class="token operator">=</span> probs<span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">[</span>t<span class="token punctuation">]</span><span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">;</span>                <span class="token punctuation">}</span>                <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> V<span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>                    probs<span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">[</span>t<span class="token punctuation">]</span><span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">/</span><span class="token operator">=</span> sum<span class="token punctuation">;</span>                <span class="token punctuation">}</span>            <span class="token punctuation">}</span>        <span class="token punctuation">}</span>                <span class="token keyword">return</span> probs<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    vector<span class="token operator">&lt;</span>vector<span class="token operator">&lt;</span><span class="token keyword">float</span><span class="token operator">>></span> <span class="token function">forward</span><span class="token punctuation">(</span>vector<span class="token operator">&lt;</span>vector<span class="token operator">&lt;</span>vector<span class="token operator">&lt;</span><span class="token keyword">float</span><span class="token operator">>></span><span class="token operator">></span><span class="token operator">&amp;</span> logits<span class="token punctuation">,</span> vector<span class="token operator">&lt;</span>vector<span class="token operator">&lt;</span><span class="token keyword">int</span><span class="token operator">>></span><span class="token operator">&amp;</span> targets<span class="token punctuation">)</span><span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">// targets is (B,T) of integers giving the correct index in logits</span>        <span class="token keyword">int</span> B <span class="token operator">=</span> logits<span class="token punctuation">.</span><span class="token function">size</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">int</span> T <span class="token operator">=</span> logits<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token function">size</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">this</span><span class="token operator">-</span><span class="token operator">></span>probs <span class="token operator">=</span> <span class="token function">softmax</span><span class="token punctuation">(</span>logits<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">this</span><span class="token operator">-</span><span class="token operator">></span>targets <span class="token operator">=</span> targets<span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// output: losses is (B,T) of the individual losses at each position</span>        vector<span class="token operator">&lt;</span>vector<span class="token operator">&lt;</span><span class="token keyword">float</span><span class="token operator">>></span> <span class="token function">losses</span><span class="token punctuation">(</span>B<span class="token punctuation">,</span> vector<span class="token operator">&lt;</span><span class="token keyword">float</span><span class="token operator">></span><span class="token punctuation">(</span>T<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">for</span><span class="token punctuation">(</span><span class="token keyword">int</span> b <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> b <span class="token operator">&lt;</span> B<span class="token punctuation">;</span> b<span class="token operator">++</span><span class="token punctuation">)</span><span class="token punctuation">{</span>            <span class="token keyword">for</span><span class="token punctuation">(</span><span class="token keyword">int</span> t <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> t <span class="token operator">&lt;</span> T<span class="token punctuation">;</span> t<span class="token operator">++</span><span class="token punctuation">)</span><span class="token punctuation">{</span>                <span class="token keyword">int</span> idx <span class="token operator">=</span> targets<span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">[</span>t<span class="token punctuation">]</span><span class="token punctuation">;</span>                losses<span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">[</span>t<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token operator">-</span><span class="token function">logf</span><span class="token punctuation">(</span>probs<span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">[</span>t<span class="token punctuation">]</span><span class="token punctuation">[</span>idx<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token punctuation">}</span>        <span class="token punctuation">}</span>        <span class="token keyword">return</span> losses<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    vector<span class="token operator">&lt;</span>vector<span class="token operator">&lt;</span>vector<span class="token operator">&lt;</span><span class="token keyword">float</span><span class="token operator">>></span><span class="token operator">></span> <span class="token function">backward</span><span class="token punctuation">(</span>vector<span class="token operator">&lt;</span>vector<span class="token operator">&lt;</span><span class="token keyword">float</span><span class="token operator">>></span><span class="token operator">&amp;</span> dlosses<span class="token punctuation">)</span><span class="token punctuation">{</span>        <span class="token keyword">int</span> B <span class="token operator">=</span> <span class="token keyword">this</span><span class="token operator">-</span><span class="token operator">></span>probs<span class="token punctuation">.</span><span class="token function">size</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">int</span> T <span class="token operator">=</span> <span class="token keyword">this</span><span class="token operator">-</span><span class="token operator">></span>probs<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token function">size</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token keyword">int</span> V <span class="token operator">=</span> <span class="token keyword">this</span><span class="token operator">-</span><span class="token operator">></span>probs<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token function">size</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>                vector<span class="token operator">&lt;</span>vector<span class="token operator">&lt;</span>vector<span class="token operator">&lt;</span><span class="token keyword">float</span><span class="token operator">>></span><span class="token operator">></span> <span class="token function">dlogits</span><span class="token punctuation">(</span>B<span class="token punctuation">,</span> vector<span class="token operator">&lt;</span>vector<span class="token operator">&lt;</span><span class="token keyword">float</span><span class="token operator">>></span><span class="token punctuation">(</span>T<span class="token punctuation">,</span> vector<span class="token operator">&lt;</span><span class="token keyword">float</span><span class="token operator">></span><span class="token punctuation">(</span>V<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> b <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> b <span class="token operator">&lt;</span> B<span class="token punctuation">;</span> b<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> t <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> t <span class="token operator">&lt;</span> T<span class="token punctuation">;</span> t<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>                <span class="token keyword">float</span> dloss <span class="token operator">=</span> dlosses<span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">[</span>t<span class="token punctuation">]</span><span class="token punctuation">;</span>                <span class="token keyword">int</span> idx <span class="token operator">=</span> <span class="token keyword">this</span><span class="token operator">-</span><span class="token operator">></span>targets<span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">[</span>t<span class="token punctuation">]</span><span class="token punctuation">;</span>                <span class="token keyword">for</span><span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> V<span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span><span class="token punctuation">{</span>                    <span class="token keyword">float</span> indicator <span class="token operator">=</span> i <span class="token operator">==</span> idx <span class="token operator">?</span> <span class="token number">1.0f</span> <span class="token operator">:</span> <span class="token number">0.0f</span><span class="token punctuation">;</span>                    dlogits<span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">[</span>t<span class="token punctuation">]</span><span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">+</span><span class="token operator">=</span> <span class="token punctuation">(</span><span class="token keyword">this</span><span class="token operator">-</span><span class="token operator">></span>probs<span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">[</span>t<span class="token punctuation">]</span><span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">-</span> indicator<span class="token punctuation">)</span> <span class="token operator">*</span> dloss<span class="token punctuation">;</span>                <span class="token punctuation">}</span>            <span class="token punctuation">}</span>        <span class="token punctuation">}</span>        <span class="token keyword">return</span> dlogits<span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token punctuation">;</span><span class="token keyword">int</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">{</span>    CrossEntropy critrion<span class="token punctuation">;</span>    vector<span class="token operator">&lt;</span>vector<span class="token operator">&lt;</span>vector<span class="token operator">&lt;</span><span class="token keyword">float</span><span class="token operator">>></span><span class="token operator">></span> logits <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">{</span><span class="token punctuation">{</span><span class="token number">0.1</span><span class="token punctuation">,</span><span class="token number">0.2</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">0.2</span><span class="token punctuation">,</span><span class="token number">0.76</span><span class="token punctuation">,</span><span class="token number">0.55</span><span class="token punctuation">}</span><span class="token punctuation">,</span>                                            <span class="token punctuation">{</span><span class="token number">1.98</span><span class="token punctuation">,</span><span class="token number">0.32</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">1.2</span><span class="token punctuation">,</span><span class="token number">0.76</span><span class="token punctuation">,</span><span class="token number">0.95</span><span class="token punctuation">}</span><span class="token punctuation">,</span>                                            <span class="token punctuation">{</span><span class="token number">0.21</span><span class="token punctuation">,</span><span class="token number">0.92</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">0.9</span><span class="token punctuation">,</span><span class="token number">1.76</span><span class="token punctuation">,</span><span class="token number">2.55</span><span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token punctuation">;</span>    vector<span class="token operator">&lt;</span>vector<span class="token operator">&lt;</span><span class="token keyword">int</span><span class="token operator">>></span> targets <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">{</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token punctuation">;</span>    vector<span class="token operator">&lt;</span>vector<span class="token operator">&lt;</span><span class="token keyword">float</span><span class="token operator">>></span> loss <span class="token operator">=</span> critrion<span class="token punctuation">.</span><span class="token function">forward</span><span class="token punctuation">(</span>logits<span class="token punctuation">,</span> targets<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">for</span><span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> loss<span class="token punctuation">.</span><span class="token function">size</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span><span class="token punctuation">{</span>        <span class="token keyword">for</span><span class="token punctuation">(</span><span class="token keyword">int</span> j <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> j <span class="token operator">&lt;</span> loss<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token function">size</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span> j<span class="token operator">++</span><span class="token punctuation">)</span><span class="token punctuation">{</span>            cout <span class="token operator">&lt;&lt;</span> loss<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token punctuation">]</span> <span class="token operator">&lt;&lt;</span> endl<span class="token punctuation">;</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token operator">>></span><span class="token operator">></span> Output<span class="token operator">:</span><span class="token number">1.39831</span><span class="token number">0.633377</span><span class="token number">1.3654</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> 算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> C++ </tag>
            
            <tag> 算法知识 </tag>
            
            <tag> 深度学习 </tag>
            
            <tag> LLM </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>时序模型RNN和LSTM</title>
      <link href="/2024/03/20/suan-fa/rnn-he-lstm/"/>
      <url>/2024/03/20/suan-fa/rnn-he-lstm/</url>
      
        <content type="html"><![CDATA[<h1 id="时序模型RNN和LSTM"><a href="#时序模型RNN和LSTM" class="headerlink" title="时序模型RNN和LSTM"></a>时序模型RNN和LSTM</h1><h2 id="RNN的基本原理"><a href="#RNN的基本原理" class="headerlink" title="RNN的基本原理"></a>RNN的基本原理</h2><p>RNN（Recurrent Neural Network）循环神经网络，是一种为解决序列化数据建模问题的模型，如视频、语音和文本等。</p><p>在理解RNN与全连接神经网络时，需要对两者的结构加以区分，通常，FCN会采用水平方式进行可视化理解，即<strong>每一层</strong>的神经元<strong>垂直排列</strong>，而<strong>不同层</strong>之间以<strong>水平方式排布</strong>。但在RNN的模型图中，<strong>隐藏层</strong>的不同神经元之间通常<strong>水平排列</strong>，而隐藏层的<strong>不同层</strong>之间以<strong>垂直方式排列</strong>，如下图所示，在FCN网络中，各层水平布局，隐藏层各神经元相互独立，在RNN中，各层以垂直布局，而水平方向上布局着各神经元。<strong>注意：下图RNN结构图只是为了使得结构直观易理解，在水平方向上（时间维度上）每个A都相同，对于每个时间步其都是采用同一个神经元进行前向传播。</strong></p><p><img src="/images/fcn%E5%92%8Crnn.jpg"></p><h3 id="RNN的前向传播"><a href="#RNN的前向传播" class="headerlink" title="RNN的前向传播"></a>RNN的前向传播</h3><p>在RNN中，序列数据按照其时间顺序，依次输入到网络中，而时间顺序则表示时间步的概念，正如上图RNN结构在水平方向所展示的。RNN中的隐藏状态极为重要，隐藏状态是连接各隐藏层各神经元的中介值，t时刻的隐藏状态通常会被表示为$h_t$。如上图，在第一层$L_1$中，在时间步t，RNN隐藏层神经元得到隐藏状态$h_t^{(1)}$ ；在时间步t+1 ，接受来自上一个时间步的隐藏状态输出$h_t^{(1)}$，得到新的隐藏状态$h_{t+1}^{(1)}$ 。而从垂直方向上看，各层之间，也通过隐藏状态所连接，对于$L_1$到$L_2$，$L_2$在水平的时间轴上，各神经元通过隐藏状态$h_t^{(2)}$连接，而层间还将接受前一层的$h_t^{(1)}$作为输入值，从而获得到该层新的隐藏状态。综上所述，<strong>RNN隐藏层接收的输入有两个，当前时间步的输入数据$x_t$和前一时间步的隐藏状态$h_{t-1}$，输出该隐藏层的隐藏状态$h_t$。</strong></p><p>根据上述文字描述，可以得出RNN模型的前向传播过程：</p><p>$$h_t &#x3D; g(Wx_t+Uh_{t-1}+b)$$</p><p>这是对于RNN模型的某一隐藏层的过程，其中$W,U,b$均是该层可学习的参数，$g$是激活函数，若是多个隐藏层，则上式改写为：</p><p>$$h_t^{[i]} &#x3D; g(W^{[i]}h_t^{[i-1]}+U^{[i]}h_{t-1}^{[i]}+b^{[i]})$$</p><p>其中$i$表示第几层隐藏层，当$i&#x3D;1$时，$h_t^{[i-1]}&#x3D;x_t$</p><p>为了简化研究，现在只对单层RNN进行讨论，如下图的RNN。在获得隐藏状态后，若需要获得该时间步的输出，则需要进一步对隐藏状态$h_t$进行映射变换，$V,b_o$均是该变换的可学习参数，$g$是激活函数。</p><p>$$\begin{aligned} h_t &amp;&#x3D; g(Wx_t+Uh_{t-1}+b) \\ &amp;&#x3D; g(Wx_t+U(g(Wx_{t-1}+Uh_{t-2}+b))+b) \\ &amp;&#x3D; g(Wx_t+U(g(Wx_{t-1}+U(g(Wx_{t-2}+Uh_{t-3}+b)))+b))+b) \\ &amp;&#x3D; g(Wx_t+U(g(Wx_{t-1}+U(g(Wx_{t-2}+U(g(Wx_{t-3}+…))+b)))+b))+b) \end{aligned}$$</p><p>$$\begin{aligned} y_t &#x3D; g(Vh_t+b_o) \end{aligned}$$</p><p><img src="/images/rnn.png"></p><h3 id="RNN的反向传播"><a href="#RNN的反向传播" class="headerlink" title="RNN的反向传播"></a>RNN的反向传播</h3><p>从RNN的模型可以看出，在反向传播时，在某一序列位置t的梯度损失由当前位置的输出对应的梯度损失和前一序列索引位置t+1时的梯度损失两部分共同决定。即不仅需要沿着隐藏层进行梯度推导，还需要沿着时间步进行梯度推导，这就是RNN中的<strong>BPTT（Back Propagation Through Time）反向传播</strong>。</p><p>对于RNN，由于我们在序列的每个时间步都有损失函数，因此最终的损失L为：</p><p>$$L&#x3D;\sum_{t&#x3D;1}^T L^{(t)}$$</p><p>根据反向传播的规则，每个在当前时间步 $t$应向前追溯直到$t_0$，计算梯度并更新参数，而在RNN中不同时间步中的$W,U,V$等参数被所有时间步共享，因此梯度是对同一个参数计算，为此可以将梯度作求和，一次性更新。</p><p>简化起见只考虑单层RNN模型，且损失函数使用MSE，则对输出层参数$V,b_o$的梯度为：</p><p>$$\begin{aligned} L^{(t)} &#x3D; \frac{1}{2}(\hat y^{(t)} - y^{(t)})^2 \end{aligned}$$</p><p>$$\begin{aligned} \frac{\partial L}{\partial b_o} &amp;&#x3D; \sum_{t&#x3D;1}^T \frac{\partial L^{(t)}}{\partial b_o} &#x3D; \sum_{t&#x3D;1}^T \frac{\partial L^{(t)}}{\partial y_t} \frac{\partial y_t}{\partial b_o} \\ &amp;&#x3D; \sum_{t&#x3D;1}^T (\hat y^{(t)} - y^{(t)})g’(s^{(t)})\end{aligned}$$</p><p>$$\begin{aligned} \frac{\partial L}{\partial V} &amp;&#x3D; \sum_{t&#x3D;1}^T \frac{\partial L^{(t)}}{\partial V} &#x3D; \sum_{t&#x3D;1}^T \frac{\partial L^{(t)}}{\partial y_t} \frac{\partial y_t}{\partial V} \\ &amp;&#x3D; \sum_{t&#x3D;1}^T (\hat y^{(t)} - y^{(t)})g’(s^{(t)})(h_t)^T\end{aligned}$$</p><p>其中$g’(s^{(t)})$表示$t$时刻输出的激活函数的导数。</p><p>对于$W,U,b$的梯度计算过程与上述类似，只是不仅需要在隐藏层之间（垂直方向）计算梯度，还需要在时间维度上（水平方向）计算梯度。这里暂不展开。</p><h3 id="RNN存在的问题"><a href="#RNN存在的问题" class="headerlink" title="RNN存在的问题"></a>RNN存在的问题</h3><p>在RNNs中，每个输出由当前时间步的输入和之前的信息（前一时间步的隐藏状态）共同决定，这个思路是很巧妙的，但是会带来一个问题。有时我们只需要最近的信息来作为当前预测任务的输入，对于一个语言模型，它要根据前面的单词预测后面的单词，比如这句话：”the clouds are in the <em>sky</em>.”，要预测最后一个单词 sky，RNN只需要参考最近的几个单词即可。</p><p>所以如下图所示，这个 RNN的时间步长为5，每一时间步的输入分别为”the”,”clouds”,” are”,” in”,”the”，对应的输出则为”clouds”,” are”,” in”,”the”,”sky”。</p><p><img src="/images/rnn%E4%B8%BE%E4%BE%8B.png"></p><p>但有时我们需要更多之前的信息，比如这句话：”I grew up in France… I speak fluent <em>French</em>.”，要预测最后一个单词，仅仅只参考最近的信息则不够了，最近的信息只知道这里应该填一种语言，但是具体什么语言则不确定，所以还需要参考更前面的信息“France”。</p><p>但是如果需要参考的信息离当前预测任务特别的远，超过了8到10个步长，也就是具有“长期依赖关系”，RNN可能会出现”梯度消失”的问题，即RNN保存的信息通常都是<strong>短期信息</strong>，之前的信息会呈几何级丢失。反向训练时，RNN计算梯度时要横向往前推（求导链式法则），一直推到序列开始的地方。当序列非常长时，就会出现梯度消失，也就是前面神经元的权重基本不变，没有训练效果。同样地，还是因为链式法则，当每一项相乘的偏导数都很大时，RNN也会出现梯度爆炸的情况，通常的解决办法就是<strong>梯度截断</strong>。</p><h2 id="LSTM基本原理"><a href="#LSTM基本原理" class="headerlink" title="LSTM基本原理"></a>LSTM基本原理</h2><p>RNN单元在面对长序列数据时，很容易出现梯度弥散，使得RNN只具备短期记忆，即RNN面对长序列数据，仅可获取较近的序列的信息，而对较早期的序列不具备记忆功能，从而丢失信息。为解决该类问题，便提出了LSTM结构，其核心关键在于：</p><ol><li>提出了门机制：<strong>遗忘门、输入门、输出门</strong>；</li><li>细胞状态：在RNN中只有隐藏状态的传播，而在LSTM中引入了<strong>细胞状态</strong>。</li></ol><p>如下图，为两个LSTM单元的连结，其中相较于传统RNN单元，其多了上下两条轴，分别用于承载细胞状态$C$及隐藏状态$h$的信息流动，而其中$\sigma$则被称为门，通过乘法运算、加法运算和激活函数实现数据的过滤与合并。</p><p><img src="/images/lstm.jpg"></p><p>对上述门进行定义，其中$f,i,o$分别表示遗忘门、输入门和输出门，不同门中的$W,U,b$表示不同门的可学习参数：</p><p>$$gate_{f,i,o}(h_{t-1},x_t)&#x3D; \sigma(Wx_t+Uh_{t-1}+b)$$</p><p>如上图所示和上述公式，$\sigma$表示各个门，其使用$\times, +$运算和激活函数做到了信息过滤和叠加。</p><h3 id="前向过程"><a href="#前向过程" class="headerlink" title="前向过程"></a>前向过程</h3><h4 id="遗忘门"><a href="#遗忘门" class="headerlink" title="遗忘门"></a>遗忘门</h4><p>LSTM的第一步是决定要从细胞（cell）状态中丢弃什么信息，遗忘门用来忘记导致错误预测的信息。比如语言模型，它试图根据前面所有的单词来预测下一个单词，这时它根据当前对象的性别信息，来预测正确的代词，当有新对象出现时，就需要忘记之前对象的性别信息。</p><p><img src="/images/lstm_f.jpg"></p><p>这里可以思考一下计算机中，逻辑电路的思想，在逻辑电路中，分为“与门”，“或门”，“非门”等，对于“与门”，只有当两者均为1时结果为1，其一为0时结果为0。同样地对于遗忘门的运算，使用sigmoid函数其输出值为$(0,1)$，当进行乘法运算时，就能达到信息过滤的效果。</p><p>$$f_t &#x3D; \sigma(W_fx_t+U_fh_{t-1}+b_f)$$</p><h4 id="输入门"><a href="#输入门" class="headerlink" title="输入门"></a>输入门</h4><p>输入门是决定要在cell状态中存储什么新信息。</p><p><img src="/images/lstm_i.jpg"></p><p>从图中可以看到输入门由两部分组成，第一部分使用了sigmoid激活函数，输出为$i_t$，第二部分使用了tanh激活函数，输出为$C_t$，两者的结果后面会相乘再去更新细胞状态。对于输入门，前向过程如下：</p><p>$$\begin{aligned} i_t &amp;&#x3D; \sigma(W_i x_t+U_i h_{t-1}+b_i) \\  \bar C_t &amp;&#x3D; \tanh(W_a x_t+U_a h_{t-1}+b_a)\end{aligned}$$</p><h4 id="细胞更新"><a href="#细胞更新" class="headerlink" title="细胞更新"></a>细胞更新</h4><p>现在知道了遗忘门决定是否遗忘之前的信息，输入门决定要在cell状态中存储什么新信息，那么现在就需要将旧的cell状态$C_{t-1}$更新为新的cell状态$C_t$了。</p><p><img src="/images/lstm_update.jpg"></p><p>前向过程如下：</p><p>$$\begin{aligned} C_t &#x3D; f_t \times C_{t-1} + i_t \times \bar C_t\end{aligned}$$</p><h4 id="输出门"><a href="#输出门" class="headerlink" title="输出门"></a>输出门</h4><p>最后，基于上面得到的新cell状态，决定最终要输出什么。</p><p><img src="/images/lstm_o.jpg"></p><p>首先$\sigma$层（sigmoid激活函数）决定要输出cell状态的哪些部分，然后使cell状态通过tanh层，并将结果乘以$\sigma$层的输出，即是决定输出的部分，前向过程如下：</p><p>$$\begin{aligned} \bar o_t &amp;&#x3D; \sigma(W_o x_t+U_o h_{t-1}+b_o) \\ h_t &amp;&#x3D; \bar o_t * \tanh(C_t)\end{aligned}$$</p><p>得到$h_t$后进一步映射变换即可得到lstm单元的输出$o_t$。</p><p><strong>LSTM的结构有效地解决了RNN的短期依赖瓶颈。但是从模型结构可以看出，相较于RNN，LSTM含有更多的参数需要学习，从而导致LSTM的学习速度大大降低。</strong></p>]]></content>
      
      
      <categories>
          
          <category> 算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 算法知识 </tag>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CLIP模型简介</title>
      <link href="/2024/03/11/lun-wen-yue-du/clip-mo-xing-xiang-jie/"/>
      <url>/2024/03/11/lun-wen-yue-du/clip-mo-xing-xiang-jie/</url>
      
        <content type="html"><![CDATA[<h1 id="CLIP模型简介"><a href="#CLIP模型简介" class="headerlink" title="CLIP模型简介"></a>CLIP模型简介</h1><p>CLIP（Contrastive Language Image Pre-training）模型是OpenAI在 2021 年初发布的用于<strong>匹配图像和文本</strong>的<strong>预训练</strong>神经网络模型，是近年来多模态研究领域工作的基础。</p><h2 id="CLIP基本原理"><a href="#CLIP基本原理" class="headerlink" title="CLIP基本原理"></a>CLIP基本原理</h2><p>在目前计算机视觉领域中，我们训练的模型通常会遇到以下问题：</p><ol><li>模型需要用到大量的格式化标注数据，获得这些标注数据通常需要高昂的成本。</li><li>模型在当前数据集的效果比较好，但是模型的泛化能力可能较差，同时迁移到新的训练任务也比较困难。</li><li>图像和文本两种不同模态的信息难以有效融合，无法达到统一。</li></ol><p>CLIP模型就是用来解决上述问题，预训练后的模型可以直接进行<strong>zero-shot</strong>，并且统一融合了文本和图像两种模态。OpenAI的思路很简单，就是大力出奇迹，从互联网收集到的<strong>4 亿对图像文本</strong>对该模型进行训练。</p><p><img src="/images/CLIP.png"></p><p>如上图（1）所示，分别将文本和图像进行编码，之后使用对比学习进行训练，将同一图像和文本对的<strong>相似性提高</strong>，不同图像和文本对的相似性降低。在预测阶段，如图（2）和（3），生成一系列的文本，对这些文本和目标图像进行编码，计算<strong>余弦相似度</strong>从而得到目标图像的预测类别。</p><p><strong>预训练阶段：</strong>对比学习中正样本对和负样本的定义：能够配对的图片-文本对为正样本对，不能匹配的图片-文本对是负样本对。具体来说，在一个训练batch中先分别对图像和文本提特征，这时图像对应生成$I_1,I_2,…I_N$的特征向量，文本对应生成$T_1,T_2,…,T_N$的特征向量，文本和图像特征向量两两做内积得到$N*N$的矩阵，中间对角线即为正样本，其余均为负样本，即尽可能使对角线元素为1，非对角线元素为0。有了正负样本，模型就可以通过对比学习的方式训练起来了，完全不需要手工的标注。基于对比学习的原理，这里训练时的batch size应该要非常大才能保证较好的效果。<br><strong>预测阶段：</strong>由于CLIP 预训练时候的输入的是个句子，因此首先需要对预测类别进行单词转句子的处理，如下：使用 A photo of a {object}. 的提示模板进行构造，比如对于 dog，就构造成句子 A photo of a dog.，然后再送入文本编码器进行特征提取，这样就会得到一个文本的特征向量。图像只需要将输入图片传给图像编码器，输出一个一维的图片特征向量，然后拿这个图片特征和刚刚生成的文本特征做余弦相似度对比，相似度最高的即为预测的图像类别。</p><p>预训练过程的伪代码如下：</p><p><img src="/images/CLIP%E4%BC%AA%E4%BB%A3%E7%A0%81.png"></p><p>国内也有针对中文场景下的CLIP模型，即阿里出品的<strong>中文CLIP</strong>，从互联网上搜集了2亿图文对进行训练，效果也非常不错。</p>]]></content>
      
      
      <categories>
          
          <category> 论文 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 论文阅读 </tag>
            
            <tag> 自监督 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>详解扩散模型DDPM</title>
      <link href="/2024/02/18/suan-fa/xiang-jie-kuo-san-mo-xing-ddpm/"/>
      <url>/2024/02/18/suan-fa/xiang-jie-kuo-san-mo-xing-ddpm/</url>
      
        <content type="html"><![CDATA[<h1 id="扩散模型DDPM"><a href="#扩散模型DDPM" class="headerlink" title="扩散模型DDPM"></a>扩散模型DDPM</h1><p>经典的生成式模型有GAN、VAE，但是目前大火的AIGC基本都是基于扩散模型的工作，相比GAN来说，扩散模型训练更稳定，而且能够生成更多样的样本。这篇文章将详细介绍扩散模型开山之作的DDPM算法。</p><h2 id="扩散模型原理"><a href="#扩散模型原理" class="headerlink" title="扩散模型原理"></a>扩散模型原理</h2><p>扩散模型包括两个过程：</p><ol><li><strong>前向过程（forward process）</strong>：前向过程又称为<strong>扩散过程（diffusion process）</strong>，如下图所示（从右到左），对一张图像逐渐添加高斯噪音直至变成<strong>随机噪音</strong>。</li><li><strong>反向过程（reverse process）</strong>：反向过程可以用来生成数据，如下图所示（从左到右），从一个随机噪音开始逐渐去噪音直至<strong>生成一张图像</strong>。</li></ol><p>无论是前向过程还是反向过程都是一个<strong>参数化的马尔可夫链（Markov chain）</strong>。</p><p><img src="/images/ddpm%E8%BF%87%E7%A8%8B2.png"></p><h3 id="前向扩散过程的解析式"><a href="#前向扩散过程的解析式" class="headerlink" title="前向扩散过程的解析式"></a>前向扩散过程的解析式</h3><p>扩散过程是指对数据逐渐增加高斯噪音直至数据变成随机噪音的过程。给定真实图片样本$x_0 \sim q(x)$，扩散模型的前向过程通过$T$次<strong>累积</strong>对其添加高斯噪声，得到$x_1,x_2,…,x_T$，如下图所示。该过程的每一步都是对上一步得到的数据$x_{t-1}$增加高斯噪声，每一步要添加的噪声大小由一系列高斯分布方差${\beta_t }_{t&#x3D;1}^T$来控制，由于前向过程的每个时刻$t$只与$t-1$时刻有关，因此该过程也可看作是马尔科夫过程。</p><p>$$\begin{aligned} q(x_t|x_{t-1}) &amp;&#x3D; N(x_t; \sqrt{1- \beta_t}x_{t-1}, \beta_t I) \\ q(x_{1:T}|x_0) &amp;&#x3D; \prod_{t&#x3D;1}^T q(x_t|x_{t-1}) \end{aligned}$$</p><p>其中${\beta_t \in (0,1)}_{t&#x3D;1}^T$表示每一步添加高斯噪声的方差，介于0～1之间，它是预先设定的超参数，称为<strong>Noise schedule</strong>或<strong>Variance schedule</strong>。通常情况下，$\beta_t$是随着时间步$t$增大的，即满足$\beta_1 \lt \beta_2 \lt … \lt \beta_T$。如果扩散步数$T$足够大，那么最终得到的$x_T$就完全丢失了原始数据而变成了一个随机噪音。DDPM中的$\beta_t$参数采用一个线性的序列，是由0.0001到0.02（时间步T为1000）线性插值形成一个序列。</p><p><img src="/images/ddpm%E5%89%8D%E5%90%91%E8%BF%87%E7%A8%8B.jpg"></p><h4 id="重要技巧：重参数化"><a href="#重要技巧：重参数化" class="headerlink" title="重要技巧：重参数化"></a>重要技巧：重参数化</h4><p>如果我们要从某个分布中（比如高斯分布）随机采样一个样本，这个过程是无法反传梯度的，通常的做法是把随机性通过一个随机变量$\epsilon$引导过去，即若要从高斯分布$z \sim N(z; \mu_{\theta}, \sigma_{\theta}^2 I)$采样一个$z$，该过程可描述为：</p><p>$$z &#x3D; \mu_{\theta}+ \sigma_{\theta}^2 \epsilon, \epsilon \sim N(0,I)$$</p><p>上述的$z$依然是有随机性的，不过随机性转嫁到了$\epsilon$上，且$z$满足均值为$\mu_{\theta}$，方差为$\sigma_{\theta}^2$的高斯分布。这个采样过程是梯度可导的，其中$\mu_{\theta}, \sigma_{\theta}^2$可以由参数$\theta$的神经网络求解出来。</p><p>扩散过程就是逐步向数据添加噪声，通过重参数化，我们可以用下面的公式表示前向扩散过程：</p><p>$$x_t &#x3D; \sqrt{\alpha_t} x_{t-1} + \sqrt{1-\alpha_t} \epsilon_{t-1}$$</p><p>其中，${\alpha_t}^T_{t&#x3D;1}&#x3D;1-\beta_t$表示不同时间步要添加的噪声大小，已知$\beta_t$是随$t$增加的，则$\alpha_t$是随着$t$减小的，扩散过程前期添加噪声比例小，后期噪声比例大；$\epsilon_{t-1} \sim N(0,I)$表示高斯噪声。从上式可知前向过程逐步采样数据，效率太低，于是通过上述公式推导出由$x_0$直接到$x_t$的表达式：</p><p>$$\begin{aligned} x_t &amp;&#x3D; \sqrt{\alpha_t} x_{t-1} + \sqrt{1-\alpha_t} \epsilon_{t-1} \\ &amp;&#x3D; \sqrt{\alpha_t} (\sqrt{\alpha_{t-1}} x_{t-2} + \sqrt{1-\alpha_{t-1}} \epsilon_{t-2})+ \sqrt{1-\alpha_t} \epsilon_{t-1} \\ &amp;&#x3D; \sqrt{\alpha_t \alpha_{t-1}}x_{t-2} + \sqrt{\alpha_t (1-\alpha_{t-1})} \epsilon_{t-2} + \sqrt{1-\alpha_t} \epsilon_{t-1} \\ &amp;&#x3D; \sqrt{\alpha_t \alpha_{t-1}}x_{t-2} + \sqrt{\sqrt{\alpha_t (1-\alpha_{t-1})}^2 + \sqrt{1-\alpha_{t}}^2} \bar\epsilon_{t-2}, \bar\epsilon_{t-2} \sim N(0,I) \\ &amp;&#x3D;  \sqrt{\alpha_t \alpha_{t-1}}x_{t-2} + \sqrt{1- \alpha_t \alpha_{t-1}} \bar\epsilon_{t-2} \\ &amp;&#x3D; ….. \\ &amp;&#x3D; \sqrt{\bar \alpha_t} x_0 + \sqrt{1- \bar\alpha_t} \bar \epsilon_t , \bar \epsilon_t  \sim N(0,I)\end{aligned}$$</p><p>其中，$\bar \alpha_t &#x3D; \prod_{i&#x3D;1}^t \alpha_i$ 表示从$i&#x3D;1$开始的$\alpha_i$累乘；$\bar \epsilon_{t-2} \sim N(0,I)$表示$\epsilon_{t-1}$和$\epsilon_{t-2}$混合的高斯噪声，由两个独立高斯分布的相加性可知，两个高斯分布相加仍是高斯分布，即$N(0, \sigma_1^2I)+N(0, \sigma_2^2I) \sim N(0, (\sigma_1^2+\sigma_2^2)I)$，故$\bar \epsilon_{t-2}$表示$\epsilon_{t-2}$和$\epsilon_{t-1}$的混合高斯噪声，则$\bar \epsilon_t$表示所有时间步的混合的高斯噪声。</p><p>此时任意时刻的$x_t$满足：</p><p>$$q(x_t|x_0) &#x3D; N(x_t; \sqrt{\bar \alpha_t}x_0, (1- \bar \alpha_t)I)$$</p><p>首先，我们可以看到$x_t$其实可以看成是原始数据$x_0$和随机噪音$\bar \epsilon$的线性组合，其中$\sqrt{\bar \alpha_t}$和$\sqrt{1- \bar\alpha_t}$为组合系数，它们的平方和等于1；更近一步地，我们可以基于$\bar \alpha_t$而不是$\beta_t$来定义<strong>noise schedule</strong>，因为这样处理更直接，比如我们直接将$\bar \alpha_T$设定为一个接近0的值，那么就可以保证最终得到的$x_T$近似为一个随机噪音。</p><h3 id="反向生成过程的解析式"><a href="#反向生成过程的解析式" class="headerlink" title="反向生成过程的解析式"></a>反向生成过程的解析式</h3><p>反向生成过程就是数据去噪过程，它首先是从标准高斯分布中采样得到一个噪声样本，再一步步地迭代去噪，最后得到数据分布中的一个样本。如果我们知道反向过程的每一步的真实分布$q(x_{t-1}|x_t)$，那么从一个高斯噪声$x_T \sim N(0,I)$开始，逐渐去噪就能生成一个真实的样本，还原出原图分布$x_0 \sim q(x)$，所以反向过程也就是<strong>生成数据的过程</strong>。</p><blockquote><p>已经有人证明了如果$q(x_t|x_{t-1})$满足高斯分布且$\beta_t$足够小，$q(x_{t-1}|x_t)$ 仍然是一个高斯分布。</p></blockquote><p><img src="/images/ddpm%E5%8F%8D%E5%90%91%E8%BF%87%E7%A8%8B.jpg"></p><p>但是，估计反向的分布$q(x_{t-1}|x_t)$需要用到整个训练样本，因此可以用神经网络来估计这些分布。反向去噪的过程可以用公式表示为：</p><p>$$\begin{aligned} x_{t-1}&#x3D;\frac{1}{\sqrt{\alpha_t}}x_t-\frac{\sqrt{1- \alpha_t}}{\sqrt{\alpha_t}} \epsilon_{\theta}(x_t,t)+ \sigma_t \end{aligned}$$</p><p>其中，$\epsilon_{\theta}(x_t,t)$表示一个由$x_t$和$t$估计噪声的神经网络模型（$\theta$表示模型参数），$\sigma_t$表示估计噪声和实际噪声的差距。</p><blockquote><p>前向扩散和反向过程都是马尔可夫链，唯一的区别就是前向扩散里每一个条件概率的高斯分布的均值和方差都是已经确定的（依赖于$β_t$和$x_0$），而反向去噪过程里面的均值和方差是未知的，需要用神经网络去近似。</p></blockquote><p>由上述可知，反向过程也是一个马尔可夫链，只不过是由一系列<strong>用神经网络参数化的高斯分布</strong>来组成：</p><p>$$\begin{aligned} p_{\theta}(x_{0:T}) &amp;&#x3D; p(x_T) \prod_{t&#x3D;1}^T p_{\theta}(x_{t-1}|x_t) \\ p_{\theta}(x_{t-1}|x_t) &amp;&#x3D; N(x_{t-1}; \mu_{\theta}(x_t, t), \sum_{\theta}(x_t,t)) \end{aligned}$$</p><p>其中，$p(x_T)&#x3D;N(x_t;0,I)$，$p_{\theta}(x_{t-1}|x_t)$为参数化的高斯分布，均值和方差由训练的网络给出。虽然真实的条件分布$q(x_{t-1}|x_t)$无法直接求解，但是如果知道$x_0$，后验分布$q(x_{t-1}|x_t,x_0)$是可求解的。</p><p>$$q(x_{t-1}|x_t,x_0) &#x3D; N(x_{t-1}; \tilde \mu(x_t,x_0), \tilde \beta_t I)$$</p><p>根据贝叶斯公式，$q(x_{t-1}|x_t, x_0)$就可以直接写出</p><p>$$\begin{aligned}q(x_{t-1}|x_t,x_0) &amp;&#x3D; \frac{q(x_t,x_0,x_{t-1})}{q(x_t,x_0)} \\ &amp;&#x3D; \frac{q(x_0)q(x_{t-1}|x_0)q(x_t|x_0,x_{t-1})}{q(x_0)q(x_t|x_0)} \\ &amp;&#x3D; q(x_t|x_0,x_{t-1}) \frac{q(x_{t-1}|x_0)}{q(x_t|x_0)} \end{aligned}$$</p><p>从上面公式可以看出，后验分布$q(x_{t-1}|x_t,x_0)$的计算只依赖前向扩散过程。由于扩散过程的马尔卡夫链特性（在马尔可夫链中，下一状态的条件概率仅取决于当前状态，而不考虑之前的历史状态），则可以得到分布</p><p>$$q(x_t|x_0,x_{t-1})&#x3D; q(x_t|x_{t-1}) &#x3D; N(x_t;\sqrt{1-\beta_t}x_{t-1}, \beta_tI)$$</p><p>由前面得到的扩散过程的结论，以及一维高斯分布的定义：</p><p>$$\begin{aligned} q(x_t|x_0) &amp;&#x3D; N(x_t; \sqrt{\bar \alpha_t}x_0, (1- \bar \alpha_t)I) \\ f(x) &amp;&#x3D; \frac{1}{\sqrt{2 \pi \sigma}} \exp(-\frac{(x - \mu)^2}{2 \sigma^2}) \end{aligned}$$</p><p>可以得到：</p><p>$$\begin{aligned}q(x_{t-1}|x_t,x_0) &amp;&#x3D; q(x_t|x_{t-1})\frac{q(x_{t-1}|x_0)}{q(x_0)q(x_t|x_0)} \\ &amp;\propto \exp(-\frac{1}{2}(\frac{(x_t - \sqrt{\alpha_t}x_{t-1})^2}{\beta_t} + \frac{(x_{t-1} - \sqrt{\bar\alpha_{t-1}}x_{0})^2}{1-\bar \alpha_{t-1}} - \frac{(x_t - \sqrt{\bar\alpha_t}x_{0})^2}{1-\bar \alpha_t})) \\ &amp;&#x3D; \exp(-\frac{1}{2}(\frac{x_t^2 -2\sqrt{\alpha_t}x_{t-1}x_t + \alpha_tx_{t-1}^2}{\beta_t} + \frac{x_{t-1}^2 - 2\sqrt{\bar\alpha_{t-1}}x_{t-1}x_0 + \bar\alpha_{t-1}x_0^2}{1-\bar \alpha_{t-1}} - \frac{x_t^2 -2\sqrt{\bar\alpha_t}x_0x_t + \bar\alpha_tx_0^2}{1-\bar \alpha_t})) \\ &amp;&#x3D; \exp(-\frac{1}{2}((\frac{\alpha_t}{\beta_t}+\frac{1}{1-\bar \alpha_{t-1}})x_{t-1}^2-(\frac{2 \sqrt{\alpha_t}}{\beta_t}x_t + \frac{2\sqrt{\bar \alpha_{t-1}}}{1-\bar \alpha_{t-1}}x_0 )x_{t-1}+C(x_t,x_0)))\end{aligned}$$</p><p>这里只关注与$x_{t-1}$有关的部分，将其凑成正态分布指数的形式。方便起见可以简化上式为：</p><p>$$\begin{aligned}\exp(-\frac{1}{2}(Ax_{t-1}^2-Bx_{t-1}+C)) &amp;&#x3D; \exp(-\frac{A}{2}(x_{t-1}^2-\frac{B}{A}x_{t-1}) - \frac{C}{2}) \\ &amp;&#x3D; \exp(-\frac{A}{2}(x_{t-1}-\frac{B}{2A})^2 - \frac{C}{2}+\frac{B^2}{8A})\end{aligned}$$</p><p>我们可以得到后验分布$q(x_{t-1}|x_t,x_0)$的方差和均值：</p><p>$$\begin{aligned} \bar \beta_t &#x3D; \frac{1}{A} &#x3D; 1&#x2F;(\frac{\alpha_t-\bar \alpha_t+ \beta_t}{\beta_t(1-\bar\alpha_{t-1})}) &#x3D; \frac{1-\bar\alpha_{t-1}}{1-\bar\alpha_t}\beta_t \end{aligned}$$</p><p>$$\begin{aligned} \bar \mu_t &#x3D; \frac{B}{2A} &amp;&#x3D; (\frac{\sqrt{\alpha_t}}{\beta_t}x_t + \frac{\sqrt{\bar \alpha_{t-1}}}{1-\bar \alpha_{t-1}}x_0 ) &#x2F;(\frac{\alpha_t-\bar \alpha_t+ \beta_t}{\beta_t(1-\bar\alpha_{t-1})}) \\ &amp;&#x3D; (\frac{\sqrt{\alpha_t}}{\beta_t}x_t + \frac{\sqrt{\bar \alpha_{t-1}}}{1-\bar \alpha_{t-1}}x_0 ) \frac{1-\bar\alpha_{t-1}}{1-\bar\alpha_t}\beta_t \\ &amp;&#x3D; \frac{\sqrt{\alpha_t}(1-\bar\alpha_{t-1})}{1-\bar\alpha_t}x_t + \frac{\sqrt{\bar \alpha_{t-1}}\beta_t}{1-\bar\alpha_t}x_0 \end{aligned}$$</p><p>由前向扩散过程的推导公式可得，$x_0 &#x3D; (x_t - \sqrt{1-\bar \alpha_t}\bar\epsilon_t)&#x2F;\sqrt{\bar \alpha_t}$，将其代入上式可得：</p><p>$$\begin{aligned} \bar \mu_t &#x3D; \frac{1}{\sqrt{\alpha_t}}(x_t - \frac{1-\alpha_t}{\sqrt{1-\bar \alpha_t}}\bar \epsilon_t) \end{aligned}$$</p><p>可以看出，在给定$x_0$的条件下，<strong>后验条件高斯分布的均值只和超参数$\alpha$、$x_t$、$\epsilon_t$ 有关，方差只与超参数$\alpha$有关。</strong>通过以上的方差和均值，我们就得到了$q(x_{t-1}|x_t, x_0)$的<strong>解析形式</strong>。</p><p>综上所述，在训练阶段，由于样本$x_0$ 是已知的，所以可以通过后验分布$q(x_{t-1}|x_t,x_0) $来近似条件分布$q(x_{t-1}|x_t)$ 。神经网络$p_{\theta}(x_{t-1}|x_t)$通过学习后验分布$q(x_{t-1}|x_t, x_0)$进行训练，训练完毕后，推理时直接使用$p_{\theta}(x_{t-1}|x_t)$进行采样。</p><p>通过上述一系列推导，我们已经得到了反向生成过程的分布，该分布仍然是一个高斯分布，且得到了分布的均值和方差，则我们可以得到反向生成过程中每一时间步的采样公式：</p><p>$$\begin{aligned} q(x_{t-1}|x_t) &amp;&#x3D; N(x_{t-1}; \bar\mu_t, \bar\beta_tI) \\ x_{t-1}&amp;&#x3D;\frac{1}{\sqrt{\alpha_t}}(x_t - \frac{1-\alpha_t}{\sqrt{1-\bar \alpha_t}}\bar \epsilon_t) + \sqrt{\bar\beta_t}\epsilon \end{aligned}$$</p><p>这里依然使用了一个重参数化技巧：从分布$N(\mu, \sigma^2)$中采样可以实现为从$N(0,1)$采样出一个样本$\epsilon$，再计算$\mu+\sigma\epsilon$得到。通过重参数化即可实现从上述的$q(x_{t-1}|x_t) $高斯分布中采样出$x_{t-1}$。</p><h3 id="训练过程"><a href="#训练过程" class="headerlink" title="训练过程"></a>训练过程</h3><p>训练过程的伪代码如下：</p><p><img src="/images/DDPM_traincode.jpg"></p><h3 id="采样过程"><a href="#采样过程" class="headerlink" title="采样过程"></a>采样过程</h3><p>采样生成过程的伪代码如下：</p><p><img src="/images/DDPM_infercode.jpg"></p><h2 id="模型部分"><a href="#模型部分" class="headerlink" title="模型部分"></a>模型部分</h2><p>前面介绍了扩散模型的原理以及优化目标，那么扩散模型的核心就在于训练噪音预测模型，由于噪音和原始数据是同维度的，所以可以选择采用<strong>AutoEncoder架构</strong>来作为噪音预测模型。DDPM所采用的模型是一个基于residual block和attention block的<strong>U-Net模型</strong>。整体算法的训练过程如下图所示：</p><p><img src="/images/diffusion%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B.jpg"></p><p>U-Net属于encoder-decoder架构，在decoder模块中还引入了<strong>skip connection</strong>，即concat了encoder中间得到的同维度特征，这有利于网络优化。DDPM所采用的U-Net部分stage还加入了<strong>self-attention模块</strong>增加网络的全局建模能力。 另外，扩散模型其实需要的是$T$个噪音预测模型，实际处理时，需要增加一个<strong>time embedding</strong>（类似transformer中的position embedding）来将timestep信息编码到网络中，从而只需要训练一个共享的U-Net模型。具体地，DDPM在各个residual block都引入了<strong>time embedding</strong>，如上图所示。</p>]]></content>
      
      
      <categories>
          
          <category> 算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 算法知识 </tag>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>C++|结构体和对象的内存布局</title>
      <link href="/2024/01/30/c-zhi-shi/jie-gou-ti-he-dui-xiang-de-nei-cun-bu-ju/"/>
      <url>/2024/01/30/c-zhi-shi/jie-gou-ti-he-dui-xiang-de-nei-cun-bu-ju/</url>
      
        <content type="html"><![CDATA[<h1 id="结构体和对象的内存布局"><a href="#结构体和对象的内存布局" class="headerlink" title="结构体和对象的内存布局"></a>结构体和对象的内存布局</h1><p>结构体和C++对象由一个一个的成员变量组成，C和C++语言规范没有明确规定某个类型的变量必须是几个字节，不同的编译器定义的大小不同，可以通过C语言中的<code>sizeof()</code>进行查看。</p><table><thead><tr><th>基础变量大小</th><th>32位系统</th><th>64位系统</th></tr></thead><tbody><tr><td>sizeof(char)</td><td>1</td><td>1</td></tr><tr><td>sizeof(short)</td><td>2</td><td>2</td></tr><tr><td>sizeof(int)</td><td>4</td><td>4</td></tr><tr><td>sizeof(long)</td><td>4</td><td>8</td></tr><tr><td>sizeof(void*)</td><td>4</td><td>8</td></tr></tbody></table><h2 id="C-对象的大小"><a href="#C-对象的大小" class="headerlink" title="C++对象的大小"></a>C++对象的大小</h2><p>首先看一个最简单的对象，该对象只有一个<code>int</code>型的成员变量，此时一个对象的大小就是<code>int</code>型变量的大小，<code>sizeof(Child)</code>大小即为4。</p><pre class="line-numbers language-cpp"><code class="language-cpp"><span class="token keyword">class</span> <span class="token class-name">Child</span><span class="token punctuation">{</span>    <span class="token keyword">int</span> age<span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>把情况稍微变复杂一下，再加入一个<code>char</code>型的成员变量，此时的对象大小是$4+1&#x3D;5$个字节吗？此时使用<code>sizeof(Child)</code>查看会输出结果为8。</p><pre class="line-numbers language-cpp"><code class="language-cpp"><span class="token keyword">class</span> <span class="token class-name">Child</span><span class="token punctuation">{</span>    <span class="token keyword">int</span> age<span class="token punctuation">;</span>    <span class="token keyword">char</span> sex<span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>为什么会这样呢，这里涉及到一个知识点<strong>内存对齐</strong>。内存对齐是指数据在内存中存储时，按照一定规则对齐的过程，内存对齐的<strong>目的是为了提高数据访问的效率</strong>。当数据按照对齐方式进行存储时，CPU可以更快地读取和写入数据。</p><p><img src="/images/%E5%86%85%E5%AD%98%E5%AF%B9%E9%BD%90.png"></p><h2 id="内存对齐"><a href="#内存对齐" class="headerlink" title="内存对齐"></a>内存对齐</h2><h3 id="内存对齐的规则"><a href="#内存对齐的规则" class="headerlink" title="内存对齐的规则"></a>内存对齐的规则</h3><p>内存对齐的两个规则：</p><ol><li>数据的起始地址必须是其自身大小的整数倍。比如一个<code>int</code>型数据，在内存中的起始地址必须是4的倍数。</li><li>结构体和对象的对齐值是其成员中占用内存最大的数据类型的大小。比如一个对象包含了一个<code>int</code>和一个<code>char</code>型，则其对齐值就是4，即起始地址必须是4的整数倍。</li></ol><p>基于上述规则，在32位系统上来看一个例子</p><pre class="line-numbers language-cpp"><code class="language-cpp"><span class="token keyword">class</span> <span class="token class-name">Child</span><span class="token punctuation">{</span>    <span class="token keyword">int</span> age<span class="token punctuation">;</span>    <span class="token keyword">char</span> sex<span class="token punctuation">;</span>    <span class="token keyword">short</span> height<span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token punctuation">;</span><span class="token keyword">class</span> <span class="token class-name">Child</span><span class="token punctuation">{</span>    <span class="token keyword">int</span> age<span class="token punctuation">;</span>    <span class="token keyword">char</span> sex<span class="token punctuation">;</span>    <span class="token keyword">char</span><span class="token operator">*</span> name<span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>对于上述的第一个对象，由于<code>short</code>型占2个字节，所以数据的起始地址必须是2的整数倍（第一条规则），所以变量<code>sex</code>和<code>height</code>进行填充以对齐内存，整个对象的大小是8个字节。</p><p>对于上述的第二个对象，由于<code>char*</code>占4个字节（32bit系统），所以起始地址必须是4的整数倍，而不能紧跟在<code>char</code>变量的地址后面，中间空出来的地址进行填充，整个对象的大小是12个字节。</p><p><img src="/images/%E5%86%85%E5%AD%98%E5%AF%B9%E9%BD%902.png"><img src="/images/%E5%86%85%E5%AD%98%E5%AF%B9%E9%BD%903.png"></p><p>让我们把情况变得更复杂一点，假设类里面有一个虚函数，此时的对象大小是多少呢，内存又是怎么布局的呢？</p><pre class="line-numbers language-cpp"><code class="language-cpp"><span class="token keyword">class</span> <span class="token class-name">Child</span><span class="token punctuation">{</span>        <span class="token keyword">int</span> age<span class="token punctuation">;</span>    <span class="token keyword">virtual</span> <span class="token keyword">void</span> <span class="token function">talk</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">{</span>        <span class="token function">printf</span><span class="token punctuation">(</span><span class="token string">"hello"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>虚函数是C++里面的一个重要机制，直接关系着面向对象中的多态性的实现。在有虚函数的对象中，会有一个隐含的指针——虚表指针，该指针指向一个虚函数表，表中存储着每个虚函数的地址。</p><p><img src="/images/%E8%99%9A%E5%87%BD%E6%95%B0%E8%A1%A8.png"><img src="/images/%E8%99%9A%E5%87%BD%E6%95%B0%E8%A1%A82.png"></p><p>如果此时在类中再加入一个虚函数，则该对象的大小会变大吗。答案是否定的，因为新加入的虚函数，只会将其函数地址放在虚函数表里，实际并不占用对象的大小。如上面右图所示。</p><p>接下来看一下64位系统上的情况。64位系统中一个指针占8个字节，如下的类定义中，对齐之后的对象占据大小就是16个字节。</p><pre class="line-numbers language-cpp"><code class="language-cpp"><span class="token keyword">class</span> <span class="token class-name">Child</span><span class="token punctuation">{</span>    <span class="token keyword">int</span> age<span class="token punctuation">;</span>    <span class="token keyword">char</span><span class="token operator">*</span> name<span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p><img src="/images/%E5%86%85%E5%AD%98%E5%AF%B9%E9%BD%904.png"></p><h3 id="自定义内存对齐"><a href="#自定义内存对齐" class="headerlink" title="自定义内存对齐"></a>自定义内存对齐</h3><p>在涉及到通信时，我们定义的通信协议里（TCP&#x2F;IP，BLE）涉及的数据都是精确到bit的，半个字节都不会浪费。此时我们并不想让编译器在内存中填充，就想让成员变量紧挨着存放。C&#x2F;C++对这种情况也有处理方法，可以使用预编译指令<code>#program pack()</code>来自定义对齐的大小。比如下面的代码，对齐大小是1，此时就不会将变量<code>sex</code>和<code>height</code>之间进行填充，整个对象的大小是7个字节。</p><pre class="line-numbers language-cpp"><code class="language-cpp"><span class="token macro property"># program pack(1)</span><span class="token keyword">class</span> <span class="token class-name">Child</span><span class="token punctuation">{</span>    <span class="token keyword">int</span> age<span class="token punctuation">;</span>    <span class="token keyword">char</span> sex<span class="token punctuation">;</span>    <span class="token keyword">short</span> height<span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token punctuation">;</span><span class="token macro property"># program pack()</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> 编程语言 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> C++ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Pytorch|多卡并行训练</title>
      <link href="/2024/01/26/pytorch-ji-chu-zhi-shi/duo-qia-bing-xing-xun-lian/"/>
      <url>/2024/01/26/pytorch-ji-chu-zhi-shi/duo-qia-bing-xing-xun-lian/</url>
      
        <content type="html"><![CDATA[<h1 id="多卡并行训练"><a href="#多卡并行训练" class="headerlink" title="多卡并行训练"></a>多卡并行训练</h1><h2 id="并行训练"><a href="#并行训练" class="headerlink" title="并行训练"></a>并行训练</h2><p>使用并行的方式训练模型，主要有两点原因：</p><ol><li>模型在一块GPU上放不下，两块或多块GPU上就能运行完整的模型（如早期的AlexNet）。</li><li>多块GPU并行计算可以减少训练时间，达到加速训练的效果。</li></ol><p>基于上述两点原因，则出现了两种多GPU训练的方法：</p><ol><li><strong>模型并行方式：</strong>如果模型特别大，GPU显存不够，无法将一个显存放在GPU上，需要把网络的不同模块放在不同GPU上，这样可以训练比较大的网络。</li><li><strong>数据并行方式：</strong>将整个模型放在一块GPU里，再复制到每一块GPU上，每块GPU跑不同的数据，同时进行正向传播和反向误差传播。相当于加大了batch_size。</li></ol><h3 id="并行训练的一些概念"><a href="#并行训练的一些概念" class="headerlink" title="并行训练的一些概念"></a>并行训练的一些概念</h3><ul><li><p>node：表示一个物理节点，通俗来说就是一台机器。节点内部可以有多个GPU（一台机器有多张卡）。</p></li><li><p>rank和local_rank：表示进程的序号，用于在进程间通信。每个进程对应一个rank。</p><ul><li>rank：全局rank，是指在整个分布式任务中进程的序号，例如机器一有8个GPU，机器二也有8个GPU，则rank为0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15。</li><li>local_rank：本地rank，是指在一个节点上（机器）进程的相对序号，例如机器一上local_rank有0,1,2,3,4,5,6,7，机器二上local_rank也有0,1,2,3,4,5,6,7。</li><li>local_rank在node之间相互独立。单机多卡时，rank就等于local_rank。</li></ul></li><li><p>nnodes：表示物理节点数量（机器数量）。</p></li><li><p>node_rank：表示物理节点（机器）的ID序号，0号机器ID为1，1号机器ID为1。</p></li><li><p>nproc_per_node：表示每个物理节点上面进程的数量。</p></li><li><p>group：进程组，默认只有一个组</p></li><li><p>world_size：表示进程总数，即全局（一个分布式任务）中rank的数量。M为机器数，N为每台机器使用的GPU数，则world_size为M*N。</p></li></ul><h3 id="Pytorch中的两种并行方式"><a href="#Pytorch中的两种并行方式" class="headerlink" title="Pytorch中的两种并行方式"></a>Pytorch中的两种并行方式</h3><p>Pytorch提供了两种GPU并行训练的手段，DP（<strong>DataParallel</strong>）和DDP（<strong>DistributedDataParallel</strong>），但是DP只会开一个进程去管理，计算资源分配不均，DDP上我们倾向于一张卡开一个进程，使得我们的计算资源能够最大化的利用。</p><ol><li>DataParallel是一种单进程多线程的方式，每个GPU是一个线程，仅仅能工作在单机中；</li><li>DistributedDataParallel是多进程的方式，每个GPU是一个进程，可以工作在单机或多机器中</li><li>DataParallel通常会慢于DistributedDataParallel。官方推荐使用的方法是DistributedDataParallel。</li></ol><h2 id="Pytoch的DDP训练"><a href="#Pytoch的DDP训练" class="headerlink" title="Pytoch的DDP训练"></a>Pytoch的DDP训练</h2><h3 id="DDP的两种启动方式"><a href="#DDP的两种启动方式" class="headerlink" title="DDP的两种启动方式"></a>DDP的两种启动方式</h3><h4 id="distributed-launch"><a href="#distributed-launch" class="headerlink" title="distributed.launch"></a>distributed.launch</h4><p>较老版本的PyTorch应使用下面这条命令：</p><pre class="line-numbers language-shell"><code class="language-shell">export CUDA_VISIBLE_DEVICES=2,3python -m torch.distributed.launch --nproc_per_node = 4 train.py --batch_size 64<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>torch v1.10 以上可以使用如下的命令：</p><pre class="line-numbers language-shell"><code class="language-shell">export CUDA_VISIBLE_DEVICES=2,3torchrun --nproc_per_node=4 train.py --batch_size 64<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>注：distributed.launch方法如果开始训练后，手动终止程序，有小概率进程没kill的情况，会占用GPU显存资源。</p><h4 id="multiprocessing"><a href="#multiprocessing" class="headerlink" title="multiprocessing"></a>multiprocessing</h4><p>除了使用<code>torch.distributed.launch</code>，也可以手动使用 <code>torch.multiprocessing</code>进行多进程控制，而避免<code>torch.distributed.launch</code>自动控制开启和退出进程的一些小毛病。</p><pre class="line-numbers language-shell"><code class="language-shell">python train.py<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>可参考MoCo代码。</p><h3 id="DDP训练代码详解-launch"><a href="#DDP训练代码详解-launch" class="headerlink" title="DDP训练代码详解(launch)"></a>DDP训练代码详解(launch)</h3><h4 id="初始化过程"><a href="#初始化过程" class="headerlink" title="初始化过程"></a>初始化过程</h4><p>首先要初始化多进程环境，nvidia显卡推荐各个进程间（显卡）通信使用NCCL协议。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> torch <span class="token keyword">import</span> distributed <span class="token keyword">as</span> dist<span class="token keyword">def</span> <span class="token function">init_distributed_mode</span><span class="token punctuation">(</span>args<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">if</span><span class="token string">'RANK'</span><span class="token keyword">in</span> os<span class="token punctuation">.</span>environ <span class="token operator">and</span><span class="token string">'WORLD_SIZE'</span><span class="token keyword">in</span> os<span class="token punctuation">.</span>environ<span class="token punctuation">:</span>        args<span class="token punctuation">.</span>rank <span class="token operator">=</span> int<span class="token punctuation">(</span>os<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">"RANK"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        args<span class="token punctuation">.</span>world_size <span class="token operator">=</span> int<span class="token punctuation">(</span>os<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">'WORLD_SIZE'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        args<span class="token punctuation">.</span>gpu <span class="token operator">=</span> int<span class="token punctuation">(</span>os<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">'LOCAL_RANK'</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># LOCAL_RANK代表某个机器上第几块GPU</span>    <span class="token keyword">else</span><span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Not using distributed mode'</span><span class="token punctuation">)</span>        args<span class="token punctuation">.</span>distributed <span class="token operator">=</span> <span class="token boolean">False</span>        <span class="token keyword">return</span>    args<span class="token punctuation">.</span>distributed <span class="token operator">=</span> <span class="token boolean">True</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>device_count<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 打印gpu数量</span>    torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>set_device<span class="token punctuation">(</span>args<span class="token punctuation">.</span>gpu<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 对当前进程指定使用的GPU</span>    dist<span class="token punctuation">.</span>init_process_group<span class="token punctuation">(</span>backend<span class="token operator">=</span><span class="token string">'nccl'</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 通信后端，nvidia GPU推荐使用NCCL</span>    dist<span class="token punctuation">.</span>barrier<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 等待每个GPU都运行完这个地方以后再继续</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>在训练之前需要注意的是，学习率需要根据batch_size增加（多卡扩增了batch_size），可以使用简单的线性倍增方法。</p><pre class="line-numbers language-python"><code class="language-python">args<span class="token punctuation">.</span>lr <span class="token operator">*=</span> args<span class="token punctuation">.</span>world_size<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="数据构造"><a href="#数据构造" class="headerlink" title="数据构造"></a>数据构造</h4><p>构造数据集可以使用与单卡相同的方法，但在样本采样时和单机不同，需要使用<code>DistributedSampler</code>和<code>BatchSampler</code>。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> Dataset<span class="token punctuation">,</span> DataLoader<span class="token punctuation">,</span> BatchSampler<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>distributed <span class="token keyword">import</span> DistributedSampler<span class="token comment" spellcheck="true"># 给每个rank对应的进程分配训练的样本索引</span>train_sampler <span class="token operator">=</span> DistributedSampler<span class="token punctuation">(</span>train_data_set<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 将样本索引每batch_size个元素组成一个list</span>train_batch_sampler <span class="token operator">=</span> BatchSampler<span class="token punctuation">(</span>train_sampler<span class="token punctuation">,</span> batch_size<span class="token punctuation">,</span> drop_last<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>train_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>train_data_set<span class="token punctuation">,</span> batch_sampler<span class="token operator">=</span>train_batch_sampler<span class="token punctuation">,</span>                pin_memory<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>num_workers<span class="token operator">=</span>nw<span class="token punctuation">,</span>collate_fn<span class="token operator">=</span>train_data_set<span class="token punctuation">.</span>collate_fn<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><code>DistributedSampler</code>原理如图所示：假设当前数据集有0~10共11个样本，使用2块GPU计算。首先打乱数据顺序，然后用 11&#x2F;2 &#x3D;6（向上取整），然后6乘以GPU个数2 &#x3D; 12，因为只有11个数据，所以再把第一个数据（索引为6的数据）补到末尾，现在就有12个数据可以均匀分到每块GPU。然后分配数据：间隔将数据分配到不同的GPU中。</p><p><img src="/images/DistributedSampler.png"></p><p><code>BatchSampler</code>原理：<code>DistributedSmpler</code>将数据分配到两个GPU上，以第一个GPU为例，分到的数据是6，9，10，1，8，7，假设batch_size&#x3D;2，就按顺序把数据两两一组，在训练时，每次获取一个batch的数据，就从组织好的一个个batch中取到。注意：只对训练集处理，验证集不使用BatchSampler。</p><p><img src="/images/BatchSampler.png"></p><p>当然，也可以只使用<code>DistributedSampler</code>，<code>Dataloader</code>内部会做好数据按batch_size分块处理的操作。注意shuffle与sampler是冲突的，并行训练需要设置sampler，此时务必要把shuffle设为False，数据乱序的方式交给sampler来控制。</p><pre class="line-numbers language-python"><code class="language-python">dataset <span class="token operator">=</span> MyDataset<span class="token punctuation">(</span><span class="token punctuation">)</span>train_sampler <span class="token operator">=</span> DistributedSampler<span class="token punctuation">(</span>dataset<span class="token punctuation">)</span>dataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>dataset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> sampler<span class="token operator">=</span>train_sampler<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h4 id="模型并行"><a href="#模型并行" class="headerlink" title="模型并行"></a>模型并行</h4><p>在这种并行训练方式下，每个模型使用完全相同的参数。在训练时，各个进程并行；在梯度下降时，各个进程会同步一次，保证每个进程的模型都更新相同的梯度，PyTorch又帮我们封装好了这些细节。我们只需要在现有模型上套一层<code>DistributedDataParallel</code>，就可以让模型在后续<code>backward</code>的时候自动同步梯度了。</p><pre class="line-numbers language-python"><code class="language-python">model <span class="token operator">=</span> MyModel<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>args<span class="token punctuation">.</span>gpu<span class="token punctuation">)</span>model <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>SyncBatchNorm<span class="token punctuation">.</span>convert_sync_batchnorm<span class="token punctuation">(</span>model<span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># model中有BN层</span>ddp_model <span class="token operator">=</span> DistributedDataParallel<span class="token punctuation">(</span>model<span class="token punctuation">,</span> device_ids<span class="token operator">=</span><span class="token punctuation">[</span>args<span class="token punctuation">.</span>gpu<span class="token punctuation">]</span><span class="token punctuation">)</span>loss_fn <span class="token operator">=</span> nn<span class="token punctuation">.</span>MSELoss<span class="token punctuation">(</span><span class="token punctuation">)</span>optimizer <span class="token operator">=</span> optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>ddp_model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.001</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>注意，如果模型中使用了BN层，则需要使用<code>SyncBatchNorm</code>对<strong>多个GPU的BN层进行同步</strong>。BN的特性是batch_size越大，均值和方差越接近与整个数据集的均值和方差，效果越好，所以多GPU训练时模型中使用BN则需要在多个GPU上进行BN的同步计算。但是由于需要对多个GPU上的批量数据进行聚合并计算整体的均值和方差，这里涉及多进程的通信，所以如果模型中有较多BN层，则<code>SyncBatchNorm</code>会降低模型训练速度。</p><p><img src="/images/%E5%90%8C%E6%AD%A5BN.png"></p><h4 id="训练过程"><a href="#训练过程" class="headerlink" title="训练过程"></a>训练过程</h4><p>准备好了一切后，就可以开始训练模型了。在每个新epoch中，要用<code>train_sampler.set_epoch(epoch)</code>更新<code>sampler</code>，根据epoch参数设置不同的随机种子，改变打乱数据的顺序，可以让不同GPU每个epoch拿到的数据不同。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">for</span> epoch <span class="token keyword">in</span> range<span class="token punctuation">(</span>epoch_num<span class="token punctuation">)</span><span class="token punctuation">:</span>    train_sampler<span class="token punctuation">.</span>set_epoch<span class="token punctuation">(</span>epoch<span class="token punctuation">)</span>    <span class="token keyword">for</span> x <span class="token keyword">in</span> dataloader<span class="token punctuation">:</span>        x <span class="token operator">=</span> x<span class="token punctuation">.</span>to<span class="token punctuation">(</span>args<span class="token punctuation">.</span>gpu<span class="token punctuation">)</span>        y <span class="token operator">=</span> ddp_model<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>        loss <span class="token operator">=</span> loss_fn<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span>        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="/images/set_epoch.png"></p><p>训练完模型后，应该保存模型。由于每个进程的模型都是一样的，我们只需要让主进程来保存模型即可。注意，在保存模型时，其他进程不要去修改模型参数。这里最好加上一行<code>dist.barrier()</code>，它可以用来同步进程的运行状态，即只有0号GPU的进程存完了模型，所有GPU再进行下一步操作。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">if</span> args<span class="token punctuation">.</span>rank <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>    torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>ddp_model<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> ckpt_path<span class="token punctuation">)</span>dist<span class="token punctuation">.</span>barrier<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>最后还需要撤销进程组，释放资源</p><pre class="line-numbers language-python"><code class="language-python">dist<span class="token punctuation">.</span>destroy_process_group<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 撤销进程组</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h4><p>读取模型时需要注意一下。模型存储参数时会保存参数所在设备。由于我们只用了0号GPU的进程存模型，所有参数的<code>device</code>都是<code>cuda:0</code>。而读取模型时，每个设备上的模型都要去读一次模型，参数的位置要做一个调整。</p><pre class="line-numbers language-python"><code class="language-python">map_location <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">'cuda:0'</span><span class="token punctuation">:</span> f<span class="token string">'cuda:{args.gpu}'</span><span class="token punctuation">}</span>state_dict <span class="token operator">=</span> torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>ckpt_path<span class="token punctuation">,</span> map_location<span class="token operator">=</span>map_location<span class="token punctuation">)</span>ddp_model<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>state_dict<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>这里还有一个重要的细节。使用<code>DistributedDataParallel</code>把<code>model</code>封装成<code>ddp_model</code>后，模型的参数名里多了一个<code>module</code>。这是因为原来的模型<code>model</code>被保存到了<code>ddp_model.module</code>这个成员变量中（<code>ddp_model.module = model</code>）。在混用单GPU和多GPU的训练代码时，要注意这个参数名不兼容的问题。最好的写法是每次存取<code>ddp_model.module</code>，这样单GPU和多GPU的checkpoint可以轻松兼容。</p><p><strong>注意</strong>：如果从头开始训练，<strong>为了保证各个进程的模型参数完全相同，会先以主进程生成一个初始权重，以临时文件的形式保存，其他进程读取该模型权重进行初始化</strong>。下面是一个简单的并行训练代码示例。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> os<span class="token keyword">import</span> torch<span class="token keyword">import</span> torch<span class="token punctuation">.</span>distributed <span class="token keyword">as</span> dist<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn<span class="token keyword">import</span> torch<span class="token punctuation">.</span>optim <span class="token keyword">as</span> optim<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> Dataset<span class="token punctuation">,</span> DataLoader<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>distributed <span class="token keyword">import</span> DistributedSampler<span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>parallel <span class="token keyword">import</span> DistributedDataParallel<span class="token keyword">def</span> <span class="token function">setup</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    dist<span class="token punctuation">.</span>init_process_group<span class="token punctuation">(</span><span class="token string">'nccl'</span><span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">cleanup</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    dist<span class="token punctuation">.</span>destroy_process_group<span class="token punctuation">(</span><span class="token punctuation">)</span>ckpt_path <span class="token operator">=</span> <span class="token string">'tmp.pth'</span><span class="token keyword">def</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    setup<span class="token punctuation">(</span><span class="token punctuation">)</span>    rank <span class="token operator">=</span> dist<span class="token punctuation">.</span>get_rank<span class="token punctuation">(</span><span class="token punctuation">)</span>    pid <span class="token operator">=</span> os<span class="token punctuation">.</span>getpid<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">'current pid: {pid}'</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">'Current rank {rank}'</span><span class="token punctuation">)</span>    device_id <span class="token operator">=</span> rank <span class="token operator">%</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>device_count<span class="token punctuation">(</span><span class="token punctuation">)</span>    dataset <span class="token operator">=</span> MyDataset<span class="token punctuation">(</span><span class="token punctuation">)</span>    sampler <span class="token operator">=</span> DistributedSampler<span class="token punctuation">(</span>dataset<span class="token punctuation">)</span>    dataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>dataset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> sampler<span class="token operator">=</span>sampler<span class="token punctuation">)</span>    model <span class="token operator">=</span> ToyModel<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device_id<span class="token punctuation">)</span>    ddp_model <span class="token operator">=</span> DistributedDataParallel<span class="token punctuation">(</span>model<span class="token punctuation">,</span> device_ids<span class="token operator">=</span><span class="token punctuation">[</span>device_id<span class="token punctuation">]</span><span class="token punctuation">)</span>    loss_fn <span class="token operator">=</span> nn<span class="token punctuation">.</span>MSELoss<span class="token punctuation">(</span><span class="token punctuation">)</span>    optimizer <span class="token operator">=</span> optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>ddp_model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.001</span><span class="token punctuation">)</span>    <span class="token keyword">if</span> rank <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span> <span class="token comment" spellcheck="true"># 临时保存初始化权重</span>        torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>ddp_model<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> ckpt_path<span class="token punctuation">)</span>    dist<span class="token punctuation">.</span>barrier<span class="token punctuation">(</span><span class="token punctuation">)</span>    map_location <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">'cuda:0'</span><span class="token punctuation">:</span> f<span class="token string">'cuda:{device_id}'</span><span class="token punctuation">}</span>    state_dict <span class="token operator">=</span> torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>ckpt_path<span class="token punctuation">,</span> map_location<span class="token operator">=</span>map_location<span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 保证各进程参数权重完全相同</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">'rank {rank}: {state_dict}'</span><span class="token punctuation">)</span>    ddp_model<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>state_dict<span class="token punctuation">)</span>    <span class="token keyword">for</span> epoch <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        sampler<span class="token punctuation">.</span>set_epoch<span class="token punctuation">(</span>epoch<span class="token punctuation">)</span>        <span class="token keyword">for</span> x <span class="token keyword">in</span> dataloader<span class="token punctuation">:</span>            <span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">'epoch {epoch}, rank {rank} data: {x}'</span><span class="token punctuation">)</span>            x <span class="token operator">=</span> x<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device_id<span class="token punctuation">)</span>            y <span class="token operator">=</span> ddp_model<span class="token punctuation">(</span>x<span class="token punctuation">)</span>            optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>            loss <span class="token operator">=</span> loss_fn<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span>            loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>            optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>    cleanup<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>    main<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="初学者容易踩的坑"><a href="#初学者容易踩的坑" class="headerlink" title="初学者容易踩的坑"></a>初学者容易踩的坑</h3><p>我们在看很多大佬写的代码时候，特别是涉及到<strong>分布式训练</strong>的时候会发现在 argsparse 中添加了这样一个参数“–loacl_rank”，比如下面的代码</p><pre class="line-numbers language-python"><code class="language-python">parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--local_rank'</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> type<span class="token operator">=</span>int<span class="token punctuation">)</span>  args <span class="token operator">=</span> parser<span class="token punctuation">.</span>parse_args<span class="token punctuation">(</span><span class="token punctuation">)</span>torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>set_device<span class="token punctuation">(</span>args<span class="token punctuation">.</span>local_rank<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>首先，这个命令行参数“–loacl_rank”是必须声明的，但<strong>它不是由用户填写的，而是由pytorch的<code>distributed.launch</code>模块为用户填写</strong>，也就是说这个值是会被自动赋值为当前进程在本机上的rank。</p><p>但是，还有很多大佬的代码在分布式训练中并没有声明命令行参数“–loacl_rank”，但程序同样可以运行，这是为什么呢？这和代码的启动命令有关，当使用下面的启动命令时，则可以不使用命令行参数“–loacl_rank”。</p><pre class="line-numbers language-shell"><code class="language-shell">python -m torch.distributed.launch --nproc_per_node=3 --use_env train.py<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>对于“–use_env”官方是这样解释的：</p><p><img src="/images/use_env.png"></p><p>大意是说，声明“–use_env”后，pytorch会将当前进程在本机上的rank添加到<strong>环境变量</strong>“LOCAL_RANK”中，而不再添加到<strong>命令行参数</strong><code>args.local_rank</code>中。该方式正如上文<em><strong>初始化过程</strong></em>小节中的<code>init_distributed_mode</code>函数所写。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> os<span class="token keyword">import</span> argparse<span class="token keyword">def</span> <span class="token function">main</span><span class="token punctuation">(</span>args<span class="token punctuation">)</span><span class="token punctuation">:</span>    local_rank <span class="token operator">=</span> args<span class="token punctuation">.</span>local_rank    <span class="token keyword">print</span><span class="token punctuation">(</span>local_rank<span class="token punctuation">,</span> os<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">'LOCAL_RANK'</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># None 0</span><span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>    parser <span class="token operator">=</span> argparse<span class="token punctuation">.</span>ArgumentParser<span class="token punctuation">(</span><span class="token punctuation">)</span>    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">"--local_rank"</span><span class="token punctuation">,</span> type<span class="token operator">=</span>int<span class="token punctuation">)</span>    args <span class="token operator">=</span> parser<span class="token punctuation">.</span>parse_args<span class="token punctuation">(</span><span class="token punctuation">)</span>    main<span class="token punctuation">(</span>args<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>官方现在已经建议废弃使用<code>torch.distributed.launch</code>，转而使用<code>torchrun</code>，而这个<code>torchrun</code>已经把“–use_env”这个参数废弃了，<strong>而强制要求用户从环境变量LOACL_RANK里获取当前进程在本机上的rank</strong>。</p><p>然而，即使我们不使用命令行参数“–loacl_rank”和“–use_env”，我们依然可以通过代码找到当前进程在本机的rank。正如前文所述的一份简单的并行训练代码示例，通过<code>torch.distributed.get_rank()</code>可以找到当前进程的rank，以此设置数据和模型拷贝到对应GPU位置。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token punctuation">.</span>distributed <span class="token keyword">as</span> distrank <span class="token operator">=</span> dist<span class="token punctuation">.</span>get_rank<span class="token punctuation">(</span><span class="token punctuation">)</span>torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>set_device<span class="token punctuation">(</span>rank<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h3 id="DDP训练代码详解-multiprocessing"><a href="#DDP训练代码详解-multiprocessing" class="headerlink" title="DDP训练代码详解(multiprocessing)"></a>DDP训练代码详解(multiprocessing)</h3><p><code>torch.multiprocessing</code>使用较为简单，只需要调用<code>torch.multiprocessing.spawn</code>，<code>torch.multiprocessing</code>会帮助我们自动创建进程。如下面的代码所示，spawn 开启了4 个进程，每个进程执行 <code>main_worker()</code>并向其中传入local_rank（当前进程【GPU】索引）、ngpus_per_node和 args（即 myargs）作为参数：</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token punctuation">.</span>multiprocessing <span class="token keyword">as</span> mpparser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--local_rank'</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> type<span class="token operator">=</span>int<span class="token punctuation">)</span>  myargs <span class="token operator">=</span> parser<span class="token punctuation">.</span>parse_args<span class="token punctuation">(</span><span class="token punctuation">)</span>mp<span class="token punctuation">.</span>spawn<span class="token punctuation">(</span>main_worker<span class="token punctuation">,</span> nprocs<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">,</span> args<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> myargs<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>这里直接将原本需要<code>torch.distributed.launch</code>管理的执行内容，封装进<code>main_worker()</code>函数中，其中  proc 对应 local_rank（当前进程索引），ngpus_per_node 对应4， args 对应 myargs。值得注意的是，由于没有 <code>torch.distributed.launch</code>读取的默认环境变量作为配置，我们需要手动为<code>init_process_group()</code>指定参数：</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">main_worker</span><span class="token punctuation">(</span>gpu<span class="token punctuation">,</span> ngpus_per_node<span class="token punctuation">,</span> args<span class="token punctuation">)</span><span class="token punctuation">:</span>   dist<span class="token punctuation">.</span>init_process_group<span class="token punctuation">(</span>backend<span class="token operator">=</span><span class="token string">'nccl'</span><span class="token punctuation">,</span> init_method<span class="token operator">=</span><span class="token string">'tcp://127.0.0.1:23456'</span><span class="token punctuation">,</span> world_size<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">,</span> rank<span class="token operator">=</span>gpu<span class="token punctuation">)</span>   torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>set_device<span class="token punctuation">(</span>args<span class="token punctuation">.</span>local_rank<span class="token punctuation">)</span>   train_dataset <span class="token operator">=</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>   train_sampler <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>distributed<span class="token punctuation">.</span>DistributedSampler<span class="token punctuation">(</span>train_dataset<span class="token punctuation">)</span>   train_loader <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>train_dataset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> sampler<span class="token operator">=</span>train_sampler<span class="token punctuation">)</span>   model <span class="token operator">=</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>   model <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>parallel<span class="token punctuation">.</span>DistributedDataParallel<span class="token punctuation">(</span>model<span class="token punctuation">,</span> device_ids<span class="token operator">=</span><span class="token punctuation">[</span>args<span class="token punctuation">.</span>local_rank<span class="token punctuation">]</span><span class="token punctuation">)</span>   optimizer <span class="token operator">=</span> optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>   <span class="token keyword">for</span> epoch <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    train_sampler<span class="token punctuation">.</span>set_epoch<span class="token punctuation">(</span>epoch<span class="token punctuation">)</span>      <span class="token keyword">for</span> batch_idx<span class="token punctuation">,</span> <span class="token punctuation">(</span>data<span class="token punctuation">,</span> target<span class="token punctuation">)</span> <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>train_loader<span class="token punctuation">)</span><span class="token punctuation">:</span>          images <span class="token operator">=</span> images<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span>non_blocking<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>          target <span class="token operator">=</span> target<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span>non_blocking<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>          <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>          output <span class="token operator">=</span> model<span class="token punctuation">(</span>images<span class="token punctuation">)</span>          loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>output<span class="token punctuation">,</span> target<span class="token punctuation">)</span>          <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>          optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>          loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>          optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> Pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Pytorch </tag>
            
            <tag> 多卡并行训练 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>浮点数和混合精度</title>
      <link href="/2024/01/19/ji-suan-ji-ji-chu/jing-du-he-fu-dian-shu/"/>
      <url>/2024/01/19/ji-suan-ji-ji-chu/jing-du-he-fu-dian-shu/</url>
      
        <content type="html"><![CDATA[<h1 id="浮点数和混合精度"><a href="#浮点数和混合精度" class="headerlink" title="浮点数和混合精度"></a>浮点数和混合精度</h1><h2 id="浮点数存储格式"><a href="#浮点数存储格式" class="headerlink" title="浮点数存储格式"></a>浮点数存储格式</h2><p>根据小数点是否固定，计算机中的数据分为浮点和定点。浮点数存储遵循IEEE标准，由如下部分组成：符号位s，指数位exp，尾数位frac。根据浮点数存储的位数不同，浮点数分为双精度浮点数（double, 64bit）、单精度浮点数（float, 32bit）、半精度浮点数（fp16, 16bit）。</p><p><img src="/images/%E6%B5%AE%E7%82%B9%E6%95%B0.png"></p><p>根据IEEE标准规定，任意一个浮点数都必须表示为</p><p>$$(-1)^{S} \times 2^E \times M$$</p><p>其中S为符号位：S为0表示正数，S为1表示负数；E为指数；M为有效数字，$M \in [1, 2)$。将十进制转换为二进制，比如178.125转二进制为（对于浮点数而言178.125可以精确存储）：</p><blockquote><p>178 &#x3D; 128 + 32 + 16 + 2 &#x3D; $2^7$+ $2^5$+$2^4$+$2^1$ &#x3D; 10110010<br>0.125 &#x3D; $2^{-3}$&#x3D;0.001<br>178.125 &#x3D; 10110010.001 &#x3D; 1.0110010001 * $2^7$</p></blockquote><h3 id="IEEE浮点数存储标准"><a href="#IEEE浮点数存储标准" class="headerlink" title="IEEE浮点数存储标准"></a>IEEE浮点数存储标准</h3><ul><li>对有效数字M的规定：</li></ul><p>之前介绍了浮点数的科学计数法表达形式，其中<code>1≤M&lt;2</code>，也就是说，M可以写成1.xxxxxx的形式，其中xxxxxx表示小数部分。IEEE标准规定，在计算机内部保存M时，默认这个数的第一位总是1，因此可以被舍去，只保存后面的xxxxxx部分。比如保存1.01的时候，只保存01，等到读取的时候，再把第一位的1加上去。 这样做的目的，是节省1位有效数字。以32位浮点数为例，留给M只有23位，将第一位的1舍去以后，等于可以保存24位有效数字。</p><ul><li>对指数E的规定：</li></ul><p>E为一个无符号整数（unsigned int）。如果E为8位，其取值范围为0-255；如果E为11位，它的取值范围为0-2047。</p><p>科学计数法中的E是可以出现负数的，所以IEEE 754规定，<strong>E的真实值&#x3D;E的计算值减去一个中间数</strong>，对于8位的E，这个中间数是127；对于11位的E，这个中间数是1023。比如2^10的E是10，所以保存成32位浮点数时，必须保存成10+127&#x3D;137，即10001001。</p><blockquote><p>(1) E全为0：这时，浮点数的指数E等于1-127（或者1-1023），有效数字M不再加上第一位的1，而是还原为0.xxxxxx的小数。这样做是为了表示±0，以及接近于0的很小的数字。</p><p>(2) E全为1：这时如果有效数字M全为0，表示±无穷大（正负取决于符号位s）；如果有效数字M不全为0，表示这个数不是一个数（NaN）。</p><p>(3) E不全为0或不全为1：此时浮点数就采用上面的规则表示，即指数E的计算值减去中间值得到真实值，再将有效数字M前加上第一位的1。</p></blockquote><p>上面提到，$178.125 &#x3D; 10110010.001 &#x3D; 1.0110010001 * 2^7$，假设该数是单精度float，则根据浮点数的上述规定和科学计数法表达形式，其中E为134，S为0，则该数在内存的二进制为<code>0 10000110 01100100010000000000000 </code>。</p><p>浮点数9.0，如何用二进制表示？还原成十进制又是多少？</p><blockquote><p>浮点数9.0等于二进制的1001.0，即$1.001×2^3$。那么，第一位的符号位s&#x3D;0，有效数字M等于001后面再加20个0，凑满23位，指数E等于3+127&#x3D;130，即10000010。<br>所以，写成二进制形式，即0 10000010 001 0000 0000 0000 0000 0000。这个32位的二进制数，还原成十进制，正是1091567616。</p></blockquote><p><strong>二进制序列本身是没有任何意义的，当我们用不同方式去看这个序列时，该序列才被赋予了特定的含义。所以在使用时我们需要以什么方式存就以什么方式拿，不然会出现乱序。</strong></p><h3 id="浮点数的精度"><a href="#浮点数的精度" class="headerlink" title="浮点数的精度"></a>浮点数的精度</h3><p>浮点数不像整数在内存中是可以精确存储的，是存在精度问题的。影响小数存储为浮点数导致精度丢失的原因是，二进制下的小数部分是跳跃的。所以对于小数部分不能表示成如下二进制相加的形式，就会发生精度丢失。对于2.5（十进制）其小数部分可以用二进制表示，就不会发生精度丢失；对于5.2（十进制）其小数部分不能用二进制表示，所以其会发生精度丢失，其二进制数列为<code>0 10000001 01001100110011001100110</code>。</p><p><img src="/images/%E5%B0%8F%E6%95%B0%E7%B2%BE%E5%BA%A6.png"></p><p>以fp16为例，它占有16bit（2字节），其中5bit用来表示指数位（表示10的幂次），10bit用来表示小数位（也叫尾数位，表示浮点数的有效数字部分），还有一个符号位。5个指数位本来可以表示00000-11111，根据IEEE标准全0和全1有特殊含义，换算成10进制也就是1至30，减去中间数15，能表示的正负区间为-14至15，尾数位可以表示1.0000000000至1.1111111111。</p><p> 那么fp16所能表示的数的取值范围是多少？最大值$1.1111111111 \times 2^{11110}$，则E为15，换算为10进制为65504，最小值为$-1.1111111111 \times 2^{11110}$，换算为10进制为-65504。而最小正值为$0.0000000001 \times 2^{00000}$，此时E为-14，所以换算成10进制为$2^{-24}&#x3D;0.000000059604645$。<strong>所以fp16的动态范围为5.96E−8 到 65504</strong>，同理也能<strong>算出fp32的动态范围为1.4E-45 到 3.40E38</strong>。</p><h2 id="混合精度"><a href="#混合精度" class="headerlink" title="混合精度"></a>混合精度</h2><h3 id="bf16浮点"><a href="#bf16浮点" class="headerlink" title="bf16浮点"></a>bf16浮点</h3><p>fp16 在科学计算中具有数值范围有限的缺点，这导致了另一种16 位格式的开发——bf16，该格式以精度换取范围。fp16、bf16分别是Intel提出的半精度浮点数（float16)、nvidia提出的半精度浮点数（bfloat16）。名字当中的数字就对应了该种浮点数表示方法所占的bit数，那么fp16和bp16的存储空间天然就是fp32的一半。</p><p><img src="/images/bf16.png"></p><p>bf16相当于是将fp32的尾数位截断了，它跟fp16一样占16bit，跟fp32一样有8个指数位，那么它的尾数位只有7位，这样一来就用损失精度的代价换来了几乎跟fp32一样大的取值范围，避免了fp16容易上、下溢的问题。他的最大值$1.1111111 \times 2^{11111110}$，换算成10进制约为3.38E38；最小正值换算成10进制约为9.2E−41，所以<strong>bf16的动态范围为9.2E−41 到 3.38E38</strong>。</p><h3 id="混合精度-1"><a href="#混合精度-1" class="headerlink" title="混合精度"></a>混合精度</h3><p>虽然理想情况下训练和推理都应该在fp32 中完成，但半精度占用内存更少、计算更快。使用FP16训练神经网络，相对比使用FP32带来的优点有：</p><ul><li>模型占用的内存更小。FP16的位宽是FP32的一半，因此权重等参数所占用的内存也是原来的一半，节省下来的内存可以放更大的网络模型或者使用更多的数据进行训练，训练的时候可以用更大的batchsize。</li><li>通讯的位宽少了意味着可以提升通讯性能，减少等待时间，加快数据的流通。模型训练时，通信量（特别是多卡，或者多机多卡）大幅减少，大幅减少等待时间，加快训练速度。</li><li>计算效率更高。在特殊的AI加速芯片如华为Ascend 910和310系列，或者NVIDIA VOTAL架构的Titan V and Tesla V100的GPU上，使用FP16的执行运算性能比FP32更加快。</li></ul><p>但是使用FP16同样会带来一些问题，其中最重要的是精度溢出和舍入误差。</p><p><img src="/images/%E6%B7%B7%E5%90%88%E7%B2%BE%E5%BA%A6.jpg"></p><p>为了想让深度学习训练可以使用FP16的好处，又要避免精度溢出和舍入误差。于是可以通过FP16和FP32的混合精度训练（Mixed-Precision），而之所以要使用混合精度、而不是全部替换为半精度的原因是数据溢出和舍入误差。</p><h3 id="数据溢出和舍入误差"><a href="#数据溢出和舍入误差" class="headerlink" title="数据溢出和舍入误差"></a>数据溢出和舍入误差</h3><p>半精度跟单精度比，容易出现数据的上溢和下溢，其中在模型训练过程中，更有可能出现的是小梯度导致的下溢；</p><p>这三种精度它们的“间隔单位”也是不一样的，我们计算的最小正值就是它们的间隔单位，而间隔单位的大小决定了一个小值是否会被舍弃。比如说fp32和bf16虽然有大致一样的取值范围，但是它们的精度（间隔单位）是不一样的，当一个fp32的值+1.4E-45时，这个小值会被看到，原值会发生变动，但如果是一个bf16的值+1.4E-45，由于bf16的间隔单位为9.2E−41，这个小值就会被舍弃，原值不发生变动，这也就导致了舍入误差。</p>]]></content>
      
      
      <categories>
          
          <category> 计算机基础 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 浮点数和模型精度 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Python的多线程和多进程</title>
      <link href="/2024/01/11/python-zhi-shi/python-de-duo-xian-cheng-he-duo-jin-cheng/"/>
      <url>/2024/01/11/python-zhi-shi/python-de-duo-xian-cheng-he-duo-jin-cheng/</url>
      
        <content type="html"><![CDATA[<h1 id="Python的多线程和多进程"><a href="#Python的多线程和多进程" class="headerlink" title="Python的多线程和多进程"></a>Python的多线程和多进程</h1><h2 id="进程和线程"><a href="#进程和线程" class="headerlink" title="进程和线程"></a>进程和线程</h2><ul><li>进程</li></ul><p>进程是程序在计算机上的一次执行活动，即正在运行中的应用程序，通常称为进程。当你运行一个程序，你就启动了一个进程。每个进程都有自己独立的地址空间(内存空间)，每当用户启动一个进程时，操作系统就会为该进程分配一个独立的内存空间，让应用程序在这个独立的内存空间中运行。</p><p>在同一个时间里，同一个计算机系统中如果允许两个或两个以上的进程处于运行状态，这便是多进程，也称多任务。现代的操作系统几乎都是多任务操作系统，能够同时管理多个进程的运行。多任务带来的好处是明显的，比如你可以边听mp3边上网，与此同时甚至可以将下载的文档打印出来，而这些任务之间丝毫不会相互干扰。</p><ul><li>线程</li></ul><p>线程是一个<strong>轻量级的子进程</strong>，是最小的处理单元，是一个单独的执行路径。可以说：线程是进程的子集（部分），一个进程可能由多个线程组成。线程是相互独立的，如果在一个线程中发生异常，则不会影响其他线程。同一个进程内的线程之间使用共享内存区域。</p><p>多线程是一种执行模型，它允许多个线程存在于进程的上下文中，以便它们独立执行但共享其进程资源。</p><ul><li>线程和进程的区别</li></ul><blockquote><p> 1）一个进程至少包含一个主线程（main线程），线程需要依赖于进程而存在。<br> 2）多个线程之间共享进程的内存空间。</p></blockquote><p>调度：进程是拥有资源的基本单位，是系统资源分配的最小单位；线程是调度和分派的基本单位，是CPU资源调度的最小单位。</p><p>共享地址空间：进程拥有各自独立的地址空间、资源，所以共享复杂，需要用IPC（Inter-Process Communication，进程间通信），但是同步简单；而线程共享所属进程的资源，因此共享简单，但是同步复杂，需要用加锁等措施。<br>占用内存和cpu：进程占用内存多，切换复杂，cpu利用率低；而线程占用内存少，切换简单，cpu利用率高。<br>互相影响：进程之间不会互相影响；而一个线程挂掉会导致整个进程挂掉。</p><p><img src="/images/%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%92%8C%E5%A4%9A%E8%BF%9B%E7%A8%8B.png"></p><h2 id="多线程threading"><a href="#多线程threading" class="headerlink" title="多线程threading"></a>多线程threading</h2><p>多线程是加速程序计算的有效方式，Python的多线程模块threading上手快速简单，包含了关于线程操作的丰富功能。</p><h3 id="创建线程"><a href="#创建线程" class="headerlink" title="创建线程"></a>创建线程</h3><p>threading模块的一些基本操作，包括获取线程数，添加线程等。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> threading<span class="token keyword">print</span><span class="token punctuation">(</span>threading<span class="token punctuation">.</span>active_count<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 获取已激活的线程数</span><span class="token keyword">print</span><span class="token punctuation">(</span>threading<span class="token punctuation">.</span>enumerate<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 查看所有线程信息---存储在一个列表中</span><span class="token keyword">print</span><span class="token punctuation">(</span>threading<span class="token punctuation">.</span>current_thread<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 查看现在正在运行的线程</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>添加线程，<code>threading.Thread()</code>接收参数<code>target</code>代表这个线程要完成的任务，需自行定义，<code>start()</code>让线程开始工作。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">thread_job</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'This is a thread of %s'</span> <span class="token operator">%</span> threading<span class="token punctuation">.</span>current_thread<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    thread <span class="token operator">=</span> threading<span class="token punctuation">.</span>Thread<span class="token punctuation">(</span>target<span class="token operator">=</span>thread_job<span class="token punctuation">,</span><span class="token punctuation">)</span>   <span class="token comment" spellcheck="true"># 定义线程 </span>    thread<span class="token punctuation">.</span>start<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 让线程开始工作</span>    <span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>    main<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>在定义线程时，还可以指定线程的名称，如下面的代码：</p><pre class="line-numbers language-python"><code class="language-python">thread <span class="token operator">=</span> threading<span class="token punctuation">.</span>Thread<span class="token punctuation">(</span>target<span class="token operator">=</span>thread_job<span class="token punctuation">,</span><span class="token punctuation">)</span>   <span class="token comment" spellcheck="true"># 定义线程, 默认线程名是Thread-1</span>thread <span class="token operator">=</span> threading<span class="token punctuation">.</span>Thread<span class="token punctuation">(</span>target<span class="token operator">=</span>thread_job<span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">"T1"</span><span class="token punctuation">)</span>   <span class="token comment" spellcheck="true"># 定义线程, 指定名称是T1</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>还可以通过自定义一个 Thread 的子类，然后复写它的 run() 方法，在 run() 方法中编写任务处理代码，实现自定义的多线程程序。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> threading<span class="token keyword">import</span> time<span class="token keyword">class</span> <span class="token class-name">TestThread</span><span class="token punctuation">(</span>threading<span class="token punctuation">.</span>Thread<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>name<span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span>self<span class="token punctuation">,</span>name<span class="token operator">=</span>name<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">run</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">print</span><span class="token punctuation">(</span>threading<span class="token punctuation">.</span>current_thread<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>name <span class="token operator">+</span> <span class="token string">' test '</span><span class="token punctuation">,</span> i<span class="token punctuation">)</span>            time<span class="token punctuation">.</span>sleep<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>            thread <span class="token operator">=</span> TestThread<span class="token punctuation">(</span>name<span class="token operator">=</span><span class="token string">'TestThread'</span><span class="token punctuation">)</span>thread<span class="token punctuation">.</span>start<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="join功能"><a href="#join功能" class="headerlink" title="join功能"></a>join功能</h3><p>首先来看一个小例子，下面定义了一个任务函数<code>func</code>，执行<code>for</code>循环10次，每次睡眠1秒，执行完成之后打印”all done”。但是我们从结果看到，打印信息”all done”先于”thread finish”被输出。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> time<span class="token keyword">import</span> threading<span class="token keyword">def</span> <span class="token function">func</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"thread start"</span><span class="token punctuation">)</span>    <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        time<span class="token punctuation">.</span>sleep<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"thread finish"</span><span class="token punctuation">)</span>t1 <span class="token operator">=</span> threading<span class="token punctuation">.</span>Thread<span class="token punctuation">(</span>target<span class="token operator">=</span>func<span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">"t1"</span><span class="token punctuation">)</span>t1<span class="token punctuation">.</span>start<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"all done"</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> Output<span class="token punctuation">:</span>thread startall donethread finish<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>这是因为这里有两个线程，分别是主线程MainThread和定义的线程t1，这两个线程同时运行时，由于t1需要执行函数<code>func</code>，共计需要10s才能完成，而主线程运行不需要这么久，因此主线程会先运行完毕输出”all done”，等t1执行函数<code>func</code>完成时才会输出”thread finish”。</p><p>因此，如果想让所有线程执行完毕后，再一起执行后面的代码（比如上面的输出all done），可以使用<code>join</code>方法。如下面的代码</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">func</span><span class="token punctuation">(</span>num<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"%s thread start"</span><span class="token operator">%</span><span class="token punctuation">(</span>threading<span class="token punctuation">.</span>current_thread<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>num<span class="token punctuation">)</span><span class="token punctuation">:</span>        time<span class="token punctuation">.</span>sleep<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"%s thread finish"</span><span class="token operator">%</span><span class="token punctuation">(</span>threading<span class="token punctuation">.</span>current_thread<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>t1 <span class="token operator">=</span> threading<span class="token punctuation">.</span>Thread<span class="token punctuation">(</span>target<span class="token operator">=</span>func<span class="token punctuation">,</span> args<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">"t1"</span><span class="token punctuation">)</span>t2 <span class="token operator">=</span> threading<span class="token punctuation">.</span>Thread<span class="token punctuation">(</span>target<span class="token operator">=</span>func<span class="token punctuation">,</span> args<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">"t2"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>上面添加了两个线程t1和t2，均执行函数<code>func</code>，但是两个线程执行任务的耗时不同，t1执行任务10s，而t2执行任务1s。下面分别使用<code>join</code>方法来观察输出。</p><ul><li>不使用join</li></ul><pre class="line-numbers language-python"><code class="language-python">t1<span class="token punctuation">.</span>start<span class="token punctuation">(</span><span class="token punctuation">)</span>t2<span class="token punctuation">.</span>start<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"all done"</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> Output<span class="token punctuation">:</span><span class="token operator">&lt;</span>Thread<span class="token punctuation">(</span>t1<span class="token punctuation">,</span> started <span class="token number">140682945677056</span><span class="token punctuation">)</span><span class="token operator">></span> thread start<span class="token operator">&lt;</span>Thread<span class="token punctuation">(</span>t2<span class="token punctuation">,</span> started <span class="token number">140682937284352</span><span class="token punctuation">)</span><span class="token operator">></span> thread startall done<span class="token operator">&lt;</span>Thread<span class="token punctuation">(</span>t2<span class="token punctuation">,</span> started <span class="token number">140682937284352</span><span class="token punctuation">)</span><span class="token operator">></span> thread finish<span class="token operator">&lt;</span>Thread<span class="token punctuation">(</span>t1<span class="token punctuation">,</span> started <span class="token number">140682945677056</span><span class="token punctuation">)</span><span class="token operator">></span> thread finish<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ul><li>t1使用join</li></ul><pre class="line-numbers language-python"><code class="language-python">t1<span class="token punctuation">.</span>start<span class="token punctuation">(</span><span class="token punctuation">)</span>t2<span class="token punctuation">.</span>start<span class="token punctuation">(</span><span class="token punctuation">)</span>t1<span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"all done"</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> Output<span class="token punctuation">:</span><span class="token operator">&lt;</span>Thread<span class="token punctuation">(</span>t1<span class="token punctuation">,</span> started <span class="token number">140483331766016</span><span class="token punctuation">)</span><span class="token operator">></span> thread start<span class="token operator">&lt;</span>Thread<span class="token punctuation">(</span>t2<span class="token punctuation">,</span> started <span class="token number">140483323373312</span><span class="token punctuation">)</span><span class="token operator">></span> thread start<span class="token operator">&lt;</span>Thread<span class="token punctuation">(</span>t2<span class="token punctuation">,</span> started <span class="token number">140483323373312</span><span class="token punctuation">)</span><span class="token operator">></span> thread finish<span class="token operator">&lt;</span>Thread<span class="token punctuation">(</span>t1<span class="token punctuation">,</span> started <span class="token number">140483331766016</span><span class="token punctuation">)</span><span class="token operator">></span> thread finishall done<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ul><li>t2使用join</li></ul><pre class="line-numbers language-python"><code class="language-python">t1<span class="token punctuation">.</span>start<span class="token punctuation">(</span><span class="token punctuation">)</span>t2<span class="token punctuation">.</span>start<span class="token punctuation">(</span><span class="token punctuation">)</span>t2<span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"all done"</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> Output<span class="token punctuation">:</span><span class="token operator">&lt;</span>Thread<span class="token punctuation">(</span>t1<span class="token punctuation">,</span> started <span class="token number">139736940828416</span><span class="token punctuation">)</span><span class="token operator">></span> thread start<span class="token operator">&lt;</span>Thread<span class="token punctuation">(</span>t2<span class="token punctuation">,</span> started <span class="token number">139736932435712</span><span class="token punctuation">)</span><span class="token operator">></span> thread start<span class="token operator">&lt;</span>Thread<span class="token punctuation">(</span>t2<span class="token punctuation">,</span> started <span class="token number">139736932435712</span><span class="token punctuation">)</span><span class="token operator">></span> thread finishall done<span class="token operator">&lt;</span>Thread<span class="token punctuation">(</span>t1<span class="token punctuation">,</span> started <span class="token number">139736940828416</span><span class="token punctuation">)</span><span class="token operator">></span> thread finish<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ul><li>都使用join</li></ul><pre class="line-numbers language-python"><code class="language-python">t1<span class="token punctuation">.</span>start<span class="token punctuation">(</span><span class="token punctuation">)</span>t2<span class="token punctuation">.</span>start<span class="token punctuation">(</span><span class="token punctuation">)</span>t1<span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token punctuation">)</span>t2<span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"all done"</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> Output<span class="token punctuation">:</span><span class="token operator">&lt;</span>Thread<span class="token punctuation">(</span>t1<span class="token punctuation">,</span> started <span class="token number">140440337422080</span><span class="token punctuation">)</span><span class="token operator">></span> thread start<span class="token operator">&lt;</span>Thread<span class="token punctuation">(</span>t2<span class="token punctuation">,</span> started <span class="token number">140440329029376</span><span class="token punctuation">)</span><span class="token operator">></span> thread start<span class="token operator">&lt;</span>Thread<span class="token punctuation">(</span>t2<span class="token punctuation">,</span> started <span class="token number">140440329029376</span><span class="token punctuation">)</span><span class="token operator">></span> thread finish<span class="token operator">&lt;</span>Thread<span class="token punctuation">(</span>t1<span class="token punctuation">,</span> started <span class="token number">140440337422080</span><span class="token punctuation">)</span><span class="token operator">></span> thread finishall done<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>执行join方法会阻塞调用线程（主线程），直到调用<code>join</code>方法的线程结束。</strong></p><h3 id="Queue功能"><a href="#Queue功能" class="headerlink" title="Queue功能"></a>Queue功能</h3><p>线程间使用队列进行通信，因为队列所有方法都是线程安全的，所以不会出现线程竞争资源的情况。queue 模块即队列，特别适合处理信息在多个线程间的安全交换。</p><p>多线程调用的函数不能有返回值，所以最直白的应用，就是多个线程处理完毕的结果，放入该队列中，最后进行整合。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> time<span class="token keyword">import</span> threading<span class="token keyword">from</span> queue <span class="token keyword">import</span> Queue<span class="token keyword">def</span> <span class="token function">square</span><span class="token punctuation">(</span>d<span class="token punctuation">,</span> q<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>len<span class="token punctuation">(</span>d<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        d<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> d<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token operator">**</span><span class="token number">2</span>    q<span class="token punctuation">.</span>put<span class="token punctuation">(</span>d<span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">multithreading</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token punctuation">:</span>    q <span class="token operator">=</span> Queue<span class="token punctuation">(</span><span class="token punctuation">)</span>    threads <span class="token operator">=</span> list<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        t <span class="token operator">=</span> threading<span class="token punctuation">.</span>Thread<span class="token punctuation">(</span>target<span class="token operator">=</span>square<span class="token punctuation">,</span> args<span class="token operator">=</span><span class="token punctuation">(</span>data<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span> q<span class="token punctuation">)</span><span class="token punctuation">)</span>        t<span class="token punctuation">.</span>start<span class="token punctuation">(</span><span class="token punctuation">)</span>        threads<span class="token punctuation">.</span>append<span class="token punctuation">(</span>t<span class="token punctuation">)</span>    <span class="token keyword">for</span> thread <span class="token keyword">in</span> threads<span class="token punctuation">:</span>        thread<span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token punctuation">)</span>    results <span class="token operator">=</span> list<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">for</span> _ <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        results<span class="token punctuation">.</span>append<span class="token punctuation">(</span>q<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>results<span class="token punctuation">)</span>data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">]</span>multithreading<span class="token punctuation">(</span>data<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>其中<code>q.put()</code>和<code>q.get()</code>均是阻塞式的。<code>q.put()</code>阻塞方式将数据添加进队列中，如果队列满了则一直等待；<code>q.get()</code>阻塞式获取，队列为空时，则一直等待。</p><p>这里的队列也可以使用multiprocessing提供的Queue。</p><h3 id="Lock锁"><a href="#Lock锁" class="headerlink" title="Lock锁"></a>Lock锁</h3><p>多个线程可以共享所属进程的资源，但是如果不加限制，则线程之间会对共享的资源进行争抢，导致无法预估的问题。比如下面的代码，两个线程共享一个变量A，如果不对共享的内存A进行限制，则最终的结果A是未知的。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> threading<span class="token keyword">def</span> <span class="token function">job1</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">global</span> A    <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        A <span class="token operator">+=</span> <span class="token number">1</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'job1'</span><span class="token punctuation">,</span> A<span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">job2</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">global</span> A    <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        A <span class="token operator">+=</span> <span class="token number">10</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'job2'</span><span class="token punctuation">,</span> A<span class="token punctuation">)</span>A <span class="token operator">=</span> <span class="token number">0</span>t1 <span class="token operator">=</span> threading<span class="token punctuation">.</span>Thread<span class="token punctuation">(</span>target<span class="token operator">=</span>job1<span class="token punctuation">)</span>t2 <span class="token operator">=</span> threading<span class="token punctuation">.</span>Thread<span class="token punctuation">(</span>target<span class="token operator">=</span>job2<span class="token punctuation">)</span>t1<span class="token punctuation">.</span>start<span class="token punctuation">(</span><span class="token punctuation">)</span>t2<span class="token punctuation">.</span>start<span class="token punctuation">(</span><span class="token punctuation">)</span>t1<span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token punctuation">)</span>t2<span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token operator">>></span><span class="token operator">></span> Output<span class="token punctuation">:</span>job1 <span class="token number">1</span>job2 <span class="token number">11</span>job2 <span class="token number">22</span>job2 <span class="token number">32</span>job1 <span class="token number">12</span>job2 <span class="token number">43</span>job2 <span class="token number">53</span>job2 <span class="token number">63</span>job2 <span class="token number">73</span>job2 <span class="token number">83</span>job2 <span class="token number">93</span>job2 <span class="token number">103</span>job1 <span class="token number">33</span>job1 <span class="token number">104</span>job1 <span class="token number">105</span>job1 <span class="token number">106</span>job1 <span class="token number">107</span>job1 <span class="token number">108</span>job1 <span class="token number">109</span>job1 <span class="token number">110</span>    <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>因此，需要使用锁（Lock）来限制多个线程对同一块内存区域的访问。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">job1</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">global</span> A<span class="token punctuation">,</span> lock    lock<span class="token punctuation">.</span>acquire<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 加锁</span>    <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        A <span class="token operator">+=</span> <span class="token number">1</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'job1'</span><span class="token punctuation">,</span> A<span class="token punctuation">)</span>    lock<span class="token punctuation">.</span>release<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 释放</span><span class="token keyword">def</span> <span class="token function">job2</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">global</span> A<span class="token punctuation">,</span>lock    lock<span class="token punctuation">.</span>acquire<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        A <span class="token operator">+=</span> <span class="token number">10</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'job2'</span><span class="token punctuation">,</span> A<span class="token punctuation">)</span>    lock<span class="token punctuation">.</span>release<span class="token punctuation">(</span><span class="token punctuation">)</span>A <span class="token operator">=</span> <span class="token number">0</span>lock <span class="token operator">=</span> threading<span class="token punctuation">.</span>Lock<span class="token punctuation">(</span><span class="token punctuation">)</span>t1 <span class="token operator">=</span> threading<span class="token punctuation">.</span>Thread<span class="token punctuation">(</span>target<span class="token operator">=</span>job1<span class="token punctuation">)</span>t2 <span class="token operator">=</span> threading<span class="token punctuation">.</span>Thread<span class="token punctuation">(</span>target<span class="token operator">=</span>job2<span class="token punctuation">)</span>t1<span class="token punctuation">.</span>start<span class="token punctuation">(</span><span class="token punctuation">)</span>t2<span class="token punctuation">.</span>start<span class="token punctuation">(</span><span class="token punctuation">)</span>t1<span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token punctuation">)</span>t2<span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token operator">>></span><span class="token operator">></span> Output<span class="token punctuation">:</span>job1 <span class="token number">1</span>job1 <span class="token number">2</span>job1 <span class="token number">3</span>job1 <span class="token number">4</span>job1 <span class="token number">5</span>job1 <span class="token number">6</span>job1 <span class="token number">7</span>job1 <span class="token number">8</span>job1 <span class="token number">9</span>job1 <span class="token number">10</span>job2 <span class="token number">20</span>job2 <span class="token number">30</span>job2 <span class="token number">40</span>job2 <span class="token number">50</span>job2 <span class="token number">60</span>job2 <span class="token number">70</span>job2 <span class="token number">80</span>job2 <span class="token number">90</span>job2 <span class="token number">100</span>job2 <span class="token number">110</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="多线程不一定有效率"><a href="#多线程不一定有效率" class="headerlink" title="多线程不一定有效率"></a>多线程不一定有效率</h3><p>多线程的工作原理：同一时间只有一个线程在工作，多个线程来回切换，实现多个线程“同时工作”的假象。多线程往往处理并发，即收到多个请求后，多个线程每次处理一点，线程来回切换完成多个请求任务。</p><p><img src="/images/%E5%A4%9A%E7%BA%BF%E7%A8%8B.png"></p><p>只有当多个线程处理的任务存在明显的效率差异时，如遇到IO，可以使用多线程提高速度和整体效率；如果是计算密集型任务，把数据拆分给多个线程运算，则不会带来很大的效率收益。</p><h2 id="多进程multiprocess"><a href="#多进程multiprocess" class="headerlink" title="多进程multiprocess"></a>多进程multiprocess</h2><p>多进程是利用多核CPU进行任务处理和运算的一种方式。Python中的multiprocessing模块提供了一种创建和管理进程的方式，使得可以利用多个CPU来加速程序运行。</p><h3 id="创建进程"><a href="#创建进程" class="headerlink" title="创建进程"></a>创建进程</h3><p>多进程的创建和多线程类似，代码如下：</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> multiprocessing <span class="token keyword">as</span> mp<span class="token keyword">def</span> <span class="token function">job</span><span class="token punctuation">(</span>a<span class="token punctuation">,</span>b<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"hello"</span><span class="token punctuation">)</span>p1 <span class="token operator">=</span> mp<span class="token punctuation">.</span>Process<span class="token punctuation">(</span>target<span class="token operator">=</span>job<span class="token punctuation">,</span> args<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>p1<span class="token punctuation">.</span>start<span class="token punctuation">(</span><span class="token punctuation">)</span>p1<span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>同样地，也可以自定义一个多进程处理的继承自Process的子类，然后复写它的 run() 方法，在 run() 方法中编写任务处理代码，实现自定义的多进程程序。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> multiprocessing <span class="token keyword">import</span> Process<span class="token keyword">class</span> <span class="token class-name">NewProcess</span><span class="token punctuation">(</span>Process<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> name<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>                  <span class="token comment" spellcheck="true"># 创建新参数</span>        self<span class="token punctuation">.</span>name <span class="token operator">=</span> name        <span class="token comment" spellcheck="true"># 在自定义Process类时，必须实现run()方法</span>    <span class="token keyword">def</span> <span class="token function">run</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">'{self.name}: Hello World'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="Queue功能-1"><a href="#Queue功能-1" class="headerlink" title="Queue功能"></a>Queue功能</h3><p>与多线程类似，多线程调用的函数不能有返回值，因此可以把多个进程的处理或运算结果，放入到队列中，等所有进程均执行完毕后进行整合。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> multiprocessing <span class="token keyword">as</span> mp<span class="token keyword">def</span> <span class="token function">job</span><span class="token punctuation">(</span>q<span class="token punctuation">)</span><span class="token punctuation">:</span>    res <span class="token operator">=</span> <span class="token number">0</span>    <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">1000</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        res <span class="token operator">+=</span> i<span class="token operator">+</span>i<span class="token operator">**</span><span class="token number">2</span><span class="token operator">+</span>i<span class="token operator">**</span><span class="token number">3</span>    q<span class="token punctuation">.</span>put<span class="token punctuation">(</span>res<span class="token punctuation">)</span>q <span class="token operator">=</span> mp<span class="token punctuation">.</span>Queue<span class="token punctuation">(</span><span class="token punctuation">)</span>p1 <span class="token operator">=</span> mp<span class="token punctuation">.</span>Process<span class="token punctuation">(</span>target<span class="token operator">=</span>job<span class="token punctuation">,</span> args<span class="token operator">=</span><span class="token punctuation">(</span>q<span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span>p2 <span class="token operator">=</span> mp<span class="token punctuation">.</span>Process<span class="token punctuation">(</span>target<span class="token operator">=</span>job<span class="token punctuation">,</span> args<span class="token operator">=</span><span class="token punctuation">(</span>q<span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span>p1<span class="token punctuation">.</span>start<span class="token punctuation">(</span><span class="token punctuation">)</span>p2<span class="token punctuation">.</span>start<span class="token punctuation">(</span><span class="token punctuation">)</span>p1<span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token punctuation">)</span>p2<span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token punctuation">)</span>res1 <span class="token operator">=</span> q<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token punctuation">)</span>res2 <span class="token operator">=</span> q<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>res1<span class="token operator">+</span>res2<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="多线程和多进程的效率对比"><a href="#多线程和多进程的效率对比" class="headerlink" title="多线程和多进程的效率对比"></a>多线程和多进程的效率对比</h3><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> multiprocessing <span class="token keyword">as</span> mp<span class="token keyword">import</span> threading <span class="token keyword">as</span> td<span class="token keyword">import</span> time<span class="token keyword">def</span> <span class="token function">job</span><span class="token punctuation">(</span>q<span class="token punctuation">)</span><span class="token punctuation">:</span>    res <span class="token operator">=</span> <span class="token number">0</span>    <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">100000</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        res <span class="token operator">+=</span> i<span class="token operator">+</span>i<span class="token operator">**</span><span class="token number">2</span><span class="token operator">+</span>i<span class="token operator">**</span><span class="token number">3</span>    q<span class="token punctuation">.</span>put<span class="token punctuation">(</span>res<span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">normal</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    res <span class="token operator">=</span> <span class="token number">0</span>    <span class="token keyword">for</span> _ <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token comment" spellcheck="true"># 对齐两个进程或线程</span>        <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">100000</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            res <span class="token operator">+=</span> i<span class="token operator">+</span>i<span class="token operator">**</span><span class="token number">2</span><span class="token operator">+</span>i<span class="token operator">**</span><span class="token number">3</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"normal"</span><span class="token punctuation">,</span> res<span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">multicore</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    q <span class="token operator">=</span> mp<span class="token punctuation">.</span>Queue<span class="token punctuation">(</span><span class="token punctuation">)</span>    p1 <span class="token operator">=</span> mp<span class="token punctuation">.</span>Process<span class="token punctuation">(</span>target<span class="token operator">=</span>job<span class="token punctuation">,</span> args<span class="token operator">=</span><span class="token punctuation">(</span>q<span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    p2 <span class="token operator">=</span> mp<span class="token punctuation">.</span>Process<span class="token punctuation">(</span>target<span class="token operator">=</span>job<span class="token punctuation">,</span> args<span class="token operator">=</span><span class="token punctuation">(</span>q<span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    p1<span class="token punctuation">.</span>start<span class="token punctuation">(</span><span class="token punctuation">)</span>    p2<span class="token punctuation">.</span>start<span class="token punctuation">(</span><span class="token punctuation">)</span>    p1<span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token punctuation">)</span>    p2<span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token punctuation">)</span>    res1 <span class="token operator">=</span> q<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token punctuation">)</span>    res2 <span class="token operator">=</span> q<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"multicore"</span><span class="token punctuation">,</span> res1<span class="token operator">+</span>res2<span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">multithread</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    q <span class="token operator">=</span> mp<span class="token punctuation">.</span>Queue<span class="token punctuation">(</span><span class="token punctuation">)</span>    t1 <span class="token operator">=</span> td<span class="token punctuation">.</span>Thread<span class="token punctuation">(</span>target<span class="token operator">=</span>job<span class="token punctuation">,</span> args<span class="token operator">=</span><span class="token punctuation">(</span>q<span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    t2 <span class="token operator">=</span> td<span class="token punctuation">.</span>Thread<span class="token punctuation">(</span>target<span class="token operator">=</span>job<span class="token punctuation">,</span> args<span class="token operator">=</span><span class="token punctuation">(</span>q<span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    t1<span class="token punctuation">.</span>start<span class="token punctuation">(</span><span class="token punctuation">)</span>    t2<span class="token punctuation">.</span>start<span class="token punctuation">(</span><span class="token punctuation">)</span>    t1<span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token punctuation">)</span>    t2<span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token punctuation">)</span>    res1 <span class="token operator">=</span> q<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token punctuation">)</span>    res2 <span class="token operator">=</span> q<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"multithread"</span><span class="token punctuation">,</span> res1<span class="token operator">+</span>res2<span class="token punctuation">)</span> st <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>normal<span class="token punctuation">(</span><span class="token punctuation">)</span>st1 <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"normal time "</span><span class="token punctuation">,</span> st1<span class="token operator">-</span>st<span class="token punctuation">)</span>multithread<span class="token punctuation">(</span><span class="token punctuation">)</span>st2 <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"thread time "</span><span class="token punctuation">,</span> st2<span class="token operator">-</span>st1<span class="token punctuation">)</span>multicore<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"core time "</span><span class="token punctuation">,</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">-</span>st2<span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> Output<span class="token punctuation">:</span>normal <span class="token number">49999666671666600000</span>normal time  <span class="token number">0.06681323051452637</span>multithread <span class="token number">49999666671666600000</span>thread time  <span class="token number">0.07323598861694336</span>multicore <span class="token number">49999666671666600000</span>core time  <span class="token number">0.03575706481933594</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="进程池Pool"><a href="#进程池Pool" class="headerlink" title="进程池Pool"></a>进程池Pool</h3><p>与<code>Process</code>创将进程不同，这次使用<code>Pool</code>创建进程池，它会自行解决多进程的问题。<code>Pool</code>和之前的<code>Process</code>的不同点是传入<code>Pool</code>的函数有返回值，而<code>Process</code>传入的函数没有返回值。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> multiprocessing <span class="token keyword">as</span> mp<span class="token keyword">def</span> <span class="token function">job</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">return</span> x<span class="token operator">*</span>x     <span class="token keyword">def</span> <span class="token function">multicore</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    pool <span class="token operator">=</span> mp<span class="token punctuation">.</span>Pool<span class="token punctuation">(</span><span class="token punctuation">)</span>    res <span class="token operator">=</span> pool<span class="token punctuation">.</span>map<span class="token punctuation">(</span>job<span class="token punctuation">,</span> range<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>res<span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># [0,1,4,9,16,25,36,49,64,81]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><code>map</code>接受数据自动分配给进程池的进程进行运算。<code>Pool</code>默认使用所有的CPU核，如果想只用其中几个核，则由参数<code>process</code>指定。</p><pre class="line-numbers language-python"><code class="language-python">pool <span class="token operator">=</span> mp<span class="token punctuation">.</span>Pool<span class="token punctuation">(</span>processes<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 使用3个核，即3个进程</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><code>Pool</code>除了<code>map()</code>外，还有可以返回结果的方式，那就是<code>apply_async()</code>。<code>apply_async()</code>中只能传递一个值，它一次只会放入一个核进行运算，但是传入值时要注意是可迭代的，同时需要用<code>get()</code>方法获取返回值。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">multicore</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    pool <span class="token operator">=</span> mp<span class="token punctuation">.</span>Pool<span class="token punctuation">(</span>processes<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">)</span>     res <span class="token operator">=</span> pool<span class="token punctuation">.</span>apply_async<span class="token punctuation">(</span>job<span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 用get获得结果</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>res<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 4</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>如果想要传入多个数值，则需要使用迭代器。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">multicore</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    pool <span class="token operator">=</span> mp<span class="token punctuation">.</span>Pool<span class="token punctuation">(</span>processes<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">)</span>     multi_res <span class="token operator">=</span> <span class="token punctuation">[</span>pool<span class="token punctuation">.</span>apply_async<span class="token punctuation">(</span>job<span class="token punctuation">,</span> <span class="token punctuation">(</span>i<span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">]</span>    <span class="token comment" spellcheck="true"># 用get获得结果</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token punctuation">[</span>res<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">for</span> res <span class="token keyword">in</span> multi_res<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 4</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="共享内存"><a href="#共享内存" class="headerlink" title="共享内存"></a>共享内存</h3><p>进程拥有各自独立的地址空间、资源，因此想要在进程之间共享是没有多线程方便的（global关键字）。共享内存是一种高效的进程间通信方式，它允许多个进程共享同一块内存区域。multiprocessing模块中提供了Value和Array类，可以用来创建共享内存。</p><pre class="line-numbers language-python"><code class="language-python">value1 <span class="token operator">=</span> mp<span class="token punctuation">.</span>Value<span class="token punctuation">(</span><span class="token string">'i'</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span> value2 <span class="token operator">=</span> mp<span class="token punctuation">.</span>Value<span class="token punctuation">(</span><span class="token string">'d'</span><span class="token punctuation">,</span> <span class="token number">3.14</span><span class="token punctuation">)</span>array <span class="token operator">=</span> mp<span class="token punctuation">.</span>Array<span class="token punctuation">(</span><span class="token string">'i'</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>这里的<code>Array</code>和numpy中的不同，它只能是一维的，不能是多维的。<code>Value</code>和<code>Array</code> 一样，需要定义数据形式，否则会报错。<code>d</code>表示一个双精浮点类型，<code>i</code>表示一个带符号的整型。具体数据类型见下表。</p><table><thead><tr><th>Type code</th><th>C Type</th><th>Python Type</th><th>Minimum size in bytes</th></tr></thead><tbody><tr><td><code>&#39;b&#39;</code></td><td>signed char</td><td>int</td><td>1</td></tr><tr><td><code>&#39;B&#39;</code></td><td>unsigned char</td><td>int</td><td>1</td></tr><tr><td><code>&#39;u&#39;</code></td><td>Py_UNICODE</td><td>Unicode character</td><td>2</td></tr><tr><td><code>&#39;h&#39;</code></td><td>signed short</td><td>int</td><td>2</td></tr><tr><td><code>&#39;H&#39;</code></td><td>unsigned short</td><td>int</td><td>2</td></tr><tr><td><code>&#39;i&#39;</code></td><td>signed int</td><td>int</td><td>2</td></tr><tr><td><code>&#39;I&#39;</code></td><td>unsigned int</td><td>int</td><td>2</td></tr><tr><td><code>&#39;l&#39;</code></td><td>signed long</td><td>int</td><td>4</td></tr><tr><td><code>&#39;L&#39;</code></td><td>unsigned long</td><td>int</td><td>4</td></tr><tr><td><code>&#39;q&#39;</code></td><td>signed long long</td><td>int</td><td>8</td></tr><tr><td><code>&#39;Q&#39;</code></td><td>unsigned long long</td><td>int</td><td>8</td></tr><tr><td><code>&#39;f&#39;</code></td><td>float</td><td>float</td><td>4</td></tr><tr><td><code>&#39;d&#39;</code></td><td>double</td><td>float</td><td>8</td></tr></tbody></table><h3 id="Lock锁-1"><a href="#Lock锁-1" class="headerlink" title="Lock锁"></a>Lock锁</h3><p>上面介绍了共享内存的概念，如果多进程程序不对共享内存加以限制，则会发生多个进程对共享内存的争夺。因此锁出现了，它是为了防止多个进程对共享内存进行读写，导致无法预估的事情发生。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> multiprocessing <span class="token keyword">as</span> mp<span class="token keyword">import</span> time <span class="token keyword">def</span> <span class="token function">job</span><span class="token punctuation">(</span>v<span class="token punctuation">,</span> num<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">for</span> _ <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        time<span class="token punctuation">.</span>sleep<span class="token punctuation">(</span><span class="token number">0.1</span><span class="token punctuation">)</span>         v<span class="token punctuation">.</span>value <span class="token operator">+=</span> num <span class="token comment" spellcheck="true"># v.value获取共享变量值</span>        <span class="token keyword">print</span><span class="token punctuation">(</span>v<span class="token punctuation">.</span>value<span class="token punctuation">,</span> end<span class="token operator">=</span><span class="token string">" "</span><span class="token punctuation">)</span>        <span class="token keyword">def</span> <span class="token function">multicore</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    v <span class="token operator">=</span> mp<span class="token punctuation">.</span>Value<span class="token punctuation">(</span><span class="token string">'i'</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 定义共享变量</span>    p1 <span class="token operator">=</span> mp<span class="token punctuation">.</span>Process<span class="token punctuation">(</span>target<span class="token operator">=</span>job<span class="token punctuation">,</span> args<span class="token operator">=</span><span class="token punctuation">(</span>v<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    p2 <span class="token operator">=</span> mp<span class="token punctuation">.</span>Process<span class="token punctuation">(</span>target<span class="token operator">=</span>job<span class="token punctuation">,</span> args<span class="token operator">=</span><span class="token punctuation">(</span>v<span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span>     p1<span class="token punctuation">.</span>start<span class="token punctuation">(</span><span class="token punctuation">)</span>    p2<span class="token punctuation">.</span>start<span class="token punctuation">(</span><span class="token punctuation">)</span>    p1<span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token punctuation">)</span>    p2<span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token punctuation">)</span>    multicore<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 1 12 23 34 45 11 22 33 44 55</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>与多线程类似，加入Lock限制共享内存。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> multiprocessing <span class="token keyword">as</span> mp<span class="token keyword">import</span> time <span class="token keyword">def</span> <span class="token function">job</span><span class="token punctuation">(</span>v<span class="token punctuation">,</span> num<span class="token punctuation">,</span> lock<span class="token punctuation">)</span><span class="token punctuation">:</span>    lock<span class="token punctuation">.</span>acquire<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">for</span> _ <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        time<span class="token punctuation">.</span>sleep<span class="token punctuation">(</span><span class="token number">0.1</span><span class="token punctuation">)</span>         v<span class="token punctuation">.</span>value <span class="token operator">+=</span> num <span class="token comment" spellcheck="true"># v.value获取共享变量值</span>        <span class="token keyword">print</span><span class="token punctuation">(</span>v<span class="token punctuation">.</span>value<span class="token punctuation">,</span> end<span class="token operator">=</span><span class="token string">" "</span><span class="token punctuation">)</span>    lock<span class="token punctuation">.</span>release<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">def</span> <span class="token function">multicore</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    lock <span class="token operator">=</span> mp<span class="token punctuation">.</span>Lock<span class="token punctuation">(</span><span class="token punctuation">)</span>    v <span class="token operator">=</span> mp<span class="token punctuation">.</span>Value<span class="token punctuation">(</span><span class="token string">'i'</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 定义共享变量</span>    p1 <span class="token operator">=</span> mp<span class="token punctuation">.</span>Process<span class="token punctuation">(</span>target<span class="token operator">=</span>job<span class="token punctuation">,</span> args<span class="token operator">=</span><span class="token punctuation">(</span>v<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span> lock<span class="token punctuation">)</span><span class="token punctuation">)</span>    p2 <span class="token operator">=</span> mp<span class="token punctuation">.</span>Process<span class="token punctuation">(</span>target<span class="token operator">=</span>job<span class="token punctuation">,</span> args<span class="token operator">=</span><span class="token punctuation">(</span>v<span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">,</span> lock<span class="token punctuation">)</span><span class="token punctuation">)</span>     p1<span class="token punctuation">.</span>start<span class="token punctuation">(</span><span class="token punctuation">)</span>    p2<span class="token punctuation">.</span>start<span class="token punctuation">(</span><span class="token punctuation">)</span>    p1<span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token punctuation">)</span>    p2<span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token punctuation">)</span>    multicore<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 1 2 3 4 5 15 25 35 45 55</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> 编程语言 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 基础知识 </tag>
            
            <tag> 进程和线程 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>C++|STL中常用容器</title>
      <link href="/2023/12/25/c-zhi-shi/chang-jian-de-rong-qi/"/>
      <url>/2023/12/25/c-zhi-shi/chang-jian-de-rong-qi/</url>
      
        <content type="html"><![CDATA[<h1 id="STL中常用容器"><a href="#STL中常用容器" class="headerlink" title="STL中常用容器"></a>STL中常用容器</h1><p>本文简要介绍C++的STL中常用容器及其用法。</p><h2 id="string容器"><a href="#string容器" class="headerlink" title="string容器"></a>string容器</h2><h3 id="string容器初识"><a href="#string容器初识" class="headerlink" title="string容器初识"></a>string容器初识</h3><p><code>string</code>是C++风格的字符串，本质上是一个类的形式。C风格的字符串<code>char*</code>是一个指针，而<code>string</code>是一个类，类内部封装了<code>char*</code>来管理这个字符串，是一个<code>char*</code>型的容器。<code>string</code>管理<code>char*</code>所分配的内存，不用担心复制越界和取值越界等问题，这些均由类内部进行负责。</p><h3 id="string的构造函数"><a href="#string的构造函数" class="headerlink" title="string的构造函数"></a>string的构造函数</h3><p><strong>函数原型：</strong></p><ul><li><code>string()</code>：创建一个空的字符串，例如: <code>string str;</code></li><li><code>string(const char* s)</code>：使用C风格的字符串<code>s</code>初始化</li><li><code>string(const string&amp; str)</code>：拷贝构造函数，使用一个string对象初始化另一个string对象</li><li><code>string(int n, char c)</code>：使用n个字符<code>c</code>初始化字符串</li></ul><pre class="line-numbers language-cpp"><code class="language-cpp"><span class="token macro property">#<span class="token directive keyword">include</span> <span class="token string">&lt;string></span></span><span class="token keyword">int</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">{</span>    string s1<span class="token punctuation">;</span> <span class="token comment" spellcheck="true">//创建空字符串，调用无参构造函数</span>    <span class="token keyword">const</span> <span class="token keyword">char</span><span class="token operator">*</span> str <span class="token operator">=</span> <span class="token string">"hello world"</span><span class="token punctuation">;</span>    string <span class="token function">s2</span><span class="token punctuation">(</span>str<span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment" spellcheck="true">//把C风格字符串转换成string</span>    string <span class="token function">s3</span><span class="token punctuation">(</span>s2<span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment" spellcheck="true">//调用拷贝构造函数</span>    string <span class="token function">s4</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token string">'a'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">return</span> <span class="token number">0</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="赋值操作"><a href="#赋值操作" class="headerlink" title="赋值操作"></a>赋值操作</h3><p><strong>函数原型：</strong></p><ul><li><code>string&amp; operator=(const char* s)</code>：运算符重载，将C风格字符串赋值给当前的字符串</li><li><code>string&amp; operator=(const string &amp;s)</code>：运算符重载，把字符串s赋给当前的字符串</li><li><code>string&amp; operator=(char c)</code>：将字符赋值给当前的字符串</li><li><code>string&amp; assign(const char *s)</code>：把字符串s赋给当前的字符串</li><li><code>string&amp; assign(const char *s, int n)</code>：把字符串s的前n个字符赋给当前的字符串</li><li><code>string&amp; assign(const string &amp;s)</code>：把字符串s赋给当前字符串</li><li><code>string&amp; assign(int n, char c)</code>：用n个字符c赋给当前字符串</li></ul><pre class="line-numbers language-cpp"><code class="language-cpp"><span class="token macro property"># <span class="token directive keyword">include</span> <span class="token string">&lt;string></span></span><span class="token keyword">int</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">{</span>    string str1<span class="token punctuation">;</span>    str1 <span class="token operator">=</span> <span class="token string">"hello world"</span><span class="token punctuation">;</span>    string str2<span class="token punctuation">;</span>    str2 <span class="token operator">=</span> str1<span class="token punctuation">;</span>    string str3<span class="token punctuation">;</span>    str3 <span class="token operator">=</span> <span class="token string">'a'</span><span class="token punctuation">;</span>    string str4<span class="token punctuation">;</span>    str4<span class="token punctuation">.</span><span class="token function">assign</span><span class="token punctuation">(</span><span class="token string">"hello c++"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    string str5<span class="token punctuation">;</span>    str5<span class="token punctuation">.</span><span class="token function">assign</span><span class="token punctuation">(</span><span class="token string">"hello c++"</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    string str6<span class="token punctuation">;</span>    str6<span class="token punctuation">.</span><span class="token function">assign</span><span class="token punctuation">(</span>str5<span class="token punctuation">)</span><span class="token punctuation">;</span>    string str7<span class="token punctuation">;</span>    str7<span class="token punctuation">.</span><span class="token function">assign</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token string">'x'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">return</span> <span class="token number">0</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="拼接、查找和替换"><a href="#拼接、查找和替换" class="headerlink" title="拼接、查找和替换"></a>拼接、查找和替换</h3><p><strong>拼接操作的函数原型：</strong></p><ul><li><code>string&amp; operator+=(const char* str)</code>：重载<code>+=</code>操作符</li><li><code>string&amp; operator+=(const char c)</code>：重载<code>+=</code>操作符</li><li><code>string&amp; operator+=(const string&amp; str)</code>：重载<code>+=</code>操作符</li><li><code>string&amp; append(const char *s)</code>：把字符串s连接到当前字符串结尾</li><li><code>string&amp; append(const char *s, int n)</code>：把字符串s的前n个字符连接到当前字符串结尾</li><li><code>string&amp; append(const string &amp;s)</code>：与<code>operator+=(const string&amp; str)</code>相似</li><li><code>string&amp; append(const string &amp;s, int pos, int n)</code>：字符串s中从pos开始的n个字符连接到字符串结尾</li></ul><p><strong>查找和替换的函数原型：</strong></p><ul><li><code>int find(const string&amp; str, int pos = 0) const</code>：查找字符串str第一次出现的位置，从位置pos开始查找</li><li><code>int find(const char* s, int pos = 0) const</code>：查找s第一次出现位置，从pos开始查找</li><li><code>int find(const char* s, int pos, int n) const</code>：从pos位置查找字符串s的前n个字符第一次出现的位置。</li><li><code>int find(const char c, int pos = 0) const</code>：查找字符c第一次出现位置</li><li><code>int rfind(const string&amp; str, int pos = npos) const</code>：从pos开始从左往右查找，查找字符串str第一次出现的位置。</li><li><code>int rfind(const char* s, int pos = npos) const</code>：从pos开始从左往右查找，查找字符串s第一次出现的位置。</li><li><code>int rfind(const char* s, int pos, int n) const</code>：从pos开始从左往右查找字符串s的前n个字符第一次出现的位置。</li><li><code>int rfind(const char c, int pos = 0) const</code>：从pos开始从左往右查找字符c第一次出现位置。</li><li><code>string&amp; replace(int pos, int n, const string&amp; str)</code>：替换从pos开始的n个字符为字符串str。</li><li><code>string&amp; replace(int pos, int n,const char* s)</code>：替换从pos开始的n个字符为字符串s。</li></ul><h3 id="比较和存取"><a href="#比较和存取" class="headerlink" title="比较和存取"></a>比较和存取</h3><p>字符串比较是按字符的ASCII码进行对比，如果所有字符相等则返回0，字符串<code>A&gt;B</code>返回1，字符串<code>A&lt;B</code>返回-1。</p><p><strong>函数原型：</strong></p><ul><li><p><code>int compare(const string &amp;s) const</code>：与字符串s比较</p></li><li><p><code>int compare(const char *s) const</code>：与C风格字符串s比较</p></li><li><p><code>char&amp; operator[](int n)</code>：重载<code>[]</code>运算符，通过<code>[]</code>方式取字符</p></li><li><p><code>char&amp; at(int idx)</code>：通过at方法获取字符，返回索引idx所指的字符。</p></li></ul><h3 id="插入、删除和子串"><a href="#插入、删除和子串" class="headerlink" title="插入、删除和子串"></a>插入、删除和子串</h3><p><strong>函数原型：</strong></p><ul><li><p><code>string&amp; insert(int pos, const char* s)</code>：在位置pos插入字符串</p></li><li><p><code>string&amp; insert(int pos, const string&amp; str)</code>：插入字符串</p></li><li><p><code>string&amp; insert(int pos, int n, char c)</code>：在指定位置插入n个字符c</p></li><li><p><code>string&amp; erase(int pos, int n = npos)</code>：删除从位置pos开始的n个字符</p></li><li><p><code>string substr(int pos = 0, int n = npos) const</code>：返回由pos开始的n个字符组成的子字符串</p></li></ul><h2 id="vector容器"><a href="#vector容器" class="headerlink" title="vector容器"></a>vector容器</h2><h3 id="vector容器初识"><a href="#vector容器初识" class="headerlink" title="vector容器初识"></a>vector容器初识</h3><p>vector数据结构和<strong>数组非常相似</strong>，也称为<strong>单端数组</strong>；与普通数组的不同之处在于，数组是静态空间，而vector可以<strong>动态扩展</strong>，动态扩展并不是在原空间之后续接新空间，而是找更大的内存空间，然后将原数据拷贝新空间，释放原空间。</p><p>vector容器的迭代器是支持随机访问的迭代器。</p><p><img src="/images/vector.jpg"></p><h3 id="vector的构造函数"><a href="#vector的构造函数" class="headerlink" title="vector的构造函数"></a>vector的构造函数</h3><p>用以创建vector容器。</p><p><strong>函数原型：</strong></p><ul><li><code>vector&lt;T&gt; v </code>：采用模板实现类实现，默认构造函数，创建一个空的vector容器。</li><li><code>vector(v.begin(), v.end()) </code>：将<code>v[begin(), end()]</code>区间（<strong>左取右不取</strong>）中的元素拷贝给将要创建的vector本身。</li><li><code>vector(n, elem)</code>： 构造函数将n个元素<code>elem</code>拷贝给将要创建的vector本身。</li><li><code>vector(const vector&amp; vec)</code> ：拷贝构造函数，使用一个<code>vce</code>初始化本身</li></ul><pre class="line-numbers language-cpp"><code class="language-cpp"><span class="token macro property"># <span class="token directive keyword">include</span> <span class="token string">&lt;vector></span></span><span class="token keyword">int</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">{</span>    vector<span class="token operator">&lt;</span><span class="token keyword">int</span><span class="token operator">></span> v1<span class="token punctuation">;</span> <span class="token comment" spellcheck="true">//无参构造</span>    <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> <span class="token number">10</span><span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span><span class="token punctuation">{</span>        v1<span class="token punctuation">.</span><span class="token function">push_back</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span>    vector<span class="token operator">&lt;</span><span class="token keyword">int</span><span class="token operator">></span> <span class="token function">v2</span><span class="token punctuation">(</span>v1<span class="token punctuation">.</span><span class="token function">begin</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> v1<span class="token punctuation">.</span><span class="token function">end</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment" spellcheck="true">// 将v1元素拷贝给v2</span>    vector<span class="token operator">&lt;</span><span class="token keyword">int</span><span class="token operator">></span> <span class="token function">v3</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment" spellcheck="true">// 指定vector大小并填充指定元素</span>    vector<span class="token operator">&lt;</span><span class="token keyword">int</span><span class="token operator">></span> <span class="token function">v4</span><span class="token punctuation">(</span>v3<span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment" spellcheck="true">// 拷贝构造函数</span>    <span class="token keyword">return</span> <span class="token number">0</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="赋值操作-1"><a href="#赋值操作-1" class="headerlink" title="赋值操作"></a>赋值操作</h3><p><strong>函数原型：</strong></p><ul><li><code>vector&amp; operator=(const vector &amp;vec)</code>：重载等号操作符</li><li><code>assign(beg, end)</code>：将<code>v[begin(), end()]</code>区间（<strong>左取右不取</strong>）中的数据赋值给vector容器本身。</li><li><code>assign(n, elem)</code>：将n个元素<code>elem</code>拷贝赋值给vector容器本身。</li></ul><pre class="line-numbers language-cpp"><code class="language-cpp"><span class="token macro property"># <span class="token directive keyword">include</span> <span class="token string">&lt;vector></span></span><span class="token keyword">int</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">{</span>    vector<span class="token operator">&lt;</span><span class="token keyword">int</span><span class="token operator">></span> v1<span class="token punctuation">;</span>     <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> <span class="token number">10</span><span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span><span class="token punctuation">{</span>        v1<span class="token punctuation">.</span><span class="token function">push_back</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span>    vector<span class="token operator">&lt;</span><span class="token keyword">int</span><span class="token operator">></span> v2<span class="token punctuation">;</span>    v2 <span class="token operator">=</span> v1<span class="token punctuation">;</span> <span class="token comment" spellcheck="true">// =运算符重载</span>    vector<span class="token operator">&lt;</span><span class="token keyword">int</span><span class="token operator">></span> v3<span class="token punctuation">;</span>    v3<span class="token punctuation">.</span><span class="token function">assign</span><span class="token punctuation">(</span>v1<span class="token punctuation">.</span><span class="token function">begin</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> v1<span class="token punctuation">.</span><span class="token function">end</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment" spellcheck="true">// 区间赋值</span>    vector<span class="token operator">&lt;</span><span class="token keyword">int</span><span class="token operator">></span> v4<span class="token punctuation">;</span>    v4<span class="token punctuation">.</span><span class="token function">assign</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment" spellcheck="true">// 指定元素赋值</span>    <span class="token keyword">return</span> <span class="token number">0</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="vector容量和大小"><a href="#vector容量和大小" class="headerlink" title="vector容量和大小"></a>vector容量和大小</h3><p><strong>函数原型：</strong></p><ul><li><code>empty() </code>：判断容器是否为空</li><li><code>capacity()</code>：容器的容量</li><li><code>size()</code>：返回容器中元素的个数</li><li><code>resize(int num)</code>：重新指定容器的长度为<code>num</code>，若容器变长，则以默认值填充新位置；如果容器变短，则末尾超出容器长度的元素被删除。</li><li><code>resize(int num, elem)</code>：重新指定容器的长度为<code>num</code>，若容器变长，则以指定元素值填充新位置；如果容器变短，则末尾超出容器长度的元素被删除。</li></ul><h3 id="插入和删除"><a href="#插入和删除" class="headerlink" title="插入和删除"></a>插入和删除</h3><p><strong>函数原型：</strong></p><ul><li><code>push_back(ele)</code>：尾部插入指定元素<code>ele</code></li><li><code>pop_back()</code>：删除最后一个元素</li><li><code>insert(const_iterator pos, ele)</code>：迭代器指向位置pos插入元素ele</li><li><code>insert(const_iterator pos, int count,ele)</code>：迭代器指向位置pos插入count个指定元素</li><li><code>erase(const_iterator pos)</code>：删除迭代器指向的元素</li><li><code>erase(const_iterator start, const_iterator end)</code>：删除迭代器从start到end之间的元素</li><li><code>clear()</code>：删除容器中所有元素</li></ul><h3 id="数据存取"><a href="#数据存取" class="headerlink" title="数据存取"></a>数据存取</h3><p><strong>函数原型：</strong></p><ul><li><code>at(int idx) </code>：返回索引idx所指的数据</li><li><code>operator[] </code>：运算符<code>[]</code>重载，返回索引idx所指的数据</li><li><code>front() </code>：返回容器中第一个数据元素</li><li><code>back()</code>：返回容器中最后一个数据元素</li></ul><pre class="line-numbers language-cpp"><code class="language-cpp"><span class="token macro property"># <span class="token directive keyword">include</span> <span class="token string">&lt;vector></span></span><span class="token macro property"># <span class="token directive keyword">include</span> <span class="token string">&lt;iostream></span></span><span class="token keyword">int</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">{</span>    vector<span class="token operator">&lt;</span><span class="token keyword">int</span><span class="token operator">></span> v1<span class="token punctuation">;</span>     <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> <span class="token number">10</span><span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span><span class="token punctuation">{</span>        v1<span class="token punctuation">.</span><span class="token function">push_back</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">for</span><span class="token punctuation">(</span><span class="token keyword">int</span> i<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> v1<span class="token punctuation">.</span><span class="token function">size</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span><span class="token punctuation">{</span>        std<span class="token operator">::</span>cout <span class="token operator">&lt;&lt;</span> v1<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">&lt;&lt;</span> std<span class="token operator">::</span>endl<span class="token punctuation">;</span>        std<span class="token operator">::</span>cout <span class="token operator">&lt;&lt;</span> v1<span class="token punctuation">.</span><span class="token function">at</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span> <span class="token operator">&lt;&lt;</span> std<span class="token operator">::</span>endl<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">for</span> <span class="token punctuation">(</span>vector<span class="token operator">&lt;</span><span class="token keyword">int</span><span class="token operator">></span><span class="token operator">::</span>iterator it <span class="token operator">=</span> v<span class="token punctuation">.</span><span class="token function">begin</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span> it <span class="token operator">!=</span> v<span class="token punctuation">.</span><span class="token function">end</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span> it<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        std<span class="token operator">::</span>cout <span class="token operator">&lt;&lt;</span> <span class="token operator">*</span>it <span class="token operator">&lt;&lt;</span> <span class="token string">" "</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span>        <span class="token keyword">return</span> <span class="token number">0</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="互换容器和预留空间"><a href="#互换容器和预留空间" class="headerlink" title="互换容器和预留空间"></a>互换容器和预留空间</h3><p><strong>函数原型：</strong></p><ul><li><p><code>swap(vec)</code>：实现两个容器内元素进行互换，将vec与本身的元素进行互换。</p></li><li><p><code>reserve(int len)</code>：减少vector在动态扩展容量时的扩展次数，该方法可以给容器预留<code>len</code>个元素长度，预留位置不初始化，元素不可访问。</p></li></ul><pre class="line-numbers language-cpp"><code class="language-cpp"><span class="token macro property"># <span class="token directive keyword">include</span> <span class="token string">&lt;vector></span></span><span class="token macro property"># <span class="token directive keyword">include</span> <span class="token string">&lt;iostream></span></span><span class="token keyword">int</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">{</span>    std<span class="token operator">::</span>vector<span class="token operator">&lt;</span><span class="token keyword">int</span><span class="token operator">></span> v<span class="token punctuation">;</span>    v<span class="token punctuation">.</span><span class="token function">reserve</span><span class="token punctuation">(</span><span class="token number">100000</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//预留空间</span>    <span class="token keyword">int</span> num <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>    <span class="token keyword">int</span><span class="token operator">*</span> p <span class="token operator">=</span> <span class="token constant">NULL</span><span class="token punctuation">;</span>    <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> <span class="token number">100000</span><span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        v<span class="token punctuation">.</span><span class="token function">push_back</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span>p <span class="token operator">!=</span> <span class="token operator">&amp;</span>v<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            p <span class="token operator">=</span> <span class="token operator">&amp;</span>v<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">;</span>            num<span class="token operator">++</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span>    std<span class="token operator">::</span>cout <span class="token operator">&lt;&lt;</span> <span class="token string">"num:"</span> <span class="token operator">&lt;&lt;</span> num <span class="token operator">&lt;&lt;</span> std<span class="token operator">::</span>endl<span class="token punctuation">;</span> <span class="token comment" spellcheck="true">// num:1</span>    <span class="token keyword">return</span> <span class="token number">0</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="deque容器"><a href="#deque容器" class="headerlink" title="deque容器"></a>deque容器</h2><h3 id="deque容器初识"><a href="#deque容器初识" class="headerlink" title="deque容器初识"></a>deque容器初识</h3><p>deque与vector很相似，deque被称为双端数组，可以对头端进行插入删除操作。</p><p><strong>deque与vector区别：</strong></p><ul><li>vector对于头部的插入删除效率低，数据量越大，效率越低</li><li>deque相对而言，对头部的插入删除速度比vector快</li><li>vector访问元素时的速度会比deque快，这和两者内部实现有关</li></ul><p><img src="/images/deque.jpg"></p><p>deque内部工作原理：deque内部有个<strong>中控器</strong>，维护每段缓冲区中的内容，缓冲区中存放真实数据；中控器维护的是每个缓冲区的地址，使得使用deque时像一片连续的内存空间。</p><p>deque容器的迭代器也是支持随机访问的。</p><p><img src="/images/deque%E4%B8%AD%E6%8E%A7%E5%99%A8.jpg"></p><h3 id="deque的构造函数"><a href="#deque的构造函数" class="headerlink" title="deque的构造函数"></a>deque的构造函数</h3><p><strong>函数原型：</strong></p><ul><li><code>deque&lt;T&gt; deq</code>：默认构造函数，创建一个空的deque容器。</li><li><code>deque(beg, end)</code>：构造函数将<code>[beg, end)</code>区间中的元素拷贝给deque本身。</li><li><code>deque(n, elem)</code>：构造函数将n个元素elem拷贝给deque本身。</li><li><code>deque(const deque&amp; deq)</code>：拷贝构造函数，使用一个<code>deq</code>初始化本身</li></ul><pre class="line-numbers language-cpp"><code class="language-cpp"><span class="token macro property"># <span class="token directive keyword">include</span> <span class="token string">&lt;deque></span></span><span class="token keyword">int</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    deque<span class="token operator">&lt;</span><span class="token keyword">int</span><span class="token operator">></span> d1<span class="token punctuation">;</span> <span class="token comment" spellcheck="true">//无参构造函数</span>    <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> <span class="token number">10</span><span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span>    <span class="token punctuation">{</span>        d1<span class="token punctuation">.</span><span class="token function">push_back</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span>    deque<span class="token operator">&lt;</span><span class="token keyword">int</span><span class="token operator">></span> <span class="token function">d2</span><span class="token punctuation">(</span>d1<span class="token punctuation">.</span><span class="token function">begin</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>d1<span class="token punctuation">.</span><span class="token function">end</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    deque<span class="token operator">&lt;</span><span class="token keyword">int</span><span class="token operator">></span> <span class="token function">d3</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    deque<span class="token operator">&lt;</span><span class="token keyword">int</span><span class="token operator">></span> <span class="token function">d4</span><span class="token punctuation">(</span>d3<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="赋值操作-2"><a href="#赋值操作-2" class="headerlink" title="赋值操作"></a>赋值操作</h3><p>赋值操作和vector相同</p><p><strong>函数原型：</strong></p><ul><li><code>deque&amp; operator=(const deque &amp;deq)</code>：重载等号操作符</li><li><code>assign(beg, end)</code>：将<code>[beg, end)</code>区间中的数据拷贝赋值给本身。</li><li><code>assign(n, elem)</code>：将n个元素elem拷贝赋值给deque本身。</li></ul><h3 id="deque容量和大小"><a href="#deque容量和大小" class="headerlink" title="deque容量和大小"></a>deque容量和大小</h3><p><strong>函数原型：</strong></p><ul><li><code>deque.empty()</code>：判断容器是否为空</li><li><code>deque.size()</code>：返回容器中元素的个数</li><li><code>deque.resize(num)</code>：重新指定容器的长度为num，若容器变长，则以默认值填充新位置。如果容器变短，则末尾超出容器长度的元素被删除。</li><li><code>deque.resize(num, elem)</code>：重新指定容器的长度为num，若容器变长，则以elem值填充新位置。如果容器变短，则末尾超出容器长度的元素被删除。</li></ul><h3 id="插入和删除-1"><a href="#插入和删除-1" class="headerlink" title="插入和删除"></a>插入和删除</h3><p><strong>函数原型：</strong></p><p>两端插入删除操作：</p><ul><li><code>push_back(elem)</code>：在容器尾部添加一个数据</li><li><code>push_front(elem)</code>：在容器头部插入一个数据</li><li><code>pop_back()</code>：删除容器最后一个数据</li><li><code>pop_front()</code>：删除容器第一个数据</li></ul><p>指定位置操作：</p><ul><li><code>insert(pos,elem)</code>：在pos位置插入一个elem元素的拷贝，返回新数据的位置。</li><li><code>insert(pos,n,elem)</code>：在pos位置插入<code>n</code>个elem数据，无返回值。</li><li><code>insert(pos,beg,end)</code>：在pos位置插入另一个容器在<code>[beg,end)</code>区间的数据，无返回值。</li><li><code>clear()</code>：清空容器的所有数据</li><li><code>erase(beg,end)</code>：删除<code>[beg,end)</code>区间的数据，返回下一个数据的位置。</li><li><code>erase(pos)</code>：删除pos位置的数据，返回下一个数据的位置。</li></ul><h3 id="数据存取-1"><a href="#数据存取-1" class="headerlink" title="数据存取"></a>数据存取</h3><p><strong>函数原型：</strong></p><ul><li><code>at(int idx)</code>：返回索引<code>idx</code>所指的数据</li><li><code>operator[]</code>：运算符重载，返回索引<code>idx</code>所指的数据</li><li><code>front()</code>：返回容器中第一个数据元素</li><li><code>back()</code>：返回容器中最后一个数据元素</li><li><code>deque&lt;T&gt;::iterator</code>：迭代器</li></ul><pre class="line-numbers language-cpp"><code class="language-cpp"><span class="token macro property">#<span class="token directive keyword">include</span> <span class="token string">&lt;deque></span></span><span class="token keyword">int</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">{</span>    deque<span class="token operator">&lt;</span><span class="token keyword">int</span><span class="token operator">></span> d<span class="token punctuation">;</span>    d<span class="token punctuation">.</span><span class="token function">push_back</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    d<span class="token punctuation">.</span><span class="token function">push_back</span><span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    d<span class="token punctuation">.</span><span class="token function">push_front</span><span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    d<span class="token punctuation">.</span><span class="token function">push_front</span><span class="token punctuation">(</span><span class="token number">200</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> d<span class="token punctuation">.</span><span class="token function">size</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        cout <span class="token operator">&lt;&lt;</span> d<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">&lt;&lt;</span> <span class="token string">" "</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span>    cout <span class="token operator">&lt;&lt;</span> endl<span class="token punctuation">;</span>    <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> d<span class="token punctuation">.</span><span class="token function">size</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        cout <span class="token operator">&lt;&lt;</span> d<span class="token punctuation">.</span><span class="token function">at</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span> <span class="token operator">&lt;&lt;</span> <span class="token string">" "</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span>    cout <span class="token operator">&lt;&lt;</span> endl<span class="token punctuation">;</span>    cout <span class="token operator">&lt;&lt;</span> <span class="token string">"front:"</span> <span class="token operator">&lt;&lt;</span> d<span class="token punctuation">.</span><span class="token function">front</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&lt;&lt;</span> endl<span class="token punctuation">;</span>    cout <span class="token operator">&lt;&lt;</span> <span class="token string">"back:"</span> <span class="token operator">&lt;&lt;</span> d<span class="token punctuation">.</span><span class="token function">back</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&lt;&lt;</span> endl<span class="token punctuation">;</span>        <span class="token keyword">for</span> <span class="token punctuation">(</span>deque<span class="token operator">&lt;</span><span class="token keyword">int</span><span class="token operator">></span><span class="token operator">::</span>const_iterator it <span class="token operator">=</span> d<span class="token punctuation">.</span><span class="token function">begin</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span> it <span class="token operator">!=</span> d<span class="token punctuation">.</span><span class="token function">end</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span> it<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        cout <span class="token operator">&lt;&lt;</span> <span class="token operator">*</span>it <span class="token operator">&lt;&lt;</span> <span class="token string">" "</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">return</span> <span class="token number">0</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="排序"><a href="#排序" class="headerlink" title="排序"></a>排序</h3><p>利用算法实现对deque容器进行排序。</p><p><strong>算法：</strong></p><ul><li><code>sort(iterator beg, iterator end)</code>：对beg和end区间内的元素进行排序，对容器进行原地操作。</li></ul><pre class="line-numbers language-cpp"><code class="language-cpp"><span class="token macro property">#<span class="token directive keyword">include</span> <span class="token string">&lt;deque></span></span><span class="token macro property">#<span class="token directive keyword">include</span> <span class="token string">&lt;algorithm></span></span><span class="token keyword">int</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">{</span>    deque<span class="token operator">&lt;</span><span class="token keyword">int</span><span class="token operator">></span> d<span class="token punctuation">;</span>    d<span class="token punctuation">.</span><span class="token function">push_back</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    d<span class="token punctuation">.</span><span class="token function">push_back</span><span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    d<span class="token punctuation">.</span><span class="token function">push_front</span><span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    d<span class="token punctuation">.</span><span class="token function">push_front</span><span class="token punctuation">(</span><span class="token number">200</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token function">sort</span><span class="token punctuation">(</span>d<span class="token punctuation">.</span><span class="token function">begin</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> d<span class="token punctuation">.</span><span class="token function">end</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="stack容器"><a href="#stack容器" class="headerlink" title="stack容器"></a>stack容器</h2><h3 id="stack容器初识"><a href="#stack容器初识" class="headerlink" title="stack容器初识"></a>stack容器初识</h3><p>stack（栈）是一种<strong>先进后出</strong>(First In Last Out, FILO)的数据结构，它只有一个出口。栈中只有顶端的元素才可以被外界使用，因此<strong>栈不允许有遍历行为</strong>：栈中进入数据称为 — <strong>入栈</strong> <code>push</code>；栈中弹出数据称为 — <strong>出栈</strong> <code>pop</code>。</p><p><img src="/images/stack.jpg"></p><h3 id="stack的构造函数"><a href="#stack的构造函数" class="headerlink" title="stack的构造函数"></a>stack的构造函数</h3><p><strong>函数原型：</strong></p><ul><li><code>stack&lt;T&gt; stk</code>：stack采用模板类实现， stack对象的默认构造形式</li><li><code>stack(const stack&amp; stk)</code>：拷贝构造函数</li></ul><h3 id="赋值操作-3"><a href="#赋值操作-3" class="headerlink" title="赋值操作"></a>赋值操作</h3><p><strong>函数原型：</strong></p><ul><li><code>stack&amp; operator=(const stack &amp;stk)</code>：重载等号<code>=</code>操作符</li></ul><h3 id="大小操作"><a href="#大小操作" class="headerlink" title="大小操作"></a>大小操作</h3><p><strong>函数原型：</strong></p><ul><li><code>empty()</code>：判断堆栈是否为空</li><li><code>size()</code>：返回栈的大小</li></ul><h3 id="数据存取-2"><a href="#数据存取-2" class="headerlink" title="数据存取"></a>数据存取</h3><p><strong>函数原型：</strong></p><ul><li><code>push(elem)</code>：向栈顶添加元素</li><li><code>pop()</code>：从栈顶移除第一个元素</li><li><code>top()</code>：返回栈顶元素</li></ul><pre class="line-numbers language-cpp"><code class="language-cpp"><span class="token macro property">#<span class="token directive keyword">include</span> <span class="token string">&lt;stack></span></span><span class="token keyword">int</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">{</span>    <span class="token comment" spellcheck="true">//创建栈容器 栈容器必须符合先进后出</span>    stack<span class="token operator">&lt;</span><span class="token keyword">int</span><span class="token operator">></span> s<span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">//向栈中添加元素</span>    s<span class="token punctuation">.</span><span class="token function">push</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    s<span class="token punctuation">.</span><span class="token function">push</span><span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    s<span class="token punctuation">.</span><span class="token function">push</span><span class="token punctuation">(</span><span class="token number">30</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        cout <span class="token operator">&lt;&lt;</span> <span class="token string">"栈的大小为："</span> <span class="token operator">&lt;&lt;</span> s<span class="token punctuation">.</span><span class="token function">size</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&lt;&lt;</span> endl<span class="token punctuation">;</span>    <span class="token keyword">while</span> <span class="token punctuation">(</span><span class="token operator">!</span>s<span class="token punctuation">.</span><span class="token function">empty</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">//输出栈顶元素</span>        cout <span class="token operator">&lt;&lt;</span> <span class="token string">"栈顶元素为： "</span> <span class="token operator">&lt;&lt;</span> s<span class="token punctuation">.</span><span class="token function">top</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&lt;&lt;</span> endl<span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">//弹出栈顶元素</span>        s<span class="token punctuation">.</span><span class="token function">pop</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span>    cout <span class="token operator">&lt;&lt;</span> <span class="token string">"栈的大小为："</span> <span class="token operator">&lt;&lt;</span> s<span class="token punctuation">.</span><span class="token function">size</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&lt;&lt;</span> endl<span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="queue容器"><a href="#queue容器" class="headerlink" title="queue容器"></a>queue容器</h2><h3 id="queue容器初识"><a href="#queue容器初识" class="headerlink" title="queue容器初识"></a>queue容器初识</h3><p>queue（队列）是一种<strong>先进先出</strong>(First In First Out, FIFO)的数据结构，它有两个出口。队列容器允许从一端新增元素，从另一端移除元素，队列中只有队头和队尾才可以被外界使用，因此<strong>队列不允许有遍历行为</strong>：队列中进数据称为 — <strong>入队</strong> <code>push</code>；队列中出数据称为 — <strong>出队</strong> <code>pop</code>。</p><p><img src="/images/queue.jpg"></p><h3 id="queue的构造函数"><a href="#queue的构造函数" class="headerlink" title="queue的构造函数"></a>queue的构造函数</h3><p><strong>函数原型：</strong></p><ul><li><code>queue&lt;T&gt; que</code>：queue采用模板类实现，queue对象的默认构造形式</li><li><code>queue(const queue&amp; que)</code>：拷贝构造函数</li></ul><h3 id="赋值操作-4"><a href="#赋值操作-4" class="headerlink" title="赋值操作"></a>赋值操作</h3><p><strong>函数原型：</strong></p><ul><li><code>queue&amp; operator=(const queue &amp;que)</code>：重载等号<code>=</code>操作符</li></ul><h3 id="大小操作-1"><a href="#大小操作-1" class="headerlink" title="大小操作"></a>大小操作</h3><p><strong>函数原型：</strong></p><ul><li><code>empty()</code>：判断队列是否为空</li><li><code>size()</code>：返回队列的大小</li></ul><h3 id="数据存取-3"><a href="#数据存取-3" class="headerlink" title="数据存取"></a>数据存取</h3><p><strong>函数原型：</strong></p><ul><li><code>push(elem)</code>：往队尾添加元素</li><li><code>pop()</code>：从队头移除第一个元素</li><li><code>back()</code>：返回队列最后一个元素</li><li><code>front()</code>：返回队列第一个元素</li></ul><pre class="line-numbers language-cpp"><code class="language-cpp"><span class="token macro property">#<span class="token directive keyword">include</span> <span class="token string">&lt;queue></span></span><span class="token keyword">int</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token comment" spellcheck="true">//创建队列</span>    queue<span class="token operator">&lt;</span><span class="token keyword">int</span><span class="token operator">></span> q<span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">//向队列中添加元素，入队操作</span>    q<span class="token punctuation">.</span><span class="token function">push</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    q<span class="token punctuation">.</span><span class="token function">push</span><span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    q<span class="token punctuation">.</span><span class="token function">push</span><span class="token punctuation">(</span><span class="token number">30</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    q<span class="token punctuation">.</span><span class="token function">push</span><span class="token punctuation">(</span><span class="token number">40</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    cout <span class="token operator">&lt;&lt;</span> <span class="token string">"队列大小为："</span> <span class="token operator">&lt;&lt;</span> q<span class="token punctuation">.</span><span class="token function">size</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&lt;&lt;</span> endl<span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">//队列不提供迭代器，更不支持随机访问</span>    <span class="token keyword">while</span> <span class="token punctuation">(</span><span class="token operator">!</span>q<span class="token punctuation">.</span><span class="token function">empty</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">//输出队头元素</span>        cout <span class="token operator">&lt;&lt;</span> <span class="token string">"队头元素"</span> <span class="token operator">&lt;&lt;</span> q<span class="token punctuation">.</span><span class="token function">front</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&lt;&lt;</span> endl<span class="token punctuation">;</span>        cout <span class="token operator">&lt;&lt;</span> <span class="token string">"队尾元素"</span> <span class="token operator">&lt;&lt;</span> q<span class="token punctuation">.</span><span class="token function">back</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&lt;&lt;</span> endl<span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">//弹出队头元素</span>        q<span class="token punctuation">.</span><span class="token function">pop</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span>    cout <span class="token operator">&lt;&lt;</span> <span class="token string">"队列大小为："</span> <span class="token operator">&lt;&lt;</span> q<span class="token punctuation">.</span><span class="token function">size</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&lt;&lt;</span> endl<span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="list容器"><a href="#list容器" class="headerlink" title="list容器"></a>list容器</h2><h3 id="list容器初识"><a href="#list容器初识" class="headerlink" title="list容器初识"></a>list容器初识</h3><p>list是一种物理存储单元上非连续的存储结构，其本质是一种数据结构 链表，数据元素的逻辑顺序是通过链表中的指针链接实现的。</p><p>链表的组成：链表由一系列<strong>结点</strong>组成，结点的组成一是存储数据元素的<strong>数据域</strong>，另一个是存储下一个结点地址的<strong>指针域</strong></p><p>STL中的链表是一个双向循环链表</p><p><img src="/images/list.jpg"></p><p>由于链表的存储方式并不是连续的内存空间，因此链表list中的迭代器只支持前移和后移，属于<strong>双向迭代器</strong>，不支持随机访问。</p><p>list的优点：</p><ul><li>采用动态存储分配，不会造成内存浪费和溢出</li><li>链表执行插入和删除操作十分方便，修改指针即可，不需要移动大量元素</li></ul><p>list的缺点：</p><ul><li>链表灵活，但是空间(指针域) 和 时间（遍历）额外耗费较大</li></ul><p>List有一个重要的性质，插入操作和删除操作都不会造成原有list迭代器的失效，这在vector是不成立的。</p><h3 id="list的构造函数"><a href="#list的构造函数" class="headerlink" title="list的构造函数"></a>list的构造函数</h3><p><strong>函数原型：</strong></p><ul><li><code>list&lt;T&gt; lst</code>：list采用采用模板类实现，对象的默认构造形式。</li><li><code>list(beg,end)</code>：构造函数将<code>[beg, end)</code>区间中的元素拷贝给list容器本身。</li><li><code>list(n,elem)</code>：构造函数将<code>n</code>个元素elem拷贝给本身。</li><li><code>list(const list&amp; lst)</code>：拷贝构造函数。</li></ul><pre class="line-numbers language-cpp"><code class="language-cpp"><span class="token macro property">#<span class="token directive keyword">include</span> <span class="token string">&lt;list></span></span><span class="token keyword">int</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">{</span>    list<span class="token operator">&lt;</span><span class="token keyword">int</span><span class="token operator">></span> L1<span class="token punctuation">;</span> <span class="token comment" spellcheck="true">//无参构造</span>    L1<span class="token punctuation">.</span><span class="token function">push_back</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    L1<span class="token punctuation">.</span><span class="token function">push_back</span><span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    L1<span class="token punctuation">.</span><span class="token function">push_back</span><span class="token punctuation">(</span><span class="token number">30</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    L1<span class="token punctuation">.</span><span class="token function">push_back</span><span class="token punctuation">(</span><span class="token number">40</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    list<span class="token operator">&lt;</span><span class="token keyword">int</span><span class="token operator">></span> <span class="token function">L2</span><span class="token punctuation">(</span>L1<span class="token punctuation">.</span><span class="token function">begin</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>L1<span class="token punctuation">.</span><span class="token function">end</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment" spellcheck="true">// 将L1元素拷贝并构造L2</span>    list<span class="token operator">&lt;</span><span class="token keyword">int</span><span class="token operator">></span> <span class="token function">L3</span><span class="token punctuation">(</span>L2<span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment" spellcheck="true">// 拷贝构造</span>    list<span class="token operator">&lt;</span><span class="token keyword">int</span><span class="token operator">></span><span class="token function">L4</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">1000</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment" spellcheck="true">// 指定大小和初始值构造</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="赋值和交换"><a href="#赋值和交换" class="headerlink" title="赋值和交换"></a>赋值和交换</h3><p><strong>函数原型：</strong></p><ul><li><code>assign(beg, end)</code>：将<code>[beg, end)</code>区间中的数据拷贝赋值给本身。</li><li><code>assign(n, elem)</code>：将n个指定元素elem拷贝赋值给本身。</li><li><code>list&amp; operator=(const list&amp; lst)</code>：重载等号<code>=</code>操作符</li><li><code>swap(lst)</code>：将lst与本身的元素互换。</li></ul><h3 id="大小和容量"><a href="#大小和容量" class="headerlink" title="大小和容量"></a>大小和容量</h3><p><strong>函数原型：</strong></p><ul><li><p><code>size()</code>：返回容器中元素的个数</p></li><li><p><code>empty()</code>：判断容器是否为空</p></li><li><p><code>resize(num)</code>：重新指定容器的长度为num，若容器变长，则以默认值填充新位置；如果容器变短，则末尾超出容器长度的元素被删除。</p></li><li><p><code>resize(num, elem)</code>：重新指定容器的长度为num，若容器变长，则以elem值填充新位置；如果容器变短，则末尾超出容器长度的元素被删除。</p></li></ul><h3 id="插入和删除-2"><a href="#插入和删除-2" class="headerlink" title="插入和删除"></a>插入和删除</h3><p><strong>函数原型：</strong></p><ul><li><code>push_back(elem)</code>：在容器尾部加入一个元素</li><li><code>pop_back()</code>：删除容器中最后一个元素</li><li><code>push_front(elem)</code>：在容器开头插入一个元素</li><li><code>pop_front()</code>：从容器开头移除第一个元素</li><li><code>insert(pos,elem)</code>：在pos位置插入elem元素的拷贝，返回新数据的位置。</li><li><code>insert(pos,n,elem)</code>：在pos位置插入<code>n</code>个elem数据，无返回值。</li><li><code>insert(pos,beg,end)</code>：在pos位置插入<code>[beg,end)</code>区间的数据，无返回值。</li><li><code>clear()</code>：移除容器的所有数据</li><li><code>erase(beg,end)</code>：删除<code>[beg,end)</code>区间的数据，返回下一个数据的位置。</li><li><code>erase(pos)</code>：删除pos位置的数据，返回下一个数据的位置。</li><li><code>remove(elem)</code>：删除容器中所有与elem值匹配的元素。</li></ul><h3 id="数据存取-4"><a href="#数据存取-4" class="headerlink" title="数据存取"></a>数据存取</h3><p>list容器中不可以通过<code>[]</code>或者<code>at()</code>方式访问数据。</p><p><strong>函数原型：</strong></p><ul><li><code>front()</code>：返回第一个元素。</li><li><code>back()</code>：返回最后一个元素。</li></ul><h3 id="反转和排序"><a href="#反转和排序" class="headerlink" title="反转和排序"></a>反转和排序</h3><p><strong>函数原型：</strong></p><ul><li><code>reverse()</code>：反转链表</li><li><code>sort()</code>：链表排序，默认的排序规则是从小到大</li></ul><pre class="line-numbers language-cpp"><code class="language-cpp"><span class="token macro property">#<span class="token directive keyword">include</span> <span class="token string">&lt;list></span></span><span class="token keyword">bool</span> <span class="token function">myCompare</span><span class="token punctuation">(</span><span class="token keyword">int</span> val1 <span class="token punctuation">,</span> <span class="token keyword">int</span> val2<span class="token punctuation">)</span><span class="token punctuation">{</span>    <span class="token keyword">return</span> val1 <span class="token operator">></span> val2<span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token keyword">int</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">{</span>    list<span class="token operator">&lt;</span><span class="token keyword">int</span><span class="token operator">></span> L<span class="token punctuation">;</span>    L<span class="token punctuation">.</span><span class="token function">push_back</span><span class="token punctuation">(</span><span class="token number">90</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    L<span class="token punctuation">.</span><span class="token function">push_back</span><span class="token punctuation">(</span><span class="token number">30</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    L<span class="token punctuation">.</span><span class="token function">push_back</span><span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    L<span class="token punctuation">.</span><span class="token function">push_back</span><span class="token punctuation">(</span><span class="token number">70</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">//反转容器的元素</span>    L<span class="token punctuation">.</span><span class="token function">reverse</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">//排序</span>    L<span class="token punctuation">.</span><span class="token function">sort</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment" spellcheck="true">//默认的排序规则 从小到大</span>    L<span class="token punctuation">.</span><span class="token function">sort</span><span class="token punctuation">(</span>myCompare<span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment" spellcheck="true">//指定规则，从大到小</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="map容器"><a href="#map容器" class="headerlink" title="map容器"></a>map容器</h2><h3 id="map容器初识"><a href="#map容器初识" class="headerlink" title="map容器初识"></a>map容器初识</h3><p><strong>简介：</strong></p><ul><li>map中所有元素都是pair。</li><li>pair中第一个元素为key（键值），起到索引作用，第二个元素为value（实值）。</li><li>所有元素都会根据元素的键值自动排序（与set类似，在插入时会自动排序）。</li></ul><p><strong>map的优点：</strong></p><ul><li>可以根据key值快速找到value值</li></ul><p>map&#x2F;multimap属于<strong>关联式容器</strong>，底层结构是用二叉树实现。map和multimap<strong>区别</strong>：</p><ul><li>map不允许容器中有重复key值元素</li><li>multimap允许容器中有重复key值元素</li></ul><h3 id="map的构造函数"><a href="#map的构造函数" class="headerlink" title="map的构造函数"></a>map的构造函数</h3><p><strong>函数原型：</strong></p><ul><li><code>map&lt;T1, T2&gt; mp</code>：map默认构造函数。</li><li><code>map(const map &amp;mp)</code>：拷贝构造函数。</li></ul><h3 id="赋值、大小和交换"><a href="#赋值、大小和交换" class="headerlink" title="赋值、大小和交换"></a>赋值、大小和交换</h3><p><strong>函数原型：</strong></p><ul><li><p><code>map&amp; operator=(const map &amp;mp)</code>：重载等号<code>=</code>操作符。</p></li><li><p><code>size()</code>：返回容器中元素的数目</p></li><li><p><code>empty()</code>：判断容器是否为空</p></li><li><p><code>swap(st)</code>：交换两个集合容器</p></li></ul><h3 id="pair对组创建"><a href="#pair对组创建" class="headerlink" title="pair对组创建"></a>pair对组创建</h3><p>成对出现的数据，利用对组可以一次性返回两个数据。</p><p><strong>两种创建方式：</strong></p><ul><li><code>pair&lt;T, T&gt; p ( value1, value2 );</code></li><li><code>pair&lt;T, T&gt; p = make_pair( value1, value2 );</code></li></ul><pre class="line-numbers language-cpp"><code class="language-cpp"><span class="token macro property">#<span class="token directive keyword">include</span> <span class="token string">&lt;string></span></span><span class="token comment" spellcheck="true">//对组创建</span><span class="token keyword">int</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">{</span>    pair<span class="token operator">&lt;</span>string<span class="token punctuation">,</span> <span class="token keyword">int</span><span class="token operator">></span> <span class="token function">p</span><span class="token punctuation">(</span><span class="token function">string</span><span class="token punctuation">(</span><span class="token string">"Tom"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    cout <span class="token operator">&lt;&lt;</span> <span class="token string">"姓名： "</span> <span class="token operator">&lt;&lt;</span>  p<span class="token punctuation">.</span>first <span class="token operator">&lt;&lt;</span> <span class="token string">" 年龄： "</span> <span class="token operator">&lt;&lt;</span> p<span class="token punctuation">.</span>second <span class="token operator">&lt;&lt;</span> endl<span class="token punctuation">;</span>    pair<span class="token operator">&lt;</span>string<span class="token punctuation">,</span> <span class="token keyword">int</span><span class="token operator">></span> p2 <span class="token operator">=</span> <span class="token function">make_pair</span><span class="token punctuation">(</span><span class="token string">"Jerry"</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    cout <span class="token operator">&lt;&lt;</span> <span class="token string">"姓名： "</span> <span class="token operator">&lt;&lt;</span> p2<span class="token punctuation">.</span>first <span class="token operator">&lt;&lt;</span> <span class="token string">" 年龄： "</span> <span class="token operator">&lt;&lt;</span> p2<span class="token punctuation">.</span>second <span class="token operator">&lt;&lt;</span> endl<span class="token punctuation">;</span>        <span class="token keyword">return</span> <span class="token number">0</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="插入和删除-3"><a href="#插入和删除-3" class="headerlink" title="插入和删除"></a>插入和删除</h3><p><strong>函数原型：</strong></p><ul><li><code>insert(elem)</code>：在容器中插入元素。</li><li><code>clear()</code>：清除所有元素</li><li><code>erase(pos)</code>：删除pos迭代器所指的元素，返回下一个元素的迭代器。</li><li><code>erase(beg, end)</code>：删除区间<code>[beg,end)</code>的所有元素 ，返回下一个元素的迭代器。</li><li><code>erase(key)</code>：删除容器中值为key的元素。</li></ul><pre class="line-numbers language-cpp"><code class="language-cpp"><span class="token macro property">#<span class="token directive keyword">include</span> <span class="token string">&lt;map></span></span><span class="token keyword">int</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">{</span>    <span class="token comment" spellcheck="true">//插入</span>    map<span class="token operator">&lt;</span><span class="token keyword">int</span><span class="token punctuation">,</span> <span class="token keyword">int</span><span class="token operator">></span> m<span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">//第一种插入方式</span>    m<span class="token punctuation">.</span><span class="token function">insert</span><span class="token punctuation">(</span>pair<span class="token operator">&lt;</span><span class="token keyword">int</span><span class="token punctuation">,</span> <span class="token keyword">int</span><span class="token operator">></span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">//第二种插入方式</span>    m<span class="token punctuation">.</span><span class="token function">insert</span><span class="token punctuation">(</span><span class="token function">make_pair</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">//第三种插入方式</span>    m<span class="token punctuation">.</span><span class="token function">insert</span><span class="token punctuation">(</span>map<span class="token operator">&lt;</span><span class="token keyword">int</span><span class="token punctuation">,</span> <span class="token keyword">int</span><span class="token operator">></span><span class="token operator">::</span><span class="token function">value_type</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">30</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">//第四种插入方式</span>    m<span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">40</span><span class="token punctuation">;</span>     <span class="token comment" spellcheck="true">//删除</span>    m<span class="token punctuation">.</span><span class="token function">erase</span><span class="token punctuation">(</span>m<span class="token punctuation">.</span><span class="token function">begin</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    m<span class="token punctuation">.</span><span class="token function">erase</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">//清空</span>    m<span class="token punctuation">.</span><span class="token function">erase</span><span class="token punctuation">(</span>m<span class="token punctuation">.</span><span class="token function">begin</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>m<span class="token punctuation">.</span><span class="token function">end</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    m<span class="token punctuation">.</span><span class="token function">clear</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">return</span> <span class="token number">0</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="查找、统计和遍历"><a href="#查找、统计和遍历" class="headerlink" title="查找、统计和遍历"></a>查找、统计和遍历</h3><p><strong>函数原型：</strong></p><ul><li><code>find(key)</code>：查找key是否存在，若存在，返回该键的元素的迭代器；若不存在，返回<code>map.end()</code>。</li><li><code>count(key)</code>：统计key的元素个数</li><li><code>map&lt;T, T&gt;::iterator</code>：迭代器。</li></ul><pre class="line-numbers language-cpp"><code class="language-cpp"><span class="token macro property">#<span class="token directive keyword">include</span> <span class="token string">&lt;map></span></span><span class="token keyword">void</span> <span class="token function">printMap</span><span class="token punctuation">(</span>map<span class="token operator">&lt;</span><span class="token keyword">int</span><span class="token punctuation">,</span><span class="token keyword">int</span><span class="token operator">></span><span class="token operator">&amp;</span>m<span class="token punctuation">)</span><span class="token punctuation">{</span>    <span class="token comment" spellcheck="true">// 遍历</span>    <span class="token keyword">for</span> <span class="token punctuation">(</span>map<span class="token operator">&lt;</span><span class="token keyword">int</span><span class="token punctuation">,</span> <span class="token keyword">int</span><span class="token operator">></span><span class="token operator">::</span>iterator it <span class="token operator">=</span> m<span class="token punctuation">.</span><span class="token function">begin</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span> it <span class="token operator">!=</span> m<span class="token punctuation">.</span><span class="token function">end</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span> it<span class="token operator">++</span><span class="token punctuation">)</span>    <span class="token punctuation">{</span>        cout <span class="token operator">&lt;&lt;</span> <span class="token string">"key = "</span> <span class="token operator">&lt;&lt;</span> it<span class="token operator">-</span><span class="token operator">></span>first <span class="token operator">&lt;&lt;</span> <span class="token string">" value = "</span> <span class="token operator">&lt;&lt;</span> it<span class="token operator">-</span><span class="token operator">></span>second <span class="token operator">&lt;&lt;</span> endl<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    cout <span class="token operator">&lt;&lt;</span> endl<span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token keyword">int</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">{</span>    map<span class="token operator">&lt;</span><span class="token keyword">int</span><span class="token punctuation">,</span> <span class="token keyword">int</span><span class="token operator">></span> m<span class="token punctuation">;</span>    m<span class="token punctuation">.</span><span class="token function">insert</span><span class="token punctuation">(</span>pair<span class="token operator">&lt;</span><span class="token keyword">int</span><span class="token punctuation">,</span> <span class="token keyword">int</span><span class="token operator">></span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    m<span class="token punctuation">.</span><span class="token function">insert</span><span class="token punctuation">(</span>pair<span class="token operator">&lt;</span><span class="token keyword">int</span><span class="token punctuation">,</span> <span class="token keyword">int</span><span class="token operator">></span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    m<span class="token punctuation">.</span><span class="token function">insert</span><span class="token punctuation">(</span>pair<span class="token operator">&lt;</span><span class="token keyword">int</span><span class="token punctuation">,</span> <span class="token keyword">int</span><span class="token operator">></span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">30</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        m<span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">40</span><span class="token punctuation">;</span>     <span class="token function">printMap</span><span class="token punctuation">(</span>m<span class="token punctuation">)</span><span class="token punctuation">;</span>     <span class="token comment" spellcheck="true">//查找</span>    map<span class="token operator">&lt;</span><span class="token keyword">int</span><span class="token punctuation">,</span> <span class="token keyword">int</span><span class="token operator">></span><span class="token operator">::</span>iterator pos <span class="token operator">=</span> m<span class="token punctuation">.</span><span class="token function">find</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">if</span> <span class="token punctuation">(</span>pos <span class="token operator">!=</span> m<span class="token punctuation">.</span><span class="token function">end</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">{</span>        cout <span class="token operator">&lt;&lt;</span> <span class="token string">"找到了元素 key = "</span> <span class="token operator">&lt;&lt;</span> <span class="token punctuation">(</span><span class="token operator">*</span>pos<span class="token punctuation">)</span><span class="token punctuation">.</span>first <span class="token operator">&lt;&lt;</span> <span class="token string">" value = "</span> <span class="token operator">&lt;&lt;</span> <span class="token punctuation">(</span><span class="token operator">*</span>pos<span class="token punctuation">)</span><span class="token punctuation">.</span>second <span class="token operator">&lt;&lt;</span> endl<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">else</span><span class="token punctuation">{</span>        cout <span class="token operator">&lt;&lt;</span> <span class="token string">"未找到元素"</span> <span class="token operator">&lt;&lt;</span> endl<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token comment" spellcheck="true">//统计</span>    <span class="token keyword">int</span> num <span class="token operator">=</span> m<span class="token punctuation">.</span><span class="token function">count</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    cout <span class="token operator">&lt;&lt;</span> <span class="token string">"num = "</span> <span class="token operator">&lt;&lt;</span> num <span class="token operator">&lt;&lt;</span> endl<span class="token punctuation">;</span>            <span class="token keyword">return</span> <span class="token number">0</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="map排序"><a href="#map排序" class="headerlink" title="map排序"></a>map排序</h3><p>map容器默认排序规则为：按照key值进行<strong>从小到大</strong>排序，可以自定义改变排序规则。</p><pre class="line-numbers language-cpp"><code class="language-cpp"><span class="token macro property">#<span class="token directive keyword">include</span> <span class="token string">&lt;map></span></span><span class="token keyword">class</span> <span class="token class-name">MyCompare</span> <span class="token punctuation">{</span><span class="token keyword">public</span><span class="token operator">:</span>    <span class="token keyword">bool</span> <span class="token keyword">operator</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">(</span><span class="token keyword">int</span> v1<span class="token punctuation">,</span> <span class="token keyword">int</span> v2<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">// 降序：从大到小</span>        <span class="token keyword">return</span> v1 <span class="token operator">></span> v2<span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token punctuation">;</span><span class="token keyword">int</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token comment" spellcheck="true">//默认从小到大排序, 利用仿函数实现从大到小排序</span>    map<span class="token operator">&lt;</span><span class="token keyword">int</span><span class="token punctuation">,</span> <span class="token keyword">int</span><span class="token punctuation">,</span> MyCompare<span class="token operator">></span> m<span class="token punctuation">;</span>    m<span class="token punctuation">.</span><span class="token function">insert</span><span class="token punctuation">(</span><span class="token function">make_pair</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    m<span class="token punctuation">.</span><span class="token function">insert</span><span class="token punctuation">(</span><span class="token function">make_pair</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    m<span class="token punctuation">.</span><span class="token function">insert</span><span class="token punctuation">(</span><span class="token function">make_pair</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">30</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    m<span class="token punctuation">.</span><span class="token function">insert</span><span class="token punctuation">(</span><span class="token function">make_pair</span><span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">40</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    m<span class="token punctuation">.</span><span class="token function">insert</span><span class="token punctuation">(</span><span class="token function">make_pair</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">50</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">for</span> <span class="token punctuation">(</span>map<span class="token operator">&lt;</span><span class="token keyword">int</span><span class="token punctuation">,</span> <span class="token keyword">int</span><span class="token punctuation">,</span> MyCompare<span class="token operator">></span><span class="token operator">::</span>iterator it <span class="token operator">=</span> m<span class="token punctuation">.</span><span class="token function">begin</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span> it <span class="token operator">!=</span> m<span class="token punctuation">.</span><span class="token function">end</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span> it<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        cout <span class="token operator">&lt;&lt;</span> <span class="token string">"key:"</span> <span class="token operator">&lt;&lt;</span> it<span class="token operator">-</span><span class="token operator">></span>first <span class="token operator">&lt;&lt;</span> <span class="token string">" value:"</span> <span class="token operator">&lt;&lt;</span> it<span class="token operator">-</span><span class="token operator">></span>second <span class="token operator">&lt;&lt;</span> endl<span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="set容器"><a href="#set容器" class="headerlink" title="set容器"></a>set容器</h2><h3 id="set容器初识"><a href="#set容器初识" class="headerlink" title="set容器初识"></a>set容器初识</h3><p><strong>简介：</strong></p><ul><li><p><strong>所有元素都会在插入时自动被排序。</strong></p></li><li><p>set&#x2F;multiset属于<strong>关联式容器</strong>，底层结构是用<strong>二叉树</strong>实现。</p></li></ul><p><strong>set和multiset区别</strong>：</p><ul><li>set不允许容器中有重复的元素</li><li>multiset允许容器中有重复的元素</li></ul><h3 id="set的构造函数"><a href="#set的构造函数" class="headerlink" title="set的构造函数"></a>set的构造函数</h3><p><strong>函数原型：</strong></p><ul><li><code>set&lt;T&gt; st</code>：默认构造函数</li><li><code>set(const set&amp; st)</code>：拷贝构造函数</li></ul><h3 id="赋值、大小和交换-1"><a href="#赋值、大小和交换-1" class="headerlink" title="赋值、大小和交换"></a>赋值、大小和交换</h3><p><strong>函数原型：</strong></p><ul><li><p><code>set&amp; operator=(const set&amp; st)</code>：重载等号操作符</p></li><li><p><code>size()</code>：返回容器中元素的数目</p></li><li><p><code>empty()</code>：判断容器是否为空</p></li><li><p><code>swap(st)</code>：交换两个集合容器</p></li></ul><h3 id="插入和删除-4"><a href="#插入和删除-4" class="headerlink" title="插入和删除"></a>插入和删除</h3><p><strong>函数原型：</strong></p><ul><li><code>insert(elem)</code>：在容器中插入元素。</li><li><code>clear()</code>：清除所有元素</li><li><code>erase(pos)</code>：删除pos迭代器所指的元素，返回下一个元素的迭代器。</li><li><code>erase(beg, end)</code>：删除区间<code>[beg,end)</code>的所有元素 ，返回下一个元素的迭代器。</li><li><code>erase(elem)</code>：删除容器中值为elem的元素。</li></ul><pre class="line-numbers language-cpp"><code class="language-cpp"><span class="token macro property">#<span class="token directive keyword">include</span> <span class="token string">&lt;set></span></span><span class="token keyword">int</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">{</span>    set<span class="token operator">&lt;</span><span class="token keyword">int</span><span class="token operator">></span> s1<span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">//插入</span>    s1<span class="token punctuation">.</span><span class="token function">insert</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    s1<span class="token punctuation">.</span><span class="token function">insert</span><span class="token punctuation">(</span><span class="token number">30</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    s1<span class="token punctuation">.</span><span class="token function">insert</span><span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    s1<span class="token punctuation">.</span><span class="token function">insert</span><span class="token punctuation">(</span><span class="token number">40</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">//删除</span>    s1<span class="token punctuation">.</span><span class="token function">erase</span><span class="token punctuation">(</span>s1<span class="token punctuation">.</span><span class="token function">begin</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    s1<span class="token punctuation">.</span><span class="token function">erase</span><span class="token punctuation">(</span><span class="token number">30</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">//清空</span>    s1<span class="token punctuation">.</span><span class="token function">erase</span><span class="token punctuation">(</span>s1<span class="token punctuation">.</span><span class="token function">begin</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> s1<span class="token punctuation">.</span><span class="token function">end</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    s1<span class="token punctuation">.</span><span class="token function">clear</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">return</span> <span class="token number">0</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="查找、统计和遍历-1"><a href="#查找、统计和遍历-1" class="headerlink" title="查找、统计和遍历"></a>查找、统计和遍历</h3><p><strong>函数原型：</strong></p><ul><li><code>find(elem)</code>：查找元素elem是否存在，若存在，返回该键的元素的迭代器；若不存在，返回<code>set.end()</code>。</li><li><code>count(elem)</code>：统计元素elem的元素个数。</li><li><code>set&lt;T, T&gt;::iterator</code>：迭代器。</li></ul><pre class="line-numbers language-cpp"><code class="language-cpp"><span class="token macro property">#<span class="token directive keyword">include</span> <span class="token string">&lt;set></span></span><span class="token keyword">void</span> <span class="token function">printSet</span><span class="token punctuation">(</span>set<span class="token operator">&lt;</span><span class="token keyword">int</span><span class="token operator">></span> <span class="token operator">&amp;</span> s<span class="token punctuation">)</span><span class="token punctuation">{</span>    <span class="token keyword">for</span> <span class="token punctuation">(</span>set<span class="token operator">&lt;</span><span class="token keyword">int</span><span class="token operator">></span><span class="token operator">::</span>iterator it <span class="token operator">=</span> s<span class="token punctuation">.</span><span class="token function">begin</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span> it <span class="token operator">!=</span> s<span class="token punctuation">.</span><span class="token function">end</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span> it<span class="token operator">++</span><span class="token punctuation">)</span>    <span class="token punctuation">{</span>        cout <span class="token operator">&lt;&lt;</span> <span class="token operator">*</span>it <span class="token operator">&lt;&lt;</span> <span class="token string">" "</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span>    cout <span class="token operator">&lt;&lt;</span> endl<span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token keyword">int</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">{</span>    set<span class="token operator">&lt;</span><span class="token keyword">int</span><span class="token operator">></span> s1<span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">//插入</span>    s1<span class="token punctuation">.</span><span class="token function">insert</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    s1<span class="token punctuation">.</span><span class="token function">insert</span><span class="token punctuation">(</span><span class="token number">30</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    s1<span class="token punctuation">.</span><span class="token function">insert</span><span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    s1<span class="token punctuation">.</span><span class="token function">insert</span><span class="token punctuation">(</span><span class="token number">40</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token function">printSet</span><span class="token punctuation">(</span>s1<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">//查找</span>    set<span class="token operator">&lt;</span><span class="token keyword">int</span><span class="token operator">></span><span class="token operator">::</span>iterator pos <span class="token operator">=</span> s1<span class="token punctuation">.</span><span class="token function">find</span><span class="token punctuation">(</span><span class="token number">30</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">if</span> <span class="token punctuation">(</span>pos <span class="token operator">!=</span> s1<span class="token punctuation">.</span><span class="token function">end</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">{</span>        cout <span class="token operator">&lt;&lt;</span> <span class="token string">"找到了元素 ： "</span> <span class="token operator">&lt;&lt;</span> <span class="token operator">*</span>pos <span class="token operator">&lt;&lt;</span> endl<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">else</span><span class="token punctuation">{</span>        cout <span class="token operator">&lt;&lt;</span> <span class="token string">"未找到元素"</span> <span class="token operator">&lt;&lt;</span> endl<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token comment" spellcheck="true">//统计</span>    <span class="token keyword">int</span> num <span class="token operator">=</span> s1<span class="token punctuation">.</span><span class="token function">count</span><span class="token punctuation">(</span><span class="token number">30</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    cout <span class="token operator">&lt;&lt;</span> <span class="token string">"num = "</span> <span class="token operator">&lt;&lt;</span> num <span class="token operator">&lt;&lt;</span> endl<span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="set排序"><a href="#set排序" class="headerlink" title="set排序"></a>set排序</h3><p>set容器默认排序规则为从小到大，可以自定义改变排序规则。</p><pre class="line-numbers language-cpp"><code class="language-cpp"><span class="token macro property">#<span class="token directive keyword">include</span> <span class="token string">&lt;set></span></span><span class="token keyword">class</span> <span class="token class-name">MyCompare</span> <span class="token punctuation">{</span><span class="token keyword">public</span><span class="token operator">:</span>    <span class="token keyword">bool</span> <span class="token keyword">operator</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">(</span><span class="token keyword">int</span> v1<span class="token punctuation">,</span> <span class="token keyword">int</span> v2<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">// 降序：从大到小</span>        <span class="token keyword">return</span> v1 <span class="token operator">></span> v2<span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token punctuation">;</span><span class="token keyword">int</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>      <span class="token comment" spellcheck="true">//指定排序规则</span>    set<span class="token operator">&lt;</span><span class="token keyword">int</span><span class="token punctuation">,</span>MyCompare<span class="token operator">></span> s2<span class="token punctuation">;</span>    s2<span class="token punctuation">.</span><span class="token function">insert</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    s2<span class="token punctuation">.</span><span class="token function">insert</span><span class="token punctuation">(</span><span class="token number">40</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    s2<span class="token punctuation">.</span><span class="token function">insert</span><span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    s2<span class="token punctuation">.</span><span class="token function">insert</span><span class="token punctuation">(</span><span class="token number">30</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    s2<span class="token punctuation">.</span><span class="token function">insert</span><span class="token punctuation">(</span><span class="token number">50</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">for</span> <span class="token punctuation">(</span>set<span class="token operator">&lt;</span><span class="token keyword">int</span><span class="token punctuation">,</span> MyCompare<span class="token operator">></span><span class="token operator">::</span>iterator it <span class="token operator">=</span> s2<span class="token punctuation">.</span><span class="token function">begin</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span> it <span class="token operator">!=</span> s2<span class="token punctuation">.</span><span class="token function">end</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span> it<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        cout <span class="token operator">&lt;&lt;</span> <span class="token operator">*</span>it <span class="token operator">&lt;&lt;</span> <span class="token string">" "</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span>    cout <span class="token operator">&lt;&lt;</span> endl<span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> 编程语言 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> C++ </tag>
            
            <tag> STL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>对比学习入门</title>
      <link href="/2023/12/06/lun-wen-yue-du/dui-bi-xue-xi-ru-men/"/>
      <url>/2023/12/06/lun-wen-yue-du/dui-bi-xue-xi-ru-men/</url>
      
        <content type="html"><![CDATA[<h1 id="对比学习入门"><a href="#对比学习入门" class="headerlink" title="对比学习入门"></a>对比学习入门</h1><p><strong>长文警告</strong></p><p>研二期间去OPPO实习，研究的课题就是对比学习和人脸识别，但是当时自己研究的并不是很深入，很多问题也是一知半解的状态。最近在知乎看到了一篇关于对比学习非常棒的文章，读完之后醍醐灌顶，因此在这整理了这篇文章。原文地址：<a href="https://zhuanlan.zhihu.com/p/367290573%E3%80%82" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/367290573。</a></p><h2 id="什么是对比学习"><a href="#什么是对比学习" class="headerlink" title="什么是对比学习"></a>什么是对比学习</h2><p>对比学习(Contrastive  Learning)最近一年比较火，各路大神比如Hinton、Yann LeCun、Kaiming  He及一流研究机构比如Facebook、Google、DeepMind，都投入其中并快速提出各种改进模型：Moco系列、SimCLR系列、BYOL、SwAV…..，各种方法相互借鉴，又各有创新，俨然一场机器学习领域的军备竞赛。对比学习属于无监督或者自监督学习，但是目前多个模型的效果已超过了有监督模型，这样的结果很令人振奋。</p><p>我想，NLP领域的Bert模型，对于这波图像领域的对比学习热潮，是具有启发和推动作用的。我们知道，Bert预训练模型，通过MLM任务的自监督学习，充分挖掘了模型从海量无标注文本中学习通用知识的能力。而图像领域的预训练，往往是有监督的，就是用ImageNet来进行预训练，但是在下游任务中Fine-tuning的效果，跟Bert在NLP下游任务中带来的性能提升，是没法比的。</p><p>“但是，既然NLP这样做（自监督，无需标注数据）成功了，图像领域难道就不能成功吗？”我相信，追寻这个问题的答案，应该是促使很多人，从图像领域的有监督预训练，向自监督预训练转向的重要心理支撑。目前看，虽然说不太容易，但也算曙光乍现，而这道曙光，正是对比学习。</p><p>我们知道，有监督预训练的典型问题，就是标注数据总是有限的，就算ImageNet已经很大，但是很难更大，那么它的天花板就摆在那，就是有限的数据总量。NLP领域目前的经验应该是：自监督预训练使用的数据量越大，模型越复杂，那么模型能够吸收的知识越多，对下游任务效果来说越好。这可能是自从Bert出现以来，一再被反复证明的真理，如果它不是唯一的真理，那也肯定是最大的真理。图像领域如果技术想要有质的提升，可能也必须得走这条路，就是：充分使用越来越大量的无标注数据，使用越来越复杂的模型，采用自监督预训练模式，来从中吸取图像本身的先验知识分布，在下游任务中通过Fine-tuning，来把预训练过程习得的知识，迁移给并提升下游任务的效果。</p><p>那对比学习是要干什么呢？从目标来说，对比学习就是要干NLP领域类似Bert预训练的事情，也即是上面那几句话。</p><p>对比学习是自监督学习的一种，也就是说，不依赖标注数据，要从无标注图像中自己学习知识。我们知道，自监督学习其实在图像领域里已经被探索了很久了。总体而言，图像领域里的自监督可以分为两种类型：生成式自监督学习，判别式自监督学习。VAE和GAN是生成式自监督学习的两类典型方法，即它要求模型重建图像或者图像的一部分，这类型的任务难度相对比较高，要求像素级的重构，中间的图像编码必须包含很多细节信息。对比学习则是典型的判别式自监督学习，相对生成式自监督学习，对比学习的任务难度要低一些。目前，对比学习貌似处于“无明确定义、有指导原则”的状态，它的指导原则是：通过自动构造相似实例和不相似实例，要求习得一个表示学习模型，通过这个模型，使得相似的实例在投影空间中比较接近，而不相似的实例在投影空间中距离比较远。而如何构造相似实例，以及不相似实例，如何构造能够遵循上述指导原则的表示学习模型结构，以及如何防止模型坍塌(Model Collapse)，这几个点是其中的关键。</p><p>目前出现的对比学习方法已有很多，如果从防止模型坍塌的不同方法角度，我们可大致把现有方法划分为：基于负例的对比学习方法、基于对比聚类的方法、基于不对称网络结构的方法，以及基于冗余消除损失函数的方法。除了介绍上述几种类型的对比学习模型外，本文后面内容，还会回答下述两个问题：目前存在诸多对比学习模型，到底哪些方法效果更好？目前的对比学习模型仍然存在哪些问题？ </p><h2 id="最简单的学习范例SimCLR"><a href="#最简单的学习范例SimCLR" class="headerlink" title="最简单的学习范例SimCLR"></a>最简单的学习范例SimCLR</h2><p>我们首先以SimCLR为例来介绍一个比较“标准”的对比学习模型，其实，在SimCLR之前已经提出不少对比学习模型，比如Moco  V1出现就比SimCLR早。我们之所以首先选择SimCLR来介绍，一方面是SimCLR的效果相对它提出之前的模型，效果好得比较明显；另外一方面SimCLR采取对称结构，整体相对简洁清晰，也比较容易说清楚。而且，它奠定的结构，已成为其它对比学习模型的标准构成部分，搞明白了SimCLR，再理解其它模型，相对而言会更容易一些。</p><p>前面说过，对比学习是自监督学习，我们没有标注数据，所以需要自己构造相似数据（正例）以及不相似数据（负例），那么SimCLR如何构造正例和负例呢？</p><p><img src="/images/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0.png"></p><p>正例构造方法如上图所示。对于某张图片，我们从可能的增强操作集合$T$中，随机抽取两种：$t_1 \in T$及 $t_2 \in T$，分别作用在原始图像上，形成两张经过增强的新图像 $x_1$，$x_2$，两者互为正例。训练时，Batch内任意其它图像，都可做为 $x_1$或$x_2$的负例。这样，对比学习希望习得某个表示模型，它能够将图片映射到某个投影空间，并在这个空间内拉近正例的距离，推远负例距离。也就是说，迫使表示模型能够忽略表面因素，学习图像的内在一致结构信息，即学会某些类型的不变性，比如遮挡不变性、旋转不变性、颜色不变性等。SimCLR证明了，如果能够同时融合多种图像增强操作，增加对比学习模型任务难度，对于对比学习效果有明显提升作用。</p><p>这一点通过下图可以很清晰的看到，对角线表示数据增强只做了一次的情况，其余代表数据增强做了两次的情况，纵坐标表示第一次，横坐标表示第二次。可以看到只做一次augmentation最终的效果都不好，crop和color distort或者sobel filtering结合使用时效果是比较好的。</p><p><img src="/images/simCLR_aug.png"></p><p>有了正例和负例，接下来需要做的是：构造一个表示学习系统，通过它将训练数据投影到某个表示空间内，并采取一定的方法，使得正例距离能够比较近，负例距离比较远。在这个对比学习的指导原则下，我们来看SimCLR是如何构造表示学习系统的。</p><p><img src="/images/simCLR_model.png" alt="img"></p><p>上图展示了SimCLR模型的整体结构。它由对称的上下两个分枝（Branch）构成，搞搜索、NLP和推荐的同学对这种结构应该不陌生。对，它来了，它来了，双塔模型又来了，它就是我们俗称的双塔结构。不过图像领域不这么叫，一般叫Branch，所以我们下文遵循这种惯用叫法。</p><p>我们随机从无标训练数据中取N个构成一个Batch，对于Batch里的任意图像，根据上述方法构造正例，形成两个图像增强视图：Aug1和Aug2。Aug1  和Aug2各自包含N个增强数据，并分别经过上下两个分枝，对增强图像做非线性变换，这两个分枝就是SimCLR设计出的表示学习所需的投影函数，负责将图像数据投影到某个表示空间。</p><p>因为上下分枝是对称的，所以我们仅以增强视图Aug1所经过的上分枝来介绍投影过程。Aug1首先经过特征编码器Encoder（一般采用ResNet做为模型结构，这里以函数$f_{\theta}(x)$代表），经CNN转换成对应的特征表示$h_i$。紧随其后，是另外一个非线性变换结构Projector（由[FC-&gt;BN-&gt;ReLU-&gt;FC]两层MLP构成，这里以函数$g_{\theta}(.)$代表），进一步将特征表示 $h_i$映射成另外一个空间里的向量$z_i$。这样，增强图像经过$g_{\theta}(f_{\theta}(x))$两次非线性变换，就将增强图像投影到了表示空间，下分枝的Aug2过程类似。这会引发一个问题：为什么这种投影操作，要做两次非线性变换，而不是直接在Encoder后，只经过一次变换即可呢？这个问题的答案，稍后我们会给出解释。</p><p>对于Batch内某张图像$x$来说，在Aug1和Aug2里的对应的增强后图像分别是$x_i$和$x_j$，那么数据对$(x_i, x_j)$互为正例，而$x_i$和Aug1及Aug2里除$x_j$之外的其它任意2N-2个图像都互为负例。在经过$g_{\theta}(f_{\theta}(x))$变换后，增强图像被投影到表示空间。在表示空间内，我们希望正例距离较近，负例距离较远。如果希望达成这一点，一般通过定义合适的损失函数来实现。在介绍损失函数前，我们首先需要一个度量函数，以判断两个向量在投影空间里的距离远近，一般采用相似性函数来作为距离度量标准。具体而言，相似性计算函数采取对表示向量L2正则后的点积或者表示向量间的Cosine相似性：</p><p>$$\begin{aligned} S(z_i,z_j)&#x3D;\frac{z_i^T z_j}{||z_i||_2 ||z_j||_2} \end{aligned} $$</p><p>至于为何对比学习的相似性计算一定要做L2正则，这有背后的道理，后文会讲述原因。损失函数很关键，SimCLR的损失函数采用InfoNCE Loss，某个例子对应的InfoNCE损失为：</p><p>$$\begin{aligned} L_i&#x3D;-log(\frac{e^{S(z_i.z_i^+)&#x2F;\tau}}{\sum_{j&#x3D;0}^K e^{S(z_i.z_j)&#x2F;\tau}}) \end{aligned}$$</p><p>其中，$z_i$和$z_i^+$代表两个正例相应的表示向量。从InfoNCE可以看出，这个函数的分子部分鼓励正例相似度越高越好，也就是在表示空间内距离越近越好；而分母部分，则鼓励任意负例之间的向量相似度越低越好，也就是距离越远越好。这样，在优化过程中，通过InfoNCE损失函数指引，就能训练模型，以达成我们期望的目标。</p><p>上面介绍了SimCLR的关键做法，本身这个过程，其实是标准的预训练模式；利用海量的无标注图像数据，根据对比学习指导原则，学习出好的Encoder模型以及它对应产生的特征表示。所谓好的Encoder，就是说输入图像，它能学会并抽取出关键特征，这个过程跟Bert模型通过MLM自监督预训练其实目的相同，只是做法有差异。学好Encoder后，可以在解决下游具体任务的时候，用学到的参数初始化Encoder中的ResNet模型，用下游任务标注数据来Fine-tuning模型参数，期待预训练阶段学到的知识对下游任务有迁移作用。由此可见，SimCLR看着有很多构件，比如Encoder、Projector、图像增强、InfoNCE损失函数，其实我们最后要的，只是Encoder，而其它所有构件以及损失函数，只是用于训练出高质量Encoder的辅助结构。目前所有对比学习模型都是如此，这点还请注意。</p><p>上面在介绍SimCLR时遗留了个问题：在将增强图像投影到表示空间过程中，我们做了两次非线性映射，分别是Encoder 和Projector，为什么要做两次投影变换呢？看上去貌似没有道理，这其实是个经验结果。Moco在做特征表示投影时只有基于ResNet  的Encoder，并未后跟Projector，其实这么做才是符合直觉的做法，而Projector是在后续的SimCLR模型中提出的。实验证明，加上这个Projector对于提升模型效果改进很明显，这从经验角度说明两次投影变换是必须的。</p><p>SimCLR论文中，对于Projector和Encoder的编码差异进行了对比实验，结论是：Encoder后的特征表示，会有更多包含图像增强信息在内的细节特征，而这些细节信息经过Projector后，很多被过滤掉了。虽然为何需要两次非线性变换，目前只有实验结果，并未有理论解释。我个人猜测，可能是如下原因：我们知道，一般的特征抽取器，在做特征提取的时候，底层偏向抽取通用的低层特征，往往与任务无关，通用性强；接近比如分类任务的高层网络结构，更倾向编码任务相关的高阶特征信息。想来，Encoder和Projector也应该如此，也就是说，在接近任务的高层网络，也就是Projector，会编码更多跟对比学习任务相关的信息，低层就是Encoder，会编码更多跟任务无关的通用细节信息。对于下游任务，这种对比学习训练任务相关的特征，可能会带来负面影响。如果映射网络只包含Encoder的话，那么特征表示里会有很多预训练任务相关特征，会影响下游任务效果；而加上Projector，等于增加了网络层深，这些任务相关特征就聚集在Projector，此时Encoder则不再包含预训练任务相关特征，只包含更通用的细节特征。这是为何需要两次映射过程，我猜大致是这个原因，但也纯属无依据猜测，不保证正确性。</p><p>要说SimCLR最大的贡献，我个人觉得有两个：一个是证明了复合图像增强很重要；另外一个就是这个Projector结构。这两者结合，给对比学习系统带来很大的性能提升，将对比学习性能提升到或者超过了有监督模型，在此之后的对比学习模型，基本都采取了Encoder+Projector的两次映射结构，以及复合图像增强方法。</p><p>上面是以SimCLR为代表的典型负例对比学习系统的要点，在介绍其它对比学习模型之前，我们下面先更深入地理解对比学习工作机理，这样能更透彻了解其它对比学习系统。</p><h2 id="对比学习的工作机理"><a href="#对比学习的工作机理" class="headerlink" title="对比学习的工作机理"></a>对比学习的工作机理</h2><p><img src="/images/%E5%8D%95%E4%BD%8D%E8%B6%85%E7%90%83%E9%9D%A2.png" alt="img"></p><p>前文有述，对比学习在做特征表示相似性计算时，要先对表示向量做L2正则，之后再做点积计算，或者直接采用Cosine相似性，为什么要这么做呢？现在很多研究表明，把特征表示$g_{\theta}(f_{\theta}(x))$映射到单位超球面上，有很多好处。这里有两个关键，一个是单位长度，一个是超球面。首先，相比带有向量长度信息的点积，在去掉长度信息后的单位长度向量上操作，能增加深度学习模型的训练稳定性。</p><p>$$\begin{aligned} \frac{g_{\theta}(f_{\theta}(x))}{||g_{\theta}(f_{\theta}(x))||_2} \end{aligned} $$</p><p>另外，当表示向量$g_{\theta}(f_{\theta}(x))$被映射到超球面上，如果模型的表示能力足够好，能够把相似的例子（比如带有相同类标号的数据）在超球面上聚集到较近区域，那么很容易使用线性分类器把某类和其它类区分开（参考上图）。在对比学习模型里，对学习到的表示向量$g_{\theta}(f_{\theta}(x))$进行L2正则，或者采用Cosine相似性，就等价于将表示向量$g_{\theta}(f_{\theta}(x))$投影到了单位超球面上进行相互比较。很多对比学习模型相关实验也证明了：对表示向量进行L2正则能提升模型效果。这是为何一般要对表示向量进行L2正则操作的原因。</p><p><img src="/images/%E5%8D%95%E4%BD%8D%E8%B6%85%E7%90%83%E9%9D%A2%E5%AF%B9%E6%AF%94.png" alt="img"></p><p>那么，好的对比学习系统，应该具备怎样的潜在能力呢？论文“Understanding Contrastive Representation  Learning through Alignment and Uniformity on the  Hypersphere”对这个问题进行了探讨。它提出了好的对比学习系统应该具备两个属性：Alignment和Uniformity（参考上图）。所谓“Alignment”，指的是相似的例子，也就是正例，映射到单位超球面后，应该有接近的特征，也即是说，在超球面上距离比较近；所谓“Uniformity”，指的是系统应该倾向在特征里保留尽可能多的信息，这等价于使得映射到单位超球面的特征，尽可能均匀地分布在球面上，分布得越均匀，意味着保留的信息越充分。乍一看不好理解“分布均匀和保留信息”两者之间的关联，其实道理很简单：分布均匀意味着两两有差异，也意味着各自保有独有信息，这代表信息保留充分。</p><p><img src="/images/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0%E5%9D%8D%E5%A1%8C.png" alt="img"></p><p>Uniformity特性的极端反例，是所有数据映射到单位超球面同一个点上，这极度违背了Uniformity原则，因为这代表所有数据的信息都被丢掉了，体现为数据极度不均匀得分布到了超球面同一个点上。也就是说，所有数据经过特征表示映射过程$g_{\theta}(f_{\theta}(x))$后，都收敛到了同一个常数解，一般将这种异常情况称为模型坍塌（Collapse）。如果对比学习的损失函数定义不好，非常容易出现模型坍塌的情形（参考上图）。</p><p>在这些背景信息下，我们再重新审视类似SimCLR结构的对比学习模型，看看它是在干什么。可以看到，对比学习模型结构里的上下两个分枝，首先会将正例对$(x_i,x_i^+)$或者负例对$(x_i,x_i^-)$，通过两次非线性映射$g_{\theta}(f_{\theta}(x))$，将训练数据投影到单位超球面上。然后通过体现优化目标的InfoNCE损失函数，来调整这些映射到单位超球面上的点之间的拓扑结构关系，希望能将正例在超球面上距离拉近，负例在超球面上，相互之间推远。那么InfoNCE又是怎么达成这一点的呢？</p><p>$$\begin{aligned} L_i&#x3D;-log(\frac{e^{S(z_i.z_i^+)&#x2F;\tau}}{\sum_{j&#x3D;0}^K e^{S(z_i.z_j)&#x2F;\tau}}) \end{aligned}$$</p><p>从上面列出的InfoNCE公式可以看出，分子$S(z_i,z_i^+)$部分体现出“Alignment”属性，它鼓励正例在单位超球面的距离越近越好；而分母里的$S(z_i,z_j)$负例，则体现了“Uniformity”属性，它鼓励任意两对负例，在单位超球面上，两两距离越远越好，这种实例两两之间的推力，会尽量让特征均匀得分布在单位超球面上，保留了尽可能多的有用信息。InfoNCE其实是在Alignment和Uniformity之间寻找折中点，因为如果只有Alignment特性，很明显，模型会快速坍塌到常数解。可以说，所有在损失函数中采用负例的对比学习方法，都是靠负例的Uniformity特性，来防止模型坍塌的，这包括SimCLR系列及Moco系列等很多典型对比学习模型。</p><p><img src="/images/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0%E6%8B%89%E8%BF%91%E4%B8%8E%E6%8E%A8%E8%BF%9C.png" alt="img"></p><p>上图更形象地说明了这一点，只不过没有将数据画在单位超球面上，如果将上图右侧部分，想象成在单位超球面上的正例相互吸引，负例互斥，就是InfoNCE思想的形象表达。</p><h3 id="温度超参数的作用"><a href="#温度超参数的作用" class="headerlink" title="温度超参数的作用"></a>温度超参数的作用</h3><p>如果你足够细心，会发现InfoNCE损失函数里，有个神秘的温度超参$\tau$。那么，这个温度超参$\tau$有什么作用呢？这其实是个好问题。目前很多实验表明，对比学习模型要想效果比较好，温度超参$\tau$要设置一个比较小的数值，一般设置为0.1或者0.2。问题是：将这个超参设大或设小，它是如何影响模型优化过程的呢？目前的研究结果表明，InfoNCE是个能够感知负例难度的损失函数，而之所以能做到这点，主要依赖超参。 </p><p>什么是有难度的负例？什么是容易的负例呢？我们知道，对比学习里，对于某个数据$x_i$，除了它的唯一的正例$x_i^+$外，所有其它数据都是负例。但是，这些负例，有些和$x_i$比较像，有些则差异比较大，比如假设$x_i$是张关于狗的图片，那么另外一张狗的图片，或者一张狼的图片，就是有难度的负例，而如果是一张关于人的或者树的图片，则比较好和$x_i$区分开，是容易例子。如果经过$g_{\theta}(f_{\theta}(x))$将数据映射到单位超球面后，根据Alignment原则，一般来说，比较像的、有难度的负例在超球面上距离$x_i$比较近，而比较容易区分的负例，则在超球面上距离$x_i$比较远。所以说，对于例子$x_i$来说，在超球面上距离$x_i$越近，则这个负例越难和$x_i$区分，距离$x_i$越远，则这个负例越容易和$x_i$区分。</p><p><img src="/images/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%B8%A9%E5%BA%A6%E5%8F%82%E6%95%B0%E5%BD%B1%E5%93%8D.png" alt="img"></p><p>总体而言，温度参数$\tau$起到如下作用：温度参数会将模型更新的重点，聚焦到有难度的负例，并对它们做相应的惩罚，难度越大，也即是与$x_i$距离越近，则分配到的惩罚越多。所谓惩罚，就是在模型优化过程中，将这些负例从$x_i$身边推开，是一种斥力。也就是说，距离$x_i$越近的负例，温度超参会赋予更多的排斥力，将它从$x_i$推远。而如果温度超参数$\tau$设置得越小，则InfoNCE分配惩罚项的范围越窄，更聚焦在距离$x_i$比较近的较小范围内的负例里。同时，这些被覆盖到的负例，因为数量减少了，所以，每个负例，会承担更大的斥力（参考上图左边子图）。极端情况下，假设温度系数趋近于0，那么InfoNCE基本退化为Triplet，也就是说，有效负例只会聚焦在距离  最近的一到两个最难的实例。从上述分析，可以看出：温度超参越小，则更倾向把超球面上的局部密集结构推开打散，使得超球面上的数据整体分布更均匀（参考上图右边子图）。</p><p>那么，是不是温度超参$\tau$设置的越小越好呢？因为这个数值越小，意味着超球面上的数据分布越均匀，越符合Uniformity原则。其实，并不是这样的。因为在对比学习这种场景下，对于某个数据$x_i$，只有一对正例$(x_i,x_i^+)$，可能会发生如下的情形：距离$x_i$比较近的所谓“负例”，其实本来应该是正例，比如$x_i$是一张狗的照片，而$x_i^-$其实也是一张狗的照片。只是因为对比学习是无监督的，我们没有先验知识知晓这一点，所以也会把这张狗的照片当作负例。而如果温度超参越小，则可能越会倾向把这些本来是潜在正例的数据在超球面上推远，而这并不是我们想要看到的。要想容忍这种误判，理论上应该把温度超参设置大一些。所以，温度超参需要在鼓励Uniformity和容忍这种误判之间找到一个平衡点，而调节这个参数大小，其实就是在寻找这两者的平衡点。</p><p>上面比较形象地解释了对比学习的工作机理，接下来我们继续介绍不同的对比学习模型。我们继续接着负例方法讲，因为这个故事还没讲完。</p><h2 id="基于负样本的对比学习"><a href="#基于负样本的对比学习" class="headerlink" title="基于负样本的对比学习"></a>基于负样本的对比学习</h2><p>在前文，我们介绍了典型的基于负例的对比学习模型SimCLR，它将Batch内数据做为负例。很多实验证明了：在基于负例的对比学习中，负例数量越多，对比学习模型效果越好（有了上一小结的介绍，我想问您这是为什么？根据现有知识储备，您应该能回答出，此问题答案在本文结尾处）。而算力受限原因，我们又不可能无限放大Batch  Size，那么很自然的一个想法就是：我们选择负例的时候，不再局限于在Batch内寻找负例，而是在整个无标注训练数据集合内，随机选择任意大小的数据，来做为模型训练时的负例。这个想法比较符合直觉，看着也比较简单，但是实际做起来并不容易。</p><p>这部分内容，我们选择Moco V2，来作为在整个训练集合内选择负例的典型做法。其实这个做法主要是Moco 提出的，Moco  V2是吸收了SimCLR的Projector结构，以及更具难度的图像增强方法之后，针对Moco 的改进版本，但是效果比Moco  有明显的提升，所以我们以Moco V2来讲解。</p><p><img src="/images/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0moco.png" alt="img"></p><p>Moco  V2的模型结构如上图所示。其图像增强方法、Encoder结构、Projector结构、相似性计算方法以及InfoNCE损失函数，和SimCLR基本一致。最主要的特点和创新在两个分枝中的下分枝：SimCLR里上下两个分枝是对称的，两者可参数共享，而Moco V2的下分枝模型参数更新，则采用了动量更新（Momentum  Update）机制。下面我们简单介绍下这种动量更新机制，这个机制目前已经在很多其它领域被广泛采用。</p><p>Moco  V2的下分枝，也由序列的Encoder和Projector两次非线性映射构成，两个构件的模型结构和上分枝对应结构保持一致，但是自身独有一套参数。这套模型参数的更新，并不是通过常规的损失函数反向传播来进行梯度更新，而是采用如下的移动平均（Moving Average）机制进行更新：</p><p>$$\xi&#x3D;m\xi+(1-m)\theta$$</p><p>其中，$\theta$是上分枝对应结构的模型参数，$\xi$是下分枝对应结构的模型参数，$m$是权重调节系数。所谓“$\xi$在移动平均更新”，意思是：模型训练开始的时候，随机初始化$\xi$，当一个Batch计算完毕，上分枝模型参数  $\theta$经过反向传播梯度更新，参数发生变化。此时，使用上述公示来更新下分枝对应的参数$\xi$，一般$m$会取较大数值（0.9甚至0.99）。这意味着，相对上分枝参数，下分枝的参数变动缓慢而稳定，从随机数值一点一点朝着$\theta$更新，“小步慢走”地向最优值进行迭代。</p><p>Moco  V2维护了一个较大的负例队列，当对比学习需要在正例和负例之间进行对比计算时，就从这个负例队列里取K个，K数值可以根据需要调整大小，但是已经不局限于Batch Size的限制了。下分枝的动量更新模型结构有两个作用：一个是将第二组图像增强视图Aug2里的图像，映射到对应的表示空间编码$z_j$，为第一组图像增强视图Aug1提供正例；第二个作用是更新负例队列里数据的图像表示编码：一般会将最新Batch里Aug2对应的特征表示编码放入队列，而最老的那个Batch对应的图像编码出队，这样就可以不断更新负例队列内负例编码内容。</p><p>新问题来了；为什么负例队列里的图像编码，不用上分枝对应的最新的模型参数$\theta$，而是采用缓慢移动的$\xi$来更新呢？实验表明，假设动量更新公式中的m取很小的数值，意味着更多依赖最新参数$\theta$来更新负例队列的编码，对比学习模型效果会急剧下降。只有当m数值比较大，即下分枝的正例和负例参数缓慢而稳定的变动，才能提供较好的模型效果。这可能是因为缓慢更新的模型参数$\xi$，给队列中来自不同Batch内的实例表征编码相对稳定而统一的改变，增加了表示空间的一致性。</p><p><img src="/images/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0%E8%B4%9F%E4%BE%8B%E6%96%B9%E6%B3%95.png" alt="img"></p><p>上面以Moco-V2为代表，介绍了在全局数据范围里选择负例的典型做法。目前主流的基于负例的对比学习方法，主要是这两类：以SimCLR为代表的Batch内负例，以及以Moco为代表的全局选择负例方法。我们知道，SimCLR和Moco不断在做技术迭代，形成了系列版本，上图列出了它们各自最关键的技术特点及传承关系。目前也有很多实验表面，Encoder特征编码部分，模型越复杂，则模型效果越好。所以SimCLR-v3和Moco-V3都不约而同的选了这条技术改进路线：SimCLR-v3增加了Encoder的复杂度，采用了更深更宽的ResNet；而Moco-v3则直接用ViT这种Transformer模型替换掉了ResNet。</p><h2 id="对比聚类：负例隐身术"><a href="#对比聚类：负例隐身术" class="headerlink" title="对比聚类：负例隐身术"></a>对比聚类：负例隐身术</h2><p>另外一类对比学习方法，在模型训练过程中引入了聚类，这类方法以SwAV为代表，下图展示了SwAV的模型结构，其中的图像增强、Encoder以及Projector结构，与SimCLR基本保持一致。</p><p><img src="/images/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0swav.png" alt="img"></p><p>SwAV也是上下分枝对称结构，我们以一个例子阐述其工作流程。对于Batch内某张图像$x$来说，假设其经过图像增强后，在Aug1和Aug2里的对应的增强后图像分别是$x_i$和$x_j$，数据对$(x_i,x_j)$互为正例。增强视图$x_i$走上分枝，经过$g_{\theta}(f_{\theta}(x_i))$投影到单位超球面中某点$z_i$，增强视图$x_j$走下分枝，经过$g_{\theta}(f_{\theta}(x_j))$投影到单位超球面中某点$z_j$。之后，SwAV对Aug1和Aug2中的表示向量，根据Sinkhorn-Knopp算法，在线对Batch内数据进行聚类。假设走下分枝的$x_j$聚类到了$q_j$类，则SwAV要求表示学习模型根据$x_i$预测$x_j$所在的类，也就是说，要将$z_i$分到第$q_j$类，具体损失函数采用$z_i$和Prototype中每个类中心向量的交叉熵：</p><p>$$\begin{aligned} L_{aug1}(z_i,q_j)&amp;&#x3D; -\sum_k q_j^klog(p_i^k) \\ p_i^k&amp;&#x3D; \frac{e^{(z_i c_k)&#x2F;\tau}}{\sum_{k’’}e^{(z_i c_{k’’})&#x2F;\tau}} \end{aligned}$$</p><p>其中，$c_k$为第k个聚类的类中心向量，$\tau$为温度超参数。因为是对称结构，同样的，SwAV要求模型根据$x_j$预测$x_i$所在的类，也就是说，要将$z_j$分到第$q_i$类。所以，SwAV的总体损失函数是两个分枝损失之和：</p><p>$$L_{SwAV}&#x3D;L_{aug1}(z_i,q_j)+L_{aug2}(z_j,q_i)$$</p><p>这被称为Swapped Prediction。</p><p>SwAV也会面临模型坍塌的问题，具体表现形式为：Batch内所有实例都聚类到同一个类里。所以为了防止模型坍塌，SwAV对聚类增加了约束条件，要求Batch内实例比较均匀地聚类到不同的类别中。</p><p>这种对比聚类方法，看上去貌似只用了正例，未使用负例。但本质上，它与直接采用负例的对比学习模型，在防止模型坍塌方面作用机制是类似的，是一种隐形的负例。我们可以再仔细观察下它的损失函数，从中不难看出，在单位球面中，它要求某个投影点$z_i$向另外一个投影点$z_j$所属的聚类中心靠近，这体现了Alignment原则；而分母中的投影点$z_j$所不属于的那些类中心，则充当了负例，它要求投影点$z_i$在超球面上，和其它聚类中心越远越好，这体现了Uniformity属性，也是防止模型坍塌的关键。我们也可以换个角度，从聚类的角度来看SimCLR中的正例和负例，我们可以把SimCLR看成是：每两个正例组成了一个聚类中心。如果从这个角度看，其实SimCLR这种正负例方法，是种极端情况下的聚类模型。我们在上文说过，SimCLR这种模式，当温度超参设的比较小的时候，容易出现误判的负例，而聚类模型无疑在容忍负例误判方面，天然有很好的包容力，这也许是聚类方法效果好的原因之一。</p><p>DeepCluster是更早出现的采用两阶段聚类的自监督模型，SwAV论文中对DeepCluser进行了改造，形成了DeepCluser-V2模型。从概念上，可以简单将DeepCluser-V2理解为和SwAV整体结构类似的工作，只不过SwAV对每个Batch数据在线聚类，而DeepCluster-V2是每个Epoch做一次更大规模的聚类。目前来看，SwAV和DeepCluster-V2是效果最好的对比学习模型之一。</p><h2 id="基于正样本的对比学习"><a href="#基于正样本的对比学习" class="headerlink" title="基于正样本的对比学习"></a>基于正样本的对比学习</h2><h3 id="未解之谜BYOL"><a href="#未解之谜BYOL" class="headerlink" title="未解之谜BYOL"></a>未解之谜BYOL</h3><p>上文有述，在常见的基于负例的对比学习方法中，负例有着举足轻重的作用，它起到了将投影到超球体平面的各个实例对应的表示向量相互推开，使得图像对应的表示向量在超球体表面分布均匀的作用，以此来避免表示学习方法模型坍塌问题。尽管对比聚类方法看似没有明确使用负例，但如果深究，会发现仍然是负例在避免模型坍塌方面起作用。</p><p>那么，问题来了：如果我们只使用正例，不使用负例来训练对比学习模型，这种思路是可行的吗？乍一看，这几乎是不可能的：假设只有正例，模型推动正例在表示空间内相互靠近。如果只有这一优化目标，很明显，理论上，模型会很快收敛到常数解，也就是所有数据会被映射到表示空间里同一个点上。就是说，很容易出现模型坍塌的结局。</p><p>但是，BYOL模型就是这么做的，关键是，它还做成功了，更关键的是，不仅做成功了，它还是目前效果最好的对比学习模型之一。那么，BYOL是怎么做到的呢？为什么它能够只用正例来训练对比学习模型，而不会出现模型崩塌的结局呢？</p><p><img src="/images/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0BYOL.png" alt="img"></p><p>BYOL的模型结构如上图所示。对于Batch内任意图像，类似SimCRL采取随机图像增强，产生两组增强图像视图Aug1和Aug2，彼此互为正例，分别走上下两个模型分枝，上分枝被称为Online，下分枝被称为Target。Online分枝的Encoder和Projector和其它对比学习模型是一样的，但是，在Projector之后，新增了一个非线性变换模块Predictor，Predictor的结构和Projector类似（[FC-&gt;BN-&gt;ReLU-&gt;FC]构成的MLP映射网络），产生表示向量$v_i$并对$v_i$做L2正则化，将向量映射到单位超球面上。Target分枝结构类似Moco  V2对应下分枝的动量更新结构，即由自有参数的Encoder和Projector构成，且模型参数不参与梯度更新，采用Online分枝对应结构参数的Moving Average动量更新方式。以此方式，产生增强图像Aug2的向量$z_j$，同样地，会对$z_j$做L2正则化操作，将表示向量映射到单位超球面上。但是，因为BYOL不用负例，所以并不需要维护Moco V2中的负例队列，下分枝只是对Aug2中的正例进行投影。</p><p>对于BYOL来说，它的优化目标要求Online部分的正例，在表示空间中向Target侧对应的正例靠近，也即拉近两组图像增强正例之间的距离，对应Loss 函数为：</p><p>$$\begin{aligned}L_{aug1}&#x3D;||v_i-z_j||_2^2&#x3D;2-2\frac{v_i z_j}{||v_i||_2 ||z_j||_2}\end{aligned}$$</p><p>可见，经过改写，$L_{aug1}$也是Cosine相似性的一个变体，它的最小值对应两个表示向量的Cosine最大值，也即优化目标是在单位超球面上，正例之间的距离越近越好。由于online和Target分枝是不对称的，所以BYOL会交换两批增强图像，要求Aug2的图像也走一遍Online网络，并向Aug1图像对应的Target分枝表示向量靠近。也就是说，BYOL的损失函数为：</p><p>$$L_{byol}&#x3D;L_{aug1}+L_{aug2}$$</p><p>我们知道，Moco V2在下分枝也采用了动量更新结构，如果我们把Moco  V2的负例队列抛掉，并在它的上分枝加入类似BYOL的Predictor模块，则BYOL和Moco  V2在结构上就保持一致。如果这么改动，两者的差异主要体现在损失函数带来的优化目标不一样：两者都试图将正例在表示空间拉近，但是Moco  V2会在InfoNCE损失函数里用负例来防止模型坍塌，而BYOL对应的损失函数里，则没有对应的负例子项。</p><p>问题是：既然BYOL只用正例，它是如何防止模型坍塌的呢？背后的原因，目前仍然是未解之谜，不过对此也有些研究进展。BYOL的论文里首先指明了：之所以它没有坍塌到常数解，是由于online和Target两者结构的不对称造成的。具体而言，是动量更新的target结构和Online中的Predictor共同协作发生作用的。如果拿掉Predictor，或者把Target结构中的模型参数改成近乎实时和Online对应结构保持一致（就是说，每个Batch反向传播后，将Online部分最新的参数完全赋予给Target对应结构参数。或者理解为，动量更新公式中权重m取值为0），无论是哪种情况，模型都会发生坍塌。BYOL在论文里进一步实验，表明了最关键的因素在于新加入的Predictor结构：即使Target结构参数和Online部分保持一致，只要把Predictor部分的学习率调大，那么BYOL同样也不会坍塌。这说明Predictor的存在，是BYOL模型不坍塌的最关键因素，但是要配置大的学习率。此外，有其它研究[参考：Understanding self-supervised and contrastive learning with bootstrap your own latent  (BYOL).]指出，Predictor中的BN在其中起到了主要原因，因为BN中采用的Batch内统计量，起到了类似负例的作用。但是很快，BYOL的作者在另外一篇文章里[参考：BYOL works even without batch statistics]对此进行了反驳，把Predictor中的BN替换成Group  Norm+Weight  standard，这样使得Predictor看不到Batch内的信息，同样可以达到采用BN类似的效果，这说明并非BN在起作用。</p><p>所以说，为何BYOL这种只用正例的对比学习模型不会发生期望中的模型坍塌，目前还未有定论，但是我们可以定位到主要由于Predictor结构的存在造成的。当然，说是模型结构的不对称带来的效果，原则上是没有问题的，因为这是一种相对粗略的说法。</p><h3 id="大道至简Simsiam"><a href="#大道至简Simsiam" class="headerlink" title="大道至简Simsiam"></a>大道至简Simsiam</h3><p>SimSiam进一步对BYOL进行了简化，我们可以大致将SimSiam看作是：把BYOL的动量更新机制移除，下分枝的Encoder及Projector和上分枝对应构件参数共享版本的BYOL（参考下图），类似前面介绍BYOL里说的Predictor加大学习率的版本。但是，从后续文献的实验对比来看，SimSiam效果是不及BYOL的，这说明动量更新机制尽管可能不是防止模型坍塌的关键因素，但是对于提升对比学习模型效果是很重要的。<br><img src="/images/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0simsiam.png" alt="img"></p><h3 id="消除冗余Barlow-Twins"><a href="#消除冗余Barlow-Twins" class="headerlink" title="消除冗余Barlow Twins"></a>消除冗余Barlow Twins</h3><p>除了BYOL这种只使用正例的模型外，还有一类对比学习模型，以Barlow Twins为代表，也只使用了正例。Barlow  Twins结构如下图所示，在图像增强、Encoder以及Projector这几处，和SimCLR模型基本保持一致。我们上面说过，BYOL是靠上下分枝的结构不对称，来阻止模型坍塌的。然而，Barlow  Twins采取了上下分枝对称结构，且两者参数共享。它既没有使用负例，也没有使用不对称结构，主要靠替换了一个新的损失函数，可称之为“冗余消除损失函数”，来防止模型坍塌。</p><p><img src="/images/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0barlowtwins.png" alt="img"></p><p>与常规的对比学习不同，在将增强图像经过$g_{\theta}(f_{\theta}(x))$投影后，一般对表示向量做L2正则，去除表示向量的长度因素，将之投影到单位超球面上。Barlow  Twins则不然，它在Batch维度，对Aug1和Aug2里的正例分别做了类似BN的正则。之后，顺着Batch维，对Aug1和Aug2两个正例表示矩阵做矩阵乘法，求出两者的互相关性矩阵（cross-correlation matrix），其损失函数定义在这个互相关矩阵$C$上：</p><p>$$L_{bt}&#x3D;\sum_i (1-C_{ii})^2 + \lambda \sum_i \sum_{j \neq i}C_{ij}^2$$</p><p>损失函数$L_{bt}$第一个子项被称为“不变项”，第二个子项被称为“冗余消除项”。$C_{ii}$为互相关性矩阵$C$的对角线元素，$C_{ij}$为非对角线元素。可以看出，它的优化目标为希望互相关性矩阵$C$的对角线元素为1，非对角线元素为0，也就是希望互相关性矩阵是个单位矩阵$I$。如果仔细分析，可以看出这个“不变项”，起到了把正例在表示空间相互拉近的作用，而“冗余消除项”，其实是希望Aug1和Aug2矩阵里的特征表示向量中，向量每个元素相互之间增强独立性，也就是尽可能消除表示向量里各个bit位之间的冗余信息表达，这个子项起到了类似负例的作用，避免模型坍塌。</p><p>从Barlow Twins我们可以看出，如果能够合理设置损失函数，那么光靠损失函数，也可以避免模型坍塌现象。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>最近一年，对比学习技术确实取得了很大的进展，在不少任务上超过了监督学习的效果。但是，从目前研究进展看，也存在一些问题。我们知道，自监督方法的一个潜在好处是；理论上随着无标注数据训练数据量的增大，那么自监督模型学习到的图像天然结构知识越丰富，应用在下游业务效果也应该越好。但是，从这一点上来看，目前的对比学习是有局限的，实验表明，当自监督数据量增加到非常大的时候，貌似并未能带来更多明显收益与效果。这说明目前的对比学习也好，自监督学习也好，仍然有很大的改进空间。</p><p>当然，因为对比学习比较火，已经被延伸应用到很多图像处理外的其它领域，比如NLP，多模态等，我们这里说的所谓问题，仅仅针对图像处理领域里对比学习基础模型本身而言的，无关其它应用领域。</p><ul><li>训练数据偏置（Bias）问题</li></ul><p>目前大多数对比学习采用的自监督训练数据，一般会用ImageNet，但是用ImageNet做为对比学习训练数据，有个问题：  ImageNet这种精挑细选出来的用于分类的数据，往往一个图片仅包含单个类别的实例，这也好理解，本来就是用来分类的，如果一张图片包含多个不同类的实体，那分类标签没法打。但是这带来的问题是：这种数据还是太干净了，如果我们在网上随意挑选图片，大多数都在描述一个场景，情况比较复杂，可能一张图片包含多个不同类别的实例。而目前的对比学习方法，对于处理此类一张图包含多类别实体的图片，效果并不好，这就是所谓的训练数据偏置问题。我个人认为，这个问题还是比较严重的，因为要想真正做到自监督，对训练数据要求就要放低，这样才能快速扩充更多数据用来训练。CASTing Your Model:Learning to Localize Improves Self-Supervised  Representations文章探讨了这个问题并提出了一些解决办法。</p><ul><li>更好构建正例的方法</li></ul><p>正确地做图像增强，构建好的有难度的正例，对于对比学习是十分关键的。这样我们可以让表示学习系统，学到更多种类的图像不变性，增强表示学习模型的表达能力。虽然目前有很多图像增强方法，但是目前研究（参考：Demystifying Contrastive Self-Supervised Learning:Invariances, Augmentations and  Dataset  Biases）表明，与监督学习相比，对比学习模型主要学习到的，更多是一种图像遮挡不变性和颜色不变性，对于其它的常见不变形，比如视角不变性、照明不变性等，对比学习模型的效果要明显弱于监督学习。所以，如何构造正例，使得对比学习模型能学习更多种类的空间不变性，也是非常关键的。</p><ul><li>像素级学习能力</li></ul><p>从目前对比学习模型的运行机制看，因为是判别模型，目标相对容易，表示学习系统能学到细粒度的特征信息，但是对于像素级特征，应该是表达能力不足的。而图像处理具体的子领域众多，除了常见的分类任务，很多任务比如Object  Segmentation等，都需要在像素级进行操作，所以如何改造现有对比学习模型，使得它能够更好地帮助像素级下游任务，也是比较重要的。论文Dense Contrastive Learning for Self-Supervised Visual  Pre-Training针对这个问题，提出了改进方法。</p><p>除了上述几个问题，其实还有很多可以列在这里的，比如只使用正例的对比学习模型，从原理上讲，到底为何模型能够不坍塌？再比如，目前很多探索，集中研究对比学习中的Hard负例问题。我们从上文讲解可知：对于负例对比学习方法，之所以负例越多模型效果越好，其实本质上，是因为越多负例，会包含更多的Hard负例，而这些Hard负例对于模型贡献较大，而easy负例，其实没多少贡献。但是，我们又知道，温度超参本身其实是可以聚焦在Hard负例上的。那么，Hard负例应该研究什么具体问题？这个需要仔细考虑。再比如，目前不少研究在考虑融合有监督模型和对比学习，试图兼具两者的优点，这个有多大意义？……..诸如此类，很多问题与方向，不一而足，篇幅原因，到此为止。</p>]]></content>
      
      
      <categories>
          
          <category> 论文 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 论文阅读 </tag>
            
            <tag> 自监督 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>分类算法的评估指标</title>
      <link href="/2023/11/27/suan-fa/fen-lei-suan-fa-de-ping-gu-zhi-biao/"/>
      <url>/2023/11/27/suan-fa/fen-lei-suan-fa-de-ping-gu-zhi-biao/</url>
      
        <content type="html"><![CDATA[<h1 id="分类算法的评估指标"><a href="#分类算法的评估指标" class="headerlink" title="分类算法的评估指标"></a>分类算法的评估指标</h1><p>分类任务中的评价指标有很多，选择何种评价指标最主要的是参考具体任务的目标。首先分类任务中最常用的计算方式是混淆矩阵，下面是一个二分类的混淆矩阵。</p><p><img src="/images/%E6%B7%B7%E6%B7%86%E7%9F%A9%E9%98%B5.jpg"></p><p>矩阵中每个值的含义：</p><p>TP(True Positive)：标签为positive，模型预测为positive的样本数量；</p><p>FP(False Positive)：标签为negative，模型预测为positive的样本数量；</p><p>FN(False Negative)：标签为positive，模型预测为negative的样本数量；</p><p>TN(True Negative)：标签为negative，模型预测为negative的样本数量。</p><p>上述四个变量可以理解为都是对于算法模型而言的，其中T(true)&#x2F;F(false)表示模型判断正确&#x2F;错误，P(positive)&#x2F;N(negative)表示模型预测为positive&#x2F;negative样本，即TP表示模型预测是Positive且模型预测正确(True)；FN表示模型预测是Negative且模型预测错误(False)。</p><h2 id="Accuracy"><a href="#Accuracy" class="headerlink" title="Accuracy"></a>Accuracy</h2><p>准确率（Accuracy）：它描述的是预测结果中，预测正确的数量占总预测数量的比例。</p><p>$$\begin{aligned} Accuracy&#x3D;\frac{TP+TN}{TP+TN+FP+FN} \end{aligned}$$</p><p>该指标的缺点是，当数据的类别分布极不平衡时，不能客观地评价模型的好坏。</p><h2 id="F1-score"><a href="#F1-score" class="headerlink" title="F1 score"></a>F1 score</h2><p>F1分数是分类模型常用的评估指标之一，它是由模型的precision和recall综合计算得到。Precision也叫查准率，它描述的是预测结果中某类别预测正确的概率；Recall也叫查全率，它描述的是真实值中某类别被预测正确的概率。</p><p>在一般意义下，precision和recall的定义都是针对正例来说的：</p><p>$$\begin{aligned} precision &#x3D; \frac{TP}{TP+FP} \end{aligned}$$</p><p>$$\begin{aligned} recall &#x3D; \frac{TP}{TP+FN} \end{aligned}$$</p><p>$$\begin{aligned} F1 &#x3D; \frac{2 \times precision \times recall}{precision+recall} \end{aligned}$$</p><p>从公式可以看出，precision计算的是模型预测的所有positive样本中，预测正确的比例；recall计算的是数据集中所有的positive样本，模型预测正确的比例。</p><p>这些指标都是基于混淆矩阵计算的。当分类的结果多于两种的时候，混淆矩阵同时适用。以下面的混淆矩阵为例，假设模型目的是为了预测样本是什么动物，左边是结果。当分析每个类别时，可以<strong>将多分类问题看作是每个类别的二分问题</strong>：</p><p><img src="/images/F1%E8%AE%A1%E7%AE%97%E4%BE%8B%E5%AD%90.jpg"></p><h2 id="AUC-Area-Under-ROC-Curve"><a href="#AUC-Area-Under-ROC-Curve" class="headerlink" title="AUC(Area Under ROC Curve)"></a>AUC(Area Under ROC Curve)</h2><h3 id="四个指标"><a href="#四个指标" class="headerlink" title="四个指标"></a>四个指标</h3><p>AUC指的是模型的ROC曲线下的面积。首先需要介绍ROC曲线是什么，我们可以根据混淆矩阵再定义几个指标：</p><p>$\begin{aligned} TPR &#x3D; \frac{TP}{TP+FN} \end{aligned}$</p><p>$\begin{aligned}FPR &#x3D; \frac{FP}{FP+TN} \end{aligned}$</p><p>$\begin{aligned} TNR &#x3D; \frac{TN}{TN+FP} \end{aligned}$</p><p>$\begin{aligned} FNR &#x3D; \frac{FN}{FN+TP} \end{aligned}$</p><p>从公式可以看出，TPR实际上就是通常意义上的recall，是对于positive样本计算的recall；而TNR是对于负样本计算的recall，即数据集中所有的negative样本中模型预测正确的比例。</p><p>如果记recall for positive为$R_p$，那么FNR就是$1-R_p$，即数据集中所有的positive样本中模型预测错误的比例（和TPR刚好相反）；如果记recall for negative为$R_n$，那么FPR就是$1-R_n$，即数据集中所有的negative样本中模型预测错误的比例（和TNR刚好相反）。</p><p>从TPR和FPR的角度来看，一个好模型需要有较高的TPR和较低的FPR，即数据集中所有positive样本预测正确的越多越好，所有negative样本中预测错误的越少越好。</p><h3 id="AUC计算"><a href="#AUC计算" class="headerlink" title="AUC计算"></a>AUC计算</h3><p>对于任意一个训练好的模型，在给定测试数据上都能计算出它的TPR和FPR。以FPR为横坐标，TPR为纵坐标，我们可以将任意模型的一对（FPR，TPR）画在该坐标图中，如下图所示。同时我们将由该坐标轴构成的空间称为ROC空间。图中假设有A、B、C、D、E共计五个模型。在ROC空间中，模型越靠近左上角，表明模型效果越好。</p><p><img src="/images/ROC%E7%A9%BA%E9%97%B4.jpg"></p><p>在二分类问题中，我们计算模型（FPR，TPR）时实际上默认假设了一个判定阈值，即当模型预测样本为positive的<strong>概率</strong>大于该阈值时，样本被判定为positive；反之样本被判定为negative。对于绝大多数算法而言，在它建模过程中都包含了该假设，且阈值通常为0.5。那么如果尝试用不同的判定阈值来计算（FPR，TPR），我们也就能得到多组（FPR，TPR），因此可以近似地在ROC空间中画出一条曲线，该曲线就是ROC曲线。只要（FPR，TPR）点对足够多，则可以近似计算出ROC曲线下的面积，该面积就是AUC值。</p><p>一个简单的计算AUC的例子如下图所示。</p><p><img src="/images/%E8%AE%A1%E7%AE%97AUC.jpg"></p><p>图中左面的表格是20测试样本，Class是它的真实标签，p表示positive，n表示negative。Score是模型预测样本为positive的概率。右图是由该预测结果画出的ROC曲线，判定概率依次从大到小取每一个Score的具体值。所以从具体操作层面来看，我们首先用模型对所有测试样本预测得到它们为positive的概率。然后将概率由高到低排序。从排序后的列表中依次选择每一个Score作为判定阈值，计算出（FPR，TPR），如此重复，即可画出ROC曲线。得到ROC曲线后，我们可以用相邻两个点之间连线与X轴构成的面积近似作为两点之间的曲线面积，如此重复，得到最终AUC。</p><h3 id="sklearn中的AUC"><a href="#sklearn中的AUC" class="headerlink" title="sklearn中的AUC"></a>sklearn中的AUC</h3><p><code>sklearn.metrics.roc_curve()</code> 函数是用于计算二分类问题中的接收者操作特征曲线（ROC 曲线）以及对应的阈值。ROC 曲线是以假阳性率（False Positive Rate, FPR）为横轴，真阳性率（True Positive Rate, TPR）为纵轴，绘制的分类器性能曲线。</p><p>以下是该函数的用法：</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>metrics <span class="token keyword">import</span> roc_curvefpr<span class="token punctuation">,</span> tpr<span class="token punctuation">,</span> thresholds <span class="token operator">=</span> roc_curve<span class="token punctuation">(</span>y_true<span class="token punctuation">,</span> y_score<span class="token punctuation">,</span> pos_label<span class="token operator">=</span>None<span class="token punctuation">,</span> sample_weight<span class="token operator">=</span>None<span class="token punctuation">,</span> drop_intermediate<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>参数：</p><ul><li><code>y_true</code>: 真实的二元类别标签，需要是 0 或 1。</li><li><code>y_score</code>: 模型预测的概率或决策函数值，用于计算 ROC 曲线的阈值。需要是浮点数数组。</li><li><code>pos_label</code>: 用于计算 ROC 曲线的正类别标签。默认为 <code>None</code>，此时将正类别标签设为 1。</li><li><code>sample_weight</code>: 样本权重，默认为 <code>None</code>，表示所有样本的权重相同。</li><li><code>drop_intermediate</code>: 是否在计算中间结果时删除阈值为 0 或 1 的点。默认为 <code>True</code>，表示删除这些点，得到的 FPR 和 TPR 的数量不一定相等。</li></ul><p>返回值：</p><ul><li><code>fpr</code>: 假阳性率数组。</li><li><code>tpr</code>: 真阳性率数组。</li><li><code>thresholds</code>: 阈值数组，用于计算 ROC 曲线。</li></ul><h2 id="语义分割的评价指标"><a href="#语义分割的评价指标" class="headerlink" title="语义分割的评价指标"></a>语义分割的评价指标</h2><p>语义分割，本质是一个分类任务，常规分类任务的对象是图像中的物体，而<strong>语义分割的对象是图像中的每个像素点</strong>。</p><h3 id="像素准确率"><a href="#像素准确率" class="headerlink" title="像素准确率"></a>像素准确率</h3><ul><li>像素准确率Pixel Accuracy：预测正确的像素值占总像素值的百分比（对应于上文的Accuracy指标）</li></ul><p>$$\begin{aligned} PA&#x3D;\frac{TP+TN}{TP+TN+FP+FN} \end{aligned}$$</p><ul><li>类别像素准确率class Pixel Accuracy：某一类预测正确的像素值占预测为该类的总像素值的百分比（对应于上文的Precision指标）</li></ul><p>$$\begin{aligned} CPA&#x3D;\frac{TP}{TP+FP} \end{aligned}$$</p><ul><li>类别平均像素准确率mean Pixel Accuracy：所有类别像素准确率之和的平均。首先求得每个类别的像素准确率，然后对它们求和再平均</li></ul><p>$$\begin{aligned} MPA&#x3D;\frac{1}{k+1}\sum_{k&#x3D;0}^k\frac{TP}{TP+FP} \end{aligned}$$</p><h3 id="交并比IoU"><a href="#交并比IoU" class="headerlink" title="交并比IoU"></a>交并比IoU</h3><p>交并比IoU（Intersection over Union），它表示模型对于某一类别预测结果和真实值的交集和并集的比值。对于目标检测来说，就是检测框与真实框之间的交并比；对于图像分割来说，就是预测mask与真实mask之间的交并比。</p><p><img src="/images/IoU.jpg"></p><p>该指标也可以通过混淆矩阵计算获得，针对正例来说，计算公式如下：</p><p>$$\begin{aligned} IoU&#x3D;\frac{X\cap Y}{X\cup Y}&#x3D;\frac{TP}{TP+FP+FN} \end{aligned}$$</p><p>举个语义分割中IoU计算例子，下图可见：</p><p><img src="/images/IoU%E4%BE%8B%E5%AD%90.png"></p><ul><li>平均交并比Mean IoU：在所有类别的IoU上取平均值。</li></ul><p>$$\begin{aligned} MIoU&#x3D;\frac{1}{k+1}\sum_{k&#x3D;0}^k\frac{TP}{TP+FP+FN} \end{aligned}$$</p><h3 id="Dice指标"><a href="#Dice指标" class="headerlink" title="Dice指标"></a>Dice指标</h3><p>语义分割模型常用的评价指标还有Dice（Dice similarity coefficient），是用于评估两个样本的相似性的度量函数，取值范围在0到1之间，<strong>取值越大表示越相似</strong>。假设标签为X，预测结果为Y，dice coefficient定义如下:</p><p>$$\begin{aligned} Dice&#x3D;\frac{2|X\cap Y|}{|X|+|Y|}&#x3D;\frac{2*TP}{(TP+FN)+(TP+FP)} \end{aligned}$$</p><p>其中$|X|$和$|Y|$分别表示X和Y的元素的个数，分子乘2为了保证分母重复计算后取值范围在[0,1]之间。</p><p>但实际上该公式是由两个公式得到，即Precision和Recall的调和平均数（harmonic mean）得到，因此Dice指标也称为F1-score：</p><p>$$\begin{aligned} F1 &#x3D; \frac{2 \times precision \times recall}{precision+recall} &#x3D; \frac{2\times TP}{2\times TP+FN+FP} &#x3D; Dice \end{aligned}$$</p><p>该指标和IoU也有联系，相比较IOU，DIce可以获得一个更高的指标分数：</p><p>$$\begin{aligned} IoU&#x3D;\frac{Dice}{2-Dice} \end{aligned}$$</p><p>下面可以用Python方便的得到语义分割中Dice指标的计算</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">dice_coeff</span><span class="token punctuation">(</span>pred<span class="token punctuation">,</span> target<span class="token punctuation">)</span><span class="token punctuation">:</span>    smooth <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">.</span>    num <span class="token operator">=</span> pred<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>    m1 <span class="token operator">=</span> pred<span class="token punctuation">.</span>view<span class="token punctuation">(</span>num<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># Flatten</span>    m2 <span class="token operator">=</span> target<span class="token punctuation">.</span>view<span class="token punctuation">(</span>num<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># Flatten</span>    intersection <span class="token operator">=</span> <span class="token punctuation">(</span>m1 <span class="token operator">*</span> m2<span class="token punctuation">)</span><span class="token punctuation">.</span>sum<span class="token punctuation">(</span><span class="token punctuation">)</span>     <span class="token keyword">return</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">.</span> <span class="token operator">*</span> intersection <span class="token operator">+</span> smooth<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token punctuation">(</span>m1<span class="token punctuation">.</span>sum<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> m2<span class="token punctuation">.</span>sum<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> smooth<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>注：调和平均数是将所有数值取倒数，并求其算术平均数后，再将此算术平均数取倒数而得，其结果等于数值的个数除以数值倒数的总和。</p>]]></content>
      
      
      <categories>
          
          <category> 算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 算法知识 </tag>
            
            <tag> 算法评估 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>C++|友元与运算符重载</title>
      <link href="/2023/11/25/c-zhi-shi/you-yuan-yu-yun-suan-fu-chong-zai/"/>
      <url>/2023/11/25/c-zhi-shi/you-yuan-yu-yun-suan-fu-chong-zai/</url>
      
        <content type="html"><![CDATA[<h1 id="友元与运算符重载"><a href="#友元与运算符重载" class="headerlink" title="友元与运算符重载"></a>友元与运算符重载</h1><h2 id="友元"><a href="#友元" class="headerlink" title="友元"></a>友元</h2><p>在类的设计过程中，通过把属性和方法放在不同的访问权限下，来控制这些属性和方法的访问范围。C++中的访问权限有三种：</p><ol><li><code>public</code>公共权限，类内可以访问  类外可以访问</li><li><code>protected</code>保护权限，类内可以访问  类外不可以访问</li><li><code>private</code>私有权限，类内可以访问  类外不可以访问</li></ol><p>如下是一个访问权限的例子：</p><pre class="line-numbers language-cpp"><code class="language-cpp"><span class="token keyword">class</span> <span class="token class-name">Person</span><span class="token punctuation">{</span><span class="token keyword">public</span><span class="token operator">:</span>    string m_Name<span class="token punctuation">;</span><span class="token keyword">protected</span><span class="token operator">:</span>    string m_Car<span class="token punctuation">;</span><span class="token keyword">private</span><span class="token operator">:</span>    <span class="token keyword">int</span> m_Password<span class="token punctuation">;</span><span class="token keyword">public</span><span class="token operator">:</span>    <span class="token keyword">void</span> <span class="token function">func</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">{</span>        m_Name <span class="token operator">=</span> <span class="token string">"张三"</span><span class="token punctuation">;</span>        m_Car <span class="token operator">=</span> <span class="token string">"拖拉机"</span><span class="token punctuation">;</span>        m_Password <span class="token operator">=</span> <span class="token number">123456</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token punctuation">;</span><span class="token keyword">int</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    Person p<span class="token punctuation">;</span>    p<span class="token punctuation">.</span>m_Name <span class="token operator">=</span> <span class="token string">"李四"</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">//p.m_Car = "奔驰";  //保护权限类外访问不到</span>    <span class="token comment" spellcheck="true">//p.m_Password = 123; //私有权限类外访问不到</span>    <span class="token keyword">return</span> <span class="token number">0</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>在C++中<code>struct</code>和<code>class</code>唯一的区别在于 <strong>默认的访问权限不同</strong>：<code>struct</code>默认权限为公共权限，<code>class</code>默认权限为私有权限。</p><p>C++中友元的目的就是让一个函数或者类访问<strong>另一个类中非公有成员</strong>，即可以访问<code>protected</code>和<code>private</code>修饰的成员，该成员既可以是属性也可以是方法。友元的关键字为<code>friend</code>，友元的三种实现：</p><ul><li>全局函数做友元</li><li>成员函数做友元</li><li>类做友元</li></ul><h3 id="全局函数做友元"><a href="#全局函数做友元" class="headerlink" title="全局函数做友元"></a>全局函数做友元</h3><p>全局函数内可以访问类中私有成员。</p><pre class="line-numbers language-cpp"><code class="language-cpp"><span class="token keyword">class</span> <span class="token class-name">Building</span><span class="token punctuation">{</span>    <span class="token comment" spellcheck="true">//告诉编译器goodGay全局函数 是Building类的好朋友，可以访问类中的私有内容</span>    <span class="token keyword">friend</span> <span class="token keyword">void</span> <span class="token function">goodGay</span><span class="token punctuation">(</span>Building <span class="token operator">*</span> building<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">public</span><span class="token operator">:</span>    <span class="token function">Building</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">{</span>        cout <span class="token operator">&lt;&lt;</span> <span class="token string">"初始化"</span> <span class="token operator">&lt;&lt;</span> endl<span class="token punctuation">;</span>        <span class="token keyword">this</span><span class="token operator">-</span><span class="token operator">></span>m_SittingRoom <span class="token operator">=</span> <span class="token string">"客厅"</span><span class="token punctuation">;</span>        <span class="token keyword">this</span><span class="token operator">-</span><span class="token operator">></span>m_BedRoom <span class="token operator">=</span> <span class="token string">"卧室"</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token keyword">public</span><span class="token operator">:</span>    string m_SittingRoom<span class="token punctuation">;</span> <span class="token comment" spellcheck="true">//客厅</span><span class="token keyword">private</span><span class="token operator">:</span>    string m_BedRoom<span class="token punctuation">;</span> <span class="token comment" spellcheck="true">//卧室</span>    <span class="token keyword">void</span> <span class="token function">private_method</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">{</span>        cout <span class="token operator">&lt;&lt;</span> <span class="token string">"调用私有方法"</span> <span class="token operator">&lt;&lt;</span> endl<span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token punctuation">;</span><span class="token keyword">void</span> <span class="token function">goodGay</span><span class="token punctuation">(</span>Building<span class="token operator">*</span> building<span class="token punctuation">)</span><span class="token punctuation">{</span>    cout <span class="token operator">&lt;&lt;</span> <span class="token string">"好基友正在访问： "</span> <span class="token operator">&lt;&lt;</span> building<span class="token operator">-</span><span class="token operator">></span>m_SittingRoom <span class="token operator">&lt;&lt;</span> endl<span class="token punctuation">;</span>    cout <span class="token operator">&lt;&lt;</span> <span class="token string">"好基友正在访问： "</span> <span class="token operator">&lt;&lt;</span> building<span class="token operator">-</span><span class="token operator">></span>m_BedRoom <span class="token operator">&lt;&lt;</span> endl<span class="token punctuation">;</span>    building<span class="token operator">-</span><span class="token operator">></span><span class="token function">private_method</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token keyword">int</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">{</span>    Building b<span class="token punctuation">;</span>    <span class="token function">goodGay</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>b<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">return</span> <span class="token number">0</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="成员函数做友元"><a href="#成员函数做友元" class="headerlink" title="成员函数做友元"></a>成员函数做友元</h3><p>不能把其他类的私有成员函数声明为友元。</p><pre class="line-numbers language-cpp"><code class="language-cpp"><span class="token keyword">class</span> <span class="token class-name">Building</span><span class="token punctuation">;</span> <span class="token comment" spellcheck="true">// 提前声明Building类</span><span class="token keyword">class</span> <span class="token class-name">goodGay</span><span class="token punctuation">{</span><span class="token keyword">public</span><span class="token operator">:</span>    <span class="token function">goodGay</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">void</span> <span class="token function">visit</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment" spellcheck="true">//只让visit函数作为Building的好朋友，可以发访问Building中私有内容</span>    <span class="token keyword">void</span> <span class="token function">visit2</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token keyword">private</span><span class="token operator">:</span>    Building<span class="token operator">*</span> building<span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token punctuation">;</span><span class="token keyword">class</span> <span class="token class-name">Building</span><span class="token punctuation">{</span>    <span class="token comment" spellcheck="true">//告诉编译器  goodGay类中的visit成员函数 是Building好朋友，可以访问私有内容</span>    <span class="token keyword">friend</span> <span class="token keyword">void</span> goodGay<span class="token operator">::</span><span class="token function">visit</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">public</span><span class="token operator">:</span>    <span class="token function">Building</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">{</span>        <span class="token keyword">this</span><span class="token operator">-</span><span class="token operator">></span>m_SittingRoom <span class="token operator">=</span> <span class="token string">"客厅"</span><span class="token punctuation">;</span>        <span class="token keyword">this</span><span class="token operator">-</span><span class="token operator">></span>m_BedRoom <span class="token operator">=</span> <span class="token string">"卧室"</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token keyword">public</span><span class="token operator">:</span>    string m_SittingRoom<span class="token punctuation">;</span> <span class="token comment" spellcheck="true">//客厅</span><span class="token keyword">private</span><span class="token operator">:</span>    string m_BedRoom<span class="token punctuation">;</span><span class="token comment" spellcheck="true">//卧室</span><span class="token punctuation">}</span><span class="token punctuation">;</span>goodGay<span class="token operator">::</span><span class="token function">goodGay</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">{</span>    building <span class="token operator">=</span> <span class="token keyword">new</span> Building<span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token keyword">void</span> goodGay<span class="token operator">::</span><span class="token function">visit</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">{</span>    cout <span class="token operator">&lt;&lt;</span> <span class="token string">"好基友正在访问"</span> <span class="token operator">&lt;&lt;</span> building<span class="token operator">-</span><span class="token operator">></span>m_SittingRoom <span class="token operator">&lt;&lt;</span> endl<span class="token punctuation">;</span>    cout <span class="token operator">&lt;&lt;</span> <span class="token string">"好基友正在访问"</span> <span class="token operator">&lt;&lt;</span> building<span class="token operator">-</span><span class="token operator">></span>m_BedRoom <span class="token operator">&lt;&lt;</span> endl<span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token keyword">void</span> goodGay<span class="token operator">::</span><span class="token function">visit2</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">{</span>    cout <span class="token operator">&lt;&lt;</span> <span class="token string">"好基友正在访问"</span> <span class="token operator">&lt;&lt;</span> building<span class="token operator">-</span><span class="token operator">></span>m_SittingRoom <span class="token operator">&lt;&lt;</span> endl<span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">//cout &lt;&lt; "好基友正在访问" &lt;&lt; building->m_BedRoom &lt;&lt; endl;</span><span class="token punctuation">}</span><span class="token keyword">int</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">{</span>    goodGay  gg<span class="token punctuation">;</span>    gg<span class="token punctuation">.</span><span class="token function">visit</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">return</span> <span class="token number">0</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>C++中如果类中定义另一个类（包括引用和指针，比如<code>Person</code>, <code>Person &amp;</code>, <code>Person *</code>）作为成员变量，那么一定要<strong>保证另一个类在本类之前已定义</strong>。如果另一个类没定义，而是采用的先写一句声明语句的方式（即前向声明），则在本类成员函数中访问另一个类的成员会报错。为了解决上述问题，实际上有两种策略：</p><ul><li>可以让另一个类提前定义好，这是最简单和直接的方法，就是将另一个类的定义放在本类之前，这样编译器就可以知道另一个类的大小和结构。</li><li>可以在本类中只声明成员函数，不定义成员函数的函数体。而在类外部，当另一个类已定义完毕后，再去写成员函数的函数体。</li></ul><p>如上面的例子，要把<code>goodGay()</code>、<code>visit()</code>和<code>visit2()</code>的定义写在Building类定义之后，访问Building类的成员才不会报错。</p><h3 id="类做友元"><a href="#类做友元" class="headerlink" title="类做友元"></a>类做友元</h3><p>如果把A类作为B类的友元类，那么A类的所有成员函数（在A类的成员函数内部），就可以直接访问B类的非公有成员。即，友元类可以直接访问对应类的所有成员。</p><pre class="line-numbers language-cpp"><code class="language-cpp"><span class="token keyword">class</span> <span class="token class-name">Building</span><span class="token punctuation">;</span><span class="token keyword">class</span> <span class="token class-name">goodGay</span><span class="token punctuation">{</span><span class="token keyword">public</span><span class="token operator">:</span>    <span class="token function">goodGay</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">void</span> <span class="token function">visit</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">private</span><span class="token operator">:</span>    Building<span class="token operator">*</span> building<span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token punctuation">;</span><span class="token keyword">class</span> <span class="token class-name">Building</span><span class="token punctuation">{</span>    <span class="token comment" spellcheck="true">//告诉编译器 goodGay类是Building类的好朋友，可以访问到Building类中私有内容</span>    <span class="token keyword">friend</span> <span class="token keyword">class</span> <span class="token class-name">goodGay</span><span class="token punctuation">;</span><span class="token keyword">public</span><span class="token operator">:</span>    <span class="token function">Building</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">{</span>        <span class="token keyword">this</span><span class="token operator">-</span><span class="token operator">></span>m_SittingRoom <span class="token operator">=</span> <span class="token string">"客厅"</span><span class="token punctuation">;</span>        <span class="token keyword">this</span><span class="token operator">-</span><span class="token operator">></span>m_BedRoom <span class="token operator">=</span> <span class="token string">"卧室"</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token keyword">public</span><span class="token operator">:</span>    string m_SittingRoom<span class="token punctuation">;</span> <span class="token comment" spellcheck="true">//客厅</span><span class="token keyword">private</span><span class="token operator">:</span>    string m_BedRoom<span class="token punctuation">;</span><span class="token comment" spellcheck="true">//卧室</span><span class="token punctuation">}</span><span class="token punctuation">;</span>goodGay<span class="token operator">::</span><span class="token function">goodGay</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">{</span>    building <span class="token operator">=</span> <span class="token keyword">new</span> Building<span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token keyword">void</span> goodGay<span class="token operator">::</span><span class="token function">visit</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">{</span>    cout <span class="token operator">&lt;&lt;</span> <span class="token string">"好基友正在访问"</span> <span class="token operator">&lt;&lt;</span> building<span class="token operator">-</span><span class="token operator">></span>m_SittingRoom <span class="token operator">&lt;&lt;</span> endl<span class="token punctuation">;</span>    cout <span class="token operator">&lt;&lt;</span> <span class="token string">"好基友正在访问"</span> <span class="token operator">&lt;&lt;</span> building<span class="token operator">-</span><span class="token operator">></span>m_BedRoom <span class="token operator">&lt;&lt;</span> endl<span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token keyword">int</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">{</span>    goodGay gg<span class="token punctuation">;</span>    gg<span class="token punctuation">.</span><span class="token function">visit</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">return</span> <span class="token number">0</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>友元类和友元函数，使用<code>friend</code>关键字进行声明即可，与访问权限无关。所以，可以放在private&#x2F;pulic&#x2F;protected任意区域内。</p><p>友元类的访问权限不会被继承。即使子类继承了父类的友元类关系，子类的友元类仍然不能访问父类的私有成员。例如：</p><blockquote><p>假设有一个基类Base和一个派生类Derived，并且Base类中有一个友元类FriendClass，可以看到友元关系不会传递给Derived类。</p></blockquote><pre class="line-numbers language-cpp"><code class="language-cpp"><span class="token keyword">class</span> <span class="token class-name">Base</span> <span class="token punctuation">{</span><span class="token keyword">private</span><span class="token operator">:</span>    <span class="token keyword">int</span> privateData<span class="token punctuation">;</span>    <span class="token keyword">friend</span> <span class="token keyword">class</span> <span class="token class-name">FriendClass</span><span class="token punctuation">;</span><span class="token keyword">public</span><span class="token operator">:</span>    <span class="token function">Base</span><span class="token punctuation">(</span><span class="token keyword">int</span> data<span class="token punctuation">)</span> <span class="token operator">:</span> <span class="token function">privateData</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span> <span class="token punctuation">{</span><span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token punctuation">;</span><span class="token keyword">class</span> <span class="token class-name">FriendClass</span> <span class="token punctuation">{</span><span class="token keyword">public</span><span class="token operator">:</span>    <span class="token keyword">void</span> <span class="token function">modifyPrivateData</span><span class="token punctuation">(</span>Base<span class="token operator">&amp;</span> obj<span class="token punctuation">,</span> <span class="token keyword">int</span> newData<span class="token punctuation">)</span> <span class="token punctuation">{</span>        obj<span class="token punctuation">.</span>privateData <span class="token operator">=</span> newData<span class="token punctuation">;</span> <span class="token comment" spellcheck="true">// 可以访问私有成员</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token punctuation">;</span><span class="token keyword">class</span> <span class="token class-name">Derived</span> <span class="token operator">:</span> <span class="token keyword">public</span> Base <span class="token punctuation">{</span><span class="token keyword">public</span><span class="token operator">:</span>    <span class="token function">Derived</span><span class="token punctuation">(</span><span class="token keyword">int</span> data<span class="token punctuation">)</span> <span class="token operator">:</span> <span class="token function">Base</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span> <span class="token punctuation">{</span><span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token punctuation">;</span><span class="token keyword">int</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    FriendClass <span class="token class-name">friendObj</span><span class="token punctuation">;</span>    Base <span class="token function">baseObj</span><span class="token punctuation">(</span><span class="token number">42</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    Derived <span class="token function">derivedObj</span><span class="token punctuation">(</span><span class="token number">23</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    friendObj<span class="token punctuation">.</span><span class="token function">modifyPrivateData</span><span class="token punctuation">(</span>baseObj<span class="token punctuation">,</span> <span class="token number">99</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">// 正确，Base类的友元类可以访问私有成员</span>    friendObj<span class="token punctuation">.</span><span class="token function">modifyPrivateData</span><span class="token punctuation">(</span>derivedObj<span class="token punctuation">,</span> <span class="token number">88</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment" spellcheck="true">// 错误，Derived类的友元类不能访问私有成员</span>    <span class="token keyword">return</span> <span class="token number">0</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="运算符重载"><a href="#运算符重载" class="headerlink" title="运算符重载"></a>运算符重载</h2><p>运算符重载（Operator overload）是对已有的运算符赋予多重含义，使同一个运算符作用于不同类型的数据时表现出不同的行为。C++预定义的运算符，只能用于基本数据类型的运算，这些运算符有：<code>+、-、*、/、%、&amp;、~、！、|、=、&lt;&lt;、&gt;&gt;、！=</code>等。为了实现自定义数据类型的运算，需要对这些运算符进行重新定义，扩展C++中提供的运算符的适用范围，以适应自定义的数据类型。</p><p><strong>运算符重载的本质是函数重载</strong>。</p><h3 id="运算符重载的语法格式"><a href="#运算符重载的语法格式" class="headerlink" title="运算符重载的语法格式"></a>运算符重载的语法格式</h3><p>重载的运算符是具有特殊名字的函数：它们的函数名由关键字<code>operator</code>开始，后跟要重载的运算符。</p><pre class="line-numbers language-cpp"><code class="language-cpp">返回类型 <span class="token keyword">operator</span> 运算符（参数列表）<span class="token punctuation">{</span>    函数体<span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>运算符重载可以重载为普通函数，也可以重载为类的成员函数；使用时把含运算符重载的表达式转换成为对运算符函数的调用，把运算符的操作数转换成运算符函数的参数；当运算符被多次重载时，根据实参的类型决定调用哪个运算符函数。</p><h3 id="运算符重载的两种方式"><a href="#运算符重载的两种方式" class="headerlink" title="运算符重载的两种方式"></a>运算符重载的两种方式</h3><h4 id="重载为类的成员函数"><a href="#重载为类的成员函数" class="headerlink" title="重载为类的成员函数"></a>重载为类的成员函数</h4><p><strong>重载为成员函数时，参数个数为运算符目数减一</strong>。</p><h5 id="双目运算符"><a href="#双目运算符" class="headerlink" title="双目运算符"></a>双目运算符</h5><p>双目运算符有两个操作数，如果将双目运算符重载为类的成员函数，则左操作数是该类的对象，由this指针指出，右操作数则通过运算符重载函数的参数表来传递。如下是加法运算的重载。</p><pre class="line-numbers language-cpp"><code class="language-cpp"><span class="token keyword">class</span> <span class="token class-name">Vector</span><span class="token punctuation">{</span><span class="token keyword">private</span><span class="token operator">:</span>    <span class="token keyword">int</span> x<span class="token punctuation">,</span> y<span class="token punctuation">;</span><span class="token keyword">public</span><span class="token operator">:</span>    <span class="token function">Vector</span><span class="token punctuation">(</span><span class="token keyword">int</span> x1<span class="token punctuation">,</span> <span class="token keyword">int</span> y1<span class="token punctuation">)</span><span class="token punctuation">{</span>        x <span class="token operator">=</span> x1<span class="token punctuation">;</span>        y <span class="token operator">=</span> y1<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token comment" spellcheck="true">//重载运算符的实现</span>    Vector <span class="token keyword">operator</span><span class="token operator">+</span><span class="token punctuation">(</span><span class="token keyword">const</span> Vector<span class="token operator">&amp;</span> p<span class="token punctuation">)</span><span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">//调用A类构造函数创建一个临时匿名对象作为函数返回</span>        <span class="token keyword">return</span> <span class="token function">Vector</span><span class="token punctuation">(</span>x <span class="token operator">+</span> p<span class="token punctuation">.</span>x<span class="token punctuation">,</span> y <span class="token operator">+</span> p<span class="token punctuation">.</span>y<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">void</span> <span class="token function">show</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">{</span>        cout <span class="token operator">&lt;&lt;</span> <span class="token string">"x="</span> <span class="token operator">&lt;&lt;</span> x <span class="token operator">&lt;&lt;</span> <span class="token string">","</span> <span class="token operator">&lt;&lt;</span> <span class="token string">"y="</span> <span class="token operator">&lt;&lt;</span> y <span class="token operator">&lt;&lt;</span> endl<span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token punctuation">;</span><span class="token keyword">int</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">{</span>    Vector <span class="token function">v1</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    Vector <span class="token function">v2</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    Vector a<span class="token punctuation">;</span>    a <span class="token operator">=</span> v1 <span class="token operator">+</span> v2<span class="token punctuation">;</span>    a<span class="token punctuation">.</span><span class="token function">show</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>在Vector类中重载了运算符+，该重载只对Vector类的对象有效。执行<code>a=v1+v2;</code>语句时，编译器检测到+号左边是一个Vector类对象（+号具有左结合性，所以先检测左边），就会调用成员函数<code>operator+()</code>，也就是转换为：<code>a = v1.operate+(v2);</code>。</p><h5 id="单目运算符"><a href="#单目运算符" class="headerlink" title="单目运算符"></a>单目运算符</h5><p>单目运算符的操作数只有一个，比如自增和自减运算符，但是需要区分前置(++i)和后置(i++)运算符。为了区分所重载的运算符是前置运算符还是后置运算符，C++规定：前置运算符作为一元运算符重载，后置运算符作为二元运算符重载，这样从重载函数的参数列表就可以区分前置和后置了。</p><p>运算符的前置形式因为是一元运算符，与声明其他任何一元运算符的方式完全相同；后置形式因为是二元运算符，需要接受 <strong><code>int</code></strong> 类型的额外参数。</p><p>当为递增或递减运算符的后置形式指定重载运算符时，其他参数的类型必须是 <code>int</code>，指定任何其他类型都会报错。</p><pre class="line-numbers language-cpp"><code class="language-cpp"><span class="token keyword">class</span> <span class="token class-name">Vector</span><span class="token punctuation">{</span><span class="token keyword">private</span><span class="token operator">:</span>    <span class="token keyword">int</span> x<span class="token punctuation">,</span> y<span class="token punctuation">;</span><span class="token keyword">public</span><span class="token operator">:</span>    <span class="token function">Vector</span><span class="token punctuation">(</span><span class="token keyword">int</span> x1<span class="token punctuation">,</span> <span class="token keyword">int</span> y1<span class="token punctuation">)</span>    <span class="token punctuation">{</span>        x <span class="token operator">=</span> x1<span class="token punctuation">;</span>        y <span class="token operator">=</span> y1<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    Vector<span class="token operator">&amp;</span> <span class="token keyword">operator</span><span class="token operator">++</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">//++i 前置++实现</span>    <span class="token punctuation">{</span>        <span class="token operator">++</span>x<span class="token punctuation">;</span>        <span class="token operator">++</span>y<span class="token punctuation">;</span>        <span class="token keyword">return</span> <span class="token operator">*</span><span class="token keyword">this</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//后引用</span>    <span class="token punctuation">}</span>    Vector <span class="token keyword">operator</span><span class="token operator">++</span><span class="token punctuation">(</span><span class="token keyword">int</span> n<span class="token punctuation">)</span><span class="token comment" spellcheck="true">//i++ 后置++实现</span>    <span class="token punctuation">{</span>        Vector a <span class="token operator">=</span> <span class="token operator">*</span><span class="token keyword">this</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//保存对象引用</span>        <span class="token operator">++</span><span class="token punctuation">(</span><span class="token operator">*</span><span class="token keyword">this</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//自增，调用前面实现的前置++</span>        <span class="token keyword">return</span> a<span class="token punctuation">;</span><span class="token comment" spellcheck="true">//返回先前保存的对象</span>    <span class="token punctuation">}</span>    <span class="token keyword">void</span> <span class="token function">show</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">{</span>        cout <span class="token operator">&lt;&lt;</span> <span class="token string">"x="</span> <span class="token operator">&lt;&lt;</span> x <span class="token operator">&lt;&lt;</span> <span class="token string">","</span> <span class="token operator">&lt;&lt;</span> <span class="token string">"y="</span> <span class="token operator">&lt;&lt;</span> y <span class="token operator">&lt;&lt;</span> endl<span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token punctuation">;</span><span class="token keyword">int</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">{</span>    Vector <span class="token function">v1</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token function">v2</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">(</span>v1<span class="token operator">++</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">show</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment" spellcheck="true">// x=1,y=2</span>    <span class="token punctuation">(</span><span class="token operator">++</span>v2<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">show</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment" spellcheck="true">// x=4,y=5</span>    <span class="token keyword">return</span> <span class="token number">0</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>调用<code>++s</code>即为<code>s.operator++()</code>；调用<code>s++</code>则为<code>s.operator++(0)</code>。</p><h4 id="重载为普通函数"><a href="#重载为普通函数" class="headerlink" title="重载为普通函数"></a>重载为普通函数</h4><p><strong>重载为普通函数时，重载函数的参数个数为运算符目数</strong>。</p><p>如果是双目运算符，则重载函数的参数列表有两个形参，如果是单目运算符，则参数列表只有一个形参。</p><pre class="line-numbers language-cpp"><code class="language-cpp"><span class="token keyword">class</span> <span class="token class-name">Vector</span><span class="token punctuation">{</span><span class="token keyword">private</span><span class="token operator">:</span>    <span class="token keyword">int</span> x<span class="token punctuation">,</span> y<span class="token punctuation">;</span><span class="token keyword">public</span><span class="token operator">:</span>    <span class="token function">Vector</span><span class="token punctuation">(</span><span class="token keyword">int</span> x1<span class="token punctuation">,</span> <span class="token keyword">int</span> y1<span class="token punctuation">)</span><span class="token punctuation">{</span>        x <span class="token operator">=</span> x1<span class="token punctuation">;</span>        y <span class="token operator">=</span> y1<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">void</span> <span class="token function">show</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">{</span>        cout <span class="token operator">&lt;&lt;</span> <span class="token string">"x="</span> <span class="token operator">&lt;&lt;</span> x <span class="token operator">&lt;&lt;</span> <span class="token string">","</span> <span class="token operator">&lt;&lt;</span> <span class="token string">"y="</span> <span class="token operator">&lt;&lt;</span> y <span class="token operator">&lt;&lt;</span> endl<span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//重载运算符的实现</span>Vector <span class="token keyword">operator</span><span class="token operator">+</span><span class="token punctuation">(</span><span class="token keyword">const</span> Vector<span class="token operator">&amp;</span> p<span class="token punctuation">,</span> <span class="token keyword">int</span> shift<span class="token punctuation">)</span><span class="token punctuation">{</span>    <span class="token comment" spellcheck="true">//调用A类构造函数创建一个临时匿名对象作为函数返回</span>    <span class="token keyword">return</span> <span class="token function">Vector</span><span class="token punctuation">(</span>p<span class="token punctuation">.</span>x<span class="token operator">+</span>shift<span class="token punctuation">,</span> p<span class="token punctuation">.</span>y<span class="token operator">+</span>shift<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token keyword">int</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">{</span>    Vector <span class="token function">v1</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    Vector a<span class="token punctuation">;</span>    a <span class="token operator">=</span> v1 <span class="token operator">+</span> <span class="token number">2</span><span class="token punctuation">;</span>    a<span class="token punctuation">.</span><span class="token function">show</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment" spellcheck="true">// x=3,y=4</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h5 id="重载为类的友元函数"><a href="#重载为类的友元函数" class="headerlink" title="重载为类的友元函数"></a>重载为类的友元函数</h5><p>运算符重载为类的友元函数，只是在函数前加一个<code>friend</code>关键字。运算符重载为类的友元函数时，由于没有隐含的<code>this</code>指针，因此操作数的个数没有变化，所有的操作数都必须通过函数形参进行传递，函数的参数与操作数 自左自右保持一一对应。</p><pre class="line-numbers language-cpp"><code class="language-cpp"><span class="token keyword">friend</span> 返回类型 <span class="token keyword">operator</span> 运算符（参数列表）<span class="token punctuation">{</span>    函数体；<span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>如下的例子。</p><pre class="line-numbers language-cpp"><code class="language-cpp"><span class="token keyword">class</span> <span class="token class-name">Vector</span><span class="token punctuation">{</span><span class="token keyword">private</span><span class="token operator">:</span>    <span class="token keyword">int</span> x<span class="token punctuation">,</span> y<span class="token punctuation">;</span><span class="token keyword">public</span><span class="token operator">:</span>    <span class="token function">Vector</span><span class="token punctuation">(</span><span class="token keyword">int</span> x1<span class="token punctuation">,</span> <span class="token keyword">int</span> y1<span class="token punctuation">)</span><span class="token punctuation">{</span>        x <span class="token operator">=</span> x1<span class="token punctuation">;</span>        y <span class="token operator">=</span> y1<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">friend</span> Vector <span class="token keyword">operator</span><span class="token operator">+</span><span class="token punctuation">(</span><span class="token keyword">const</span> Vector<span class="token operator">&amp;</span> v1<span class="token punctuation">,</span> <span class="token keyword">const</span> Vector<span class="token operator">&amp;</span> v2<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">void</span> <span class="token function">show</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">{</span>        cout <span class="token operator">&lt;&lt;</span> <span class="token string">"x="</span> <span class="token operator">&lt;&lt;</span> x <span class="token operator">&lt;&lt;</span> <span class="token string">","</span> <span class="token operator">&lt;&lt;</span> <span class="token string">"y="</span> <span class="token operator">&lt;&lt;</span> y <span class="token operator">&lt;&lt;</span> endl<span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//重载运算符的实现</span>Vector <span class="token keyword">operator</span><span class="token operator">+</span><span class="token punctuation">(</span><span class="token keyword">const</span> Vector<span class="token operator">&amp;</span> v1<span class="token punctuation">,</span> <span class="token keyword">const</span> Vector<span class="token operator">&amp;</span> v2<span class="token punctuation">)</span><span class="token punctuation">{</span>    <span class="token comment" spellcheck="true">//调用A类构造函数创建一个临时匿名对象作为函数返回</span>    <span class="token keyword">return</span> <span class="token function">Vector</span><span class="token punctuation">(</span>v1<span class="token punctuation">.</span>x<span class="token operator">+</span>v2<span class="token punctuation">.</span>x<span class="token punctuation">,</span> v1<span class="token punctuation">.</span>y<span class="token operator">+</span>v2<span class="token punctuation">.</span>y<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token keyword">int</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">{</span>    Vector <span class="token function">v1</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    Vector <span class="token function">v1</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    Vector a<span class="token punctuation">;</span>    a <span class="token operator">=</span> v1 <span class="token operator">+</span> v2<span class="token punctuation">;</span>    a<span class="token punctuation">.</span><span class="token function">show</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment" spellcheck="true">// x=4,y=6</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h3><ol><li>重载为成员函数时，参数个数为运算符目数减一；重载为普通函数时，参数个数为运算符目数。</li><li>成员函数运算符重载时，运算符左值类型必须为所在类类型；而非成员函数运算符重载则不必。</li><li>一般，单目运算符最好重载为类的成员函数，双目运算符最好重载为类的友元函数。</li><li>有4个运算符必须重载为类的成员函数：赋值＝、下标[ ]、调用( )、成员访问-&gt;；而&lt;&lt;运算符由于其第一个运算符必须是ostream对象，&gt;&gt;第一个运算符必须是istream对象，所以只能重载为友元函数。</li></ol>]]></content>
      
      
      <categories>
          
          <category> 编程语言 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> C++ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>线性回归算法原理与实现</title>
      <link href="/2023/11/11/suan-fa/xian-xing-hui-gui/"/>
      <url>/2023/11/11/suan-fa/xian-xing-hui-gui/</url>
      
        <content type="html"><![CDATA[<h1 id="线性回归"><a href="#线性回归" class="headerlink" title="线性回归"></a>线性回归</h1><h2 id="基本原理"><a href="#基本原理" class="headerlink" title="基本原理"></a>基本原理</h2><p>线性模型试图<strong>通过线性组合的方式对目标进行拟合或逼近</strong>。它的一般形式如$\hat y &#x3D; f(x) &#x3D; w_1x_1+w_2x_2+…+w_dx_d+b$</p><p>其中$ x_1,x_2,…,x_d$是我们的输入数据，$x_i$表示样本数据的某个特征，$ w_1,w_2,…,w_d $和$b$是线性回归模型的参数，将其改写为向量形式：</p><p>$\hat y &#x3D; f(x) &#x3D; w^T*x + b$</p><p>当建立了这样一个形如$\hat{y}&#x3D;w*x+b$的模型之后，我们并不知道参数$w$和$b$的具体数值是多少，那么怎么确定参数$w$和$b$呢？首先考虑一种简单的情形：输入的样本数据只有一个特征。假设有一批数据${ (x_1,y_1),(x_2,y_2),…,(x_d,y_d) }$，已经知道数据$x_i$和对应的结果$y_i$，则可以定义线性回归模型的损失为：真实值$y$与预测值$\hat{y}$的差的平方和——MSE损失（Mean Square Error）。</p><p>$$\begin{aligned} L &#x3D; \sum_{i&#x3D;1}^{N} (y_i - \hat{y_i})^2 \end{aligned}$$</p><p>则线性回归模型的参数$w$和$b$可以通过下面的公式得到，当真实值$y$和预测值$\hat{y}$的损失达到最小时，此时线性回归模型的参数$w^*$和$b^*$就是我们要找的模型参数。</p><p>$$\begin{aligned} (w^{*}, b^{*}) &#x3D; \arg \mathop{\min}\limits_{(w,b)} \sum_{i&#x3D;1}^N (y_i-f(x_i))^2 \ &#x3D; \arg \mathop{\min}\limits_{(w,b)} \sum_{i&#x3D;1}^N (y_i-w*x_i - b)^2 \end{aligned}$$</p><p>由均方差损失（MSE）可知该损失函数是一个关于$w$和$b$的凸函数，当该函数对$w$和$b$的导数均为0时，该函数达到极小值，即可求得模型参数$w^*$和$b^*$。因此，将损失$L$对两个参数分别求导</p><p>$\begin{aligned} \frac{\partial L}{\partial w} &#x3D; 2\sum_{i&#x3D;1}^N (y_i - w*x_i - b)(-x_i)&#x3D;2(w\sum_{i&#x3D;1}^N x_i^2 - \sum_{i&#x3D;1}^N(y_i -b)x_i) \end{aligned}$</p><p>$\begin{aligned} \frac{\partial L}{\partial b} &#x3D; 2\sum_{i&#x3D;1}^N (y_i - w*x_i - b)(-1)&#x3D;2(Nb- \sum_{i&#x3D;1}^N (y_i-wx_i)) \end{aligned}$</p><p>令导数$\frac{\partial L}{\partial b}&#x3D;0$，则</p><p>$$\begin{aligned} Nb &amp;&#x3D;\sum_{i&#x3D;1}^N (y_i-wx_i)\\ b &amp;&#x3D;\frac{1}{N}\sum_{i&#x3D;1}^N (y_i-wx_i) \\ b^* &amp;&#x3D;\bar y - w \bar x  \end{aligned}$$</p><p>令导数$\frac{\partial L}{\partial w}&#x3D;0$，并将$b&#x3D;\bar y - w \bar x $带入，则</p><p>$$\begin{aligned} w\sum_{i&#x3D;1}^N x_i^2 &amp;&#x3D; \sum_{i&#x3D;1}^N y_i x_i - \sum_{i&#x3D;1}^N bx_i &#x3D; \sum_{i&#x3D;1}^N y_i x_i - \sum_{i&#x3D;1}^N (\bar y-w\bar x)x_i \Rightarrow \\ w\sum_{i&#x3D;1}^N x_i^2 &amp;&#x3D; \sum_{i&#x3D;1}^N y_i x_i - \bar y \sum_{i&#x3D;1}^N x_i + w\bar x \sum_{i&#x3D;1}^N x_i \\ w &amp;&#x3D; \frac{\sum_{i&#x3D;1}^N y_i x_i - \bar y \sum_{i&#x3D;1}^N x_i }{\sum_{i&#x3D;1}^N x_i^2 - \bar x \sum_{i&#x3D;1}^N x_i} \end{aligned}$$</p><p>又有$\bar y \sum_{i&#x3D;1}^N x_i &#x3D; \frac{1}{N} \sum_{i&#x3D;1}^N y_i \sum_{i&#x3D;1}^N x_i &#x3D; \bar x \sum_{i&#x3D;1}^N y_i $，$\bar x \sum_{i&#x3D;1}^N x_i &#x3D; \frac{1}{N} \sum_{i&#x3D;1}^N x_i \sum_{i&#x3D;1}^N x_i&#x3D;\frac{1}{N} (\sum_{i&#x3D;1}^N x_i)^2$，将其代入上式：</p><p>$$\begin{aligned} w^* &#x3D; \frac{\sum_{i&#x3D;1}^N y_i(x_i - \bar x)}{\sum_{i&#x3D;1}^N x_i^2 - \frac{1}{N}(\sum_{i&#x3D;1}^N x_i)^2}  \end{aligned}$$</p><p>推广到矩阵形式，若每个样本有<code>d</code>个特征，则线性回归模型的数学表达式为：</p><p>$$\hat{Y}&#x3D;\begin{bmatrix} \hat{y}_1 \\ \hat{y}_2\\ \vdots\\ \hat{y}_N \end {bmatrix}&#x3D;XW+b&#x3D;  \begin {bmatrix} x_1^1 &amp; x_1^2 &amp; \cdots &amp; x_1^d\\ x_2^1 &amp; x_2^2 &amp; \cdots &amp; x_2^d\\ \vdots &amp; \vdots &amp; \ddots &amp; \vdots\\ x_N^1 &amp; x_N^2 &amp; \cdots &amp; x_N^d \end {bmatrix} \begin {bmatrix} w_1 \\ w_2\\ \vdots\\ x_d \end {bmatrix} + b$$</p><p>为便于讨论将参数$W$和$b$合并为一个矩阵$\widehat W &#x3D; (w; b)$，相应地样本数据$X$变为一个$N*(d+1)$大小的新矩阵$X$，如下式：</p><p>$$\hat{Y}&#x3D;X \widehat W&#x3D;  \begin {bmatrix} x_1^1 &amp; x_1^2 &amp; \cdots &amp; x_1^d &amp; 1\\ x_2^1 &amp; x_2^2 &amp; \cdots &amp; x_2^d &amp; 1\\ \vdots &amp; \vdots &amp; \ddots &amp; \vdots &amp; \vdots \\ x_N^1 &amp; x_N^2 &amp; \cdots &amp; x_N^d &amp; 1 \end {bmatrix} \begin {bmatrix} w_1 \\ w_2\\ \vdots\\ x_d  \\ b\end {bmatrix} $$</p><p>可以得出损失函数为如下形式</p><p>$L &#x3D; (Y-X \widehat W)^T (Y-X \widehat W)$</p><p>则当损失$L$为最小时，可求得参数$\widehat W$为最优解，令损失$L$对参数$\widehat W$求导，得</p><p>$$\begin{aligned} \widehat W^* &amp;&#x3D; \arg \mathop{\min}\limits_{\widehat W} (Y-X \widehat W)^T (Y-X \widehat W) \Rightarrow  \\ \frac{\partial L}{\partial \widehat W} &amp;&#x3D; \frac{\partial}{\partial \widehat W} \big[ Y^TY -Y^TX\widehat W - \widehat W^TX^TY + \widehat W^TX^T X \widehat W \big] \\ &amp;&#x3D;0-X^TY - X^TY + (X^TX+X^TX)\widehat W \\ &amp;&#x3D; 2X^T(X\widehat W-Y) \end{aligned}$$</p><p>令$\frac{\partial L}{\partial \widehat W} &#x3D; 0$，则</p><p>$$\begin{aligned} 2X^T(X\widehat W-Y) &amp;&#x3D; 0 \Rightarrow X^TX \widehat W &#x3D; X^T Y \\ \widehat W^* &amp;&#x3D; (X^TX)^{-1} X^TY\end{aligned}$$</p><h2 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h2><p>上面介绍了线性回归的基本原理，下面通过Python和Numpy来实现一个线性回归模型。这里使用波士顿房价预测的数据来举例，为了后面的可视化，自变量只用了房屋面积一个维度，即通过房屋面积去拟合房价。通过上面的公式推导，我们已经求出了线性回归模型的解析式，因此我们按照公式实现代码即可。<br>首先是数据读取，只取出房价和房屋面积的数据。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> load_boston<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd<span class="token keyword">import</span> numpy <span class="token keyword">as</span> npdataset <span class="token operator">=</span> load_boston<span class="token punctuation">(</span><span class="token punctuation">)</span>dataframe <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>dataset<span class="token punctuation">[</span><span class="token string">"data"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>dataframe<span class="token punctuation">.</span>columns <span class="token operator">=</span> dataset<span class="token punctuation">[</span><span class="token string">"feature_names"</span><span class="token punctuation">]</span>dataframe<span class="token punctuation">[</span><span class="token string">"price"</span><span class="token punctuation">]</span> <span class="token operator">=</span> dataset<span class="token punctuation">[</span><span class="token string">"target"</span><span class="token punctuation">]</span> <span class="token comment" spellcheck="true"># X房屋面积 y房价</span>X<span class="token punctuation">,</span> y <span class="token operator">=</span> dataframe<span class="token punctuation">[</span><span class="token string">"RM"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>values<span class="token punctuation">,</span> dataframe<span class="token punctuation">[</span><span class="token string">"price"</span><span class="token punctuation">]</span> X<span class="token punctuation">,</span> y <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>X<span class="token punctuation">)</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>y<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 训练集与测试集的简单划分</span>offset <span class="token operator">=</span> int<span class="token punctuation">(</span>X<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">*</span> <span class="token number">0.9</span><span class="token punctuation">)</span>X_train<span class="token punctuation">,</span> y_train <span class="token operator">=</span> X<span class="token punctuation">[</span><span class="token punctuation">:</span>offset<span class="token punctuation">]</span><span class="token punctuation">,</span> y<span class="token punctuation">[</span><span class="token punctuation">:</span>offset<span class="token punctuation">]</span>X_test<span class="token punctuation">,</span> y_test <span class="token operator">=</span> X<span class="token punctuation">[</span>offset<span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">,</span> y<span class="token punctuation">[</span>offset<span class="token punctuation">:</span><span class="token punctuation">]</span>X_train <span class="token operator">=</span> X_train<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>X_test <span class="token operator">=</span> X_test<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>y_train <span class="token operator">=</span> y_train<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>y_test <span class="token operator">=</span> y_test<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'X_train='</span><span class="token punctuation">,</span> X_train<span class="token punctuation">.</span>shape<span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># X_train= (455, 1)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'X_test='</span><span class="token punctuation">,</span> X_test<span class="token punctuation">.</span>shape<span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># X_test= (51, 1)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'y_train='</span><span class="token punctuation">,</span> y_train<span class="token punctuation">.</span>shape<span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># y_train= (455, 1)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'y_test='</span><span class="token punctuation">,</span> y_test<span class="token punctuation">.</span>shape<span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># y_test= (51, 1)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>按照公式实现参数计算的代码：</p><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 通过解析式计算参数</span><span class="token keyword">def</span> <span class="token function">linear_analysis</span><span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">:</span>    params_temp <span class="token operator">=</span> np<span class="token punctuation">.</span>linalg<span class="token punctuation">.</span>inv<span class="token punctuation">(</span>np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>X<span class="token punctuation">.</span>T<span class="token punctuation">,</span> X<span class="token punctuation">)</span><span class="token punctuation">)</span>    params <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>params_temp<span class="token punctuation">,</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>X<span class="token punctuation">.</span>T<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> params<span class="token comment" spellcheck="true"># 线性模型的解析解</span>temp <span class="token operator">=</span> np<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">(</span>X_train<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>dtype<span class="token operator">=</span>np<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>X_new <span class="token operator">=</span> np<span class="token punctuation">.</span>concatenate<span class="token punctuation">(</span><span class="token punctuation">(</span>X_train<span class="token punctuation">,</span> temp<span class="token punctuation">)</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>params <span class="token operator">=</span> linear_analysis<span class="token punctuation">(</span>X_new<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span>params_analysis <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">"w"</span><span class="token punctuation">:</span>params<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">"b"</span><span class="token punctuation">:</span>params<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">}</span><span class="token keyword">print</span><span class="token punctuation">(</span>params_analysis<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># {'w': array([9.16394512]), 'b': array([-34.8343267])}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>但是，我们看到参数的解析式中有求逆的操作，只有当$X^TX$是满秩矩阵或正定矩阵才会成立，当实际情况下$X^TX$不满秩则参数的解析解不唯一。</p><p>因此，这里我们使用剃度下降算法进行参数求解。首先定义模型的参数并初始化，参数$w$和$b$全部初始化为0。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">initialize_params</span><span class="token punctuation">(</span>dims<span class="token punctuation">)</span><span class="token punctuation">:</span>    w <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>dims<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    b <span class="token operator">=</span> <span class="token number">0</span>    <span class="token keyword">return</span> w<span class="token punctuation">,</span> b<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>然后定义线性回归模型的计算、损失计算和求导计算。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>X<span class="token punctuation">,</span> w<span class="token punctuation">,</span> b<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment" spellcheck="true"># 模型公式</span>    y_hat <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>X<span class="token punctuation">,</span> w<span class="token punctuation">)</span> <span class="token operator">+</span> b     <span class="token keyword">return</span> y_hat<span class="token keyword">def</span> <span class="token function">cal_loss</span><span class="token punctuation">(</span>y<span class="token punctuation">,</span> y_hat<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment" spellcheck="true"># 损失函数</span>    loss <span class="token operator">=</span> np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">(</span>y_hat<span class="token operator">-</span>y<span class="token punctuation">)</span><span class="token operator">**</span><span class="token number">2</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> loss<span class="token keyword">def</span> <span class="token function">cal_grad</span><span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">,</span> y_hat<span class="token punctuation">)</span><span class="token punctuation">:</span>    num_train <span class="token operator">=</span> X<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>    <span class="token comment" spellcheck="true"># 参数的偏导</span>    dw <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>X<span class="token punctuation">.</span>T<span class="token punctuation">,</span> <span class="token punctuation">(</span>y_hat<span class="token operator">-</span>y<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">/</span> num_train    db <span class="token operator">=</span> np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">(</span>y_hat<span class="token operator">-</span>y<span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> dw<span class="token punctuation">,</span> db<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>这里使用梯度下降算法求解模型参数$w$和$b$。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">linear_train</span><span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">,</span> learning_rate<span class="token punctuation">,</span> epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>    w<span class="token punctuation">,</span> b <span class="token operator">=</span> initialize_params<span class="token punctuation">(</span>X<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>      loss_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>      <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>                <span class="token comment" spellcheck="true"># 计算当前预测值、损失和参数偏导</span>        y_hat <span class="token operator">=</span> forward<span class="token punctuation">(</span>X<span class="token punctuation">,</span> w<span class="token punctuation">,</span> b<span class="token punctuation">)</span>        loss <span class="token operator">=</span> cal_loss<span class="token punctuation">(</span>y<span class="token punctuation">,</span> y_hat<span class="token punctuation">)</span>         loss_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>loss<span class="token punctuation">)</span>              dw<span class="token punctuation">,</span> db <span class="token operator">=</span> cal_grad<span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">,</span> y_hat<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 基于梯度下降的参数更新过程</span>        w <span class="token operator">+=</span> <span class="token operator">-</span>learning_rate <span class="token operator">*</span> dw        b <span class="token operator">+=</span> <span class="token operator">-</span>learning_rate <span class="token operator">*</span> db           <span class="token comment" spellcheck="true"># 打印迭代次数和损失</span>        <span class="token keyword">if</span> i <span class="token operator">%</span> <span class="token number">10000</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'epoch %d loss %f'</span> <span class="token operator">%</span> <span class="token punctuation">(</span>i<span class="token punctuation">,</span> loss<span class="token punctuation">)</span><span class="token punctuation">)</span>                        <span class="token comment" spellcheck="true"># 保存参数</span>        params <span class="token operator">=</span> <span class="token punctuation">{</span>                        <span class="token string">'w'</span><span class="token punctuation">:</span> w<span class="token punctuation">,</span>                        <span class="token string">'b'</span><span class="token punctuation">:</span> b        <span class="token punctuation">}</span>                <span class="token comment" spellcheck="true"># 保存梯度</span>        grads <span class="token operator">=</span> <span class="token punctuation">{</span>                        <span class="token string">'dw'</span><span class="token punctuation">:</span> dw<span class="token punctuation">,</span>                        <span class="token string">'db'</span><span class="token punctuation">:</span> db        <span class="token punctuation">}</span>        <span class="token keyword">return</span> loss_list<span class="token punctuation">,</span> loss<span class="token punctuation">,</span> params<span class="token punctuation">,</span> grads<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>上面基本实现了一个线性回归的功能，为了检测我们实现的线性回归模型的有效性，仍然使用波士顿房价预测的数据进行测试，自变量只用了房屋面积一个维度，通过房屋面积去拟合房价。接着使用上述的训练数据训练模型，使用测试数据预测结果。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 训练</span>loss_list<span class="token punctuation">,</span> loss<span class="token punctuation">,</span> params<span class="token punctuation">,</span> grads <span class="token operator">=</span> linear_train<span class="token punctuation">(</span>X_train<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> <span class="token number">0.001</span><span class="token punctuation">,</span> <span class="token number">100000</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 预测结果并绘图</span><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> pltf <span class="token operator">=</span> X_test<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>params<span class="token punctuation">[</span><span class="token string">'w'</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">+</span> params<span class="token punctuation">[</span><span class="token string">'b'</span><span class="token punctuation">]</span>plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>X_test<span class="token punctuation">,</span> y_test<span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>X_test<span class="token punctuation">,</span> f<span class="token punctuation">,</span> color <span class="token operator">=</span> <span class="token string">'darkorange'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'X'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'y'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="/images/linear_reg.png"></p><p>最后，为了更好的评估模型，使用K折交叉验证来评估我们实现的线性回归模型，计算的指标是回归中常用的$R^2$。可以看到$R^2$的均值为168，结合上面测试集的散点图和拟合直线，说明回归的效果不是非常理想，这是因为但从房屋面积去拟合房价是有失偏颇的。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">predict</span><span class="token punctuation">(</span>X<span class="token punctuation">,</span> params<span class="token punctuation">)</span><span class="token punctuation">:</span>    w <span class="token operator">=</span> params<span class="token punctuation">[</span><span class="token string">'w'</span><span class="token punctuation">]</span>    b <span class="token operator">=</span> params<span class="token punctuation">[</span><span class="token string">'b'</span><span class="token punctuation">]</span>    y_pred <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>X<span class="token punctuation">,</span> w<span class="token punctuation">)</span> <span class="token operator">+</span> b        <span class="token keyword">return</span> y_pred<span class="token keyword">def</span> <span class="token function">linear_cross_validation</span><span class="token punctuation">(</span>data<span class="token punctuation">,</span> k<span class="token punctuation">,</span> randomize<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span>       <span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>utils <span class="token keyword">import</span> shuffle    <span class="token keyword">if</span> randomize<span class="token punctuation">:</span>        data <span class="token operator">=</span> list<span class="token punctuation">(</span>data<span class="token punctuation">)</span>        shuffle<span class="token punctuation">(</span>data<span class="token punctuation">)</span>    slices <span class="token operator">=</span> <span class="token punctuation">[</span>data<span class="token punctuation">[</span>i<span class="token punctuation">:</span><span class="token punctuation">:</span>k<span class="token punctuation">]</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>k<span class="token punctuation">)</span><span class="token punctuation">]</span>          <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>k<span class="token punctuation">)</span><span class="token punctuation">:</span>        validation <span class="token operator">=</span> slices<span class="token punctuation">[</span>i<span class="token punctuation">]</span>        train <span class="token operator">=</span> list<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">for</span> s <span class="token keyword">in</span> slices<span class="token punctuation">:</span>            <span class="token keyword">if</span> s <span class="token keyword">is</span> <span class="token operator">not</span> validation<span class="token punctuation">:</span>                train<span class="token punctuation">.</span>extend<span class="token punctuation">(</span>s<span class="token punctuation">)</span>        train <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>train<span class="token punctuation">)</span>        validation <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>validation<span class="token punctuation">)</span>                    <span class="token keyword">yield</span> train<span class="token punctuation">,</span> validation        <span class="token comment" spellcheck="true"># K折交叉验证</span>data <span class="token operator">=</span> np<span class="token punctuation">.</span>concatenate<span class="token punctuation">(</span><span class="token punctuation">(</span>X<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> y<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token keyword">print</span><span class="token punctuation">(</span>data<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>r_square_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token keyword">for</span> train<span class="token punctuation">,</span> validation <span class="token keyword">in</span> linear_cross_validation<span class="token punctuation">(</span>data<span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    X_train <span class="token operator">=</span> train<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>    y_train <span class="token operator">=</span> train<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    X_valid <span class="token operator">=</span> validation<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>    y_valid <span class="token operator">=</span> validation<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    loss_list<span class="token punctuation">,</span> loss<span class="token punctuation">,</span> params<span class="token punctuation">,</span> grads <span class="token operator">=</span> linear_train<span class="token punctuation">(</span>X_train<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> <span class="token number">0.001</span><span class="token punctuation">,</span> <span class="token number">100000</span><span class="token punctuation">)</span>    y_pred <span class="token operator">=</span> predict<span class="token punctuation">(</span>X_valid<span class="token punctuation">,</span> params<span class="token punctuation">)</span>    r_square <span class="token operator">=</span> np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">(</span>y_valid<span class="token operator">-</span>y<span class="token punctuation">)</span><span class="token operator">**</span><span class="token number">2</span><span class="token punctuation">)</span>    r_square_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>r_square<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'five kold cross validation score is'</span><span class="token punctuation">,</span> r_square_list<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># five kold cross validation score is [162.41398318220567, 164.19161507455092, 178.86012366454037, 179.2822412241224, 159.51121355613822]</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'valid score is'</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>r_square_list<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># valid score is 168.85183534031154</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> 算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 算法知识 </tag>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>C++|指针与引用</title>
      <link href="/2023/11/06/c-zhi-shi/zhi-zhen-yu-yin-yong/"/>
      <url>/2023/11/06/c-zhi-shi/zhi-zhen-yu-yin-yong/</url>
      
        <content type="html"><![CDATA[<h1 id="指针与引用"><a href="#指针与引用" class="headerlink" title="指针与引用"></a>指针与引用</h1><h2 id="指针定义和使用"><a href="#指针定义和使用" class="headerlink" title="指针定义和使用"></a>指针定义和使用</h2><p>作用：通过指针间接访问内存，<strong>指针保存数据的地址</strong>。</p><p>语法：<code>数据类型* 指针变量名</code></p><p>通过解引用的方式找到指针指向的内存——即找到指针指向的内存的数据</p><pre class="line-numbers language-cpp"><code class="language-cpp"><span class="token keyword">int</span> a <span class="token operator">=</span> <span class="token number">10</span><span class="token punctuation">;</span><span class="token keyword">int</span><span class="token operator">*</span> p <span class="token operator">=</span> <span class="token operator">&amp;</span>a<span class="token punctuation">;</span>cout <span class="token operator">&lt;&lt;</span> <span class="token operator">&amp;</span>a <span class="token operator">&lt;&lt;</span> endl<span class="token punctuation">;</span>cout <span class="token operator">&lt;&lt;</span> p <span class="token operator">&lt;&lt;</span> endl<span class="token punctuation">;</span>cout <span class="token operator">&lt;&lt;</span> a <span class="token operator">&lt;&lt;</span> endl<span class="token punctuation">;</span>cout <span class="token operator">&lt;&lt;</span> <span class="token operator">*</span>p <span class="token operator">&lt;&lt;</span> endl<span class="token punctuation">;</span> <span class="token comment" spellcheck="true">// 解引用</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="指针所占的内存空间"><a href="#指针所占的内存空间" class="headerlink" title="指针所占的内存空间"></a>指针所占的内存空间</h3><p>占据的内存空间与数据类型无关，与操作系统有关</p><p>32位系统下，占用4个字节，64位系统下，占用8个字节</p><pre class="line-numbers language-cpp"><code class="language-cpp"><span class="token keyword">int</span> a <span class="token operator">=</span> <span class="token number">10</span><span class="token punctuation">;</span><span class="token keyword">int</span><span class="token operator">*</span> p<span class="token punctuation">;</span>p <span class="token operator">=</span> <span class="token operator">&amp;</span>a<span class="token punctuation">;</span>cout <span class="token operator">&lt;&lt;</span> <span class="token keyword">sizeof</span><span class="token punctuation">(</span>p<span class="token punctuation">)</span> <span class="token operator">&lt;&lt;</span> endl<span class="token punctuation">;</span>cout <span class="token operator">&lt;&lt;</span> <span class="token keyword">sizeof</span><span class="token punctuation">(</span><span class="token keyword">int</span><span class="token operator">*</span><span class="token punctuation">)</span> <span class="token operator">&lt;&lt;</span> endl<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="空指针和野指针"><a href="#空指针和野指针" class="headerlink" title="空指针和野指针"></a>空指针和野指针</h3><p>空指针：指针变量指向内存中编号为0的空间</p><p>空指针用途：初始化指针变量</p><p>注意：空指针指向的内存不可以访问（0-255之间的内存编号由系统占用）</p><pre class="line-numbers language-cpp"><code class="language-cpp"><span class="token keyword">int</span><span class="token operator">*</span> p <span class="token operator">=</span> <span class="token constant">NULL</span><span class="token punctuation">;</span> <span class="token comment" spellcheck="true">// 空指针</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>野指针：指针变量指向非法的内存空间，不是自己申请的空间</p><pre class="line-numbers language-cpp"><code class="language-cpp"><span class="token keyword">int</span><span class="token operator">*</span> p <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token keyword">int</span><span class="token operator">*</span><span class="token punctuation">)</span><span class="token number">0x1100</span><span class="token punctuation">;</span> <span class="token comment" spellcheck="true">// 野指针</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="const修饰指针"><a href="#const修饰指针" class="headerlink" title="const修饰指针"></a>const修饰指针</h3><h4 id="常量指针"><a href="#常量指针" class="headerlink" title="常量指针"></a>常量指针</h4><p>指针的指向可以修改，但是指针指向的数据不可以修改</p><pre class="line-numbers language-cpp"><code class="language-cpp"><span class="token keyword">int</span> a <span class="token operator">=</span> <span class="token number">10</span><span class="token punctuation">;</span><span class="token keyword">int</span> b <span class="token operator">=</span> <span class="token number">10</span><span class="token punctuation">;</span><span class="token keyword">const</span> <span class="token keyword">int</span><span class="token operator">*</span> p <span class="token operator">=</span> <span class="token operator">&amp;</span>a<span class="token punctuation">;</span>p <span class="token operator">=</span> <span class="token operator">&amp;</span>b<span class="token punctuation">;</span> <span class="token comment" spellcheck="true">// 正确</span><span class="token operator">*</span>p <span class="token operator">=</span> <span class="token number">200</span><span class="token punctuation">;</span> <span class="token comment" spellcheck="true">// 错误</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="指针常量"><a href="#指针常量" class="headerlink" title="指针常量"></a>指针常量</h4><p>指针的指向不可以修改，但是指针指向的数据可以修改</p><pre class="line-numbers language-cpp"><code class="language-cpp"><span class="token keyword">int</span> a <span class="token operator">=</span> <span class="token number">10</span><span class="token punctuation">;</span><span class="token keyword">int</span> b <span class="token operator">=</span> <span class="token number">10</span><span class="token punctuation">;</span><span class="token keyword">int</span><span class="token operator">*</span> <span class="token keyword">const</span> p <span class="token operator">=</span> <span class="token operator">&amp;</span>a<span class="token punctuation">;</span>p <span class="token operator">=</span> <span class="token operator">&amp;</span>b<span class="token punctuation">;</span> <span class="token comment" spellcheck="true">// 错误</span><span class="token operator">*</span>P <span class="token operator">=</span> <span class="token number">200</span>； <span class="token comment" spellcheck="true">// 正确</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="既修饰指针又修饰常量"><a href="#既修饰指针又修饰常量" class="headerlink" title="既修饰指针又修饰常量"></a>既修饰指针又修饰常量</h4><p>指针的指向不可以修改，指针指向的数据也不可以修改</p><pre class="line-numbers language-cpp"><code class="language-cpp"><span class="token keyword">int</span> a <span class="token operator">=</span> <span class="token number">10</span><span class="token punctuation">;</span><span class="token keyword">int</span> b <span class="token operator">=</span> <span class="token number">10</span><span class="token punctuation">;</span><span class="token keyword">const</span> <span class="token keyword">int</span><span class="token operator">*</span> <span class="token keyword">const</span> p <span class="token operator">=</span> <span class="token operator">&amp;</span>a<span class="token punctuation">;</span>p <span class="token operator">=</span> <span class="token operator">&amp;</span>b<span class="token punctuation">;</span> <span class="token comment" spellcheck="true">// 错误</span><span class="token operator">*</span>P <span class="token operator">=</span> <span class="token number">200</span>； <span class="token comment" spellcheck="true">// 错误</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="指针和数组"><a href="#指针和数组" class="headerlink" title="指针和数组"></a>指针和数组</h3><p>利用指针访问数组的元素</p><pre class="line-numbers language-cpp"><code class="language-cpp"><span class="token keyword">int</span> arr<span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">}</span><span class="token punctuation">;</span><span class="token keyword">int</span><span class="token operator">*</span> p <span class="token operator">=</span> arr<span class="token punctuation">;</span><span class="token comment" spellcheck="true">// 遍历数组</span><span class="token keyword">for</span><span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> <span class="token number">5</span><span class="token punctuation">,</span> i<span class="token operator">++</span><span class="token punctuation">)</span><span class="token punctuation">{</span>    <span class="token comment" spellcheck="true">// 方式一</span>    cout <span class="token operator">&lt;&lt;</span> arr<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">&lt;&lt;</span> endl<span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">// 方式二</span>    cout <span class="token operator">&lt;&lt;</span> <span class="token operator">*</span>p <span class="token operator">&lt;&lt;</span> endl<span class="token punctuation">;</span>    p<span class="token operator">++</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="引用的定义和使用"><a href="#引用的定义和使用" class="headerlink" title="引用的定义和使用"></a>引用的定义和使用</h2><p>作用：给变量取别名，降低操作指针的风险，简化代码。</p><p>语法：<code>数据类型&amp; 别名 = 原名</code></p><pre class="line-numbers language-cpp"><code class="language-cpp"><span class="token keyword">int</span> a <span class="token operator">=</span> <span class="token number">10</span><span class="token punctuation">;</span><span class="token keyword">int</span><span class="token operator">&amp;</span> b <span class="token operator">=</span> a<span class="token punctuation">;</span>cout <span class="token operator">&lt;&lt;</span> a <span class="token operator">&lt;&lt;</span> endl<span class="token punctuation">;</span> <span class="token comment" spellcheck="true">// 10</span>cout <span class="token operator">&lt;&lt;</span> b <span class="token operator">&lt;&lt;</span> endl<span class="token punctuation">;</span> <span class="token comment" spellcheck="true">// 10</span>b <span class="token operator">=</span> <span class="token number">100</span><span class="token punctuation">;</span>cout <span class="token operator">&lt;&lt;</span> a <span class="token operator">&lt;&lt;</span> endl<span class="token punctuation">;</span> <span class="token comment" spellcheck="true">// 100</span>cout <span class="token operator">&lt;&lt;</span> b <span class="token operator">&lt;&lt;</span> endl<span class="token punctuation">;</span> <span class="token comment" spellcheck="true">// 100</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="使用注意事项"><a href="#使用注意事项" class="headerlink" title="使用注意事项"></a>使用注意事项</h3><ul><li>引用必须<strong>初始化</strong></li><li>引用一旦初始化，就不可以更改了**(本质是指针常量)**，详细看下节【引用的本质】</li></ul><h3 id="引用做函数参数"><a href="#引用做函数参数" class="headerlink" title="引用做函数参数"></a>引用做函数参数</h3><p>函数参数有值传递和地址传递</p><p>作用：在函数传参时，可以使用<strong>引用</strong>作为形参。此时的形参可以修改实参</p><pre class="line-numbers language-cpp"><code class="language-cpp"><span class="token keyword">void</span> <span class="token function">swap1</span><span class="token punctuation">(</span><span class="token keyword">int</span> a<span class="token punctuation">,</span> <span class="token keyword">int</span> b<span class="token punctuation">)</span><span class="token punctuation">{</span>    <span class="token keyword">int</span> temp <span class="token operator">=</span> a<span class="token punctuation">;</span>    a <span class="token operator">=</span> b<span class="token punctuation">;</span>    b <span class="token operator">=</span> temp<span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token keyword">void</span> <span class="token function">swap2</span><span class="token punctuation">(</span><span class="token keyword">int</span><span class="token operator">*</span> a<span class="token punctuation">,</span> <span class="token keyword">int</span><span class="token operator">*</span> b<span class="token punctuation">)</span><span class="token punctuation">{</span>    <span class="token keyword">int</span> temp <span class="token operator">=</span> <span class="token operator">*</span>a<span class="token punctuation">;</span>    <span class="token operator">*</span>a <span class="token operator">=</span> <span class="token operator">*</span>b<span class="token punctuation">;</span>    <span class="token operator">*</span>b <span class="token operator">=</span> temp<span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token keyword">void</span> <span class="token function">swap3</span><span class="token punctuation">(</span><span class="token keyword">int</span><span class="token operator">&amp;</span> a<span class="token punctuation">,</span> <span class="token keyword">int</span><span class="token operator">&amp;</span> b<span class="token punctuation">)</span><span class="token punctuation">{</span>    <span class="token keyword">int</span> temp <span class="token operator">=</span> a<span class="token punctuation">;</span>    a <span class="token operator">=</span> b<span class="token punctuation">;</span>    b <span class="token operator">=</span> temp<span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="引用做函数返回值"><a href="#引用做函数返回值" class="headerlink" title="引用做函数返回值"></a>引用做函数返回值</h3><ol><li><p>引用可以作为函数的返回值</p></li><li><p>如果函数的返回值是引用，则<strong>函数调用</strong>可以作为左值</p></li></ol><pre class="line-numbers language-cpp"><code class="language-cpp"><span class="token keyword">int</span><span class="token operator">&amp;</span> <span class="token function">test1</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">{</span>    <span class="token keyword">int</span> a <span class="token operator">=</span> <span class="token number">10</span><span class="token punctuation">;</span>    <span class="token keyword">return</span> a<span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token keyword">int</span><span class="token operator">&amp;</span> ref <span class="token operator">=</span> <span class="token function">test1</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>cout <span class="token operator">&lt;&lt;</span> ref <span class="token operator">&lt;&lt;</span> endl<span class="token punctuation">;</span> <span class="token comment" spellcheck="true">// 局部变量被释放</span><span class="token keyword">int</span><span class="token operator">&amp;</span> <span class="token function">test2</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">{</span>    <span class="token keyword">static</span> <span class="token keyword">int</span> a <span class="token operator">=</span> <span class="token number">10</span><span class="token punctuation">;</span>    <span class="token keyword">return</span> a<span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token keyword">int</span><span class="token operator">&amp;</span> ref2 <span class="token operator">=</span> <span class="token function">test2</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>cout <span class="token operator">&lt;&lt;</span> ref2 <span class="token operator">&lt;&lt;</span> endl<span class="token punctuation">;</span> <span class="token comment" spellcheck="true">// 10</span><span class="token function">test2</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">=</span> <span class="token number">1000</span><span class="token punctuation">;</span> <span class="token comment" spellcheck="true">// 函数调用作为左值</span>cout <span class="token operator">&lt;&lt;</span> ref2 <span class="token operator">&lt;&lt;</span> endl<span class="token punctuation">;</span> <span class="token comment" spellcheck="true">// 1000</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><code>test2()</code>返回的是静态变量<code>a</code>的引用，<code>ref2</code>同理，和静态变量<code>a</code>指向同一块内存，因此<code>test2()</code>作为左值表示的是<code>a</code>的引用。</p><h3 id="引用的本质"><a href="#引用的本质" class="headerlink" title="引用的本质"></a>引用的本质</h3><p>本质：引用的本质是一个<strong>指针常量</strong></p><p>编译器会把引用转换为指针常量</p><pre class="line-numbers language-cpp"><code class="language-cpp"><span class="token keyword">int</span> a <span class="token operator">=</span> <span class="token number">10</span><span class="token punctuation">;</span><span class="token keyword">int</span><span class="token operator">&amp;</span> ref <span class="token operator">=</span> a<span class="token punctuation">;</span><span class="token comment" spellcheck="true">// 转换为 int* const ref = &amp;a;</span>ref <span class="token operator">=</span> <span class="token number">100</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">// 转换为 *ref = 100;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="常量引用"><a href="#常量引用" class="headerlink" title="常量引用"></a>常量引用</h3><p>作用：常量引用主要修饰形参，防止误操作。在函数的形参列表中，可以加<code>const</code>修饰形参<strong>防止形参改变实参</strong>。</p><pre class="line-numbers language-cpp"><code class="language-cpp"><span class="token keyword">void</span> <span class="token function">test1</span><span class="token punctuation">(</span><span class="token keyword">int</span><span class="token operator">&amp;</span> val<span class="token punctuation">)</span><span class="token punctuation">{</span>    val <span class="token operator">=</span> <span class="token number">1000</span><span class="token punctuation">;</span> <span class="token comment" spellcheck="true">// 误操作，修改了外部的实参</span>    cout <span class="token operator">&lt;&lt;</span> val <span class="token operator">&lt;&lt;</span> endl<span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token keyword">void</span> <span class="token function">test2</span><span class="token punctuation">(</span><span class="token keyword">const</span> <span class="token keyword">int</span><span class="token operator">&amp;</span> val<span class="token punctuation">)</span><span class="token punctuation">{</span>    val <span class="token operator">=</span> <span class="token number">1000</span><span class="token punctuation">;</span> <span class="token comment" spellcheck="true">// 代码报错</span>    cout <span class="token operator">&lt;&lt;</span> val <span class="token operator">&lt;&lt;</span> endl<span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token keyword">int</span> a <span class="token operator">=</span> <span class="token number">10</span><span class="token punctuation">;</span><span class="token function">test1</span><span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment" spellcheck="true">// 导致变量a被误修改</span><span class="token function">test2</span><span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment" spellcheck="true">// const修饰之后使其无法修改</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> 编程语言 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> C++ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深度学习中的图像操作</title>
      <link href="/2023/10/27/pytorch-ji-chu-zhi-shi/tu-xiang-du-qu/"/>
      <url>/2023/10/27/pytorch-ji-chu-zhi-shi/tu-xiang-du-qu/</url>
      
        <content type="html"><![CDATA[<h1 id="深度学习中的图像操作"><a href="#深度学习中的图像操作" class="headerlink" title="深度学习中的图像操作"></a>深度学习中的图像操作</h1><p>计算机视觉中图像增强是很实用的trick，下面介绍一下深度学习中常用的图像增强操作。</p><h2 id="图像读取和保存"><a href="#图像读取和保存" class="headerlink" title="图像读取和保存"></a>图像读取和保存</h2><p>在Python中常用的图像处理的库有OpenCV和PIL，这里简单介绍一下这两个库的最基本用法。</p><h3 id="opencv"><a href="#opencv" class="headerlink" title="opencv"></a>opencv</h3><p><code>cv2.imread()</code>读取图像的代码示例如下，该方法返回得到的img数据类型是<code>np.ndarray</code>类型，使用<code>img.shape</code>可读取数组的维度，该维度的物理含义为<code>(Height, Width, Channel)</code>。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> cv2img <span class="token operator">=</span> cv2<span class="token punctuation">.</span>imread<span class="token punctuation">(</span><span class="token string">"xxxxx.jpg"</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># flags是可选的读入模式，如灰度图等，默认为None</span>img <span class="token operator">=</span> cv2<span class="token punctuation">.</span>imread<span class="token punctuation">(</span><span class="token string">"xxxxx.jpg"</span><span class="token punctuation">,</span> flages<span class="token operator">=</span>cv2<span class="token punctuation">.</span>IMREAD_GRAYSCALE<span class="token punctuation">)</span>     <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p><code>img = cv2.imread(&quot;xxxxx.jpg&quot;)</code>读取图像的通道顺序为BGR，即使图片是RGBA四通道，<code>cv2.imread()</code>方法仍然读取的是BGR三通道。可以通过使用<code>cv2.split(img)</code>分别得到图像img的BGR通道值。</p><pre class="line-numbers language-python"><code class="language-python">b<span class="token punctuation">,</span>g<span class="token punctuation">,</span>r <span class="token operator">=</span> cv2<span class="token punctuation">.</span>split<span class="token punctuation">(</span>img<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>如果图像路径中存在中文、或是图像文件名含有中文，有时使用<code>cv2.imread()</code>是无法正常读取图像的，因此可以使用下面的方式读取和写入。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> cv2<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token comment" spellcheck="true"># 读取图像</span>img <span class="token operator">=</span> cv2<span class="token punctuation">.</span>imdecode<span class="token punctuation">(</span>np<span class="token punctuation">.</span>fromfile<span class="token punctuation">(</span>img_path<span class="token punctuation">,</span> dtype<span class="token operator">=</span>np<span class="token punctuation">.</span>uint8<span class="token punctuation">)</span><span class="token punctuation">,</span> cv2<span class="token punctuation">.</span>IMREAD_COLOR<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 保存图像</span>cv2<span class="token punctuation">.</span>imencode<span class="token punctuation">(</span><span class="token string">".jpg"</span><span class="token punctuation">,</span> img<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>tofile<span class="token punctuation">(</span>img_path<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="PIL"><a href="#PIL" class="headerlink" title="PIL"></a>PIL</h3><p>使用PIL读取图像的代码示例如下，<code>Image.open()</code>返回的img数据类型是<code>PIL.Image</code>对象，不是普通的数组。使用<code>img.size</code>可读取图像的维度大小，该维度的物理含义为<code>(Width, Height)</code>，注意没有通道维度的大小。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> PIL <span class="token keyword">import</span> Image<span class="token comment" spellcheck="true"># 读取图像</span>img <span class="token operator">=</span> Image<span class="token punctuation">.</span>open<span class="token punctuation">(</span><span class="token string">"xxx.jpg"</span><span class="token punctuation">)</span>img <span class="token operator">=</span> Image<span class="token punctuation">.</span>open<span class="token punctuation">(</span><span class="token string">"xxx.jpg"</span><span class="token punctuation">,</span> mode<span class="token operator">=</span>‘r’ <span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># mode只能且默认是‘r’</span><span class="token comment" spellcheck="true"># 保存图像</span>img<span class="token punctuation">.</span>save<span class="token punctuation">(</span><span class="token string">"xxx.jpg"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><code>Image.open()</code>方法只是保持了图像被读取的状态，但是图像的真实数据并未被读取，因此如果需要操作图像每个元素，如输出某个像素的RGB值等，需要执行对象的load()方法读取数据。具体如下：</p><pre class="line-numbers language-python"><code class="language-python">img <span class="token operator">=</span> Image<span class="token punctuation">.</span>open<span class="token punctuation">(</span><span class="token string">"xxx.jpg"</span><span class="token punctuation">)</span>img <span class="token operator">=</span> img<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>img<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># result：(255, 201, 166)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p><code>Image.open()</code>方法返回的默认彩色图像读取通道顺序为RGB，同时当图像格式为RGBA时，<code>Image.open(‘xxx.jpg’)</code>读取的格式为RGBA（其中A表示图像的alpha通道，即RGBA共四个通道），可以使用<code>convert()</code>函数转换为RGB</p><pre class="line-numbers language-python"><code class="language-python">Image<span class="token punctuation">.</span>open<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">.</span>convert<span class="token punctuation">(</span><span class="token string">'RGB'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="opencv和PIL的格式转换"><a href="#opencv和PIL的格式转换" class="headerlink" title="opencv和PIL的格式转换"></a>opencv和PIL的格式转换</h3><p><code>np.ndarray</code>格式转换为<code>PIL.Image</code>格式</p><pre class="line-numbers language-python"><code class="language-python">img <span class="token operator">=</span> cv2<span class="token punctuation">.</span>imread<span class="token punctuation">(</span>path<span class="token punctuation">)</span>img_Image <span class="token operator">=</span> Image<span class="token punctuation">.</span>fromarray<span class="token punctuation">(</span>np<span class="token punctuation">.</span>uint8<span class="token punctuation">(</span>img<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p><code>PIL.Image</code>格式转换为<code>np.ndarray</code>格式</p><pre class="line-numbers language-python"><code class="language-python">img <span class="token operator">=</span> Image<span class="token punctuation">.</span>open<span class="token punctuation">(</span>path<span class="token punctuation">)</span>img_array <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>img<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h2 id="torchvision中的图像预处理"><a href="#torchvision中的图像预处理" class="headerlink" title="torchvision中的图像预处理"></a>torchvision中的图像预处理</h2><p>torchvision是一个计算机视觉工具包，包含了常用的模型、数据集和图像预处理方法：</p><ul><li><code>torchvision.transforms</code> ：常用的图像预处理方法</li><li><code>torchvision.datasets</code>：常用数据集的dataset实现，如MNIST，CIFAR-10等</li><li><code>torchvision.model</code>：常用的模型预训练，AlexNet，VGG， ResNet等</li></ul><h3 id="基本操作"><a href="#基本操作" class="headerlink" title="基本操作"></a>基本操作</h3><p>图像预处理的基本操作如下：</p><ol><li><p><code>transforms.Tensor()</code>：将PIL图像或<code>np.ndarray</code>转换为<code>torch.Tensor</code>，并进行数值缩放。首先在数据格式上形如$H<em>W</em>C$的PIL图像和numpy数组转换为$C<em>H</em>W$，并将$[0,255]$的数值缩放到$[0,1]$，最后返回<code>torch.FloatTensor</code>的张量。</p></li><li><p><code>transforms.Normalize()</code>：对图像逐通道进行标准化操作，传入的参数有<code>mean</code>、<code>std</code>，分别表示均值和方差。输入是<code>torch.Tensor</code>，不支持直接对PIL图像进行操作。</p></li><li><p><code>transforms.PILToTensor()</code>：将PIL图像（$H<em>W</em>C$）转换为<code>torch.Tensor</code>（$C<em>H</em>W$），该操作不会进行数值缩放。</p></li><li><p><code>transforms.ToPILImage()</code>：将<code>torch.Tensor</code>形如（$C<em>H</em>W$）或<code>np.ndarray</code>形如（$H<em>W</em>C$）转换为PIL图像。该方法常用作张量的可视化。</p></li></ol><h3 id="裁剪"><a href="#裁剪" class="headerlink" title="裁剪"></a>裁剪</h3><pre class="line-numbers language-python"><code class="language-python">path <span class="token operator">=</span> <span class="token string">"lena_example/lena.jpg"</span>image <span class="token operator">=</span> Image<span class="token punctuation">.</span>open<span class="token punctuation">(</span>path<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>image<span class="token punctuation">.</span>size<span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># (474, 474)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p><code>transforms.CenterCrop()</code>：将PIL图像或是<code>torch.Tensor</code>进行中心裁剪。传入参数<code>size</code>是int整数或序列，表示裁剪的图像大小；如果输入数据的维度小于裁剪图像的大小，则会进行补0操作。</p><pre class="line-numbers language-python"><code class="language-python">crop1 <span class="token operator">=</span> transforms<span class="token punctuation">.</span>CenterCrop<span class="token punctuation">(</span><span class="token number">224</span><span class="token punctuation">)</span><span class="token punctuation">(</span>image<span class="token punctuation">)</span>crop2 <span class="token operator">=</span> transforms<span class="token punctuation">.</span>CenterCrop<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">474</span><span class="token punctuation">,</span><span class="token number">500</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">(</span>image<span class="token punctuation">)</span>plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>crop1<span class="token punctuation">)</span>plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>crop2<span class="token punctuation">)</span>crop1 <span class="token operator">=</span> transforms<span class="token punctuation">.</span>CenterCrop<span class="token punctuation">(</span><span class="token number">224</span><span class="token punctuation">)</span><span class="token punctuation">(</span>image<span class="token punctuation">)</span>crop2 <span class="token operator">=</span> transforms<span class="token punctuation">.</span>CenterCrop<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">474</span><span class="token punctuation">,</span><span class="token number">500</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">(</span>image<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="/images/centercrop.png"></p><p><code>transforms.RandomCrop()</code>：将PIL图像或是<code>torch.Tensor</code>进行随机位置裁剪。传入参数<code>size</code>是int整数或序列，表示裁剪的图像大小；该方法的其余参数都是填充相关的，如下：</p><ul><li><code>padding</code>参数表示填充大小，当输入为a时表示上下左右均填充a个像素；当输入为(a, b)时，上下填充b个像素，左右填充a个像素；当输入为(a, b, c, d)时，表示左，上，右，下分别填充a, b, c, d个像素</li><li><code>pad_if_need</code>参数表示如果裁剪图像小于<code>size</code>则进行填充。</li><li><code>padding_mode</code>参数表示填充模式：”constant”、”edge”、”reflect”、”symmetric”，区别见下文<code>Pad()</code>。</li><li><code>fill</code>参数表示填充的元素（当填充模式是constant时）</li></ul><pre class="line-numbers language-python"><code class="language-python">crop1 <span class="token operator">=</span> transforms<span class="token punctuation">.</span>RandomCrop<span class="token punctuation">(</span><span class="token number">224</span><span class="token punctuation">)</span><span class="token punctuation">(</span>image<span class="token punctuation">)</span>crop2 <span class="token operator">=</span> transforms<span class="token punctuation">.</span>RandomCrop<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">474</span><span class="token punctuation">,</span><span class="token number">500</span><span class="token punctuation">)</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">50</span><span class="token punctuation">)</span><span class="token punctuation">(</span>image<span class="token punctuation">)</span>crop3 <span class="token operator">=</span> transforms<span class="token punctuation">.</span>RandomCrop<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">474</span><span class="token punctuation">,</span><span class="token number">500</span><span class="token punctuation">)</span><span class="token punctuation">,</span> pad_if_needed<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> padding_mode<span class="token operator">=</span><span class="token string">"edge"</span><span class="token punctuation">)</span><span class="token punctuation">(</span>image<span class="token punctuation">)</span>fig <span class="token operator">=</span> plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>crop1<span class="token punctuation">)</span> plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">"random"</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>crop2<span class="token punctuation">)</span>plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">"padding"</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>crop3<span class="token punctuation">)</span>plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">"padding_mode"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="/images/randomcrop.png"></p><p><code>transforms.RandomResizedCrop()</code>：将PIL图像或是<code>torch.Tensor</code>进行随机大小、长宽比的裁剪，并进行指定尺寸的缩放。第一个参数<code>size</code>表示裁剪图像的大小，第二个参数<code>scale</code>表示随机裁剪的面积比例，默认值是(0.08, 1.0)；第三个参数<code>ratio</code>表示长宽比，默认值是(3&#x2F;4, 4&#x2F;3)，第四个参数<code>interpolation</code>表示插值算法。</p><pre class="line-numbers language-python"><code class="language-python">crop1 <span class="token operator">=</span> transforms<span class="token punctuation">.</span>RandomResizedCrop<span class="token punctuation">(</span><span class="token number">224</span><span class="token punctuation">)</span><span class="token punctuation">(</span>image<span class="token punctuation">)</span>crop2 <span class="token operator">=</span> transforms<span class="token punctuation">.</span>RandomResizedCrop<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">474</span><span class="token punctuation">,</span><span class="token number">500</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">(</span>image<span class="token punctuation">)</span>plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>crop1<span class="token punctuation">)</span> plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>crop2<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="/images/randomresizecrop.png"></p><p><code>transforms.FiveCrop()</code>：图像的上下左右以及中心裁剪出尺寸为size的5张图片。返回值是一个元组，包含5张图像。</p><p><code>transforms.FiveCrop()</code>：图像的上下左右以及中心裁剪出尺寸为size的5张图片，对这5张图片进行水平或者垂直镜像获得10张图片。返回值是一个元组，包含10张图像。</p><h3 id="翻转"><a href="#翻转" class="headerlink" title="翻转"></a>翻转</h3><p><code>transforms.RandomHorizontalFlip()</code>：依概率水平（左右）翻转图片，传入参数<code>p</code>表示概率。</p><p><code>transforms.RandomVerticalFlip()</code>：依概率垂直（上下）翻转图片，传入参数<code>p</code>表示概率。</p><p><code>transforms.RandomRotation()</code>：随机旋转图片，传入参数<code>degrees</code>表示旋转角度范围，当为a时，在（-a，a）之间选择旋转角度，当为(a, b)时，在(a, b)之间选择旋转角度。</p><h3 id="图像变换"><a href="#图像变换" class="headerlink" title="图像变换"></a>图像变换</h3><p><code>transforms.Pad()</code>：对图片边缘进行填充。</p><ul><li><p>参数<code>padding</code>表示设置填充大小，当为a时，上下左右均填充a个像素，当为(a, b)时，上下填充b个像素，左右填充a个像素，当为(a, b, c, d)时，左，上，右，下分别填充a, b, c, d个像素。</p></li><li><p>参数<code>padding_mode</code>：填充模式，有4种模式</p><ul><li>constant：填充的像素值由<code>fill</code>参数设定</li><li>edge：像素值由图像边缘像素决定</li><li>reflect：镜像填充，最后一个像素不镜像，例如[1,2,3,4] → [3,2,1,2,3,4,3,2]</li><li>symmetric：镜像填充，最后一个像素也会镜像，例如[1,2,3,4] → [2,1,1,2,3,4,4,3]</li></ul></li><li><p>参数<code>fill</code>：设置填充的像素值。</p></li></ul><pre class="line-numbers language-python"><code class="language-python">crop1 <span class="token operator">=</span> transforms<span class="token punctuation">.</span>Pad<span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">(</span>image<span class="token punctuation">)</span>crop2 <span class="token operator">=</span> transforms<span class="token punctuation">.</span>Pad<span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">,</span> padding_mode<span class="token operator">=</span><span class="token string">"edge"</span><span class="token punctuation">)</span><span class="token punctuation">(</span>image<span class="token punctuation">)</span>crop3 <span class="token operator">=</span> transforms<span class="token punctuation">.</span>Pad<span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">,</span> padding_mode<span class="token operator">=</span><span class="token string">"reflect"</span><span class="token punctuation">)</span><span class="token punctuation">(</span>image<span class="token punctuation">)</span>fig <span class="token operator">=</span> plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>crop1<span class="token punctuation">)</span> plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">"pure"</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>crop2<span class="token punctuation">)</span>plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">"edge"</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>crop3<span class="token punctuation">)</span>plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">"reflect"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="/images/Pad.png"></p><p><code>transforms.ColorJitter()</code>：调整图像的亮度、对比度、饱和度和色相</p><ul><li><code>brightness</code>参数：亮度调整因子当为a时，从[max(0, 1-a), 1+a]中随机选择；当为(a, b)时，从[a, b]中随机选择。</li><li><code>contrast</code>参数：对比度参数，同brightness</li><li><code>saturation</code>参数：饱和度参数，同brightness</li><li><code>hue</code>参数：色相参数，当为a时，从[-a, a]中选择参数，注： 0&lt;&#x3D; a &lt;&#x3D; 0.5；当为(a, b)时，从[a, b]中选择参数，注：-0.5 &lt;&#x3D; a &lt;&#x3D; b &lt;&#x3D; 0.5</li></ul><pre class="line-numbers language-python"><code class="language-python">img1 <span class="token operator">=</span> transforms<span class="token punctuation">.</span>ColorJitter<span class="token punctuation">(</span>brightness<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">,</span> contrast<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> saturation<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> hue<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">(</span>image<span class="token punctuation">)</span>img2 <span class="token operator">=</span> transforms<span class="token punctuation">.</span>ColorJitter<span class="token punctuation">(</span>brightness<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> contrast<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">,</span> saturation<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> hue<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">(</span>image<span class="token punctuation">)</span>img3 <span class="token operator">=</span> transforms<span class="token punctuation">.</span>ColorJitter<span class="token punctuation">(</span>brightness<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> contrast<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> saturation<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">,</span> hue<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">(</span>image<span class="token punctuation">)</span>img4 <span class="token operator">=</span> transforms<span class="token punctuation">.</span>ColorJitter<span class="token punctuation">(</span>brightness<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> contrast<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> saturation<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> hue<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">(</span>image<span class="token punctuation">)</span>fig <span class="token operator">=</span> plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>img1<span class="token punctuation">)</span> plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">"brightness"</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>img2<span class="token punctuation">)</span>plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">"contrast"</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>img3<span class="token punctuation">)</span> plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">"saturation"</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>img4<span class="token punctuation">)</span>plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">"hue"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="/images/color_jitter.png"></p><p><code>transforms.Grayscale()</code>：灰度化图像，传入参数<code>num_output_channels</code>表示输出图像的通道数，只能为1或3。</p><p><code>transforms.RandomGrayscale()</code>：随机灰度化图像，传入参数<code>num_output_channels</code>表示输出图像的通道数，只能为1或3，参数<code>p</code>表示转换为灰度图的概率。</p><p><code>transforms.RandomAffine()</code>：对图像进行仿射变换，仿射变换是二维的线性变换，由五种基本原子变换构成，分别是旋转、平移、缩放、错切和翻转。该方法有如下参数，</p><ul><li><code>degrees</code>表示图像旋转角度</li><li><code>translate</code>表示图像平移区间，如(a, b)，a设置宽，b设置高。图像在宽维度平移的区间为 -img_width * a &lt; dx &lt; img_width * a。</li><li><code>scale</code>表示图像缩放比例（以面积为单位）</li><li><code>shear</code>表示图像错切</li><li><code>fill_color</code>表示填充颜色设置</li></ul><pre class="line-numbers language-python"><code class="language-python">img1 <span class="token operator">=</span> transforms<span class="token punctuation">.</span>RandomAffine<span class="token punctuation">(</span>degrees<span class="token operator">=</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">45</span><span class="token punctuation">,</span><span class="token number">45</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">(</span>image<span class="token punctuation">)</span>img2 <span class="token operator">=</span> transforms<span class="token punctuation">.</span>RandomAffine<span class="token punctuation">(</span>degrees<span class="token operator">=</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">45</span><span class="token punctuation">,</span><span class="token number">45</span><span class="token punctuation">)</span><span class="token punctuation">,</span> translate<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0.3</span><span class="token punctuation">,</span><span class="token number">0.8</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">(</span>image<span class="token punctuation">)</span>img3 <span class="token operator">=</span> transforms<span class="token punctuation">.</span>RandomAffine<span class="token punctuation">(</span>degrees<span class="token operator">=</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">45</span><span class="token punctuation">,</span><span class="token number">45</span><span class="token punctuation">)</span><span class="token punctuation">,</span>scale<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">(</span>image<span class="token punctuation">)</span>img4 <span class="token operator">=</span> transforms<span class="token punctuation">.</span>RandomAffine<span class="token punctuation">(</span>degrees<span class="token operator">=</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">45</span><span class="token punctuation">,</span><span class="token number">45</span><span class="token punctuation">)</span><span class="token punctuation">,</span>shear<span class="token operator">=</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">45</span><span class="token punctuation">,</span><span class="token number">45</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">(</span>image<span class="token punctuation">)</span>fig <span class="token operator">=</span> plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>img1<span class="token punctuation">)</span> plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">"rotate"</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>img2<span class="token punctuation">)</span>plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">"translate"</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>img3<span class="token punctuation">)</span> plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">"scale"</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>img4<span class="token punctuation">)</span>plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">"shear"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="/images/randomAffine.png"></p><p><code>transforms.RandomErasing()</code>：对图像进行随机擦除。参数<code>p</code>表示概率值，执行随机擦除的概率；参数<code>scale</code>表示擦除区域的面积；参数<code>ratio</code>表示擦除区域的长宽比；参数<code>value</code>表示设置遮挡区域的像素值(R, G, B)或(Gray)。<strong>该操作不支持PIL图像</strong>。</p><pre class="line-numbers language-python"><code class="language-python">image_tensor <span class="token operator">=</span> transforms<span class="token punctuation">.</span>PILToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">(</span>image<span class="token punctuation">)</span>img1 <span class="token operator">=</span> transforms<span class="token punctuation">.</span>RandomErasing<span class="token punctuation">(</span>p<span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">)</span><span class="token punctuation">(</span>image_tensor<span class="token punctuation">)</span>img2 <span class="token operator">=</span> transforms<span class="token punctuation">.</span>RandomErasing<span class="token punctuation">(</span>p<span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">,</span> value<span class="token operator">=</span><span class="token number">127</span><span class="token punctuation">)</span><span class="token punctuation">(</span>image_tensor<span class="token punctuation">)</span>img3 <span class="token operator">=</span> transforms<span class="token punctuation">.</span>RandomErasing<span class="token punctuation">(</span>p<span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">,</span> value<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">255</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">(</span>image_tensor<span class="token punctuation">)</span>fig <span class="token operator">=</span> plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>transforms<span class="token punctuation">.</span>ToPILImage<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">(</span>img1<span class="token punctuation">)</span><span class="token punctuation">)</span> plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">"pure"</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>transforms<span class="token punctuation">.</span>ToPILImage<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">(</span>img2<span class="token punctuation">)</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">"value=127"</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>transforms<span class="token punctuation">.</span>ToPILImage<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">(</span>img3<span class="token punctuation">)</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">"rgb"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="/images/randomerase.png"></p><h3 id="transforms的操作"><a href="#transforms的操作" class="headerlink" title="transforms的操作"></a>transforms的操作</h3><p><code>transforms.Compose()</code>：把一系列transforms方法集成到一起，并顺序执行transforms方法。</p><pre class="line-numbers language-python"><code class="language-python">transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>transforms1<span class="token punctuation">,</span> transforms2<span class="token punctuation">,</span> transforms3<span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><code>transforms.RandomChoice()</code>：从一系列transforms方法中随机挑选一个。</p><pre class="line-numbers language-python"><code class="language-python">transforms<span class="token punctuation">.</span>RandomChoice<span class="token punctuation">(</span><span class="token punctuation">[</span>transforms1<span class="token punctuation">,</span> transforms2<span class="token punctuation">,</span> transforms3<span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><code>transforms.RandomApply()</code>：依据概率执行一组transforms方法。</p><pre class="line-numbers language-python"><code class="language-python">transforms<span class="token punctuation">.</span>RandomApply<span class="token punctuation">(</span><span class="token punctuation">[</span>transforms1<span class="token punctuation">,</span> transforms2<span class="token punctuation">,</span> transforms3<span class="token punctuation">]</span><span class="token punctuation">,</span> p<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><code>transforms.RandomOrder()</code>：将一组transforms方法的操作顺序打乱。</p><pre class="line-numbers language-python"><code class="language-python">transforms<span class="token punctuation">.</span>RandomOrder<span class="token punctuation">(</span><span class="token punctuation">[</span>transforms1<span class="token punctuation">,</span> transforms2<span class="token punctuation">,</span> transforms3<span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><code>transforms.Lambda()</code>：用户自定义transforms方法，传入参数<code>lambda</code>是一个匿名函数。比如<code>FiveCrop()</code>返回的元组数据，和GT可能不匹配时，可以如下操作。</p><pre class="line-numbers language-python"><code class="language-python">trans <span class="token operator">=</span> transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>    transforms<span class="token punctuation">.</span>FiveCrop<span class="token punctuation">(</span>size<span class="token punctuation">)</span><span class="token punctuation">,</span>    transforms<span class="token punctuation">.</span>Lambda<span class="token punctuation">(</span><span class="token keyword">lambda</span> crops<span class="token punctuation">:</span> torch<span class="token punctuation">.</span>stack<span class="token punctuation">(</span><span class="token punctuation">[</span>PILToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">(</span>crop<span class="token punctuation">)</span> <span class="token keyword">for</span> crop <span class="token keyword">in</span> crops<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>上述就是深度学习中常用的图像操作，这里并没有介绍完torchvision中包含的所有图像增强方法，但是基本常用的都能涵盖，其他方法就在实践中探索吧。</p>]]></content>
      
      
      <categories>
          
          <category> Pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Pytorch </tag>
            
            <tag> 计算机视觉 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Python的魔法方法(下)</title>
      <link href="/2023/10/16/python-zhi-shi/python-mo-fang-fang-fa-xia/"/>
      <url>/2023/10/16/python-zhi-shi/python-mo-fang-fang-fa-xia/</url>
      
        <content type="html"><![CDATA[<h1 id="Python的魔法方法（下）"><a href="#Python的魔法方法（下）" class="headerlink" title="Python的魔法方法（下）"></a>Python的魔法方法（下）</h1><p>本文是对B站UP主“码农高天”的《Python的魔法方法》系列视频的总结和整理，搭配视频食用本文效果更佳。</p><p>魔法方法：Python提供的让用户客制化一个类的方式，定义在类内的一些特殊方法，这些方法的名称前后会有两个下划线。</p><h2 id="与类的建立有关的方法"><a href="#与类的建立有关的方法" class="headerlink" title="与类的建立有关的方法"></a>与类的建立有关的方法</h2><h3 id="init-subclass"><a href="#init-subclass" class="headerlink" title="__ init_subclass__"></a>__ init_subclass__</h3><p>这个魔法方法需要定义在基类里，当以这个类为基类，定义一个派生类的时候，这个方法就会被调用。运行下面的代码就会打印出类A。其中<code>cls</code>参数就是定义的派生类。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Base</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init_subclass__</span><span class="token punctuation">(</span>cls<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span>cls<span class="token punctuation">)</span>        <span class="token keyword">class</span> <span class="token class-name">A</span><span class="token punctuation">(</span>Base<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">pass</span><span class="token comment" spellcheck="true"># 执行：</span><span class="token operator">&lt;</span><span class="token keyword">class</span> <span class="token string">'__main__.A'</span><span class="token operator">></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>可以在该方法里定义一个空字典，如下所示。同时，该方法也可以传入参数。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Base</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init_subclass__</span><span class="token punctuation">(</span>cls<span class="token punctuation">,</span> name<span class="token punctuation">)</span><span class="token punctuation">:</span>        cls<span class="token punctuation">.</span>x <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>        cls<span class="token punctuation">.</span>name <span class="token operator">=</span> name        <span class="token keyword">class</span> <span class="token class-name">A</span><span class="token punctuation">(</span>Base<span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">"Jack"</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">pass</span><span class="token keyword">print</span><span class="token punctuation">(</span>A<span class="token punctuation">.</span>x<span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># {}</span><span class="token keyword">print</span><span class="token punctuation">(</span>A<span class="token punctuation">.</span>name<span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># Jack</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="set-name"><a href="#set-name" class="headerlink" title="__ set_name__"></a>__ set_name__</h3><p>该方法更多是用在描述器里。当在某个类的定义内，去实例化该类的对象时，就会调用这个方法。执行下面的代码，发现owner参数是类A，即表示在哪个类内去实例化对象；而name表示实例化对象时所赋值的变量名。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">D</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__set_name__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> owner<span class="token punctuation">,</span> name<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span>owner<span class="token punctuation">,</span> name<span class="token punctuation">)</span><span class="token keyword">class</span> <span class="token class-name">A</span><span class="token punctuation">:</span>    x <span class="token operator">=</span> D<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 执行：</span><span class="token operator">&lt;</span><span class="token keyword">class</span> <span class="token string">'__main__.A'</span><span class="token operator">></span> x<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="class-getitem-和-mro-entries"><a href="#class-getitem-和-mro-entries" class="headerlink" title="__ class_getitem__ 和__ mro_entries__"></a>__ class_getitem__ 和__ mro_entries__</h3><p><code>__getitem__</code>：是当<strong>类实例化的对象</strong>使用<code>[]</code>进行取值时调用的方法。</p><p><code>__class_getitem__</code>：是当<strong>类</strong>使用<code>[]</code>进行取值时调用的方法。可以用来对type hint做增强。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">A</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__class_getitem__</span><span class="token punctuation">(</span>cls<span class="token punctuation">,</span> item<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span>item<span class="token punctuation">)</span>        <span class="token keyword">return</span> <span class="token string">"abc"</span><span class="token keyword">print</span><span class="token punctuation">(</span>A<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 0</span><span class="token comment" spellcheck="true"># abc</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>如下的代码，在类型提示中<code>list[int]</code>表示一个由int组成的列表，可以将其赋给一个变量作为类型提示。</p><pre class="line-numbers language-python"><code class="language-python">int_arr_type <span class="token operator">=</span> list<span class="token punctuation">[</span>int<span class="token punctuation">]</span>list1<span class="token punctuation">:</span> int_arr_type <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>list2<span class="token punctuation">:</span> int_arr_type <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p><code>__mro_entries__</code>：某个类在做继承的时候，大多数是<code>class B(A)</code>的形式，如果直接写做<code>class B(A())</code>的就会报错，报错是因为建立类B的时候寻找自己的基类出现了问题，因此<code>__mro_entries__</code>方法就是在建立类的过程中帮助寻找基类的，该方法会返回一个tuple，表示去哪里找基类。执行下面的代码则不会再报错并能运行了。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">A</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__mro_entries__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> bases<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span>base<span class="token punctuation">)</span>        <span class="token keyword">return</span> <span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">class</span> <span class="token class-name">B</span><span class="token punctuation">(</span>A<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">pass</span><span class="token comment" spellcheck="true"># 执行：</span><span class="token comment" spellcheck="true"># (&lt;__main__.A object at 0x7f87ab86a400>,)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>从上面代码可以看到，<code>__mro_entries__</code>返回的是一个空tuple，因此在建立类B的过程中，类A的实例化对象提供不了类B的基类，如下面的代码打印结果是False。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">A</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__mro_entries__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> bases<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span>base<span class="token punctuation">)</span>        <span class="token keyword">return</span> <span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">class</span> <span class="token class-name">B</span><span class="token punctuation">(</span>A<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">pass</span><span class="token keyword">print</span><span class="token punctuation">(</span>issubclass<span class="token punctuation">(</span>B<span class="token punctuation">,</span> A<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># False</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>那再修改一下代码看看，说明B是A的子类，B成功找到了自己的基类。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">A</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__mro_entries__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> bases<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span>base<span class="token punctuation">)</span>        <span class="token keyword">return</span> <span class="token punctuation">(</span>A<span class="token punctuation">,</span><span class="token punctuation">)</span>    <span class="token keyword">class</span> <span class="token class-name">B</span><span class="token punctuation">(</span>A<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">pass</span><span class="token keyword">print</span><span class="token punctuation">(</span>issubclass<span class="token punctuation">(</span>B<span class="token punctuation">,</span> A<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># True</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="与metaclass有关的方法"><a href="#与metaclass有关的方法" class="headerlink" title="与metaclass有关的方法"></a>与metaclass有关的方法</h2><p>待补充</p><h2 id="运算方法"><a href="#运算方法" class="headerlink" title="运算方法"></a>运算方法</h2><h3 id="常用的运算方法"><a href="#常用的运算方法" class="headerlink" title="常用的运算方法"></a>常用的运算方法</h3><p>在Python中，如果直接对一个对象做数学运算，Python会报错。如下面的代码中的两个向量相加。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Vector</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>x <span class="token operator">=</span> x        self<span class="token punctuation">.</span>y <span class="token operator">=</span> y    <span class="token keyword">def</span> <span class="token function">__repr__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> f<span class="token string">"Vector({self.x}, {self.y})"</span>    v1 <span class="token operator">=</span> Vector<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>v2 <span class="token operator">=</span> Vector<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>v1<span class="token operator">+</span>v2<span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 报错</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>这个时候可以在类Vector中定义<code>__add__</code>方法，帮助自定义的向量对象做加法操作。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Vector</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>x <span class="token operator">=</span> x        self<span class="token punctuation">.</span>y <span class="token operator">=</span> y    <span class="token keyword">def</span> <span class="token function">__repr__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> f<span class="token string">"Vector({self.x}, {self.y})"</span>    <span class="token keyword">def</span> <span class="token function">__add__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> other<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> Vector<span class="token punctuation">(</span>self<span class="token punctuation">.</span>x <span class="token operator">+</span> other<span class="token punctuation">.</span>x<span class="token punctuation">,</span> self<span class="token punctuation">.</span>y <span class="token operator">+</span> other<span class="token punctuation">.</span>y<span class="token punctuation">)</span>    v1 <span class="token operator">=</span> Vector<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>v2 <span class="token operator">=</span> Vector<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>v1<span class="token operator">+</span>v2<span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># Vector(2, 4)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>在Python中可以定义的与数值运算相关的魔法方法如下，这也是对Python中的运算符号(<code>+</code>、<code>-</code>、<code>*</code>、<code>/</code>等)进行重写：</p><p>加法<code>__add__</code>、减法<code>__sub__</code>、乘法<code>__mul__</code>、矩阵乘法<code>__matmul__</code>、除法<code>__truediv__</code>、整除<code>__floordiv__</code>、取余<code>__mod__</code>、既拿到商也拿到余数<code>__divmod__</code>、乘方<code>__pow__</code>。</p><p>左移<code>lshift</code>、右移<code>rshift</code>。</p><p>逻辑计算与<code>__and__</code>、逻辑计算异或<code>__xor__</code>、逻辑计算或<code>__or__</code>，注意这里不是对Python的关键字<code>and</code>和<code>or</code>的重写，是对符号<code>&amp;</code>和<code>|</code>的重写。</p><p>这里的魔法方法除了乘方比较特殊外，其余的魔法方法定义形式基本相同。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">A</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__xxx__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> other<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># self和other做定义的运算</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>乘方的魔法方法的定义如下，相比于其他方法多了一个参数mod，该参数是指在做完乘方运算后可以再进行取余操作。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">A</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__pow__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> other<span class="token punctuation">,</span> mod<span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">pass</span>        <span class="token comment" spellcheck="true"># pow(v1, v2, mod) => (v1**v2)%mod</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>这里有几个注意的地方：首先，<code>self</code>和<code>other</code>并不一定是相同的类型，比如self是一个Vector对象，而other是一个int整数。可以在这个方法里实现数乘和点乘的功能。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Vector</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__mul__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> other<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">if</span> isinstance<span class="token punctuation">(</span>other<span class="token punctuation">,</span> int<span class="token punctuation">)</span>            <span class="token keyword">return</span> Vector<span class="token punctuation">(</span>self<span class="token punctuation">.</span>x <span class="token operator">*</span> other<span class="token punctuation">,</span> self<span class="token punctuation">.</span>y <span class="token operator">*</span> other<span class="token punctuation">)</span>           <span class="token keyword">elif</span> isinstance<span class="token punctuation">(</span>other<span class="token punctuation">,</span> Vector<span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">return</span> Vector<span class="token punctuation">(</span>self<span class="token punctuation">.</span>x <span class="token operator">*</span> other<span class="token punctuation">.</span>x<span class="token punctuation">,</span> self<span class="token punctuation">.</span>y <span class="token operator">*</span> other<span class="token punctuation">.</span>y<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>另外，使用魔法方法只是借用这个符号，并不一定要符合原来的定义，比如在C++ 中将左移运算符重新定义为<code>cout.print</code>，因此在使用<code>&lt;&lt;</code>符号时本质是在执行打印功能。</p><p>最后看一个例子，我们在下面的代码中执行<code>print(v1*2)</code>时本质是<code>v1.__mul__(2)</code>，可以正确得到结果，那么如果是执行<code>print(2*v1)</code>则会报错，对于这种情况应该怎么办呢？</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Vector</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>x <span class="token operator">=</span> x        self<span class="token punctuation">.</span>y <span class="token operator">=</span> y    <span class="token keyword">def</span> <span class="token function">__repr__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> f<span class="token string">"Vector({self.x}, {self.y})"</span>        <span class="token keyword">def</span> <span class="token function">__mul__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> other<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">if</span> isinstance<span class="token punctuation">(</span>other<span class="token punctuation">,</span> int<span class="token punctuation">)</span>            <span class="token keyword">return</span> Vector<span class="token punctuation">(</span>self<span class="token punctuation">.</span>x <span class="token operator">*</span> other<span class="token punctuation">,</span> self<span class="token punctuation">.</span>y <span class="token operator">*</span> other<span class="token punctuation">)</span>           <span class="token keyword">elif</span> isinstance<span class="token punctuation">(</span>other<span class="token punctuation">,</span> Vector<span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">return</span> Vector<span class="token punctuation">(</span>self<span class="token punctuation">.</span>x <span class="token operator">*</span> other<span class="token punctuation">.</span>x<span class="token punctuation">,</span> self<span class="token punctuation">.</span>y <span class="token operator">*</span> other<span class="token punctuation">.</span>y<span class="token punctuation">)</span>v1 <span class="token operator">=</span> Vector<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>v1<span class="token operator">*</span><span class="token number">2</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 等价于 v1.__mul__(2)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token operator">*</span>v1<span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 报错</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>此时，可以定义方法<code>__rmul__</code>来解决：如果操作符左侧的对象没有定义运算操作怎么完成时，就会尝试去找操作符右侧的数据对象的<strong>r版本</strong>的运算方法，也即执行<code>other*self</code>时，<code>other</code>不知道怎么做乘法时，就会调用<code>self</code>的<code>__rmul__</code>方法，然后把<code>other</code>作为参数传入，方法内部的实现与<code>__mul__</code>方法完全相同。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Vector</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>x <span class="token operator">=</span> x        self<span class="token punctuation">.</span>y <span class="token operator">=</span> y    <span class="token keyword">def</span> <span class="token function">__repr__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> f<span class="token string">"Vector({self.x}, {self.y})"</span>        <span class="token keyword">def</span> <span class="token function">__mul__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> other<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">if</span> isinstance<span class="token punctuation">(</span>other<span class="token punctuation">,</span> int<span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">return</span> Vector<span class="token punctuation">(</span>self<span class="token punctuation">.</span>x <span class="token operator">*</span> other<span class="token punctuation">,</span> self<span class="token punctuation">.</span>y <span class="token operator">*</span> other<span class="token punctuation">)</span>           <span class="token keyword">elif</span> isinstance<span class="token punctuation">(</span>other<span class="token punctuation">,</span> Vector<span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">return</span> Vector<span class="token punctuation">(</span>self<span class="token punctuation">.</span>x <span class="token operator">*</span> other<span class="token punctuation">.</span>x<span class="token punctuation">,</span> self<span class="token punctuation">.</span>y <span class="token operator">*</span> other<span class="token punctuation">.</span>y<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">__rmul__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> other<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">if</span> isinstance<span class="token punctuation">(</span>other<span class="token punctuation">,</span> int<span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">return</span> Vector<span class="token punctuation">(</span>self<span class="token punctuation">.</span>x <span class="token operator">*</span> other<span class="token punctuation">,</span> self<span class="token punctuation">.</span>y <span class="token operator">*</span> other<span class="token punctuation">)</span>           <span class="token keyword">elif</span> isinstance<span class="token punctuation">(</span>other<span class="token punctuation">,</span> Vector<span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">return</span> Vector<span class="token punctuation">(</span>self<span class="token punctuation">.</span>x <span class="token operator">*</span> other<span class="token punctuation">.</span>x<span class="token punctuation">,</span> self<span class="token punctuation">.</span>y <span class="token operator">*</span> other<span class="token punctuation">.</span>y<span class="token punctuation">)</span>        v1 <span class="token operator">=</span> Vector<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>v1<span class="token operator">*</span><span class="token number">2</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># Vector(0, 2)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token operator">*</span>v1<span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># Vector(0, 2)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>这里提到的所有和数值计算有关的魔法方法，都有对应的r版本，也即在方法名前加一个字母“r”。比如加法<code>__add__</code>和<code>__radd__</code>。</p><p>除了魔法方法的<strong>r 版本</strong>外，还有一个<strong>i版本</strong>，这是指原地（in-place）进行运算操作，修改self自身：相比于上述方法，不是返回一个新的内存数据，而是修改自身的内存数据。对应的运算符号是原来的操作符后面加一个等号，比如加法，<code>v1 += v2</code>就会调用<code>__iadd__</code>方法：<code>v1.__iadd__(v2)</code>。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">A</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>x <span class="token operator">=</span> x        self<span class="token punctuation">.</span>y <span class="token operator">=</span> y    <span class="token keyword">def</span> <span class="token function">__repr__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> f<span class="token string">"Vector({self.x}, {self.y})"</span>        <span class="token keyword">def</span> <span class="token function">__iadd__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> other<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># v1 += v2</span>        self<span class="token punctuation">.</span>x <span class="token operator">+=</span> other<span class="token punctuation">.</span>x        self<span class="token punctuation">.</span>y <span class="token operator">+=</span> other<span class="token punctuation">.</span>y        <span class="token keyword">return</span> self<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>在所有<strong>使用运算符号</strong>的操作中，都有对应的<strong>i版本</strong>，比如<code>+=</code>、<code>-=</code>、<code>*=</code>、<code>/=</code>等操作，对应的i版本方法在方法名前加一个字母“i”。</p><h3 id="其他的一元运算"><a href="#其他的一元运算" class="headerlink" title="其他的一元运算"></a>其他的一元运算</h3><p><code>__pos__</code>：对应的操作是在数据对象之前加一个正号</p><p><code>__neg__</code>：对应的操作是在数据对象之前加一个负号</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Vector</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>x <span class="token operator">=</span> x        self<span class="token punctuation">.</span>y <span class="token operator">=</span> y    <span class="token keyword">def</span> <span class="token function">__repr__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> f<span class="token string">"Vector({self.x}, {self.y})"</span>        <span class="token keyword">def</span> <span class="token function">__pos__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Pos"</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> Vector<span class="token punctuation">(</span>self<span class="token punctuation">.</span>x<span class="token punctuation">,</span> self<span class="token punctuation">.</span>y<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">__neg__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> Vector<span class="token punctuation">(</span><span class="token operator">-</span>self<span class="token punctuation">.</span>x<span class="token punctuation">,</span> <span class="token operator">-</span>self<span class="token punctuation">.</span>y<span class="token punctuation">)</span>    v1 <span class="token operator">=</span> Vector<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token operator">+</span>v1<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># Pos</span><span class="token comment" spellcheck="true"># Vector(1,2)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><code>__abs__</code>：求绝对值操作，对应的运算符是<code>abs</code>，在Python中使用<code>abs(xxx)</code>会调用<code>__abs__</code>方法。</p><p><code>__invert__</code>：取反操作，对应的运算符号是<code>~</code>，一般用作位运算。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Vector</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>x <span class="token operator">=</span> x        self<span class="token punctuation">.</span>y <span class="token operator">=</span> y    <span class="token keyword">def</span> <span class="token function">__repr__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> f<span class="token string">"Vector({self.x}, {self.y})"</span>        <span class="token keyword">def</span> <span class="token function">__abs__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> Vector<span class="token punctuation">(</span>abs<span class="token punctuation">(</span>self<span class="token punctuation">.</span>x<span class="token punctuation">)</span><span class="token punctuation">,</span> abs<span class="token punctuation">(</span>self<span class="token punctuation">.</span>y<span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">__neg__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token comment" spellcheck="true"># 这里自定义顺序取反</span>        <span class="token keyword">return</span> Vector<span class="token punctuation">(</span>self<span class="token punctuation">.</span>y<span class="token punctuation">,</span> self<span class="token punctuation">.</span>x<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><code>__int__</code>：使用Python的内置函数<code>int()</code>时，调用该方法</p><p><code>__float__</code>：使用Python的内置函数<code>float()</code>时，调用该方法</p><p><code>__complex__</code>：使用Python的内置函数<code>complex()</code>时，调用该方法</p><p>这三个魔法方法规定，方法的返回值必须是它们对应的数据结构。假如想定义<code>int()</code>操作是对Vector里的x和y都进行<code>int</code>操作，如下代码定义，则执行这段代码会报错。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Vector</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>x <span class="token operator">=</span> x        self<span class="token punctuation">.</span>y <span class="token operator">=</span> y    <span class="token keyword">def</span> <span class="token function">__repr__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> f<span class="token string">"Vector({self.x}, {self.y})"</span>        <span class="token keyword">def</span> <span class="token function">__int__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> Vector<span class="token punctuation">(</span>int<span class="token punctuation">(</span>self<span class="token punctuation">.</span>x<span class="token punctuation">)</span><span class="token punctuation">,</span> int<span class="token punctuation">(</span>self<span class="token punctuation">.</span>y<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><code>__index__</code>：表示当把数据对象当作索引使用时，它产生的行为功能是什么。</p><p>当定义了<code>__index__</code>方法，且<code>__int__</code>、<code>__complex__</code>和<code>__float__</code>没有被定义时，使用Python的内置方法<code>int()</code>、<code>float()</code>和<code>complex()</code>时会默认执行<code>__index__</code>方法。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Vector</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>x <span class="token operator">=</span> x        self<span class="token punctuation">.</span>y <span class="token operator">=</span> y    <span class="token keyword">def</span> <span class="token function">__repr__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> f<span class="token string">"Vector({self.x}, {self.y})"</span>        <span class="token keyword">def</span> <span class="token function">__index__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> int<span class="token punctuation">(</span>self<span class="token punctuation">.</span>x<span class="token punctuation">)</span>    v <span class="token operator">=</span> Vector<span class="token punctuation">(</span><span class="token number">1.5</span><span class="token punctuation">,</span> <span class="token number">2.5</span><span class="token punctuation">)</span>lst <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token keyword">print</span><span class="token punctuation">(</span>lst<span class="token punctuation">[</span>v<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 1</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="取整操作"><a href="#取整操作" class="headerlink" title="取整操作"></a>取整操作</h3><p><code>__round__</code>：对应Python的内置函数<code>round</code>，四舍五入，取最近的整数</p><p><code>__trunc__</code>：math库内的<code>trunc</code>函数，小数点后面不要，即向0取整</p><p><code>__floor__</code>：math库内的<code>floor</code>函数，向下取整，即向负无穷取整</p><p><code>__ceil__</code>：math库内的<code>ceil</code>函数，向上取整，即向正无穷取整</p><h2 id="模拟行为的方法"><a href="#模拟行为的方法" class="headerlink" title="模拟行为的方法"></a>模拟行为的方法</h2><h3 id="call"><a href="#call" class="headerlink" title="__ call__"></a>__ call__</h3><p><code>__call__</code>：该方法可以以函数调用的形式使用对象。</p><p>如下面代码所示，定义了一个乘法器，乘法倍数是3，该类实例化得到对象o。因为定义了<code>__call__</code>方法，则对象o可以以函数形式被使用。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Multiplier</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> mul<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>mul <span class="token operator">=</span> mul    <span class="token keyword">def</span> <span class="token function">__call__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> arg<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>mul<span class="token operator">*</span>arg    o <span class="token operator">=</span> Multiplier<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>o<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 12</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="len"><a href="#len" class="headerlink" title="__ len__"></a>__ len__</h3><p><code>__len__</code>：描述该对象（容器）的长度。</p><p>如下代码所示，自定义一个列表容器，这里使用Python内置的list的<code>__len__</code>实现，返回<code>self.data</code>的长度。<code>__len__</code>会被Python内置方法<code>len()</code>调用</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">MyList</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> data<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>data <span class="token operator">=</span> data    <span class="token keyword">def</span> <span class="token function">__len__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> len<span class="token punctuation">(</span>self<span class="token punctuation">.</span>data<span class="token punctuation">)</span>    x <span class="token operator">=</span> MyList<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>len<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 3</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>如果自定义的类内没有定义<code>__bool__</code>方法，而且又把该类的对象当作条件去做判断时，该对象就会尝试调用<code>__len__</code>方法，在<code>__len__</code>被定义的情况下，如果返回长度为0则认为False，否则认为True。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">MyList</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> data<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>data <span class="token operator">=</span> data    <span class="token keyword">def</span> <span class="token function">__len__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> len<span class="token punctuation">(</span>self<span class="token punctuation">.</span>data<span class="token punctuation">)</span>    x <span class="token operator">=</span> MyList<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">if</span> x<span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Hello"</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># Hello</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>该特性和所有Python内置的容器是一样的。比如下面的代码：</p><pre class="line-numbers language-python"><code class="language-python">x <span class="token operator">=</span> list<span class="token punctuation">(</span><span class="token punctuation">)</span>d <span class="token operator">=</span> dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">if</span> x <span class="token operator">and</span> d<span class="token punctuation">:</span>    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><h3 id="getitem-、-setitem-和-delitem"><a href="#getitem-、-setitem-和-delitem" class="headerlink" title="__ getitem__ 、 __ setitem __ 和 __ delitem__"></a>__ getitem__ 、 __ setitem __ 和 __ delitem__</h3><p>这三个方法都是在描述对象使用<code>[]</code>时具体的行为功能。</p><p><code>__getitem__</code>：对象使用<code>[]</code>去读取数据时会调用该方法。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">MyList</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> data<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>data <span class="token operator">=</span> data    <span class="token keyword">def</span> <span class="token function">__getitem__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> index<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>data<span class="token punctuation">[</span>index<span class="token punctuation">]</span>    x <span class="token operator">=</span> MyList<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>x<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 2</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><code>__setitem__</code>：对象使用<code>[]</code>去赋值数据时会调用该方法。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">MyList</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> data<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>data <span class="token operator">=</span> data    <span class="token keyword">def</span> <span class="token function">__getitem__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> index<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>data<span class="token punctuation">[</span>index<span class="token punctuation">]</span>            <span class="token keyword">def</span> <span class="token function">__setitem__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> index<span class="token punctuation">,</span> value<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>data<span class="token punctuation">[</span>index<span class="token punctuation">]</span> <span class="token operator">=</span> value    x <span class="token operator">=</span> MyList<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>x<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">10</span><span class="token keyword">print</span><span class="token punctuation">(</span>x<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 10</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><code>__delitem__</code>：对象使用<code>[]</code>去删除数据时会调用该方法：即被关键字<code>del</code>触发。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">MyList</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> data<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>data <span class="token operator">=</span> data    <span class="token keyword">def</span> <span class="token function">__getitem__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> index<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>data<span class="token punctuation">[</span>index<span class="token punctuation">]</span>            <span class="token keyword">def</span> <span class="token function">__delitem__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> index<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>data <span class="token operator">=</span> self<span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">:</span>index<span class="token punctuation">]</span> <span class="token operator">+</span> self<span class="token punctuation">.</span>data<span class="token punctuation">[</span>index<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span>    x <span class="token operator">=</span> MyList<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>x<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 2</span><span class="token keyword">del</span> x<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token keyword">print</span><span class="token punctuation">(</span>x<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 3</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="reversed"><a href="#reversed" class="headerlink" title="__ reversed__"></a>__ reversed__</h3><p><code>__reversed__</code>：将对象（容器）里的数据翻转，会被Python内置的<code>reversed()</code>函数调用。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">MyList</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> data<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>data <span class="token operator">=</span> data    <span class="token keyword">def</span> <span class="token function">__reversed__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> MyList<span class="token punctuation">(</span>self<span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    x <span class="token operator">=</span> MyList<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>reversed<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">.</span>data<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># [3,2,1]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="contains"><a href="#contains" class="headerlink" title="__ contains__"></a>__ contains__</h3><p><code>__contains__</code>：描述对象在使用<code>in</code>操作时的功能行为，即对象在使用<code>in</code>会调用该方法。</p><p>如下代码所示，自定义一个列表容器，这里使用Python内置的list的<code>__contains__</code>实现：<code>item in self.data</code>。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">MyList</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> data<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>data <span class="token operator">=</span> data    <span class="token keyword">def</span> <span class="token function">__contains__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> item<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> item <span class="token keyword">in</span> self<span class="token punctuation">.</span>data   x <span class="token operator">=</span> MyList<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token number">2</span> <span class="token keyword">in</span> x<span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># True</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token number">5</span> <span class="token keyword">in</span> x<span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># False</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="iter"><a href="#iter" class="headerlink" title="__ iter__"></a>__ iter__</h3><p><code>__iter__</code>：返回该对象（容器）的一个迭代器，会被Python内置的<code>iter()</code>函数调用。</p><p>如下代码所示，自定义一个列表容器，这里使用Python内置的list的<code>__iter__</code>实现：<code>iter(self.data)</code>。注意：在使用for循环时，Python会隐性调用<code>iter()</code>函数，所以<code>for i in x</code>其实是<code>for i in iter(x)</code>。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">MyList</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> data<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>data <span class="token operator">=</span> data    <span class="token keyword">def</span> <span class="token function">__iter__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> iter<span class="token punctuation">(</span>self<span class="token punctuation">.</span>data<span class="token punctuation">)</span>  x <span class="token operator">=</span> MyList<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">for</span> i <span class="token keyword">in</span> x<span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="上下文-enter-和-exit"><a href="#上下文-enter-和-exit" class="headerlink" title="上下文__ enter__ 和__ exit__"></a>上下文__ enter__ 和__ exit__</h3><p>平时的代码<code>with open(xxxx) as f</code>中，<code>with</code>后面的部分就是上下文，要想定义一个上下文，需要定义两个魔法方法：<code>__enter__</code>和<code>__exit__</code>。</p><p><code>__enter__</code>：与大于运算<code>__gt__</code>方法类似，greater than  or equal to</p><p><code>__exit__</code>：与小于运算<code>__lt__</code>方法类似，less than  or equal to</p><p>如下的代码，自定义一个计时器，执行代码<code>with Timer():</code>，这时会显示花费的时间。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> time<span class="token keyword">class</span> <span class="token class-name">Timer</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__enter__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>start <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">__exit__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> exc_type<span class="token punctuation">,</span> exc_value<span class="token punctuation">,</span> traceback<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">"Time: {time.time() - self.start}"</span><span class="token punctuation">)</span><span class="token keyword">with</span> Timer<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    x <span class="token operator">=</span> <span class="token number">1000</span><span class="token operator">*</span><span class="token number">10</span><span class="token comment" spellcheck="true"># 执行</span><span class="token comment" spellcheck="true"># Time: 1.4342545363673e-06</span><span class="token keyword">with</span> Timer<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">as</span> t<span class="token punctuation">:</span>    x <span class="token operator">=</span> <span class="token number">1000</span><span class="token operator">*</span><span class="token number">10</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>一般的代码是<code>with open() as f</code>，如同下面的代码，执行代码<code>with Timer() as t:</code>，这个<code>as t</code>就是将<code>__enter__</code>的返回值保存在t里，一般常见的操作是将对象本身<code>self</code>返回。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Timer</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__enter__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>start <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> self    <span class="token keyword">def</span> <span class="token function">__exit__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> exc_type<span class="token punctuation">,</span> exc_value<span class="token punctuation">,</span> traceback<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">"Time: {time.time() - self.start}"</span><span class="token punctuation">)</span><span class="token keyword">with</span> Timer<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">as</span> t<span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>t<span class="token punctuation">.</span>start<span class="token punctuation">)</span>    x <span class="token operator">=</span> <span class="token number">1000</span><span class="token operator">*</span><span class="token number">10</span><span class="token comment" spellcheck="true"># 执行</span><span class="token comment" spellcheck="true"># 1231423426.45353</span><span class="token comment" spellcheck="true"># Time: 1.4342545363673e-05</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><code>__exit__</code>方法里的几个参数，都是和异常相关的，比如下面的代码，值的注意的是，程序依然得出了花费的时间。即即使代码抛出了异常，<code>__exit__</code>方法内的代码依然被执行了，比如在文件操作中，常常使用<code>with open() as f</code>的代码，而不是<code>f = open()</code>，就可以防止忘记关闭文件，同时就算程序报错，也可以成功把文件关闭</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Timer</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__enter__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>start <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> self    <span class="token keyword">def</span> <span class="token function">__exit__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> exc_type<span class="token punctuation">,</span> exc_value<span class="token punctuation">,</span> traceback<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span>exc_type<span class="token punctuation">,</span> exc_value<span class="token punctuation">,</span> traceback<span class="token punctuation">)</span>        <span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">"Time: {time.time() - self.start}"</span><span class="token punctuation">)</span><span class="token keyword">with</span> Timer<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">as</span> t<span class="token punctuation">:</span>    x <span class="token operator">=</span> <span class="token number">1000</span> <span class="token operator">/</span> <span class="token number">0</span><span class="token comment" spellcheck="true"># 执行</span><span class="token comment" spellcheck="true"># &lt;class 'ZeroDivisionError'> division by zero &lt;traceback object at 0x7f6961387800></span><span class="token comment" spellcheck="true"># Time:6.103745625e-05</span><span class="token comment" spellcheck="true"># Traceback (most recent call last):</span><span class="token comment" spellcheck="true">#   File "&lt;stdin>", line 2, in &lt;module></span><span class="token comment" spellcheck="true"># ZeroDivisionError: division by zero</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> 编程语言 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 基础知识 </tag>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Python的魔法方法(上)</title>
      <link href="/2023/10/15/python-zhi-shi/python-mo-fang-fang-fa-shang/"/>
      <url>/2023/10/15/python-zhi-shi/python-mo-fang-fang-fa-shang/</url>
      
        <content type="html"><![CDATA[<h1 id="Python的魔法方法（上）"><a href="#Python的魔法方法（上）" class="headerlink" title="Python的魔法方法（上）"></a>Python的魔法方法（上）</h1><p>本文是对B站UP主“码农高天”的《Python的魔法方法》系列视频的总结和整理，搭配视频食用本文效果更佳。</p><p>魔法方法：Python提供的让用户客制化一个类的方式，定义在类内的一些特殊方法，这些方法的名称前后会有两个下划线。</p><h2 id="基础方法"><a href="#基础方法" class="headerlink" title="基础方法"></a>基础方法</h2><h3 id="init-和-new"><a href="#init-和-new" class="headerlink" title="__ init__ 和__ new__"></a>__ init__ 和__ new__</h3><p>这两个魔法方法能够<strong>改变一个类实例化对象时的行为</strong>。</p><p><code>__new__</code>：是描述从一个class建立一个object的过程</p><p><code>__init__</code>：是描述当存在一个object后，对其进行初始化的过程</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">A</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__new__</span><span class="token punctuation">(</span>cls<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"__new__"</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> super<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__new__<span class="token punctuation">(</span>cls<span class="token punctuation">)</span>        <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>x <span class="token operator">=</span> x        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"__init__"</span><span class="token punctuation">)</span>        o <span class="token operator">=</span> A<span class="token punctuation">(</span>xxx<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 等价于</span><span class="token comment" spellcheck="true"># 1. obj = __new__(A, xxx)</span><span class="token comment" spellcheck="true"># 2. __init__(obj, xxx)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>如果在建立object的过程中传入了若干参数，则这些参数既会被传入到<code>__new__</code>中，也会被传入到<code>__ini__</code>中。<code>__new__</code>因为是建立object，所以是有返回值的。</p><h3 id="del"><a href="#del" class="headerlink" title="__ del__"></a>__ del__</h3><p><code>__del__</code>可以粗略的认为是一个析构函数，是描述一个object被释放的过程。但是由于Python的对象释放过程较为复杂，因此该方法不可控。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">A</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__del__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"__del__"</span><span class="token punctuation">)</span>o <span class="token operator">=</span> A<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p><strong>注意</strong>：这里的<code>__del__</code>和关键字<code>del</code>没有关系，<code>del o</code>并不一定会触发<code>__del__</code>方法，只是让对象的引用-1。</p><h3 id="repr-str-和-format"><a href="#repr-str-和-format" class="headerlink" title="__ repr__ , __ str__ 和__ format__"></a>__ repr__ , __ str__ 和__ format__</h3><p><code>__repr__</code>和<code>__str__</code>这两个方法的功能是相似的，都是返回一个object的字符串表示，这两个方法主要是语义的不同。</p><p><code>__repr</code>：representation，一般要有更详细的信息，可以通过<code>repr()</code>内置函数调用该方法。</p><p><code>__str__</code>：注重可读性，可以通过<code>str()</code>内置函数调用该方法，<code>print</code>内部就是使用了<code>str()</code>方法。</p><p><code>__format__</code>：使用某种格式打印object时，会调用该方法。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"{}"</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span><span class="token number">15</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 10进制</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"{:b}"</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span><span class="token number">15</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 2进制</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"{:x}"</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span><span class="token number">15</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 16进制</span><span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">"{15}"</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 10进制</span><span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">"{15:b}"</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 2进制</span><span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">"{15:x}"</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 16进制</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">A</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__format__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> spec<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">if</span> spec <span class="token operator">==</span> <span class="token string">"x"</span><span class="token punctuation">:</span>            <span class="token keyword">return</span> <span class="token string">"0xA"</span>        <span class="token keyword">return</span> <span class="token string">"&lt;A>"</span><span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">"{A()}"</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># &lt;A></span><span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">"{A():x}"</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 0xA</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="bytes"><a href="#bytes" class="headerlink" title="__ bytes__"></a>__ bytes__</h3><p><code>__bytes__</code>：通过class去建立bytes时的行为，客制化object的bytes表示。通过内置方法<code>bytes()</code>调用该魔法方法。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">A</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__bytes__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"__bytes__"</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> bytes<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>bytes<span class="token punctuation">(</span>A<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># b'\x00\x01'</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="比较方法"><a href="#比较方法" class="headerlink" title="比较方法"></a>比较方法</h2><h3 id="等于-eq-和不等于-ne"><a href="#等于-eq-和不等于-ne" class="headerlink" title="等于 __ eq__ 和不等于__ ne__"></a>等于 __ eq__ 和不等于__ ne__</h3><p><code>__eq__</code>：描述两个object进行比较时的过程，判断两个object是否相等。</p><p><code>__ne__</code>：描述两个object进行比较时的过程，判断两个object是否不相等。</p><p>上述两个方法，等于和不等于，是有默认实现的，如果没有自定义的等于和不等于，会使用<code>is</code>进行比较。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Date</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> year<span class="token punctuation">,</span> month<span class="token punctuation">,</span> day<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>year <span class="token operator">=</span> year        self<span class="token punctuation">.</span>month <span class="token operator">=</span> month        self<span class="token punctuation">.</span>day <span class="token operator">=</span> day    <span class="token keyword">def</span> <span class="token function">__eq__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> other<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> <span class="token punctuation">(</span>self<span class="token punctuation">.</span>year <span class="token operator">==</span> other<span class="token punctuation">.</span>year <span class="token operator">and</span> self<span class="token punctuation">.</span>month <span class="token operator">==</span> other<span class="token punctuation">.</span>month                 <span class="token operator">and</span> self<span class="token punctuation">.</span>day <span class="token operator">=</span> other<span class="token punctuation">.</span>day<span class="token punctuation">)</span>x <span class="token operator">=</span> Date<span class="token punctuation">(</span><span class="token number">2023</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">24</span><span class="token punctuation">)</span>y <span class="token operator">=</span> Date<span class="token punctuation">(</span><span class="token number">2023</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">24</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>x <span class="token operator">==</span> y<span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># True</span>z <span class="token operator">=</span> Date<span class="token punctuation">(</span><span class="token number">2023</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">14</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>x <span class="token operator">!=</span> z<span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># True</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>注意</strong>：当没有定义不等于的方法时，使用不等于运算符Python会对<code>__eq__</code>等于方法进行取反，所以通常情况下定义<code>__eq__</code>方法足够处理等于和不等于的运算了。当然也可以定义不等于的魔法方法<code>__ne__</code>。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Date</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> year<span class="token punctuation">,</span> month<span class="token punctuation">,</span> day<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>year <span class="token operator">=</span> year        self<span class="token punctuation">.</span>month <span class="token operator">=</span> month        self<span class="token punctuation">.</span>day <span class="token operator">=</span> day    <span class="token keyword">def</span> <span class="token function">__eq__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> other<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"__eq__"</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> <span class="token punctuation">(</span>self<span class="token punctuation">.</span>year <span class="token operator">==</span> other<span class="token punctuation">.</span>year <span class="token operator">and</span> self<span class="token punctuation">.</span>month <span class="token operator">==</span> other<span class="token punctuation">.</span>month                 <span class="token operator">and</span> self<span class="token punctuation">.</span>day <span class="token operator">==</span> other<span class="token punctuation">.</span>day<span class="token punctuation">)</span>        <span class="token keyword">def</span> <span class="token function">__ne__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> other<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"__ne__"</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> <span class="token punctuation">(</span>self<span class="token punctuation">.</span>year <span class="token operator">!=</span> other<span class="token punctuation">.</span>year <span class="token operator">and</span> self<span class="token punctuation">.</span>month <span class="token operator">!=</span> other<span class="token punctuation">.</span>month                 <span class="token operator">and</span> self<span class="token punctuation">.</span>day <span class="token operator">!=</span> other<span class="token punctuation">.</span>day<span class="token punctuation">)</span>    x <span class="token operator">=</span> Date<span class="token punctuation">(</span><span class="token number">2023</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">24</span><span class="token punctuation">)</span>y <span class="token operator">=</span> Date<span class="token punctuation">(</span><span class="token number">2023</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">24</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>x <span class="token operator">==</span> y<span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># __eq__</span><span class="token comment" spellcheck="true"># True</span>z <span class="token operator">=</span> Date<span class="token punctuation">(</span><span class="token number">2023</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">14</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>x <span class="token operator">!=</span> z<span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># __ne__</span><span class="token comment" spellcheck="true"># True</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="大于-gt-和小于-lt"><a href="#大于-gt-和小于-lt" class="headerlink" title="大于 __ gt__ 和小于__ lt__"></a>大于 __ gt__ 和小于__ lt__</h3><p><code>__gt__</code>：描述两个object进行比较时的过程，判断一个object是否大于另一个object。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Date</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> year<span class="token punctuation">,</span> month<span class="token punctuation">,</span> day<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>year <span class="token operator">=</span> year        self<span class="token punctuation">.</span>month <span class="token operator">=</span> month        self<span class="token punctuation">.</span>day <span class="token operator">=</span> day    <span class="token keyword">def</span> <span class="token function">__gt__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> other<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">if</span> self<span class="token punctuation">.</span>year <span class="token operator">></span> other<span class="token punctuation">.</span>year<span class="token punctuation">:</span>            <span class="token keyword">return</span> <span class="token boolean">True</span>           <span class="token keyword">if</span> self<span class="token punctuation">.</span>year <span class="token operator">==</span> other<span class="token punctuation">.</span>year<span class="token punctuation">:</span>            <span class="token keyword">if</span> self<span class="token punctuation">.</span>month <span class="token operator">></span> other<span class="token punctuation">.</span>month<span class="token punctuation">:</span>                <span class="token keyword">return</span> <span class="token boolean">True</span>            <span class="token keyword">if</span> self<span class="token punctuation">.</span>month <span class="token operator">==</span> other<span class="token punctuation">.</span>month<span class="token punctuation">:</span>                <span class="token keyword">return</span> self<span class="token punctuation">.</span>day <span class="token operator">></span> other<span class="token punctuation">.</span>day            x <span class="token operator">=</span> Date<span class="token punctuation">(</span><span class="token number">2023</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">22</span><span class="token punctuation">)</span>y <span class="token operator">=</span> Date<span class="token punctuation">(</span><span class="token number">2023</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">24</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>x <span class="token operator">></span> y<span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># False</span><span class="token keyword">print</span><span class="token punctuation">(</span>x <span class="token operator">&lt;</span> y<span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># True</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>当调用<code>&gt;</code>大于运算符时，即 <code>x &gt; y</code> 可以看作是<code>x.__gt__(y)</code>的运算。<br><strong>注意</strong>：当没有实现小于运算却调用<code>&lt;</code>小于运算符时，也可以正常返回结果，是因为<code>x &lt; y</code>就对应<code>y &gt; x</code>，所以可以认为进行了<code>y.__gt__(x)</code>的运算。</p><p><code>__lt__</code>：描述两个object进行比较时的过程，判断一个object是否小于另一个object。当一个类里同时实现了<code>__gt__</code>和<code>__lt__</code>时，使用<code>&lt;</code>运算符会优先调用<code>__lt__</code>。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Date</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> year<span class="token punctuation">,</span> month<span class="token punctuation">,</span> day<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>year <span class="token operator">=</span> year        self<span class="token punctuation">.</span>month <span class="token operator">=</span> month        self<span class="token punctuation">.</span>day <span class="token operator">=</span> day    <span class="token keyword">def</span> <span class="token function">__gt__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> other<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"__gt__"</span><span class="token punctuation">)</span>        <span class="token keyword">if</span> self<span class="token punctuation">.</span>year <span class="token operator">></span> other<span class="token punctuation">.</span>year<span class="token punctuation">:</span>            <span class="token keyword">return</span> <span class="token boolean">True</span>           <span class="token keyword">if</span> self<span class="token punctuation">.</span>year <span class="token operator">==</span> other<span class="token punctuation">.</span>year<span class="token punctuation">:</span>            <span class="token keyword">if</span> self<span class="token punctuation">.</span>month <span class="token operator">></span> other<span class="token punctuation">.</span>month<span class="token punctuation">:</span>                <span class="token keyword">return</span> <span class="token boolean">True</span>            <span class="token keyword">if</span> self<span class="token punctuation">.</span>month <span class="token operator">==</span> other<span class="token punctuation">.</span>month<span class="token punctuation">:</span>                <span class="token keyword">return</span> self<span class="token punctuation">.</span>day <span class="token operator">></span> other<span class="token punctuation">.</span>day    <span class="token keyword">def</span> <span class="token function">__lt__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> other<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"__lt__"</span><span class="token punctuation">)</span>        <span class="token keyword">if</span> self<span class="token punctuation">.</span>year <span class="token operator">&lt;</span> other<span class="token punctuation">.</span>year<span class="token punctuation">:</span>            <span class="token keyword">return</span> <span class="token boolean">True</span>           <span class="token keyword">if</span> self<span class="token punctuation">.</span>year <span class="token operator">==</span> other<span class="token punctuation">.</span>year<span class="token punctuation">:</span>            <span class="token keyword">if</span> self<span class="token punctuation">.</span>month <span class="token operator">&lt;</span> other<span class="token punctuation">.</span>month<span class="token punctuation">:</span>                <span class="token keyword">return</span> <span class="token boolean">True</span>            <span class="token keyword">if</span> self<span class="token punctuation">.</span>month <span class="token operator">==</span> other<span class="token punctuation">.</span>month<span class="token punctuation">:</span>                <span class="token keyword">return</span> self<span class="token punctuation">.</span>day <span class="token operator">&lt;</span> other<span class="token punctuation">.</span>day  x <span class="token operator">=</span> Date<span class="token punctuation">(</span><span class="token number">2023</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">22</span><span class="token punctuation">)</span>y <span class="token operator">=</span> Date<span class="token punctuation">(</span><span class="token number">2023</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">24</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>x <span class="token operator">&lt;</span> y<span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># __lt__</span><span class="token comment" spellcheck="true"># True</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>因为<code>x &lt; y</code>就对应<code>y &gt; x</code>，<code>x &lt; y</code>既可以通过<code>x.__lt__(y)</code>，也可以通过<code>y.__gt__(x)</code>，那么使用<code>&gt;</code>或<code>&lt;</code>到底调用哪个魔法方法呢？</p><p>调用原则：</p><ul><li>当x和y是同一个类的不同object，则优先使用运算符左侧的比较方法，当左侧object没有定义时，才会去使用右侧object的比较方法（不限于大于小于，还有等于不等于）。</li><li>如果y是x的类的子类object，则优先使用y的<strong>比较方法</strong>（不限于大于小于，还有等于不等于）。</li></ul><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">NewDate</span><span class="token punctuation">(</span>Date<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">pass</span>x <span class="token operator">=</span> Date<span class="token punctuation">(</span><span class="token number">2023</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">22</span><span class="token punctuation">)</span>y <span class="token operator">=</span> NewDate<span class="token punctuation">(</span><span class="token number">2023</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">24</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>x <span class="token operator">&lt;</span> y<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># __gt__</span><span class="token comment" spellcheck="true"># True</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="大于等于-ge-和小于等于-le"><a href="#大于等于-ge-和小于等于-le" class="headerlink" title="大于等于 __ ge__ 和小于等于__ le__"></a>大于等于 __ ge__ 和小于等于__ le__</h3><p><code>__ge__</code>：与大于运算<code>__gt__</code>方法类似，greater than  or equal to</p><p><code>__le__</code>：与小于运算<code>__lt__</code>方法类似，less than  or equal to</p><h3 id="hash"><a href="#hash" class="headerlink" title="__ hash__"></a>__ hash__</h3><p><code>__hash__</code>：求某个数据结构（自定义）的哈希值，一个自定义的数据结构，是有其默认的hash算法的，使用<code>hash()</code>可以直接拿到其哈希值。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Date</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> year<span class="token punctuation">,</span> month<span class="token punctuation">,</span> day<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>year <span class="token operator">=</span> year        self<span class="token punctuation">.</span>month <span class="token operator">=</span> month        self<span class="token punctuation">.</span>day <span class="token operator">=</span> day        x <span class="token operator">=</span> Date<span class="token punctuation">(</span><span class="token number">2023</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span><span class="token number">22</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>hash<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 8771107107837</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>如果要自定义hash算法，则一般也要定义<code>__eq__</code>方法，定义<code>__hash__</code>的要求如下：</p><ol><li>返回值必须是整数</li><li>对于两个相等的object，其哈希值必须相同</li></ol><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Date</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> year<span class="token punctuation">,</span> month<span class="token punctuation">,</span> day<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>year <span class="token operator">=</span> year        self<span class="token punctuation">.</span>month <span class="token operator">=</span> month        self<span class="token punctuation">.</span>day <span class="token operator">=</span> day    <span class="token keyword">def</span> <span class="token function">__eq__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> other<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> <span class="token punctuation">(</span>self<span class="token punctuation">.</span>year <span class="token operator">==</span> other<span class="token punctuation">.</span>year <span class="token operator">and</span> self<span class="token punctuation">.</span>month <span class="token operator">==</span> other<span class="token punctuation">.</span>month         <span class="token operator">and</span> self<span class="token punctuation">.</span>day <span class="token operator">==</span> other<span class="token punctuation">.</span>day<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">__hash</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> <span class="token number">2</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="bool"><a href="#bool" class="headerlink" title="__ bool___"></a>__ bool___</h3><p><code>__bool__</code>：描述object在条件判断语句中的行为。所有的object出现在条件判断语句中时，都会被判定为True，如果想要改变条件判断的结果，可以使用该方法。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Date</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> year<span class="token punctuation">,</span> month<span class="token punctuation">,</span> day<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>year <span class="token operator">=</span> year        self<span class="token punctuation">.</span>month <span class="token operator">=</span> month        self<span class="token punctuation">.</span>day <span class="token operator">=</span> daya <span class="token operator">=</span> Date<span class="token punctuation">(</span><span class="token number">2023</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">23</span><span class="token punctuation">)</span><span class="token keyword">if</span> a<span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"hello"</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># hello</span><span class="token keyword">class</span> <span class="token class-name">Date</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> year<span class="token punctuation">,</span> month<span class="token punctuation">,</span> day<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>year <span class="token operator">=</span> year        self<span class="token punctuation">.</span>month <span class="token operator">=</span> month        self<span class="token punctuation">.</span>day <span class="token operator">=</span> day    <span class="token keyword">def</span> <span class="token function">__bool__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"__bool__"</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> <span class="token boolean">False</span>a <span class="token operator">=</span> Date<span class="token punctuation">(</span><span class="token number">2023</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">23</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>bool<span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 当把object转变为bool时也会调用该方法</span><span class="token keyword">if</span> a<span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"hello"</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># __bool__</span><span class="token comment" spellcheck="true"># False</span><span class="token comment" spellcheck="true"># __bool__</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="对象属性相关的方法"><a href="#对象属性相关的方法" class="headerlink" title="对象属性相关的方法"></a>对象属性相关的方法</h2><h3 id="getattr-和-getattribute"><a href="#getattr-和-getattribute" class="headerlink" title="__ getattr__ 和 __ getattribute__"></a>__ getattr__ 和 __ getattribute__</h3><p><code>__getattr__</code>：尝试访问object的属性时，描述该属性不存在时object的行为。默认情况下如果访问一个object里不存在的属性时，会抛出<code>AttributeError</code>。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">A</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>exist <span class="token operator">=</span> <span class="token string">"abc"</span>    <span class="token keyword">def</span> <span class="token function">__getattr__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> name<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">"getting {name}"</span><span class="token punctuation">)</span>o <span class="token operator">=</span> A<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>o<span class="token punctuation">.</span>exist<span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># abc</span><span class="token keyword">print</span><span class="token punctuation">(</span>o<span class="token punctuation">.</span>test<span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># getting test</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>注意</strong>：访问的该属性，会以字符串的形式传入到<code>__getattr__</code>里。只有在读取一个不存在的属性时才会调用该魔法方法。</p><p><code>__getattribute__</code>：尝试访问object的属性时，不论该属性是否存在，都会调用该方法。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">A</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>exist <span class="token operator">=</span> <span class="token string">"abc"</span>    <span class="token keyword">def</span> <span class="token function">__getattribute__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> name<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">"getting {name}"</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> Noneo <span class="token operator">=</span> A<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>o<span class="token punctuation">.</span>exist<span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># getting exist</span><span class="token comment" spellcheck="true"># None</span><span class="token keyword">print</span><span class="token punctuation">(</span>o<span class="token punctuation">.</span>test<span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># getting test</span><span class="token comment" spellcheck="true"># None</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="setattr-和-delattr"><a href="#setattr-和-delattr" class="headerlink" title="__ setattr__ 和 __ delattr__"></a>__ setattr__ 和 __ delattr__</h3><p><code>__setattr__</code>：尝试写入object的属性时，描述该过程中object的行为。该方法有两个参数：一是属性名，二是属性值。一般情况下调用<code>super().__setattr__()</code>执行该方法的默认行为。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">A</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>data <span class="token operator">=</span> <span class="token string">"abc"</span>        self<span class="token punctuation">.</span>counter <span class="token operator">=</span> <span class="token number">0</span>    <span class="token keyword">def</span> <span class="token function">__setatter__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> name<span class="token punctuation">,</span> val<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">"set{name}"</span><span class="token punctuation">)</span>        super<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__setattr__<span class="token punctuation">(</span>name<span class="token punctuation">,</span> val<span class="token punctuation">)</span>o <span class="token operator">=</span> A<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>o<span class="token punctuation">.</span>data<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># set data</span><span class="token comment" spellcheck="true"># set counter</span><span class="token comment" spellcheck="true"># abc</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><code>__delattr__</code>：与<code>__del__</code>不同，在一个object正常产生和消亡的过程中，不会调用<code>__delattr__</code>方法，而在尝试删除一个object的属性时才会调用。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">A</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>data <span class="token operator">=</span> <span class="token string">"abc"</span>    <span class="token keyword">def</span> <span class="token function">__delatter__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> name<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">"del{name}"</span><span class="token punctuation">)</span>        super<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__delattr<span class="token punctuation">(</span>name<span class="token punctuation">)</span>        o <span class="token operator">=</span> A<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">del</span> o<span class="token punctuation">.</span>data <span class="token comment" spellcheck="true"># del data</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="dir"><a href="#dir" class="headerlink" title="__ dir__"></a>__ dir__</h3><p><code>__dir__</code>：列出object的所有属性名和方法名，Python规定该方法必须返回一个sequence（如列表list）。通过内置函数<code>dir()</code>调用该魔法方法。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span>dir<span class="token punctuation">(</span><span class="token punctuation">)</span>   <span class="token comment" spellcheck="true">#  获得当前模块的属性列表</span><span class="token punctuation">[</span><span class="token string">'__builtins__'</span><span class="token punctuation">,</span> <span class="token string">'__doc__'</span><span class="token punctuation">,</span> <span class="token string">'__name__'</span><span class="token punctuation">,</span> <span class="token string">'__package__'</span><span class="token punctuation">,</span> <span class="token string">'arr'</span><span class="token punctuation">,</span> <span class="token string">'myslice'</span><span class="token punctuation">]</span>a <span class="token operator">=</span> list<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>dir<span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 查看列表的方法</span><span class="token punctuation">[</span><span class="token string">'__add__'</span><span class="token punctuation">,</span> <span class="token string">'__class__'</span><span class="token punctuation">,</span> <span class="token string">'__contains__'</span><span class="token punctuation">,</span> <span class="token string">'__delattr__'</span><span class="token punctuation">,</span> <span class="token string">'__delitem__'</span><span class="token punctuation">,</span> <span class="token string">'__delslice__'</span><span class="token punctuation">,</span> <span class="token string">'__doc__'</span><span class="token punctuation">,</span> <span class="token string">'__eq__'</span><span class="token punctuation">,</span> <span class="token string">'__format__'</span><span class="token punctuation">,</span> <span class="token string">'__ge__'</span><span class="token punctuation">,</span> <span class="token string">'__getattribute__'</span><span class="token punctuation">,</span> <span class="token string">'__getitem__'</span><span class="token punctuation">,</span> <span class="token string">'__getslice__'</span><span class="token punctuation">,</span> <span class="token string">'__gt__'</span><span class="token punctuation">,</span> <span class="token string">'__hash__'</span><span class="token punctuation">,</span> <span class="token string">'__iadd__'</span><span class="token punctuation">,</span> <span class="token string">'__imul__'</span><span class="token punctuation">,</span> <span class="token string">'__init__'</span><span class="token punctuation">,</span> <span class="token string">'__iter__'</span><span class="token punctuation">,</span> <span class="token string">'__le__'</span><span class="token punctuation">,</span> <span class="token string">'__len__'</span><span class="token punctuation">,</span> <span class="token string">'__lt__'</span><span class="token punctuation">,</span> <span class="token string">'__mul__'</span><span class="token punctuation">,</span> <span class="token string">'__ne__'</span><span class="token punctuation">,</span> <span class="token string">'__new__'</span><span class="token punctuation">,</span> <span class="token string">'__reduce__'</span><span class="token punctuation">,</span> <span class="token string">'__reduce_ex__'</span><span class="token punctuation">,</span> <span class="token string">'__repr__'</span><span class="token punctuation">,</span> <span class="token string">'__reversed__'</span><span class="token punctuation">,</span> <span class="token string">'__rmul__'</span><span class="token punctuation">,</span> <span class="token string">'__setattr__'</span><span class="token punctuation">,</span> <span class="token string">'__setitem__'</span><span class="token punctuation">,</span> <span class="token string">'__setslice__'</span><span class="token punctuation">,</span> <span class="token string">'__sizeof__'</span><span class="token punctuation">,</span> <span class="token string">'__str__'</span><span class="token punctuation">,</span> <span class="token string">'__subclasshook__'</span><span class="token punctuation">,</span> <span class="token string">'append'</span><span class="token punctuation">,</span> <span class="token string">'count'</span><span class="token punctuation">,</span> <span class="token string">'extend'</span><span class="token punctuation">,</span> <span class="token string">'index'</span><span class="token punctuation">,</span> <span class="token string">'insert'</span><span class="token punctuation">,</span> <span class="token string">'pop'</span><span class="token punctuation">,</span> <span class="token string">'remove'</span><span class="token punctuation">,</span> <span class="token string">'reverse'</span><span class="token punctuation">,</span> <span class="token string">'sort'</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">A</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>data <span class="token operator">=</span> <span class="token string">"abc"</span>    <span class="token keyword">def</span> <span class="token function">__dir__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> name<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    o <span class="token operator">=</span> A<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>dir<span class="token punctuation">(</span>o<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># []</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="描述器"><a href="#描述器" class="headerlink" title="描述器"></a>描述器</h2><p>描述器的定义：在Python代码层面，如果一个类的内部定义了<code>__get__()</code>、<code>__set__()</code>或<code>__delete__()</code>这三个方法中的其中一个，则这个类被称为描述器。</p><p>如下代码是描述器最简单的用法，其中类<code>Name</code>就是一个描述器，内部定义了一个<code>__get__()</code>方法，该方的两个参数<code>obj</code>和<code>objtype</code>是必须的。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Name</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__get__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> obj<span class="token punctuation">,</span> objtype<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> <span class="token string">"Peter"</span>    <span class="token keyword">class</span> <span class="token class-name">A</span><span class="token punctuation">:</span>    name <span class="token operator">=</span> Name<span class="token punctuation">(</span><span class="token punctuation">)</span>o <span class="token operator">=</span> A<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>o<span class="token punctuation">.</span>name<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># Peter</span><span class="token keyword">print</span><span class="token punctuation">(</span>A<span class="token punctuation">.</span>name<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># Peter</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>从上面代码的运行结果可以推断出，调用<code>o.name</code>实际上是执行类<code>Name</code>的<code>__get__</code>方法，同样调用<code>A.name</code>也是执行类<code>Name</code>的<code>__get__</code>方法。这里的执行原理和Python内部关于描述器的机制有关，暂且不展开了。</p><h3 id="get"><a href="#get" class="headerlink" title="__ get __"></a>__ get __</h3><p>上述的代码中，描述器方法的<code>self</code>参数是描述器对象本身，也就是name，<code>obj</code>是对应类A的对象，也就是o，<code>objtype</code>是对象o的类型。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Name</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__get__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> obj<span class="token punctuation">,</span> objtype<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span>obj<span class="token punctuation">,</span> objtype<span class="token punctuation">)</span>        <span class="token keyword">return</span> <span class="token string">"Peter"</span>    <span class="token keyword">class</span> <span class="token class-name">A</span><span class="token punctuation">:</span>    name <span class="token operator">=</span> Name<span class="token punctuation">(</span><span class="token punctuation">)</span>o <span class="token operator">=</span> A<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>o<span class="token punctuation">.</span>name<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># &lt;__main__.A object at 0x7f87ab86a400> &lt;class '__main__.A'></span><span class="token comment" spellcheck="true"># Peter</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="set"><a href="#set" class="headerlink" title="__ set __"></a>__ set __</h3><p>通过<code>__get__</code>和<code>__set__</code>可以实现一个设置属性和读取属性的功能，与上述<code>__setattr_</code>和<code>__getattr__</code>相同的功能。不过描述器是class级别的(见下面代码的o2)。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">D</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>val <span class="token operator">=</span> <span class="token number">0</span>    <span class="token keyword">def</span> <span class="token function">__get__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> obj<span class="token punctuation">,</span> objtype<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>val    <span class="token keyword">def</span> <span class="token function">__set__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> obj<span class="token punctuation">,</span> value<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>val <span class="token operator">=</span> value<span class="token keyword">class</span> <span class="token class-name">A</span><span class="token punctuation">:</span>    x <span class="token operator">=</span> D<span class="token punctuation">(</span><span class="token punctuation">)</span>    o <span class="token operator">=</span> A<span class="token punctuation">(</span><span class="token punctuation">)</span>o2 <span class="token operator">=</span> A<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>o<span class="token punctuation">.</span>x<span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 0</span>o<span class="token punctuation">.</span>x <span class="token operator">=</span> <span class="token number">1</span><span class="token keyword">print</span><span class="token punctuation">(</span>o<span class="token punctuation">.</span>x<span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 1</span><span class="token keyword">print</span><span class="token punctuation">(</span>o2<span class="token punctuation">.</span>x<span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 1</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="delete"><a href="#delete" class="headerlink" title="__ delete __"></a>__ delete __</h3><p>当调用<code>del o.x</code>时会执行<code>__delete__</code>方法</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">D</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>val <span class="token operator">=</span> <span class="token number">0</span>    <span class="token keyword">def</span> <span class="token function">__get__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> obj<span class="token punctuation">,</span> objtype<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>val    <span class="token keyword">def</span> <span class="token function">__set__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> obj<span class="token punctuation">,</span> value<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>val <span class="token operator">=</span> value    <span class="token keyword">def</span> <span class="token function">__delete__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> obj<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"delete"</span><span class="token punctuation">)</span><span class="token keyword">class</span> <span class="token class-name">A</span><span class="token punctuation">:</span>    x <span class="token operator">=</span> D<span class="token punctuation">(</span><span class="token punctuation">)</span>    o <span class="token operator">=</span> A<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">del</span> o<span class="token punctuation">.</span>x <span class="token comment" spellcheck="true"># delete</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h2><h3 id="slots"><a href="#slots" class="headerlink" title="__ slots __"></a>__ slots __</h3><p><code>__slots__</code>不是一个方法，但是是一个有特殊含义的变量。它规定了当前这个类的对象可以有哪些自定义的属性，是一个类的白名单。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">A</span><span class="token punctuation">:</span>    __slots__ <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"a"</span><span class="token punctuation">,</span> <span class="token string">"b"</span><span class="token punctuation">]</span>o <span class="token operator">=</span> A<span class="token punctuation">(</span><span class="token punctuation">)</span>o<span class="token punctuation">.</span>x <span class="token operator">=</span> <span class="token number">1</span> <span class="token comment" spellcheck="true"># 报错</span>o<span class="token punctuation">.</span>a <span class="token operator">=</span> <span class="token number">1</span> <span class="token comment" spellcheck="true"># 正常</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="迭代器：-iter-和-next"><a href="#迭代器：-iter-和-next" class="headerlink" title="迭代器：__ iter__ 和__ next__"></a>迭代器：__ iter__ 和__ next__</h2><p>迭代器就是重复地做一些事情，可以简单的理解为循环。</p><ul><li>迭代是访问集合元素的一种方式。</li><li>迭代器是一个可以<strong>记住遍历的位置</strong>的对象。</li><li>迭代器对象从集合的第一个元素开始访问，直到所有的元素被访问完结束。<strong>迭代器只能往前不会后退</strong>。</li><li>迭代器有两个基本的方法：iter() 和 next()。</li></ul><p>Python中<strong>实现了__iter__方法的对象是可迭代的，实现了__next__方法的对象是迭代器</strong>。实际上要想让一个迭代器工作，至少要实现__iter__方法和__next__方法。<br>常见的就是我们在使用<code>for</code>语句的时候，python内部其实在<code>for</code>后面的对象上使用了内建函数<code>iter()</code>：</p><pre class="line-numbers language-python"><code class="language-python">a <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token keyword">for</span> i <span class="token keyword">in</span> a<span class="token punctuation">:</span>    do_something<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 其实内部做了如下转换</span><span class="token keyword">for</span> i <span class="token keyword">in</span> iter<span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token punctuation">:</span>    do_something<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>下面引入两个概念：</p><ol><li>Iterable: 有迭代能力的对象。一个类实现了__iter__，那么就认为它有迭代能力，通常此函数<strong>必须</strong>返回一个实现了__next__方法的对象，<strong>如果自己实现了，则可以返回</strong><code>self</code>，当然这个返回值不是必须的；</li><li>Iterator: 迭代器(当然也是Iterable)。同时实现了__iter__和__next__的对象，缺少任何一个都不算是Iterator，比如下面例子中，A()可以是一个Iterable，但是A()和B()都不能算是和Iterator，因为A只实现了__iter__，而B只实现了__next__()。</li></ol><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">B</span><span class="token punctuation">(</span>object<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__next__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">raise</span> StopIteration<span class="token keyword">class</span> <span class="token class-name">A</span><span class="token punctuation">(</span>object<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__iter__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> B<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">from</span> collections<span class="token punctuation">.</span>abc <span class="token keyword">import</span> <span class="token operator">*</span>a <span class="token operator">=</span> A<span class="token punctuation">(</span><span class="token punctuation">)</span>b <span class="token operator">=</span> B<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>isinstance<span class="token punctuation">(</span>a<span class="token punctuation">,</span> Iterable<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># True</span><span class="token keyword">print</span><span class="token punctuation">(</span>isinstance<span class="token punctuation">(</span>a<span class="token punctuation">,</span> Iterator<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># False</span><span class="token keyword">print</span><span class="token punctuation">(</span>isinstance<span class="token punctuation">(</span>b<span class="token punctuation">,</span> Iterable<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># False</span><span class="token keyword">print</span><span class="token punctuation">(</span>isinstance<span class="token punctuation">(</span>b<span class="token punctuation">,</span> Iterator<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># False</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="创建一个迭代器"><a href="#创建一个迭代器" class="headerlink" title="创建一个迭代器"></a>创建一个迭代器</h3><p>把一个类作为一个迭代器使用需要在类中实现两个方法**<strong>iter</strong><strong>与</strong><strong>next</strong><strong>。<br>__iter__方法</strong>返回一个迭代对象<strong>， 这个迭代对象</strong>实现了__next__方法<strong>并</strong>通过StopIteration异常**来标识迭代的完成。<br>__next__方法会返回下一个迭代器对象。就可以通过<code>next()</code>函数访问这个对象的下一个元素了，并且在你不想继续有迭代的情况下抛出一个StopIteration的异常（for语句会捕获这个异常，并且自动结束for）</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">MyRange</span><span class="token punctuation">(</span>object<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> end<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>start <span class="token operator">=</span> <span class="token number">0</span>        self<span class="token punctuation">.</span>end <span class="token operator">=</span> end    <span class="token keyword">def</span> <span class="token function">__iter__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> self    <span class="token keyword">def</span> <span class="token function">__next__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">if</span> self<span class="token punctuation">.</span>start <span class="token operator">&lt;</span> self<span class="token punctuation">.</span>end<span class="token punctuation">:</span>            ret <span class="token operator">=</span> self<span class="token punctuation">.</span>start            self<span class="token punctuation">.</span>start <span class="token operator">+=</span> <span class="token number">1</span>            <span class="token keyword">return</span> ret        <span class="token keyword">else</span><span class="token punctuation">:</span>            <span class="token keyword">raise</span> StopIterationa <span class="token operator">=</span> MyRange<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token keyword">for</span> i <span class="token keyword">in</span> a<span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 0 1 2 3 4</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><ul><li>可以使用<code>collection.abs</code>里面的<code>Iterator</code>和<code>Iterable</code>配合<code>isinstance</code>函数来判断一个对象是否是可迭代的，是否是迭代器对象</li><li>iter()实际是映射到了__iter__函数</li><li>只要实现了__iter__的对象就是可迭代对象(Iterable)，正常情况下应该返回一个实现了__next__的对象（<strong>强制要求</strong>，否则报错），如果自己实现了__next__，也可以返回自己。</li><li>同时实现了__iter__和__next__的是迭代器(Iterator)，当然也是一个可迭代对象了，其中__next__应该在迭代完成后，抛出一个StopIteration异常</li><li>for语句会自动处理这个StopIteration异常以便结束for循环</li></ul><h2 id="生成器-yield表达式"><a href="#生成器-yield表达式" class="headerlink" title="生成器(yield表达式)"></a>生成器(yield表达式)</h2><p><code>str</code>，<code>list</code>，<code>tuple</code>，<code>dict</code>，<code>set</code>这些都是可迭代的，就是可用for来访问里面的每一个元素。但他们并不是迭代器。<br><strong>生成器是一个可以快速创建迭代器的工具</strong>。生成器是可迭代的，更准确的说法是它就是个迭代器。<br>我们可以用列表生成式来初始化一个列表：</p><pre class="line-numbers language-python"><code class="language-python">list1 <span class="token operator">=</span> <span class="token punctuation">[</span>x <span class="token keyword">for</span> x <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token keyword">print</span><span class="token punctuation">(</span>list1<span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># [0,1,2,3,4]</span>gen <span class="token operator">=</span> <span class="token punctuation">(</span>x <span class="token keyword">for</span> x <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 生成器表达式</span><span class="token keyword">print</span><span class="token punctuation">(</span>gen<span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># generator object &lt;genexpr> at 0x000000ADEF</span><span class="token comment" spellcheck="true"># 调用gen的方法和迭代器一模一样</span><span class="token comment" spellcheck="true"># 方法一</span><span class="token keyword">for</span> x <span class="token keyword">in</span> gen<span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 方法二</span><span class="token keyword">print</span><span class="token punctuation">(</span>next<span class="token punctuation">(</span>gen<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>在 Python 中，使用了<code>yield</code>的函数被称为生成器（generator）。生成器是一个返回迭代器的函数，只能用于迭代操作，更简单点理解生成器就是一个迭代器。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">MyRange</span><span class="token punctuation">(</span>end<span class="token punctuation">)</span><span class="token punctuation">:</span>    start <span class="token operator">=</span> <span class="token number">0</span>    <span class="token keyword">while</span> start <span class="token operator">&lt;</span> end<span class="token punctuation">:</span>        <span class="token keyword">yield</span> start        start <span class="token operator">+=</span> <span class="token number">1</span><span class="token keyword">from</span> collections<span class="token punctuation">.</span>abc <span class="token keyword">import</span> <span class="token operator">*</span>a <span class="token operator">=</span> MyRange<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>isinstance<span class="token punctuation">(</span>a<span class="token punctuation">,</span> Iterator<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># True</span><span class="token keyword">print</span><span class="token punctuation">(</span>isinstance<span class="token punctuation">(</span>a<span class="token punctuation">,</span> Iterable<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># True</span><span class="token keyword">for</span> i <span class="token keyword">in</span> a<span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 0 1</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>可以看见，函数MyRange里面使用了yield语句，结果变成了generator，也是Iterator，我们在使用for语句的时候，执行步骤如下：</p><ol><li>start &#x3D; 0， while 0 &lt; 2，遇到了yield语句，返回start的值0，然后print这值；</li><li>第二次for的时候，执行yield后面的语句，start &#x3D; 1，while 1&lt;2，遇到了yield语句，返回start的值1，然后print；</li><li>第三次for的时候，执行yield后面的语句，start &#x3D; 2，while 2&lt;2不成立，此时函数结束运行，会抛出StopIterator的异常(这个是自动抛出的，不需要显示的调用raise语句，可以使用下面的next方法来查看这个异常)。</li></ol><p><strong>在调用生成器运行的过程中，每次遇到 yield 时函数会暂停并保存当前所有的运行信息，返回 yield 的值, 并在下一次执行 next() 方法时从当前位置继续运行</strong>。</p>]]></content>
      
      
      <categories>
          
          <category> 编程语言 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 基础知识 </tag>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Python中的MRO</title>
      <link href="/2023/10/10/python-zhi-shi/python-zhong-de-mro/"/>
      <url>/2023/10/10/python-zhi-shi/python-zhong-de-mro/</url>
      
        <content type="html"><![CDATA[<h1 id="Python中的MRO"><a href="#Python中的MRO" class="headerlink" title="Python中的MRO"></a>Python中的MRO</h1><p>面向对象的编程语言有三大特性：封装、继承和多态，在继承中不仅涉及到数据变量，还有方法的继承，因此关于继承的方法的执行顺序问题，称为MRO(Method Resolution Order)，方法解析顺序。</p><p>MRO是对于每个类，会把它的所有父类和自己做一个线性序列化，即把它所有继承的类和它自己做一个优先级的排序，当它想要调用某个方法时，会从这个优先级序列中去找。</p><p>Python从2.3版本开始，使用C3算法来求解MRO，C3算法可以满足三个性质：扩展优先图、局部优先、单调性。</p><h2 id="一个继承的简单例子"><a href="#一个继承的简单例子" class="headerlink" title="一个继承的简单例子"></a>一个继承的简单例子</h2><p>如下面的代码，类B继承了类A，因此在实例化类B的一个对象后，可以调用类A的<code>say()</code>方法，即使类B没有定义<code>say()</code>方法。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">A</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">say</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"AAA"</span><span class="token punctuation">)</span><span class="token keyword">class</span> <span class="token class-name">B</span><span class="token punctuation">(</span>A<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">pass</span>b <span class="token operator">=</span> B<span class="token punctuation">(</span><span class="token punctuation">)</span>b<span class="token punctuation">.</span>say<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># AAA</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>但是在一般项目中，类之间的继承关系不可能这么简单，比如下面的两段代码，区别仅仅是类B是否继承了类A，代码的执行结果就出现了变化。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">A</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">say</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"AAA"</span><span class="token punctuation">)</span><span class="token keyword">class</span> <span class="token class-name">B</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">say</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"BBB"</span><span class="token punctuation">)</span><span class="token keyword">class</span> <span class="token class-name">C</span><span class="token punctuation">(</span>A<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">pass</span><span class="token keyword">class</span> <span class="token class-name">D</span><span class="token punctuation">(</span>C<span class="token punctuation">,</span>B<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">pass</span>d <span class="token operator">=</span> D<span class="token punctuation">(</span><span class="token punctuation">)</span>d<span class="token punctuation">.</span>say<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">### AAA</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">A</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">say</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"AAA"</span><span class="token punctuation">)</span><span class="token keyword">class</span> <span class="token class-name">B</span><span class="token punctuation">(</span>A<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">say</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"BBB"</span><span class="token punctuation">)</span><span class="token keyword">class</span> <span class="token class-name">C</span><span class="token punctuation">(</span>A<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">pass</span><span class="token keyword">class</span> <span class="token class-name">D</span><span class="token punctuation">(</span>C<span class="token punctuation">,</span>B<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">pass</span>d <span class="token operator">=</span> D<span class="token punctuation">(</span><span class="token punctuation">)</span>d<span class="token punctuation">.</span>say<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">### BBB</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>Python提供了两种方式供我们查看类的MRO，即类的继承的优先级顺序，在上面的代码中，使用<code>D.__mro__</code>或者<code>D.mro()</code>会返回类D的MRO。</p><h2 id="局部优先顺序"><a href="#局部优先顺序" class="headerlink" title="局部优先顺序"></a>局部优先顺序</h2><p>局部优先顺序：顾名思义，局部优先。当一个类继承了多个类的时候，它会优先使用你写在前面的类的方法。如下面的代码所示</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">A</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">say</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"AAA"</span><span class="token punctuation">)</span><span class="token keyword">class</span> <span class="token class-name">B</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">say</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"BBB"</span><span class="token punctuation">)</span>        <span class="token keyword">class</span> <span class="token class-name">C</span><span class="token punctuation">(</span>A<span class="token punctuation">,</span>B<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">pass</span><span class="token keyword">print</span><span class="token punctuation">(</span>C<span class="token punctuation">.</span>mro<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># [&lt;class '__main__.C'>, &lt;class '__main__.A'>, &lt;class '__main__.B'>, &lt;class 'object'>]</span>c <span class="token operator">=</span> C<span class="token punctuation">(</span><span class="token punctuation">)</span>c<span class="token punctuation">.</span>say<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># AAA</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>局部优先的特性，不仅仅针对类C，也针对C的所有子类，即如果有任何类继承了类C，则该类也满足局部优先的特性。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">A</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">say</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"AAA"</span><span class="token punctuation">)</span><span class="token keyword">class</span> <span class="token class-name">B</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">say</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"BBB"</span><span class="token punctuation">)</span>  <span class="token keyword">class</span> <span class="token class-name">C</span><span class="token punctuation">(</span>A<span class="token punctuation">,</span>B<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">pass</span><span class="token keyword">class</span> <span class="token class-name">D</span><span class="token punctuation">(</span>C<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">pass</span><span class="token keyword">print</span><span class="token punctuation">(</span>D<span class="token punctuation">.</span>mro<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># [&lt;class '__main__.D'>, &lt;class '__main__.C'>, &lt;class '__main__.A'>, &lt;class '__main__.B'>, &lt;class 'object'>]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>局部优先特性更专业的表述是：MRO里任意两个类的相对顺序和继承图里所有直接继承自这两个类的类在程序中声明的相对顺序一致。</p><h2 id="单调性"><a href="#单调性" class="headerlink" title="单调性"></a>单调性</h2><p>单调性：是指任何一个类，所使用的方法需要来自于它的直接父类。</p><p>我们回到最开始的“简单”例子，如下面的代码，D的对象调用<code>say()</code>方法执行的是类B的方法，根据单调性的含义，类D执行的方法<code>say()</code>来自于它的直接父类C或B，根据局部优先原则现在C里面找，找不到接着去B里找，找到之后开始执行。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">A</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">say</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"AAA"</span><span class="token punctuation">)</span><span class="token keyword">class</span> <span class="token class-name">B</span><span class="token punctuation">(</span>A<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">say</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"BBB"</span><span class="token punctuation">)</span><span class="token keyword">class</span> <span class="token class-name">C</span><span class="token punctuation">(</span>A<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">pass</span><span class="token keyword">class</span> <span class="token class-name">D</span><span class="token punctuation">(</span>C<span class="token punctuation">,</span>B<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">pass</span>d <span class="token operator">=</span> D<span class="token punctuation">(</span><span class="token punctuation">)</span>d<span class="token punctuation">.</span>say<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># BBB </span><span class="token keyword">print</span><span class="token punctuation">(</span>D<span class="token punctuation">.</span>mro<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># [&lt;class '__main__.D'>, &lt;class '__main__.C'>, &lt;class '__main__.B'>, &lt;class '__main__.A'>, &lt;class 'object'>]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>更专业的表述是：MRO里任意两个类的相对顺序和自己所有父类的MRO里这两个类的相对顺序一致。</p><p>观察上面的代码，类C和类B都继承了类A，类D又同时继承了C和B，因此根据局部优先原则，在类D的MRO中C的优先级高于B，根据单调性原则，类D的MRO中任意两个类的顺序和自己所有父类（C和B）的MRO中这两个类的顺序一致，C的MRO中C优先于A，B的MRO中B优先于A，又已知C优先于B，因此D的MRO中优先级是C、B、A。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">print</span><span class="token punctuation">(</span>C<span class="token punctuation">.</span>mro<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>B<span class="token punctuation">.</span>mro<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># [&lt;class '__main__.C'>, &lt;class '__main__.A'>, &lt;class 'object'>]</span><span class="token comment" spellcheck="true"># [&lt;class '__main__.B'>, &lt;class '__main__.A'>, &lt;class 'object'>]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>当类B中没有<code>say()</code>方法会怎么样呢？如下面的代码，此时D的直接父类C和B均没有<code>say()</code>方法，但是看到结果执行了类A的方法，因此上文的单调性含义“调用直接父类”不是必须的，找不到就沿着优先级序列继续往上找。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">A</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">say</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"AAA"</span><span class="token punctuation">)</span><span class="token keyword">class</span> <span class="token class-name">B</span><span class="token punctuation">(</span>A<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">see</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"see"</span><span class="token punctuation">)</span><span class="token keyword">class</span> <span class="token class-name">C</span><span class="token punctuation">(</span>A<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">pass</span><span class="token keyword">class</span> <span class="token class-name">D</span><span class="token punctuation">(</span>C<span class="token punctuation">,</span>B<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">pass</span>d <span class="token operator">=</span> D<span class="token punctuation">(</span><span class="token punctuation">)</span>d<span class="token punctuation">.</span>say<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># AAA</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="扩展优先图"><a href="#扩展优先图" class="headerlink" title="扩展优先图"></a>扩展优先图</h2><p>扩展优先图：如果两个类不具有直接的继承关系，那么找到两个类的最小公共子类，这个最小公共子类的多继承顺序靠前的分支上的类具有高优先级。</p><p>继续再来看开头的“简单”例子。如下面的代码，类C继承了类A，类D又同时继承了C和B，此时类D的对象调用<code>say()</code>方法会执行A中的方法。在D的mro中因为局部优先原则，C的优先级高于B，但是A和B的顺序关系还没有确定。此时我们应用扩展优先图的原则，A和B不具有直接的继承关系，且最小公共子类是D，则在D的继承中靠前的分支是类C，具有高优先级，此分支上还有类A，所以类A的优先级高于B。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">A</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">say</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"AAA"</span><span class="token punctuation">)</span><span class="token keyword">class</span> <span class="token class-name">B</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">say</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"BBB"</span><span class="token punctuation">)</span><span class="token keyword">class</span> <span class="token class-name">C</span><span class="token punctuation">(</span>A<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">pass</span><span class="token keyword">class</span> <span class="token class-name">D</span><span class="token punctuation">(</span>C<span class="token punctuation">,</span>B<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">pass</span>d <span class="token operator">=</span> D<span class="token punctuation">(</span><span class="token punctuation">)</span>d<span class="token punctuation">.</span>say<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">print</span><span class="token punctuation">(</span>D<span class="token punctuation">.</span>mro<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> 编程语言 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 基础知识 </tag>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Pytorch|张量的特殊操作</title>
      <link href="/2023/10/04/pytorch-ji-chu-zhi-shi/zhang-liang-de-te-shu-cao-zuo/"/>
      <url>/2023/10/04/pytorch-ji-chu-zhi-shi/zhang-liang-de-te-shu-cao-zuo/</url>
      
        <content type="html"><![CDATA[<h1 id="张量的特殊操作"><a href="#张量的特殊操作" class="headerlink" title="张量的特殊操作"></a>张量的特殊操作</h1><p>在阅读别人的代码时，会遇到一些针对张量的特殊操作的方法，这些方法的具体使用在Pytorch的官方文档有解释，但是阅读官方文档往往更加迷惑，因此在这里对这些方法进行详细的解释。</p><h2 id="torch-scatter方法"><a href="#torch-scatter方法" class="headerlink" title="torch.scatter方法"></a>torch.scatter方法</h2><p><code>torch.scatter()</code>方法正如字面含义“放置”，如代码<code>torch.scatter(B, dim, index, A)</code>，就是将张量A，根据参数dim和index填充到张量B中去；也可以写作<code>B.scatter(dim, index, A)</code>。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> x <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> xtensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.9026</span><span class="token punctuation">,</span> <span class="token number">0.3278</span><span class="token punctuation">,</span> <span class="token number">0.4902</span><span class="token punctuation">,</span> <span class="token number">0.6585</span><span class="token punctuation">,</span> <span class="token number">0.1589</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">0.3596</span><span class="token punctuation">,</span> <span class="token number">0.5294</span><span class="token punctuation">,</span> <span class="token number">0.6111</span><span class="token punctuation">,</span> <span class="token number">0.5385</span><span class="token punctuation">,</span> <span class="token number">0.2100</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">.</span>scatter_<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> x<span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.9026</span><span class="token punctuation">,</span> <span class="token number">0.5294</span><span class="token punctuation">,</span> <span class="token number">0.6111</span><span class="token punctuation">,</span> <span class="token number">0.6585</span><span class="token punctuation">,</span> <span class="token number">0.1589</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">0.0000</span><span class="token punctuation">,</span> <span class="token number">0.3278</span><span class="token punctuation">,</span> <span class="token number">0.0000</span><span class="token punctuation">,</span> <span class="token number">0.5385</span><span class="token punctuation">,</span> <span class="token number">0.0000</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">0.3596</span><span class="token punctuation">,</span> <span class="token number">0.0000</span><span class="token punctuation">,</span> <span class="token number">0.4902</span><span class="token punctuation">,</span> <span class="token number">0.0000</span><span class="token punctuation">,</span> <span class="token number">0.2100</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="参数解释"><a href="#参数解释" class="headerlink" title="参数解释"></a>参数解释</h3><p>在代码<code>torch.scatter(B, dim, index, A)</code>中，该方法有几个重要的参数：目标张量(B)、dim、index和源张量(A)，其中各变量及参数的说明如下：</p><ul><li>目标张量：将在该张量上进行数据的填充，如上述代码的张量<code>B</code></li><li>源张量：将把该张量上的元素逐个填充到目标张量上，如上述代码的张量<code>A</code></li><li>dim：指定轴的方向，即指定<strong>沿着目标张量的哪个轴</strong>进行填充。对于二维张量，dim&#x3D;0表示逐列进行行填充，而dim&#x3D;1表示逐行进行填充</li><li>index：指定<strong>源张量的每个元素将要填充到目标张量的位置</strong>。按照轴方向，在target张量中需要填充的位置</li></ul><p>上述参数的本质即：dim参数指明沿着目标张量的哪个轴进行填充，而index参数指明源张量的每个元素将会填充的位置。为了保证scatter填充的有效性，需要注意：</p><ol><li>index的形状大小必须和源张量保持一致。因为index参数指明源张量的每个元素的填充位置，index的元素和源张量的元素是一一对应的。</li></ol><p>借用网上一张图片来理解上述的内容。</p><p><img src="/images/scatter.jpg"></p><p>如上图所示，因为指定了<code>dim=0</code>，所以是按照目标张量的列方向进行填充，即填充时逐列去填充数据。然后逐列的观察index参数（因为dim&#x3D;0），index的第一列是0和2，上述说明了index参数指明源张量的每个元素将会填充的位置，对应源张量的元素0.3992和0.5735，因此这两个元素放在目标张量的第一列的第一行和第三行（第一行和第三行对应0和2，0和2表示索引）。继续逐列填充，假设进行到第三列，index的第三列是2和0，对应源张量的元素0.9044和0.6797，因此这两个元素放在目标张量的第三列的第三行和第一行。</p><p>下面的举例将对<code>dim=1</code>进行解释，<code>dim=1</code>按照目标张量的行方向进行填充，即填充时逐行去填充数据。逐行观察index参数，index的第一行是0, 1, 2, 0, 0，对应源张量的0.9026, 0.3278, 0.4902, 0.6585, 0.1589，因此0.3287放在第一行的第二列，0.4902放在第一行的第三列，0.9026,  0.6585, 0.1589这三个数据放在第一行的第一列(index均是0)，因为填充时是逐个元素进行填充的，最后一个元素0.1589把前两个元素0.9026,  0.6585都给覆盖了，最后目标张量的第一行第一列是0.1589。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> x <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> xtensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.9026</span><span class="token punctuation">,</span> <span class="token number">0.3278</span><span class="token punctuation">,</span> <span class="token number">0.4902</span><span class="token punctuation">,</span> <span class="token number">0.6585</span><span class="token punctuation">,</span> <span class="token number">0.1589</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">0.3596</span><span class="token punctuation">,</span> <span class="token number">0.5294</span><span class="token punctuation">,</span> <span class="token number">0.6111</span><span class="token punctuation">,</span> <span class="token number">0.5385</span><span class="token punctuation">,</span> <span class="token number">0.2100</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">.</span>scatter_<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span>torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>x<span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.1589</span><span class="token punctuation">,</span> <span class="token number">0.3278</span><span class="token punctuation">,</span> <span class="token number">0.4902</span><span class="token punctuation">,</span> <span class="token number">0.0000</span><span class="token punctuation">,</span> <span class="token number">0.0000</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">0.6111</span><span class="token punctuation">,</span> <span class="token number">0.5385</span><span class="token punctuation">,</span> <span class="token number">0.2100</span><span class="token punctuation">,</span> <span class="token number">0.0000</span><span class="token punctuation">,</span> <span class="token number">0.0000</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">0.0000</span><span class="token punctuation">,</span> <span class="token number">0.0000</span><span class="token punctuation">,</span> <span class="token number">0.0000</span><span class="token punctuation">,</span> <span class="token number">0.0000</span><span class="token punctuation">,</span> <span class="token number">0.0000</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>这个例子可以再分析一下，看看为什么目标张量的第二行第三列是0.2100。具体过程和上述分析是一样的。</p><h3 id="官方文档的说明"><a href="#官方文档的说明" class="headerlink" title="官方文档的说明"></a>官方文档的说明</h3><p>官方文档是张量为3维的情况下进行说明，在3维和3维以上的更高维度下，做法和我们上述的描述是类似的。先来看看官方文档：</p><pre class="line-numbers language-python"><code class="language-python">target<span class="token punctuation">[</span>index<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">[</span>k<span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">[</span>k<span class="token punctuation">]</span> <span class="token operator">=</span> src<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">[</span>k<span class="token punctuation">]</span> <span class="token comment" spellcheck="true"># dim=0</span>target<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>index<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">[</span>k<span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">[</span>k<span class="token punctuation">]</span> <span class="token operator">=</span> src<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">[</span>k<span class="token punctuation">]</span> <span class="token comment" spellcheck="true"># dim=1</span>target<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">[</span>index<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">[</span>k<span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> src<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">[</span>k<span class="token punctuation">]</span> <span class="token comment" spellcheck="true"># dim=2</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>当dim&#x3D;0时沿着张量的列方向，所以index出现在第0维度的位置；以此类推，dim&#x3D;1沿着张量的行方向，所以index出现在第1维度的位置；dim&#x3D;2沿着张量的通道方向，所以index出现在第2维度的位置。这样理解起来官方文档的解释就清晰明了。</p><h2 id="torch-gather方法"><a href="#torch-gather方法" class="headerlink" title="torch.gather方法"></a>torch.gather方法</h2><p><code>torch.gather()</code>正如字面意思“收集”，即取出张量中对应的某些索引下的具体的元素。如代码<code>torch.gather(data, dim ,index)</code>表示按照dim和index参数从data张量中取出数值。也可以写作<code>data.gather(dim, index)</code>。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> data <span class="token operator">=</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">12</span><span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> datatensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">3</span><span class="token punctuation">,</span>  <span class="token number">4</span><span class="token punctuation">,</span>  <span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">6</span><span class="token punctuation">,</span>  <span class="token number">7</span><span class="token punctuation">,</span>  <span class="token number">8</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">9</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">11</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> index <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> out <span class="token operator">=</span> data<span class="token punctuation">.</span>gather<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> index<span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> outtensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">9</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>gather的操作，其实包含在scatter中。scatter是先根据index和dim找到data中的这些值，然后使用src去替换；而gather就是根据dim和index来找到data中的值，然后把这些值取出来构成新的张量。</p><p>因此，可以先搞明白scatter的操作机制，再来看gather的操作。</p><p>下面是一些代码示例，当传入的index是行向量时，</p><pre class="line-numbers language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> data <span class="token operator">=</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">12</span><span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> datatensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">3</span><span class="token punctuation">,</span>  <span class="token number">4</span><span class="token punctuation">,</span>  <span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">6</span><span class="token punctuation">,</span>  <span class="token number">7</span><span class="token punctuation">,</span>  <span class="token number">8</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">9</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">11</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> index <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> out <span class="token operator">=</span> data<span class="token punctuation">.</span>gather<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> index<span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> outtensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">9</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> out <span class="token operator">=</span> data<span class="token punctuation">.</span>gather<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> index<span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> outtensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>当传入的index是列向量时，</p><pre class="line-numbers language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> data <span class="token operator">=</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">12</span><span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> datatensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">3</span><span class="token punctuation">,</span>  <span class="token number">4</span><span class="token punctuation">,</span>  <span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">6</span><span class="token punctuation">,</span>  <span class="token number">7</span><span class="token punctuation">,</span>  <span class="token number">8</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">9</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">11</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> index <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>t<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> indextensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> out <span class="token operator">=</span> data<span class="token punctuation">.</span>gather<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> index<span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> outtensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">7</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">9</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> out <span class="token operator">=</span> data<span class="token punctuation">.</span>gather<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> index<span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> outtensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">9</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>当传入的index是矩阵时，</p><pre class="line-numbers language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> data <span class="token operator">=</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">12</span><span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> datatensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">3</span><span class="token punctuation">,</span>  <span class="token number">4</span><span class="token punctuation">,</span>  <span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">6</span><span class="token punctuation">,</span>  <span class="token number">7</span><span class="token punctuation">,</span>  <span class="token number">8</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">9</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">11</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> index <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                           <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> out <span class="token operator">=</span> data<span class="token punctuation">.</span>gather<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> index<span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> outtensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> out <span class="token operator">=</span> data<span class="token punctuation">.</span>gather<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> index<span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> outtensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> Pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 基础知识 </tag>
            
            <tag> Pytorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>vim命令的基本使用</title>
      <link href="/2023/08/19/ji-suan-ji-ji-chu/vim-shi-yong-jian-yi-jiao-cheng/"/>
      <url>/2023/08/19/ji-suan-ji-ji-chu/vim-shi-yong-jian-yi-jiao-cheng/</url>
      
        <content type="html"><![CDATA[<h1 id="vim命令的基本使用"><a href="#vim命令的基本使用" class="headerlink" title="vim命令的基本使用"></a>vim命令的基本使用</h1><p>vim 是一个全屏幕纯文本编辑器，是 vi 编辑器的增强版。</p><p>vim的工作模式</p><p><img src="/images/vim%E5%B7%A5%E4%BD%9C%E6%A8%A1%E5%BC%8F.jpg"></p><p>命令模式：是主要输入快捷键的模式。命名模式要想进入输入模式，可以使用<code>a, i, o</code>等快捷键来进入。</p><p>输入模式：主要用于文本编辑，和记事本类似。</p><p>末行模式（编辑模式）：</p><ul><li><code>:w</code>：保存不退出</li><li><code>:w 新文件名</code>：把文件另存为新文件</li><li><code>:q</code>：不保存退出</li><li><code>:wq</code>：保存退出</li><li><code>:!</code>：强制</li><li><code>:q!</code>：强制不保存退出，用于修改文件之后，不保存数据退出</li><li><code>:wq!</code>：强制保存退出，当文件的所有者或 root 用户，对文件没有写权限的时候，强制写入数据使用</li></ul><h2 id="插入模式"><a href="#插入模式" class="headerlink" title="插入模式"></a>插入模式</h2><table><thead><tr><th>命令</th><th>作用</th></tr></thead><tbody><tr><td><code>a</code></td><td>在光标所在字符后插入</td></tr><tr><td><code>A</code></td><td>在光标所在行尾插入</td></tr><tr><td><code>i</code></td><td>在光标所在字符前插入</td></tr><tr><td><code>I</code></td><td>在光标所在行首插入</td></tr><tr><td><code>o</code></td><td>在光标下插入新行</td></tr><tr><td><code>O</code></td><td>在光标上插入新行</td></tr></tbody></table><h2 id="命令模式操作"><a href="#命令模式操作" class="headerlink" title="命令模式操作"></a>命令模式操作</h2><h3 id="移动光标"><a href="#移动光标" class="headerlink" title="移动光标"></a>移动光标</h3><p>1)上下左右移动光标</p><blockquote><p>上、下、左、右方向键 移动光标<br><code>h</code>（左）<code>j</code>（下）<code>k</code>（上） <code>l</code>（右） 移动光标</p></blockquote><p>2)光标移动到文件头或文件尾</p><blockquote><p><code>gg</code> 移动到文件头<br><code>G</code> 移动到文件尾（shift + g）</p></blockquote><p>3)光标移动到行首或行尾</p><blockquote><p><code>^</code> 移动到行首<br><code>$</code> 移动到行尾</p></blockquote><p>4)移动到指定行</p><blockquote><p><code>:n</code> 移动到第几行（这里的 n 是数字）</p></blockquote><h3 id="删除或剪切"><a href="#删除或剪切" class="headerlink" title="删除或剪切"></a>删除或剪切</h3><p>1)删除字母</p><blockquote><p><code>x</code> 删除单个字母<br><code>nx</code> 删除 n 个字母（n 是数字，如果打算从光标位置连续删除 10 个字母，可以使用 10x 即可）</p></blockquote><p>2)删除整行或剪切</p><blockquote><p><code>dd</code> 删除单行<br><code>ndd</code> 删除多行<br><code>:n1,n2d</code> 删除指定范围的行</p></blockquote><p>删除行或多行，是比较常用的删除方法。这里的 dd 快捷键既是删除也是剪切。删除内容放入了剪切板，如果不粘贴就是删除，粘贴就是剪切。粘贴方法：</p><blockquote><p><code>p</code> 粘贴到光标下面一行<br><code>P</code> 粘贴到光标上面一行（shift+p）</p></blockquote><p>3)从光标所在行删除到文件尾</p><blockquote><p><code>dG</code> 从光标所在行删除到文件尾（d 是删除行，G 是文件尾，连起来就是从光标行删除到文件尾）</p></blockquote><h3 id="复制"><a href="#复制" class="headerlink" title="复制"></a>复制</h3><blockquote><p><code>yy</code> 复制单行<br><code>nyy</code> 复制多行</p></blockquote><p>复制之后的粘贴依然可以使用 p 键或 P 键</p><h3 id="撤销"><a href="#撤销" class="headerlink" title="撤销"></a>撤销</h3><blockquote><p><code>u</code> 撤销<br><code>ctrl + r</code> 反撤销</p></blockquote><p>u 键能一直撤销到文件打开时的状态，ctrl + r 能一直反撤销到最后一次操作状态</p><h3 id="替换"><a href="#替换" class="headerlink" title="替换"></a>替换</h3><blockquote><p><code>r</code> 替换光标所在处的字符<br><code>R</code> 从光标所在处开始替换字符，按 esc 键结束</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> 计算机基础 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 基础知识 </tag>
            
            <tag> vim </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深度学习中的正则化</title>
      <link href="/2023/07/19/suan-fa/shen-du-xue-xi-zheng-ze-hua/"/>
      <url>/2023/07/19/suan-fa/shen-du-xue-xi-zheng-ze-hua/</url>
      
        <content type="html"><![CDATA[<h1 id="深度学习中的正则化"><a href="#深度学习中的正则化" class="headerlink" title="深度学习中的正则化"></a>深度学习中的正则化</h1><p>先来看一个python实现的最简单的单参数线性回归模型。</p><h2 id="简单的线性回归"><a href="#简单的线性回归" class="headerlink" title="简单的线性回归"></a>简单的线性回归</h2><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">import</span> randomx <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>np<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>y <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1.8</span><span class="token punctuation">,</span> <span class="token number">2.1</span><span class="token punctuation">,</span> <span class="token number">2.3</span><span class="token punctuation">,</span> <span class="token number">2.3</span><span class="token punctuation">,</span> <span class="token number">2.85</span><span class="token punctuation">,</span> <span class="token number">3.0</span><span class="token punctuation">,</span> <span class="token number">3.3</span><span class="token punctuation">,</span> <span class="token number">4.9</span><span class="token punctuation">,</span> <span class="token number">5.45</span><span class="token punctuation">,</span> <span class="token number">5.0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>np<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>k <span class="token operator">=</span> random<span class="token punctuation">.</span>random<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 0-1</span>b <span class="token operator">=</span> <span class="token number">0</span>lr <span class="token operator">=</span> <span class="token number">1e</span><span class="token operator">-</span><span class="token number">2</span>  <span class="token comment" spellcheck="true"># 学习率</span><span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    predict <span class="token operator">=</span> x <span class="token operator">*</span> k <span class="token operator">+</span> b    loss <span class="token operator">=</span> <span class="token number">0.5</span> <span class="token operator">*</span> np<span class="token punctuation">.</span>sum<span class="token punctuation">(</span><span class="token punctuation">(</span>y <span class="token operator">-</span> predict<span class="token punctuation">)</span> <span class="token operator">**</span> <span class="token number">2</span><span class="token punctuation">)</span>    <span class="token keyword">if</span> i <span class="token operator">%</span> <span class="token number">100</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"loss = "</span><span class="token punctuation">,</span> loss<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 梯度</span>    delta_b <span class="token operator">=</span> np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>predict <span class="token operator">-</span> y<span class="token punctuation">)</span>    delta_k <span class="token operator">=</span> np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">(</span>predict <span class="token operator">-</span> y<span class="token punctuation">)</span> <span class="token operator">*</span> x<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 更新参数</span>    k <span class="token operator">=</span> k <span class="token operator">-</span> lr <span class="token operator">*</span> delta_k    b <span class="token operator">=</span> b <span class="token operator">-</span> lr <span class="token operator">*</span> delta_bk b<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="/images/LinearRegression.png"></p><h2 id="复杂的线性回归"><a href="#复杂的线性回归" class="headerlink" title="复杂的线性回归"></a>复杂的线性回归</h2><p>下面我们写一个稍微复杂些的模型，因为对房价预测模型用直线会使得误差较大，对于输入和输出接近线性相关的问题，这些线性函数是很有用的，但对于非线性它们则不太有效。在这里增加模型复杂度，代码如下：<br>$y&#x3D;k_{identity}x+k_{sin} \sin(x) +k_{cos}  \cos(x) + b$</p><pre class="line-numbers language-python"><code class="language-python"><span class="token triple-quoted-string string">'''对数据进行减去均值除以标准差，使得均值为0，标准差为1数据加载，并执行标准化，使得数据服从正态分布 '''</span>xm<span class="token punctuation">,</span> ym <span class="token operator">=</span> np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>data<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>xs<span class="token punctuation">,</span> ys  <span class="token operator">=</span> np<span class="token punctuation">.</span>std<span class="token punctuation">(</span>data<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>x <span class="token operator">=</span> <span class="token punctuation">(</span>x <span class="token operator">-</span> xm<span class="token punctuation">)</span> <span class="token operator">/</span> xsy <span class="token operator">=</span> <span class="token punctuation">(</span>y <span class="token operator">-</span> ym<span class="token punctuation">)</span> <span class="token operator">/</span> ys<span class="token triple-quoted-string string">'''一般而言，k的初始值不适合设置为0而b的初始值更适合设置为0，由于数据做了标准化，所以学习率可以给更大的值'''</span>k_identity <span class="token operator">=</span> <span class="token number">0.1</span>k_sin      <span class="token operator">=</span> <span class="token number">0.1</span>k_cos      <span class="token operator">=</span> <span class="token number">0.1</span>b          <span class="token operator">=</span> <span class="token number">0</span>lr         <span class="token operator">=</span> <span class="token number">0.01</span><span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">1000</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    predict <span class="token operator">=</span> x <span class="token operator">*</span> k_identity <span class="token operator">+</span> np<span class="token punctuation">.</span>sin<span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token operator">*</span> k_sin <span class="token operator">+</span> np<span class="token punctuation">.</span>cos<span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token operator">*</span> k_cos <span class="token operator">+</span> b    loss <span class="token operator">=</span> <span class="token number">0.5</span> <span class="token operator">*</span> <span class="token punctuation">(</span><span class="token punctuation">(</span>predict <span class="token operator">-</span> y<span class="token punctuation">)</span> <span class="token operator">**</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>sum<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">if</span> i <span class="token operator">%</span> <span class="token number">100</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">"Iter: {i}, Loss: {loss:.3f}"</span><span class="token punctuation">)</span>    dk_identity <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token punctuation">(</span>predict <span class="token operator">-</span> y<span class="token punctuation">)</span> <span class="token operator">*</span> x<span class="token punctuation">)</span><span class="token punctuation">.</span>sum<span class="token punctuation">(</span><span class="token punctuation">)</span>    dk_sin      <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token punctuation">(</span>predict <span class="token operator">-</span> y<span class="token punctuation">)</span> <span class="token operator">*</span> np<span class="token punctuation">.</span>sin<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>sum<span class="token punctuation">(</span><span class="token punctuation">)</span>    dk_cos      <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token punctuation">(</span>predict <span class="token operator">-</span> y<span class="token punctuation">)</span> <span class="token operator">*</span> np<span class="token punctuation">.</span>cos<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>sum<span class="token punctuation">(</span><span class="token punctuation">)</span>    db          <span class="token operator">=</span> <span class="token punctuation">(</span>predict <span class="token operator">-</span> y<span class="token punctuation">)</span><span class="token punctuation">.</span>sum<span class="token punctuation">(</span><span class="token punctuation">)</span>    k_identity <span class="token operator">=</span> k_identity <span class="token operator">-</span> dk_identity <span class="token operator">*</span> lr    k_sin      <span class="token operator">=</span> k_sin      <span class="token operator">-</span> dk_sin <span class="token operator">*</span> lr    k_cos      <span class="token operator">=</span> k_cos      <span class="token operator">-</span> dk_cos <span class="token operator">*</span> lr    b          <span class="token operator">=</span> b <span class="token operator">-</span> db <span class="token operator">*</span> lrrestore_x <span class="token operator">=</span> x <span class="token operator">*</span> xs <span class="token operator">+</span> xmrestore_y <span class="token operator">=</span> predict <span class="token operator">*</span> ys <span class="token operator">+</span> ym<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ul><li>注意：我们在求导数时是累加，在样本数量少的时候没有区别，样本数量大的时候常用平均值。</li></ul><p>看看训练效果，拟合了出我们希望的结果。<br><img src="/images/fit.png"><br>这里再看下使用的线性回归公式，对于复杂度，由于多引入了2个k，使得模型比直线更加复杂：<br>$y&#x3D;k_{identity}x+k_{sin} \sin(x) +k_{cos}  \cos(x) + b$<br>上述训练过程的损失函数如下：<br>$L&#x3D;\frac{1}{2}[k_{identity}x+k_{sin} \sin(x) +k_{cos}  \cos(x) + b - y]^2$<br>但是，也可以定义如下损失函数：<br>$L&#x3D;\frac{1}{2}[k_{identity}x+k_{sin} \sin(x) +k_{cos}  \cos(x) + b - y]^2 + \lambda(k_{identity}^2+k_{sin}^2 + k_{cos}^2 + b^2)$<br>$\lambda$是提前挑好的值，控制我们偏好小范数权重的程度，取一个比较小的数字，例如1e-5。当$\lambda &#x3D; 0$时，我们没有任何偏好，越大的$\lambda$偏好越小的权重。可以使用不同的$\lambda$来训练回归模型，看一下结果：<br><img src="/images/%E6%AD%A3%E5%88%99%E5%8C%96.png"></p><p>这里增加的约束，称之为对**模型的正则化(Regularization)**，相当于对模型的参数做了约束，要求其越简单越好，最小化模型参数，也称为：结构风险最小化(Structural Risk Minimization，SRM)。</p><h2 id="正则化"><a href="#正则化" class="headerlink" title="正则化"></a>正则化</h2><p>正则化也称之为对参数的<strong>惩罚项</strong>，也有称之为<strong>权重衰减</strong>，即Penalty、WeightDecay。<br>对于如下平方和，称之为<strong>L2正则化</strong>，也叫(ridge回归，岭回归)：<br>$L&#x3D;\frac{1}{2}[k_{identity}x+k_{sin} \sin(x) +k_{cos}  \cos(x) + b - y]^2 + \lambda(k_{identity}^2+k_{sin}^2 + k_{cos}^2 + b^2)$<br>对于如下绝对值和，称之为<strong>L1正则化</strong>，也叫(lasso回归)：<br>$L&#x3D;\frac{1}{2}[k_{identity}x+k_{sin} \sin(x) +k_{cos}  \cos(x) + b - y]^2 + \lambda(|k_{identity}|+|k_{sin}| + |k_{cos}| + |b|)$<br>带正则化的模型表示如下：<br>$L&#x3D;L_{\theta}(x) + \lambda || \theta ||_p^p$<br>此时表示最小化经验风险和最小化结构风险。<br><strong>正则化是增加了对模型复杂度的约束</strong>，<strong>要求模型使用更少的参数</strong>表示问题，<strong>抑制过拟合的现象</strong>发生的一种常见手段，但是要注意，正则化是指修改学习算法，使其降低泛化误差，而非训练误差。</p>]]></content>
      
      
      <categories>
          
          <category> 算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 基础知识 </tag>
            
            <tag> 数学 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Python的argparse模块</title>
      <link href="/2023/07/17/python-zhi-shi/argparse-xiang-jie/"/>
      <url>/2023/07/17/python-zhi-shi/argparse-xiang-jie/</url>
      
        <content type="html"><![CDATA[<h1 id="Python中的argparse模块"><a href="#Python中的argparse模块" class="headerlink" title="Python中的argparse模块"></a>Python中的argparse模块</h1><p>argparse 模块是 Python 内置的用于命令项选项与参数解析的模块，argparse 模块可以让人轻松编写用户友好的命令行接口，能够帮助程序员为模型定义参数。<br>本质上是用sys.argv从命令行语句中解析出命令行参数，然后自动生成帮助和使用信息。<br>argparse定义四个步骤</p><ul><li>导入argparse包 ——import argparse</li><li>创建一个命令行解析器对象 ——创建 ArgumentParser() 对象</li><li>给解析器添加命令行参数 ——调用add_argument() 方法添加参数</li><li>解析命令行的参数 ——使用 parse_args() 解析添加的参数</li></ul><h2 id="基本用法"><a href="#基本用法" class="headerlink" title="基本用法"></a>基本用法</h2><p>argparse的使用非常简单，代码示例如下。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 导入库</span><span class="token keyword">import</span> argparse <span class="token comment" spellcheck="true"># 1. 定义命令行解析器对象</span>parser <span class="token operator">=</span> argparse<span class="token punctuation">.</span>ArgumentParser<span class="token punctuation">(</span>description<span class="token operator">=</span><span class="token string">'Demo of argparse'</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 2. 添加命令行参数</span>parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--epochs'</span><span class="token punctuation">,</span> type<span class="token operator">=</span>int<span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">30</span><span class="token punctuation">)</span>parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--batch'</span><span class="token punctuation">,</span> type<span class="token operator">=</span>int<span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 3. 从命令行中结构化解析参数</span>args <span class="token operator">=</span> parser<span class="token punctuation">.</span>parse_args<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>args<span class="token punctuation">)</span>epochs <span class="token operator">=</span> args<span class="token punctuation">.</span>epochsbatch <span class="token operator">=</span> args<span class="token punctuation">.</span>batch<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'show {}  {}'</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>epochs<span class="token punctuation">,</span> batch<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="参数详解"><a href="#参数详解" class="headerlink" title="参数详解"></a>参数详解</h2><h3 id="add-argument-方法"><a href="#add-argument-方法" class="headerlink" title="add_argument() 方法"></a>add_argument() 方法</h3><p>添加命令行参数。给一个 ArgumentParser 对象添加程序参数信息，是通过调用 add_argument() 方法完成的。通常，这些调用指定 ArgumentParser 对象获取命令行字符串并将其转换为对象。这些信息在 parse_args() 调用时被存储在ArgumentParser实例化对象中，以供后续使用。</p><h3 id="parse-args-方法"><a href="#parse-args-方法" class="headerlink" title="parse_args()方法"></a>parse_args()方法</h3><p>ArgumentParser对象通过 parse_args() 方法解析命令行的参数。它将检查命令行中每个参数，转换为适当的数据类型，然后调用相应的操作，并把参数结构化后存放在对象args中。</p><pre class="line-numbers language-python"><code class="language-python">args <span class="token operator">=</span> parser<span class="token punctuation">.</span>parse_args<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>在脚本中，通常 parse_args() 会被不带参数调用，而 ArgumentParser 将自动从 sys.argv 中确定命令行参数。</p><h2 id="add-argument-参数解析"><a href="#add-argument-参数解析" class="headerlink" title="add_argument() 参数解析"></a>add_argument() 参数解析</h2><p>每个参数解释如下:</p><ul><li><strong>name or flags: <strong>一个命名或者一个选项字符串的列表。可以传</strong>位置参数名</strong>或者<strong>可选参数标识符</strong>，它必须作为add_argument()方法的第一个参数。例如 epochs 或者 -e, –epochs。当<code>parse_args()</code>被调用，选项会以<code>-</code>前缀识别，剩下的参数则会被假定为位置参数。</li></ul><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 可选参数</span>parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'-f'</span><span class="token punctuation">,</span> <span class="token string">'--foo'</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 位置参数</span>parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'bar'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><ul><li><p><strong>action:</strong> 命令行遇到flags参数（可选参数）时的动作。有两个常见的动作：</p><blockquote><p>store_true：设定flag参数为true；<br>store_false：设定flag参数为False。<br>注意：如果直接运行程序，默认不读取该变量，要使用必须要进行传参，例如：python try.py –epochs</p></blockquote></li><li><p>nargs: 应该读取的命令行参数个数，</p><blockquote><p>可以是具体的数字，<br>或者是 ? 号，当不指定值时对于 位置参数 使用 default，对于 可选参数 使用 const；<br>或者是 * 号，表示 0 或多个参数；<br>或者是 + 号，表示 1 或多个参数。</p></blockquote></li><li><p><strong>default:</strong> 不指定参数时该参数的默认值。</p></li><li><p><strong>type:</strong> 命令行参数应该被转换成的数据类型。</p></li><li><p>required: 是否为必选参数或可选参数。</p></li><li><p><strong>help:</strong> 参数的帮助信息。</p></li><li><p>metavar： 在 usage 说明中的参数名称，对于必选参数，默认就是参数名称，对于可选参数默认是全大写的参数名称。</p></li><li><p>dest： 解析后的参数名称，默认情况下，对于可选参数选取最长的名称，中划线转换为下划线。</p></li><li><p>choices： 参数可允许的值的一个容器。</p></li><li><p>const： action 和 nargs 所需要的常量值。</p></li><li><p>store_const：表示赋值为const；</p></li><li><p>append：将遇到的值存储成列表，也就是如果参数重复则会保存多个值;</p></li><li><p>append_const：将参数规范中定义的一个值保存到一个列表；</p></li><li><p>count：存储遇到的次数；此外，也可以继承 argparse.Action 自定义参数解析；</p></li></ul><h2 id="参数示例说明"><a href="#参数示例说明" class="headerlink" title="参数示例说明"></a>参数示例说明</h2><h3 id="位置参数"><a href="#位置参数" class="headerlink" title="位置参数"></a>位置参数</h3><p>位置参数是<code>XXX</code>。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> argparseparse <span class="token operator">=</span> argparse<span class="token punctuation">.</span>ArgumentParser<span class="token punctuation">(</span><span class="token string">'This script is for argparse learning'</span><span class="token punctuation">)</span>parse<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'echo'</span><span class="token punctuation">,</span>help<span class="token operator">=</span><span class="token string">'this option where return what you input'</span><span class="token punctuation">)</span>opt <span class="token operator">=</span> parser<span class="token punctuation">.</span>parse_args<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">print</span><span class="token punctuation">(</span>opt<span class="token punctuation">.</span>echo<span class="token punctuation">)</span>python opt<span class="token punctuation">.</span>py hello<span class="token operator">>></span><span class="token operator">></span>Output<span class="token punctuation">:</span>hello<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>type参数用来指定输入该参数的类型</p><pre class="line-numbers language-python"><code class="language-python">parse<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'echo'</span><span class="token punctuation">,</span>help<span class="token operator">=</span><span class="token string">'this option where return what you input'</span><span class="token punctuation">,</span>                   type<span class="token operator">=</span>int<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h3 id="可选参数"><a href="#可选参数" class="headerlink" title="可选参数"></a>可选参数</h3><h4 id="指定参数"><a href="#指定参数" class="headerlink" title="指定参数"></a>指定参数</h4><p>使用<code>--XXX</code>或<code>-XXX</code>来指定可选参数，参数类型可以由type指定，如果使用可选参数则必须有一个参数，如下错误</p><pre class="line-numbers language-python"><code class="language-python">parse<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--input'</span><span class="token punctuation">,</span>help<span class="token operator">=</span><span class="token string">'this will return what you input'</span><span class="token punctuation">,</span>type <span class="token operator">=</span> int<span class="token punctuation">)</span>arg <span class="token operator">=</span> parse<span class="token punctuation">.</span>parse_args<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>arg<span class="token punctuation">.</span>input<span class="token punctuation">)</span>python opt<span class="token punctuation">.</span>py <span class="token operator">-</span><span class="token operator">-</span>input<span class="token operator">>></span><span class="token operator">></span>Output<span class="token punctuation">:</span>usage<span class="token punctuation">:</span> This script <span class="token keyword">is</span> <span class="token keyword">for</span> argparse learning <span class="token punctuation">[</span><span class="token operator">-</span>h<span class="token punctuation">]</span> <span class="token punctuation">[</span><span class="token operator">-</span><span class="token operator">-</span>input INPUT<span class="token punctuation">]</span>This script <span class="token keyword">is</span> <span class="token keyword">for</span> argparse learning<span class="token punctuation">:</span> error<span class="token punctuation">:</span> argument <span class="token operator">-</span><span class="token operator">-</span>input<span class="token punctuation">:</span> expected one argument<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="标值参数"><a href="#标值参数" class="headerlink" title="标值参数"></a>标值参数</h4><p><code>action = &#39;store_true&#39;</code>或者<code>action=&#39;store_false&#39;</code></p><pre class="line-numbers language-python"><code class="language-python">parse<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--flag'</span><span class="token punctuation">,</span>help<span class="token operator">=</span><span class="token string">'this is test for flag'</span><span class="token punctuation">,</span>action<span class="token operator">=</span><span class="token string">'store_true'</span><span class="token punctuation">)</span>arg <span class="token operator">=</span> parse<span class="token punctuation">.</span>parse_args<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>arg<span class="token punctuation">.</span>input<span class="token punctuation">)</span>python opt<span class="token punctuation">.</span>py  <span class="token operator">-</span><span class="token operator">-</span>flag<span class="token operator">>></span><span class="token operator">></span>Output<span class="token punctuation">:</span><span class="token boolean">True</span>python opt<span class="token punctuation">.</span>py<span class="token operator">>></span><span class="token operator">></span>Output<span class="token punctuation">:</span><span class="token boolean">False</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>当你为其指定一个值的时候，也会报错，说明这个标志只有存在和不存在的区别，不可以对其赋值。<br>也可以使用<code>action=&#39;store_const&#39;</code>来指定一个const参数。</p><pre class="line-numbers language-python"><code class="language-python">parse<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--store_con'</span><span class="token punctuation">,</span>action<span class="token operator">=</span><span class="token string">'store_const'</span><span class="token punctuation">,</span>const<span class="token operator">=</span><span class="token number">12</span><span class="token punctuation">)</span>arg <span class="token operator">=</span> parse<span class="token punctuation">.</span>parse_args<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>arg<span class="token punctuation">.</span>store_con<span class="token punctuation">)</span>python opt<span class="token punctuation">.</span>py <span class="token operator">-</span><span class="token operator">-</span>store_con<span class="token operator">>></span><span class="token operator">></span>Output<span class="token punctuation">:</span><span class="token number">12</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="限制参数的选项"><a href="#限制参数的选项" class="headerlink" title="限制参数的选项"></a>限制参数的选项</h4><p>使用choices来限制参数的选项</p><pre class="line-numbers language-python"><code class="language-python">parse<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--choice'</span><span class="token punctuation">,</span>choices<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span>type<span class="token operator">=</span>int<span class="token punctuation">,</span>                   help<span class="token operator">=</span><span class="token string">'the choice only can be used in [1,2,3]'</span><span class="token punctuation">)</span>arg <span class="token operator">=</span> parse<span class="token punctuation">.</span>parse_args<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>arg<span class="token punctuation">.</span>choice<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>使用不在choices中的参数会报错</p><h4 id="计数某一可选参数出现次数"><a href="#计数某一可选参数出现次数" class="headerlink" title="计数某一可选参数出现次数"></a>计数某一可选参数出现次数</h4><p>使用count动作来计数某一可选参数出现的次数</p><pre class="line-numbers language-python"><code class="language-python">parse<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--num'</span><span class="token punctuation">,</span><span class="token string">'-n'</span><span class="token punctuation">,</span>action<span class="token operator">=</span><span class="token string">'count'</span><span class="token punctuation">,</span>help<span class="token operator">=</span><span class="token string">'this option is used for count'</span><span class="token punctuation">)</span>arg <span class="token operator">=</span> parse<span class="token punctuation">.</span>parse_args<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">if</span> arg<span class="token punctuation">.</span>num <span class="token operator">==</span> None<span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'count is 0'</span><span class="token punctuation">)</span><span class="token keyword">if</span> arg<span class="token punctuation">.</span>num <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'count is 1'</span><span class="token punctuation">)</span><span class="token keyword">if</span> arg<span class="token punctuation">.</span>num <span class="token operator">==</span> <span class="token number">2</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'count is 2'</span><span class="token punctuation">)</span>python opt<span class="token punctuation">.</span>py  <span class="token operator">-</span>n<span class="token operator">>></span><span class="token operator">></span>Output<span class="token punctuation">:</span>count <span class="token keyword">is</span> <span class="token number">1</span>————————————————————————————————python opt<span class="token punctuation">.</span>py  <span class="token operator">-</span>nn<span class="token operator">>></span><span class="token operator">></span>Output<span class="token punctuation">:</span>count <span class="token keyword">is</span> <span class="token number">2</span>————————————————————————————————python opt<span class="token punctuation">.</span>py  <span class="token operator">-</span>n <span class="token operator">-</span>n<span class="token operator">>></span><span class="token operator">></span>Output<span class="token punctuation">:</span>count <span class="token keyword">is</span> <span class="token number">2</span>————————————————————————————————python opt<span class="token punctuation">.</span>py  <span class="token operator">-</span>n <span class="token operator">-</span><span class="token operator">-</span>num<span class="token operator">>></span><span class="token operator">></span>Output<span class="token punctuation">:</span>count <span class="token keyword">is</span> <span class="token number">2</span>————————————————————————————————python opt<span class="token punctuation">.</span>py<span class="token operator">>></span><span class="token operator">></span>Output<span class="token punctuation">:</span>count <span class="token keyword">is</span> <span class="token number">0</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="使用default指定默认参数"><a href="#使用default指定默认参数" class="headerlink" title="使用default指定默认参数"></a>使用default指定默认参数</h4><p>可以在添加参数的时候使用default来指定默认的参数</p>]]></content>
      
      
      <categories>
          
          <category> 编程语言 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 基础知识 </tag>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深度学习中的损失函数</title>
      <link href="/2023/07/14/suan-fa/shen-du-xue-xi-chang-yong-sun-shi-han-shu/"/>
      <url>/2023/07/14/suan-fa/shen-du-xue-xi-chang-yong-sun-shi-han-shu/</url>
      
        <content type="html"><![CDATA[<h1 id="深度学习中常用的损失函数"><a href="#深度学习中常用的损失函数" class="headerlink" title="深度学习中常用的损失函数"></a>深度学习中常用的损失函数</h1><p>机器学习中的监督学习本质是给定一系列训练样本$(x_i, y_i)$，尝试学习$x \rightarrow y$的映射关系，使得给定一个$x$，即便这个$x$不在训练样本中，也能够得到尽量接近真实$y$的输出$\hat{y}$。而损失函数（Loss Function）则是这个过程中关键的一个组成部分，用来<strong>衡量模型的输出</strong>$\hat{y}$<strong>与真实的</strong>$y$<strong>之间的差距</strong>，给模型的优化指明方向。<br>本文将介绍分类与回归常用的几种损失函数，包括</p><ol><li>均方差损失 Mean Squared Loss</li><li>平均绝对误差损失 Mean Absolute Error Loss</li><li>Huber Loss</li><li>分位数损失 Quantile Loss</li><li>交叉熵损失函数 Cross Entropy Loss</li><li>Hinge 损失 Hinge Loss</li></ol><h2 id="几个概念的区分"><a href="#几个概念的区分" class="headerlink" title="几个概念的区分"></a>几个概念的区分</h2><p>在正文开始之前，先说下关于<strong>Loss Function</strong>、<strong>Cost Function</strong>和<strong>Objective Function</strong>的区别和联系。在机器学习的语境下这三个术语经常被交叉使用。</p><ul><li>损失函数 Loss Function 通常是<strong>针对单个训练样本而言</strong>，给定一个模型输出$\hat{y}$和一个真实$y$，损失函数输出一个实值损失$L&#x3D;f(y_i, \hat{y_i})$</li><li>代价函数 Cost Function 通常是<strong>针对整个训练集</strong>（或者在使用 mini-batch gradient descent 时一个 mini-batch）的总损失$J&#x3D;\frac{1}{N} \sum_{i&#x3D;1}^{N} f(y_i, \hat{y_i})$。<strong>代价函数是损失函数的期望（总和的平均）</strong>。</li><li>目标函数 Objective Function 是一个更通用的术语，表示任意希望被优化的函数，用于机器学习领域和非机器学习领域（比如运筹优化）</li></ul><p>一句话总结三者的关系就是：A loss function is a part of a cost function which is a type of an objective function.<br>由于损失函数和代价函数只是在针对样本集上有区别，因此在本文中统一使用了损失函数这个术语，但下文的相关公式实际上采用的是代价函数 Cost Function 的形式。</p><h2 id="均方差损失-Mean-Squared-Error-Loss"><a href="#均方差损失-Mean-Squared-Error-Loss" class="headerlink" title="均方差损失(Mean Squared Error Loss)"></a>均方差损失(Mean Squared Error Loss)</h2><h3 id="基本形式与原理"><a href="#基本形式与原理" class="headerlink" title="基本形式与原理"></a>基本形式与原理</h3><p>均方差（MSE）损失是机器学习、深度学习回归任务中最常用的一种损失函数，也称为 L2 Loss。其基本形式如下<br>$$J&#x3D;\frac {1}{N} \sum_{i&#x3D;1}^{N} (y_i- \hat{y_i})^2$$<br>从直觉上理解均方差损失，这个损失函数的最小值为 0（当预测等于真实值时），最大值为无穷大。下图是对于真实值$y&#x3D;0$，不同的预测值$[-1.5,1.5]$的均方差损失的变化图。横轴是不同的预测值，纵轴是均方差损失，可以看到随着预测与真实值绝对误差$|y-\hat{y}|$的增加，均方差损失呈二次方地增加。<br><img src="/images/MSE.jpg"></p><h3 id="背后的假设"><a href="#背后的假设" class="headerlink" title="背后的假设"></a>背后的假设</h3><p>实际上在一定的假设下，我们可以使用<strong>最大化似然</strong>得到均方差损失的形式。假设<strong>模型预测值与真实值之间的误差服从标准高斯分布</strong>$(\mu&#x3D;0, \sigma&#x3D;1)$，则给定一个$x_i$模型输出真实值$y_i$的概率为<br>$$p(y_i|x_i)&#x3D;\frac{1}{\sqrt{2 \pi}} exp(- \frac{(y_i - \hat{y_i})^2}{2})$$<br>进一步我们假设数据集中$N$个样本点之间相互独立，则给定所有$x$输出所有真实值$y$的概率，即似然（Likelihood），为所有$p(y_i|x_i)$的累乘<br>$$L(x,y)&#x3D;\prod_{i&#x3D;1}^N \frac{1}{\sqrt{2 \pi}} exp(- \frac{(y_i - \hat{y_i})^2}{2})$$<br>通常为了计算方便，我们通常最大化对数似然（Log-Likelihood）<br>$$LL(x,y)&#x3D;\log(L(x,y))&#x3D;-\frac{N}{2} \log2\pi-\frac{1}{2} \sum_{i&#x3D;1}^N (y_i - \hat{y_i})^2$$<br>去掉与$\hat{y_i}$无关的第一项，然后转化为最小化负对数似然（Negative Log-Likelihood）<br>$$NLL(x,y) &#x3D; \frac{1}{2} \sum_{i&#x3D;1}^N (y_i - \hat{y_i})^2$$<br>可以看到这个实际上就是均方差损失的形式。也就是说<strong>在模型输出值与真实值的误差服从高斯分布的假设下，最小化均方差损失函数与极大似然估计本质上是一致的</strong>，因此在这个假设能被满足的场景中（比如回归），均方差损失是一个很好的损失函数选择；当这个假设没能被满足的场景中（比如分类），均方差损失不是一个好的选择。</p><h2 id="平均绝对误差损失-Mean-Absolute-Error-Loss"><a href="#平均绝对误差损失-Mean-Absolute-Error-Loss" class="headerlink" title="平均绝对误差损失(Mean Absolute Error Loss)"></a>平均绝对误差损失(Mean Absolute Error Loss)</h2><h3 id="基本形式与原理-1"><a href="#基本形式与原理-1" class="headerlink" title="基本形式与原理"></a>基本形式与原理</h3><p>平均绝对误差（MAE）是另一类常用的损失函数，也称为 L1 Loss。其基本形式如下：<br>$$J &#x3D; \frac {1}{N} \sum_{i&#x3D;1}^{N} |y_i - \hat{y_i}|$$<br>同样的我们可以对这个损失函数进行可视化如下图，MAE 损失的最小值为 0（当预测等于真实值时），最大值为无穷大。可以看到随着预测与真实值绝对误差$|y-\hat{y}|$的增加，MAE 损失呈线性增长。<br><img src="/images/MAE.jpg"></p><h3 id="背后的假设-1"><a href="#背后的假设-1" class="headerlink" title="背后的假设"></a>背后的假设</h3><p>同样的我们可以在一定的假设下通过<strong>最大化似然</strong>得到MAE损失的形式，假设<strong>模型预测值与真实值之间的误差服从拉普拉斯分布（Laplace distribution）</strong>$(\mu&#x3D;0, b&#x3D;1)$，则给定一个$x_i$模型输出真实值$y_i$的概率为<br>$$p(y_i|x_i)&#x3D;\frac{1}{2} exp(- |y_i - \hat{y_i}|)$$<br>与上面推导MSE时类似，我们可以得到的负对数似然实际上就是 MAE 损失的形式<br>$$L(x,y)&#x3D;\prod_{i&#x3D;1}^N \frac{1}{2} exp(- |y_i - \hat{y_i}|)$$<br>$$LL(x,y)&#x3D;N \ln \frac{1}{2} - \sum_{i&#x3D;1}^N |y_i - \hat{y_i}|$$<br>$$NLL(x,y) &#x3D; \sum_{i&#x3D;1}^N |y_i - \hat{y_i}|$$</p><h2 id="MAE与MSE的区别"><a href="#MAE与MSE的区别" class="headerlink" title="MAE与MSE的区别"></a>MAE与MSE的区别</h2><p>MAE 和 MSE 作为损失函数的主要区别是：MSE 损失相比 MAE 通常可以更快地收敛，但 MAE 损失对于 outlier 更加健壮，即更加不易受到 outlier 影响。<br><strong>MSE 通常比 MAE 可以更快地收敛</strong>。当使用梯度下降算法时，MSE损失的梯度为$-\hat{y_i}$，而MAE的损失的梯度为$\pm 1$，即 MSE 的梯度的 scale 会随误差大小变化，而 MAE 的梯度的 scale 则一直保持为 1，即便在绝对误差$|y_i-\hat{y_i}|$很小的时候 MAE 的梯度 scale 也同样为 1，这实际上是非常不利于模型的训练的。当然你可以通过在训练过程中动态调整学习率缓解这个问题，但是总的来说，损失函数梯度之间的差异导致了 MSE 在大部分时候比 MAE 收敛地更快。这个也是 MSE 更为流行的原因。<br><strong>MAE 对于 outlier 更加 robust</strong>。我们可以从两个角度来理解这一点：</p><ul><li>第一个角度是直观地理解，下图是 MAE 和 MSE 损失画到同一张图里面，由于MAE 损失与绝对误差之间是线性关系，MSE 损失与误差是平方关系，当误差非常大的时候，MSE 损失会远远大于 MAE 损失。因此当数据中出现一个误差非常大的 outlier 时，MSE 会产生一个非常大的损失，对模型的训练会产生较大的影响。</li></ul><p><img src="/images/MSE_MAE1.jpg"></p><ul><li>第二个角度是从两个损失函数的假设出发，MSE 假设了误差服从高斯分布，MAE 假设了误差服从拉普拉斯分布。拉普拉斯分布本身对于 outlier 更加健壮。参考下图（来源：Machine Learning: A Probabilistic Perspective 2.4.3 The Laplace distribution Figure 2.8），当右图右侧出现了 outliers 时，拉普拉斯分布相比高斯分布受到的影响要小很多。因此以拉普拉斯分布为假设的 MAE 对 outlier 比高斯分布为假设的 MSE 更加 robust。</li></ul><p><img src="/images/MSE_MAE2.jpg"></p><h2 id="Huber-Loss"><a href="#Huber-Loss" class="headerlink" title="Huber Loss"></a>Huber Loss</h2><h3 id="基本形式与原理-2"><a href="#基本形式与原理-2" class="headerlink" title="基本形式与原理"></a>基本形式与原理</h3><p>上文我们分别介绍了 MSE 和 MAE 损失以及各自的优缺点，MSE 损失收敛快但容易受 outlier 影响，MAE 对 outlier 更加健壮但是收敛慢。Huber Loss 则是一种将 MSE 与 MAE 结合起来，取两者优点的损失函数，也被称作<strong>Smooth Mean Absolute Error Loss</strong>。<br>其原理很简单，就是在误差接近 0 时使用 MSE，误差较大时使用 MAE，公式为</p><p>$$J &#x3D; \begin{cases} \frac{1}{N} \sum_{i&#x3D;1}^N \frac{(y_i - \hat{y_i})^2}{2} &amp; | y_i - \hat{y_i}| \leq \delta \newline \frac{1}{N} \sum_{i&#x3D;1}^N \delta |y_i - \hat{y_i}| - \frac{1}{2} \delta^2 &amp; | y_i - \hat{y_i}| &gt; \delta \end{cases}$$</p><p>上式中$\delta$是 Huber Loss 的一个超参数，$\delta$的值是 MSE 和 MAE 两个损失连接的位置。上式等号右边第一项是 MSE 的部分，第二项是 MAE 部分，在 MAE 的部分公式为$\delta|y_i - \hat{y_i}| - \frac{1}{2} \delta^2$是为了保证误差$|y-\hat{y}|&#x3D;\pm \delta$时 MAE 和 MSE 的取值一致，进而保证 Huber Loss连续可导。<br>下图是$\delta &#x3D; 1.0$时的 Huber Loss，可以看到在$[-\delta, \delta]$的区间内实际上就是 MSE 损失，在$(-\infty, \delta)$和$(\delta, \infty)$区间内为 MAE损失。<br><img src="/images/HuberLoss.jpg"></p><h3 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h3><p>Huber Loss 结合了 MSE 和 MAE 损失，在误差接近 0 时使用 MSE，使损失函数可导并且梯度更加稳定；在误差较大时使用 MAE 可以降低 outlier 的影响，使训练对 outlier 更加健壮。缺点是需要额外地设置一个$\delta$超参数。</p><h2 id="分位数损失-Quantile-Loss"><a href="#分位数损失-Quantile-Loss" class="headerlink" title="分位数损失(Quantile Loss)"></a>分位数损失(Quantile Loss)</h2><p>分位数回归 Quantile Regression 是一类在实际应用中非常有用的回归算法，通常的回归算法是拟合目标值的期望或者中位数，而分位数回归可以通过给定不同的分位点，拟合目标值的不同分位数。例如我们可以分别拟合出多个分位点，得到一个置信区间，如下图所示。<br><img src="/images/%E5%88%86%E4%BD%8D%E6%95%B0%E5%9B%9E%E5%BD%92.jpg"><br>分位数回归是通过使用分位数损失 Quantile Loss 来实现这一点的，分位数损失形式如下，式中的$r$是分位数系数。</p><p>$$J &#x3D; \begin{cases} \frac{1}{N}\sum_{i&#x3D;1}^{N} (1-r)|y_i - \hat{y_i}| &amp;  \hat{y_i}\geq y_i \newline \frac{1}{N}\sum_{i&#x3D;1}^{N} r|y_i-\hat{y_i}| &amp; \hat{y_i}&lt; y_i \end{cases}$$</p><p>如何理解这个损失函数呢？这个损失函数是一个分段的函数 ，将$\hat{y_i} \geq y_i$（高估） 和$\hat{y_i} &lt; y_i$（低估） 两种情况分开来，并分别给予不同的系数。当$r&gt;0.5$时，低估的损失要比高估的损失更大，反过来当$r&lt;0.5$时，高估的损失比低估的损失大；分位数损失实现了<strong>分别用不同的系数控制高估和低估的损失，进而实现分位数回归</strong>。特别地，当$r&#x3D;0.5$时，分位数损失退化为 MAE 损失，从这里可以看出 MAE 损失实际上是分位数损失的一个特例 — 中位数回归（这也可以解释为什么 MAE 损失对 outlier 更鲁棒：MSE 回归期望值，MAE 回归中位数，通常 outlier 对中位数的影响比对期望值的影响小）。<br>$$J^{r&#x3D;0.5} &#x3D; \frac {1}{N} \sum_{i&#x3D;1}^{N} |y_i- \hat{y_i}|$$<br>下图是取不同的分位点 0.2、0.5、0.6 得到的三个不同的分位损失函数的可视化，可以看到 0.2 和 0.6 在高估和低估两种情况下损失是不同的，而 0.5 实际上就是 MAE。<br><img src="/images/%E5%88%86%E4%BD%8D%E6%95%B0%E6%8D%9F%E5%A4%B1.jpg"></p><h2 id="交叉熵损失-Cross-Entropy-Loss"><a href="#交叉熵损失-Cross-Entropy-Loss" class="headerlink" title="交叉熵损失(Cross Entropy Loss)"></a>交叉熵损失(Cross Entropy Loss)</h2><p>对于分类问题，最常用的损失函数是交叉熵损失函数Cross Entropy Loss。</p><h3 id="二分类"><a href="#二分类" class="headerlink" title="二分类"></a>二分类</h3><p>考虑二分类。在二分类中我们通常使用 Sigmoid 函数将模型的输出压缩到 (0, 1) 区间内$\hat{y_i} \in (0,1)$，用来表示给定输入$x_i$，模型判断为正类的概率。由于只有正负两类，因此同时也得到了负类的概率。<br>$$p(y_i &#x3D; 1 | x_i) &#x3D; \hat{y_i}$$<br>$$p(y_i &#x3D; 0 | x_i) &#x3D; 1-\hat{y_i}$$<br>将两条式子合并成一条<br>$$p(y_i | x_i) &#x3D; (\hat{y_i})^{y_i} (1-\hat{y_i})^{1-y_i}$$<br>假设数据点之间独立同分布，则似然可以表示为<br>$$L(x,y)&#x3D;\prod_{i&#x3D;1}^N (\hat{y_i})^{y_i} (1-\hat{y_i})^{1-y_i}$$<br>对似然取对数，然后加负号变成最小化负对数似然，即为交叉熵损失函数的形式<br>$$NLL(x, y)&#x3D;J_{CE}&#x3D;-\sum_{i&#x3D;1}^N\left (y_i\mathbb{log(}\hat{y_i}) + (1- y_i)\mathbb{log}(1-\hat{y_i})\right)$$<br>下图是对二分类的交叉熵损失函数的可视化，蓝线是目标值为 0 时输出不同输出的损失，黄线是目标值为 1 时的损失。可以看到约接近目标值损失越小，随着误差变差，损失呈指数增长。<br><img src="/images/CE_Loss.jpg" alt="CE Loss.jpg"></p><h3 id="多分类"><a href="#多分类" class="headerlink" title="多分类"></a>多分类</h3><p>在多分类的任务中，交叉熵损失函数的推导思路和二分类是一样的，变化的地方是真实值$y_i$现在是一个 One-hot 向量，同时模型输出的压缩由原来的 Sigmoid 函数换成 Softmax 函数。Softmax 函数将每个维度的输出范围都限定在$(0,1)$之间，同时所有维度的输出和为 1，用于表示一个概率分布。<br>$$p(y_i|x_i) &#x3D; \prod_{k&#x3D;1}^K(\hat{y_i}^k)^{y_i^k}$$<br>其中$k \in K$表示$K$个类别中的一类，同样地，假设数据点之间独立同分布，可得到负对数似然为<br>$$NLL(x,y) &#x3D; J_{CE} &#x3D; - \sum_{i&#x3D;1}^N \sum_{k&#x3D;1}^K y_i^k \log(\hat{y_i}^k)$$<br>由于$y_i$是一个 one-hot 向量，除了目标类为 1 之外其他类别上的输出都为 0，因此上式也可以写为<br>$$J_{CE} &#x3D; - \sum_{i&#x3D;1}^N y_i^{c_i} \log(\hat{y_i}^{c_i})$$<br>其中$c_i$是样本$x_i$的目标类。通常这个应用于多分类的交叉熵损失函数也被称为 Softmax Loss 或者 Categorical Cross Entropy Loss。</p><h3 id="背后的假设-2"><a href="#背后的假设-2" class="headerlink" title="背后的假设"></a>背后的假设</h3><p>分类中为什么不用均方差损失？上文在介绍均方差损失的时候讲到实际上均方差损失假设了误差服从高斯分布，在分类任务下这个假设没办法被满足，因此效果会很差。为什么是交叉熵损失呢？有两个角度可以解释这个事情，一个角度从最大似然的角度，也就是我们上面的推导；另一个角度是可以用信息论来解释交叉熵损失：</p><p>假设对于样本$x_i$存在一个最优分布$y_i^{\ast}$真实地表明了这个样本属于各个类别的概率，那么我们希望模型的输出$\hat{y_i}$尽可能地逼近这个最优分布，在信息论中，我们可以使用 KL 散度（Kullback–Leibler Divergence）来衡量两个分布的相似性。给定分布$p$和分布$q$，两者的 KL 散度公式如下<br>$$KL(p,q) &#x3D; \sum_{k&#x3D;1}^K p^k \log(p^k) - \sum_{k&#x3D;1}^K p^k \log(q^k)$$<br>其中第一项为分布$p$的信息熵，第二项为分布$p$和$q$的交叉熵。将最优分布$y_i^{\ast}$和输出分布$\hat{y_i}$带入$p$和$q$得到<br>$$KL(y_i^{\ast}, \hat{y_i}) &#x3D; \sum_{k&#x3D;1}^K y_i^{\ast k} \log(y_i^{\ast k}) - \sum_{k&#x3D;1}^K y_i^{\ast k} \log(\hat{y_i}^k)$$<br>由于我们希望两个分布尽量相近，因此我们最小化 KL 散度。同时由于上式第一项信息熵仅与最优分布本身相关，因此我们在最小化的过程中可以忽略掉，变成最小化<br>$$- \sum_{k&#x3D;1}^K y_i^{\ast k} \log(\hat{y_i}^k)$$<br>我们并不知道最优分布$y_i^{\ast}$，但训练数据里面的目标值$y_i$可以看做是$y_i^{\ast}$的一个近似分布<br>$$- \sum_{k&#x3D;1}^K y_i^{k} \log(\hat{y_i}^k)$$<br>这个是针对单个训练样本的损失函数，如果考虑整个数据集，则<br>$$J_{KL} &#x3D; - \sum_{i&#x3D;1}^N \sum_{k&#x3D;1}^K y_i^{k} \log(\hat{y_i}^k) &#x3D; - \sum_{i&#x3D;1}^N y_i^{c_i} \log(\hat{y_i}^{c_i})$$<br>可以看到<strong>通过最小化交叉熵的角度推导出来的结果和使用最大 化似然得到的结果是一致的</strong>。</p><h2 id="合页损失-Hinge-Loss"><a href="#合页损失-Hinge-Loss" class="headerlink" title="合页损失(Hinge Loss)"></a>合页损失(Hinge Loss)</h2><p>合页损失 Hinge Loss 是另外一种二分类损失函数，适用于 maximum-margin 的分类，支持向量机（SVM）模型的损失函数本质上就是 Hinge Loss + L2 正则化。合页损失的公式如下<br>$$J &#x3D; \sum_{i&#x3D;1}^N \max(0,1 - sgn(y_i)\hat{y_i})$$<br>下图是$y$为正类， 即$sgn(y)&#x3D;1$时，不同输出的合页损失示意图<br><img src="/images/%E5%90%88%E9%A1%B5%E6%8D%9F%E5%A4%B1.jpg"><br>可以看到当$y$为正类时，模型输出负值会有较大的惩罚，当模型输出为正值且在$(0,1)$区间时还会有一个较小的惩罚。即合页损失不仅惩罚预测错的，并且对于预测对了但是置信度不高的也会给一个惩罚，只有置信度高的才会有零损失。使用合页损失直觉上理解是要<strong>找到一个决策边界，使得所有数据点被这个边界正确地、高置信地被分类</strong>。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>首先是适用于回归的均方差损失（Mean Squared Loss）、平均绝对误差损失（Mean Absolute Error Loss），两者的区别以及两者相结合得到的 Huber Loss，接着是应用于分位数回归的分位数损失 Quantile Loss，表明了平均绝对误差损失实际上是分位数损失的一种特例。<br>在分类场景下，本文讨论了最常用的交叉熵损失函数 Cross Entropy Loss，包括二分类和多分类下的形式，并从信息论的角度解释了交叉熵损失函数，最后简单介绍了应用于 SVM 中的 Hinge 损失 Hinge Loss。<br>另外通常在损失函数中还会有正则项（L1&#x2F;L2 正则），这些正则项作为损失函数的一部分，通过约束参数的绝对值大小以及增加参数稀疏性来降低模型的复杂度，防止模型过拟合，这部分内容在本文中也没有详细展开。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="https://www.cs.ubc.ca/~murphyk/MLbook/" target="_blank" rel="noopener">Machine Learning: A Probabilistic Perspective</a></li><li><a href="https://rohanvarma.me/Loss-Functions/" target="_blank" rel="noopener">Picking Loss Functions - A comparison between MSE, Cross Entropy, and Hinge Loss</a></li><li><a href="https://heartbeat.fritz.ai/5-regression-loss-functions-all-machine-learners-should-know-4fb140e9d4b0" target="_blank" rel="noopener">5 Regression Loss Functions All Machine Learners Should Know</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> 算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 基础知识 </tag>
            
            <tag> 数学 </tag>
            
            <tag> 损失函数 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>DTW算法原理与实现</title>
      <link href="/2023/06/16/suan-fa/dtw-suan-fa-yuan-li-yu-shi-xian/"/>
      <url>/2023/06/16/suan-fa/dtw-suan-fa-yuan-li-yu-shi-xian/</url>
      
        <content type="html"><![CDATA[<h1 id="DTW算法原理与实现"><a href="#DTW算法原理与实现" class="headerlink" title="DTW算法原理与实现"></a>DTW算法原理与实现</h1><p>Dynamic Time Warping（动态时间规整，简称DTW）是时间序列分析的经典算法，用来比较两个时间序列之间的距离。</p><h2 id="基本原理"><a href="#基本原理" class="headerlink" title="基本原理"></a>基本原理</h2><p>DTW最初用于识别语音的相似性。我们用数字表示音调高低，例如某个单词发音的音调为1-3-2-4。现在有两个人说这个单词，一个人在前半部分拖长，其发音为1-1-3-3-2-4；另一个人在后半部分拖长，其发音为1-3-2-2-4-4。</p><p><img src="/images/%E4%B8%A4%E4%B8%AA%E5%BA%8F%E5%88%97.png"></p><p>现在要计算1-1-3-3-2-4和1-3-2-2-4-4两个序列的距离（距离越小，相似度越高）。因为两个序列代表同一个单词，所以希望算出的距离越小越好，这样把两个序列识别为同一单词的概率就越大。</p><p>先用传统方法计算两个序列的欧几里得距离，即计算两个序列各个对应的点之间的距离之和。</p><p><img src="/images/%E4%B8%A4%E4%B8%AA%E5%BA%8F%E5%88%97%E7%9A%84%E6%AC%A7%E5%BC%8F%E8%B7%9D%E7%A6%BB.png"></p><p>两个序列之间的距离计算如下述公式</p><pre class="line-numbers language-plain"><code class="language-plain">距离之和 = |A(1)-B(1)| + |A(2)-B(2)| + |A(3)-B(3)| + |A(4)-B(4)| + |A(5)-B(5)| + |A(6)-B(6)|= |1-1| + |1-3| + |3-2| + |3-2| + |2-4| + |4-4|= 6<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>如果允许序列的点与另一序列的多个连续的点相对应（相当于把这个点所代表的音调的发音时间延长），然后再计算对应点之间的距离之和。如下图：B(1)与A(1)、A(2)相对应，B(2)与A(3)、A(4)相对应，A(5)与B(3)、B(4)相对应，A(6)与B(5)、B(6)相对应。</p><p><img src="/images/%E4%B8%A4%E4%B8%AA%E5%BA%8F%E5%88%97%E7%9A%84%E8%A7%84%E6%95%B4%E8%B7%9D%E7%A6%BB.png"></p><p>规整之后两个序列之间的距离计算如下述公式</p><pre class="line-numbers language-plain"><code class="language-plain">距离之和= |A(1)-B(1)| + |A(2)-B(1)| + |A(3)-B(2)| + |A(4)-B(2)| + |A(5)-B(3)| + |A(5)-B(4)| + |A(6)-B(5)| + |A(6)-B(6)| = |1-1| + |1-1| + |3-3| + |3-3| + |2-2| + |2-2| + |4-4| + |4-4|= 0<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>把这种“可以把序列某个时刻的点跟另一序列多个连续时刻的点相对应”的做法称为时间规整（Time Warping）。现在用一个6*6矩阵M表示序列A(1-1-3-3-2-4)和序列B(1-3-2-2-4-4)各个点之间的距离，M(i, j)等于A的第i个点和B的第j个点之间的距离，即</p><p>$M(i,j)&#x3D;|A(i)-B(j)|, i \le i, j \le 6$</p><p><img src="/images/dtw_path.png"></p><p>灰色的路径表示欧氏距离对应的两个序列的点，正好是对角线；红色的路径表示时间规整方法对应的两个序列的点。</p><p>因此，DTW算法的步骤为：</p><ol><li><strong>计算两个序列各个点之间的距离矩阵。</strong></li><li><strong>寻找一条从矩阵左上角到右下角的路径，使得路径上的元素和最小。</strong></li></ol><p>称路径上的元素和为路径长度。那么如何寻找长度最小的路径呢？</p><h2 id="DTW求解"><a href="#DTW求解" class="headerlink" title="DTW求解"></a>DTW求解</h2><p>矩阵从左上角到右下角的路径长度有以下性质：</p><ol><li>当前路径长度 &#x3D; 前一步的路径长度 + 当前元素的大小</li><li>对于路径上的某个元素(i, j)，它的前一步的路径长度只可能为以下三者之一：<ul><li>左边的相邻元素 (i, j-1)</li><li>上面的相邻元素 (i-1, j)</li><li>左上方的相邻元素 (i-1, j-1)</li></ul></li></ol><p>即可使用动态规划的思想求解：</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">_traceback</span><span class="token punctuation">(</span>D<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">'''    根据代价矩阵回溯路径    '''</span>    i<span class="token punctuation">,</span> j <span class="token operator">=</span> array<span class="token punctuation">(</span>D<span class="token punctuation">.</span>shape<span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">1</span>    path <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">(</span>i<span class="token punctuation">,</span>j<span class="token punctuation">)</span><span class="token punctuation">]</span>    <span class="token keyword">while</span> <span class="token punctuation">(</span><span class="token punctuation">(</span>i <span class="token operator">></span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token operator">or</span> <span class="token punctuation">(</span>j <span class="token operator">></span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        back <span class="token operator">=</span> argmin<span class="token punctuation">(</span><span class="token punctuation">(</span>D<span class="token punctuation">[</span>i<span class="token number">-1</span><span class="token punctuation">,</span> j<span class="token number">-1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> D<span class="token punctuation">[</span>i<span class="token punctuation">,</span> j<span class="token number">-1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> D<span class="token punctuation">[</span>i<span class="token number">-1</span><span class="token punctuation">,</span> j<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span>back <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            i <span class="token operator">-=</span> <span class="token number">1</span>            j <span class="token operator">-=</span> <span class="token number">1</span>        <span class="token keyword">elif</span> <span class="token punctuation">(</span>back <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            j <span class="token operator">-=</span> <span class="token number">1</span>        <span class="token keyword">else</span><span class="token punctuation">:</span>            i <span class="token operator">-=</span> <span class="token number">1</span>        path<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">(</span>i<span class="token punctuation">,</span>j<span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> list<span class="token punctuation">(</span>reversed<span class="token punctuation">(</span>path<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">dtw_distance</span><span class="token punctuation">(</span>ts_a<span class="token punctuation">,</span> ts_b<span class="token punctuation">,</span> d<span class="token operator">=</span><span class="token keyword">lambda</span> x<span class="token punctuation">,</span>y<span class="token punctuation">:</span> abs<span class="token punctuation">(</span>x<span class="token operator">-</span>y<span class="token punctuation">)</span><span class="token punctuation">,</span> mww<span class="token operator">=</span>np<span class="token punctuation">.</span>inf<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""Computes dtw distance between two time series        Args:        ts_a: time series a        ts_b: time series b        d: distance function        mww: max warping window, int, optional (default = infinity)            Returns:        dtw distance    """</span>        <span class="token comment" spellcheck="true"># Create cost matrix via broadcasting with large int</span>    ts_a<span class="token punctuation">,</span> ts_b <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>ts_a<span class="token punctuation">)</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>ts_b<span class="token punctuation">)</span>    M<span class="token punctuation">,</span> N <span class="token operator">=</span> len<span class="token punctuation">(</span>ts_a<span class="token punctuation">)</span><span class="token punctuation">,</span> len<span class="token punctuation">(</span>ts_b<span class="token punctuation">)</span>    cost <span class="token operator">=</span> np<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">(</span>M<span class="token punctuation">,</span> N<span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># Initialize the first row and column</span>    cost<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span> d<span class="token punctuation">(</span>ts_a<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> ts_b<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> M<span class="token punctuation">)</span><span class="token punctuation">:</span>        cost<span class="token punctuation">[</span>i<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span> cost<span class="token punctuation">[</span>i<span class="token number">-1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">+</span> d<span class="token punctuation">(</span>ts_a<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span> ts_b<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    <span class="token keyword">for</span> j <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> N<span class="token punctuation">)</span><span class="token punctuation">:</span>        cost<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> j<span class="token punctuation">]</span> <span class="token operator">=</span> cost<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> j<span class="token number">-1</span><span class="token punctuation">]</span> <span class="token operator">+</span> d<span class="token punctuation">(</span>ts_a<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> ts_b<span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># Populate rest of cost matrix within window</span>    <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> M<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">for</span> j <span class="token keyword">in</span> range<span class="token punctuation">(</span>max<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> i <span class="token operator">-</span> mww<span class="token punctuation">)</span><span class="token punctuation">,</span> min<span class="token punctuation">(</span>N<span class="token punctuation">,</span> i <span class="token operator">+</span> mww<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            choices <span class="token operator">=</span> cost<span class="token punctuation">[</span>i<span class="token number">-1</span><span class="token punctuation">,</span> j<span class="token number">-1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> cost<span class="token punctuation">[</span>i<span class="token punctuation">,</span> j<span class="token number">-1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> cost<span class="token punctuation">[</span>i<span class="token number">-1</span><span class="token punctuation">,</span> j<span class="token punctuation">]</span>            cost<span class="token punctuation">[</span>i<span class="token punctuation">,</span> j<span class="token punctuation">]</span> <span class="token operator">=</span> min<span class="token punctuation">(</span>choices<span class="token punctuation">)</span> <span class="token operator">+</span> d<span class="token punctuation">(</span>ts_a<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span> ts_b<span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># Return DTW distance given window </span>    <span class="token keyword">return</span> cost<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> _traceback<span class="token punctuation">(</span>cost<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> 算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 算法知识 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>常见的最优化方法</title>
      <link href="/2023/05/13/shu-xue/chang-jian-de-zui-you-hua-fang-fa/"/>
      <url>/2023/05/13/shu-xue/chang-jian-de-zui-you-hua-fang-fa/</url>
      
        <content type="html"><![CDATA[<h1 id="常见的最优化方法"><a href="#常见的最优化方法" class="headerlink" title="常见的最优化方法"></a>常见的最优化方法</h1><p>我们每个人都会遇到各种各样的最优化问题，比如”在一定成本下，如何使利润最大化“等。<strong>最优化方法是一种数学方法，它是研究在给定约束之下如何寻求某些因素(的量)，以使某一(或某些)指标达到最优的一些学科的总称</strong>。大部分的机器学习算法的本质都是建立优化模型，通过最优化方法对目标函数（或损失函数）进行优化，从而训练出最好的模型。<br>常见的最优化方法有<strong>梯度下降法</strong>、<strong>牛顿法和拟牛顿法</strong>、<strong>共轭梯度法</strong>等等。</p><h2 id="梯度下降法"><a href="#梯度下降法" class="headerlink" title="梯度下降法"></a>梯度下降法</h2><p>梯度下降法是最早最简单，也是最为常用的最优化方法。<br>梯度下降法实现简单，当目标函数是凸函数时，梯度下降法的解是全局解。一般情况下，其解不保证是全局最优解，梯度下降法的速度也未必是最快的。<strong>梯度下降法的优化思想是用当前位置负梯度方向作为搜索方向，因为该方向为当前位置的最快下降方向，所以也被称为是”最速下降法“。最速下降法越接近目标值，步长越小，前进越慢。</strong>梯度下降法的搜索迭代示意图如下图所示：<br><img src="/images/350px-Gradient_descent.png"></p><p><strong>梯度下降法的缺点：</strong></p><ol><li>靠近极小值时收敛速度减慢，如下图所示；</li><li>直线搜索时可能会产生一些问题；</li><li>可能会“之字形”地下降。</li></ol><p><img src="/images/Banana-SteepDesc.gif"><br>从上图可以看出，梯度下降法在接近最优解的区域收敛速度明显变慢，利用梯度下降法求解需要很多次的迭代。在机器学习中，基于基本的梯度下降法发展了两种梯度下降方法，分别为<strong>随机梯度下降法</strong>和<strong>批量梯度下降法</strong>。<br>比如对一个线性回归模型，假设下面的$h(x)$是要拟合的函数，$J(\theta)$为损失函数，$\theta$是参数，要迭代求解的值，$\theta$求解出来了那最终要拟合的函数$h(\theta)$就出来了。其中$m$是训练集的样本个数，$n$是特征的个数。<br>$$h(\theta)&#x3D;\sum_{j&#x3D;0}^n \theta_j x_j$$<br>$$J(\theta)&#x3D; \frac{1}{2m} \sum_{i&#x3D;1}^m (y^i - h_{\theta}(x^i))^2$$</p><h3 id="批量梯度下降法（Batch-Gradient-Descent-BGD）"><a href="#批量梯度下降法（Batch-Gradient-Descent-BGD）" class="headerlink" title="批量梯度下降法（Batch Gradient Descent, BGD）"></a>批量梯度下降法（Batch Gradient Descent, BGD）</h3><p>将$J(\theta)$对$\theta$求偏导，得到每个$\theta$对应的的梯度：<br>$$\frac{\partial J(\theta)}{\partial \theta_j}&#x3D;- \frac{1}{m} \sum_{i&#x3D;1}^m (y^i - h_{\theta}(x^i))x_j^i$$<br>由于是要最小化代价函数，所以按每个参数$\theta$的梯度负方向，来更新每个$\theta$：<br>$$\theta_j &#x3D; \theta_j + \frac{1}{m} \sum_{i&#x3D;1}^m (y^i - h_{\theta}(x^i))x_j^i$$<br>从上面公式可以注意到，它得到的是一个全局最优解，但是<strong>每迭代一步，都要用到训练集所有的数据</strong>。如果$m$很大，那么可想而知这种方法的迭代速度会相当的慢。对于批量梯度下降法，样本个数$m$，样本$x$为$n$维向量，一次迭代需要把$m$个样本全部带入计算，迭代一次计算量为$m*n^2$。<br>所以，这就引入了另外一种方法——随机梯度下降。</p><h3 id="随机梯度下降（Stochastic-Gradient-Descent，SGD）"><a href="#随机梯度下降（Stochastic-Gradient-Descent，SGD）" class="headerlink" title="随机梯度下降（Stochastic Gradient Descent，SGD）"></a>随机梯度下降（Stochastic Gradient Descent，SGD）</h3><p>上面的代价函数可以写成如下这种形式，损失函数对应的是训练集中每个样本的梯度，而上面批量梯度下降对应的是所有的训练样本：<br>$$J(\theta)&#x3D; \frac{1}{m} \sum_{i&#x3D;1}^m \frac{1}{2} (y^i - h_{\theta}(x^i))^2 &#x3D; \frac{1}{m} \sum_{i&#x3D;1}^m \cos t(\theta, (x^i,y^i))$$<br>$$\cos t(\theta, (x^i,y^i))&#x3D;\frac{1}{2} (y^i - h_{\theta}(x^i))^2$$<br>每个样本的损失函数，对$\theta$求偏导得到对应梯度，来更新$\theta$：<br>$$\theta_j &#x3D; \theta_j +  (y^i - h_{\theta}(x^i))x_j^i$$<br>随机梯度下降是通过<strong>每个样本迭代更新一次</strong>，如果样本量很大的情况（例如几十万），那么可能只用其中几万条或者几千条的样本，就已经将$\theta$迭代到最优解了。对比上面的批量梯度下降，迭代一次需要用到十几万训练样本，一次迭代不可能最优，如果迭代10次的话就需要遍历训练样本10次。<br>但是，SGD伴随的一个问题是噪音较BGD要多，使得SGD并不是每次迭代都向着整体最优化方向。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>批量梯度下降每次迭代需要整个数据集，迭代一次计算量为$m \times n^2$，随机梯度下降每次迭代只使用一个样本，迭代一次计算量为$n^2$，当样本个数$m$很大的时候，随机梯度下降迭代一次的速度要远高于批量梯度下降方法。<br>两者的关系可以这样理解：<strong>随机梯度下降方法以损失很小的一部分精确度和增加一定数量的迭代次数为代价，换取了总体的优化效率的提升。增加的迭代次数远远小于样本的数量</strong>。<br>对批量梯度下降法和随机梯度下降法的总结：</p><ul><li>批量梯度下降—最小化所有训练样本的损失函数，使得最终求解的是全局的最优解，即求解的参数是使得代价函数最小，但是对于大规模样本问题效率低下。</li><li>随机梯度下降—最小化每条样本的损失函数，虽然不是每次迭代得到的损失函数都向着全局最优方向， 但是大的整体的方向是向全局最优解的，最终的结果往往是在全局最优解附近，适用于大规模训练样本情况。</li></ul><h2 id="牛顿法和拟牛顿法"><a href="#牛顿法和拟牛顿法" class="headerlink" title="牛顿法和拟牛顿法"></a>牛顿法和拟牛顿法</h2><h3 id="牛顿法"><a href="#牛顿法" class="headerlink" title="牛顿法"></a>牛顿法</h3><p>牛顿法是一种在实数域和复数域上近似求解方程的方法。该方法使用函数$f (x)$的泰勒级数的前面几项来寻找方程$f (x) &#x3D; 0$的根。牛顿法最大的特点就在于它的收敛速度很快。<br>首先，选择一个接近函数$f (x)$零点的$x_0$，计算相应的$f (x_0)$和切线斜率$f  \prime (x0)$（这里$f  \prime$表示函数$f$的导数）。然后我们计算穿过点$(x_0,  f  (x_0))$并且斜率为$f  \prime (x0)$的直线和$x$轴的交点的$x$坐标，也就是求如下方程的解：<br>$$x \cdot f \prime (x_0) + f(x_0) - x_0 \cdot f \prime (x_0) &#x3D; 0$$<br>我们将新求得的点的$x$坐标命名为$x_1$，通常$x_1$会比$x_0$更接近方程$f  (x) &#x3D; 0$的解。因此我们现在可以利用$x_1$开始下一轮迭代。迭代公式可化简为如下所示：<br>$$x_{n+1}&#x3D;x_n - \frac{f(x_n)}{f \prime (x_n)}$$<br>已经证明，如果$f ‘$是连续的，并且待求的零点$x$是孤立的，那么在零点$x$周围存在一个区域，只要初始值$x_0$位于这个邻近区域内，那么牛顿法必定收敛。 并且，如果$f  ‘ (x)$不为0，那么牛顿法将具有平方收敛的性能。粗略的说，这意味着每迭代一次，牛顿法结果的有效数字将增加一倍。<br>由于牛顿法是基于当前位置的切线来确定下一次的位置，所以牛顿法又被很形象地称为是**”切线法”**。牛顿法的搜索路径（二维情况）如下图所示：<br>牛顿法搜索动态示例图：<br><img src="/images/NewtonIteration_Ani.gif"><br><strong>关于牛顿法和梯度下降法的效率对比：</strong><br>从本质上去看，牛顿法是二阶收敛，梯度下降是一阶收敛，所以牛顿法就更快。<br>如果更通俗地说的话，比如你想找一条最短的路径走到一个盆地的最底部，梯度下降法每次只从你当前所处位置选一个坡度最大的方向走一步，牛顿法在选择方向时，不仅会考虑坡度是否够大，还会考虑你走了一步之后，坡度是否会变得更大。所以，可以说牛顿法比梯度下降法看得更远一点，能更快地走到最底部。（牛顿法目光更加长远，所以少走弯路；相对而言，梯度下降法只考虑了局部的最优，没有全局思想。）<br>从几何上说，牛顿法就是用一个二次曲面去拟合你当前所处位置的局部曲面，而梯度下降法是用一个平面去拟合当前的局部曲面，通常情况下，二次曲面的拟合会比平面更好，所以牛顿法选择的下降路径会更符合真实的最优下降路径。<br><img src="/images/%E7%89%9B%E9%A1%BF%E6%B3%95.png"><br>红色的牛顿法的迭代路径，绿色的是梯度下降法的迭代路径<br><strong>牛顿法的优缺点总结：</strong><br><strong>优点：</strong>二阶收敛，收敛速度快；<br><strong>缺点：</strong>牛顿法是一种迭代算法，每一步都需要求解目标函数的Hessian矩阵的逆矩阵，计算比较复杂。</p><h3 id="牛顿法为什么是二阶"><a href="#牛顿法为什么是二阶" class="headerlink" title="牛顿法为什么是二阶"></a>牛顿法为什么是二阶</h3><p>牛顿法一般应用场景：</p><ol><li>求方程的根；</li><li>求解最优化方法；</li></ol><p>上小节中牛顿法用来求方程的根，牛顿法求根是一阶算法。当牛顿法用作优化算法的时候，它就是二阶的。<br>假设我们有一个凸优化问题$\min_xf(x)$，也就是说我们要找一个$x$来最小化$f(x)$。对于凸优化问题，$f(x)$的最小值点就是$f(x)$的极值点，也就是导数为0的点。那么我们上面的优化问题就转换为了如下的求根问题：<br>$$f’(x)&#x3D;0$$<br>利用牛顿法求解上面的式子，我们先选取初始点$x_0$，然后进行如下迭代：<br>$$x_{n+1}&#x3D;x_n - \frac{f’(x_n)}{f ‘’ (x_n)}$$<br>直到$|x_{n+1}-x_n|&lt;\epsilon$停止。<br>综上，牛顿法求根是一阶算法，我们将优化问题转为求根问题需要一阶导数，所以用牛顿法进行最优化是二阶算法。</p><h3 id="拟牛顿法"><a href="#拟牛顿法" class="headerlink" title="拟牛顿法"></a>拟牛顿法</h3><p>拟牛顿法是求解非线性优化问题最有效的方法之一，于20世纪50年代由美国Argonne国家实验室的物理学家W.C.Davidon所提出来。Davidon设计的这种算法在当时看来是非线性优化领域最具创造性的发明之一。不久有人证实了这种新的算法远比其他方法快速和可靠，使得非线性优化这门学科在一夜之间突飞猛进。<br><strong>拟牛顿法的本质思想是改善牛顿法每次需要求解复杂的Hessian矩阵的逆矩阵的缺陷，它使用正定矩阵来近似Hessian矩阵的逆，从而简化了运算的复杂度。</strong><br>拟牛顿法和最速下降法一样只要求每一步迭代时知道目标函数的梯度。通过测量梯度的变化，构造一个目标函数的模型使之足以产生超线性收敛性。这类方法大大优于最速下降法，尤其对于困难的问题。另外，因为拟牛顿法不需要二阶导数的信息，所以有时比牛顿法更为有效。如今，优化软件中包含了大量的拟牛顿算法用来解决无约束，约束，和大规模的优化问题。</p><h2 id="共轭梯度法（Conjugate-Gradient）"><a href="#共轭梯度法（Conjugate-Gradient）" class="headerlink" title="共轭梯度法（Conjugate Gradient）"></a>共轭梯度法（Conjugate Gradient）</h2>]]></content>
      
      
      <categories>
          
          <category> 数学 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数学基础 </tag>
            
            <tag> 最优化 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>C++结构体</title>
      <link href="/2023/05/03/c-zhi-shi/c-jie-gou-ti/"/>
      <url>/2023/05/03/c-zhi-shi/c-jie-gou-ti/</url>
      
        <content type="html"><![CDATA[<h1 id="结构体"><a href="#结构体" class="headerlink" title="结构体"></a>结构体</h1><h2 id="1-结构体的定义和使用"><a href="#1-结构体的定义和使用" class="headerlink" title="1. 结构体的定义和使用"></a>1. 结构体的定义和使用</h2><p>语法：<code>struct 结构体名 { 结构体成员列表 };</code></p><p>创建结构体变量时，可以省略<code>struct</code>关键字</p><p>三种创建结构体变量的方式：</p><pre class="line-numbers language-cpp"><code class="language-cpp"><span class="token keyword">struct</span> Student<span class="token punctuation">{</span>    string name<span class="token punctuation">;</span>    <span class="token keyword">int</span> age<span class="token punctuation">;</span>    <span class="token keyword">float</span> score<span class="token punctuation">;</span><span class="token punctuation">}</span>s3<span class="token punctuation">;</span> <span class="token comment" spellcheck="true">// s3在定义结构体时创建结构体变量</span><span class="token comment" spellcheck="true">// struct可省略</span><span class="token keyword">struct</span> Student s1<span class="token punctuation">;</span> s1<span class="token punctuation">.</span>name <span class="token operator">=</span> <span class="token string">"张三"</span><span class="token punctuation">;</span>s1<span class="token punctuation">.</span>age <span class="token operator">=</span> <span class="token number">20</span><span class="token punctuation">;</span>s1<span class="token punctuation">.</span>score <span class="token operator">=</span> <span class="token number">89.5</span><span class="token punctuation">;</span><span class="token keyword">struct</span> Student s2 <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">"李四"</span><span class="token punctuation">,</span> <span class="token number">19</span><span class="token punctuation">,</span> <span class="token number">80.5</span><span class="token punctuation">}</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>与类（class）不同，结构体内的成员，默认是public修饰。</p><h2 id="2-结构体数组"><a href="#2-结构体数组" class="headerlink" title="2. 结构体数组"></a>2. 结构体数组</h2><p>作用：将自定义结构体存入数组中</p><h2 id="3-结构体指针"><a href="#3-结构体指针" class="headerlink" title="3. 结构体指针"></a>3. 结构体指针</h2><p>作用：通过指针访问结构体中的成员</p><p>利用<code>-&gt;</code>可以通过结构体指针访问结构体属性</p><pre class="line-numbers language-cpp"><code class="language-cpp"><span class="token keyword">struct</span> Student<span class="token punctuation">{</span>    string name<span class="token punctuation">;</span>    <span class="token keyword">int</span> age<span class="token punctuation">;</span>    <span class="token keyword">float</span> score<span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token punctuation">;</span>Student s <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">"李四"</span><span class="token punctuation">,</span> <span class="token number">19</span><span class="token punctuation">,</span> <span class="token number">80.5</span><span class="token punctuation">}</span><span class="token punctuation">;</span>Student<span class="token operator">*</span> p <span class="token operator">=</span> <span class="token operator">&amp;</span>s<span class="token punctuation">;</span>cout <span class="token operator">&lt;&lt;</span> p<span class="token operator">-</span><span class="token operator">></span>name <span class="token operator">&lt;&lt;</span> p<span class="token operator">-</span><span class="token operator">></span>age <span class="token operator">&lt;&lt;</span> p<span class="token operator">-</span><span class="token operator">></span>score <span class="token operator">&lt;&lt;</span> endl<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="4-嵌套结构体"><a href="#4-嵌套结构体" class="headerlink" title="4. 嵌套结构体"></a>4. 嵌套结构体</h2><pre class="line-numbers language-cpp"><code class="language-cpp"><span class="token keyword">struct</span> Student<span class="token punctuation">{</span>    string name<span class="token punctuation">;</span>    <span class="token keyword">int</span> age<span class="token punctuation">;</span>    <span class="token keyword">float</span> score<span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token punctuation">;</span><span class="token keyword">struct</span> Teacher<span class="token punctuation">{</span>    <span class="token keyword">int</span> id<span class="token punctuation">;</span>    string name<span class="token punctuation">;</span>    <span class="token keyword">int</span> age<span class="token punctuation">;</span>    Student stu<span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="5-结构体做函数参数"><a href="#5-结构体做函数参数" class="headerlink" title="5. 结构体做函数参数"></a>5. 结构体做函数参数</h2><p>函数参数有两种形式：1. 值传递。2. 地址传递</p><pre class="line-numbers language-cpp"><code class="language-cpp"><span class="token keyword">struct</span> Student<span class="token punctuation">{</span>    string name<span class="token punctuation">;</span>    <span class="token keyword">int</span> age<span class="token punctuation">;</span>    <span class="token keyword">float</span> score<span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">// 值传递</span><span class="token keyword">void</span> <span class="token function">myprint1</span><span class="token punctuation">(</span>Student s<span class="token punctuation">)</span><span class="token punctuation">{</span>    cout <span class="token operator">&lt;&lt;</span> s<span class="token punctuation">.</span>name <span class="token operator">&lt;&lt;</span> s<span class="token punctuation">.</span>age <span class="token operator">&lt;&lt;</span> s<span class="token punctuation">.</span>score <span class="token operator">&lt;&lt;</span> endl<span class="token punctuation">;</span> <span class="token punctuation">}</span><span class="token comment" spellcheck="true">// 地指传递</span><span class="token keyword">void</span> <span class="token function">myprint2</span><span class="token punctuation">(</span>Student<span class="token operator">*</span> s<span class="token punctuation">)</span><span class="token punctuation">{</span>    cout <span class="token operator">&lt;&lt;</span> s<span class="token operator">-</span><span class="token operator">></span>name <span class="token operator">&lt;&lt;</span> s<span class="token operator">-</span><span class="token operator">></span>age <span class="token operator">&lt;&lt;</span> s<span class="token operator">-</span><span class="token operator">></span>score <span class="token operator">&lt;&lt;</span> endl<span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token keyword">struct</span> Student s1<span class="token punctuation">;</span> s1<span class="token punctuation">.</span>name <span class="token operator">=</span> <span class="token string">"张三"</span><span class="token punctuation">;</span>s1<span class="token punctuation">.</span>age <span class="token operator">=</span> <span class="token number">20</span><span class="token punctuation">;</span>s1<span class="token punctuation">.</span>score <span class="token operator">=</span> <span class="token number">89.5</span><span class="token punctuation">;</span><span class="token function">myprint1</span><span class="token punctuation">(</span>s<span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ul><li><code>const</code>在结构体中使用，用<code>const</code>防止误操作</li></ul><pre class="line-numbers language-cpp"><code class="language-cpp"><span class="token keyword">struct</span> Student<span class="token punctuation">{</span>    string name<span class="token punctuation">;</span>    <span class="token keyword">int</span> age<span class="token punctuation">;</span>    <span class="token keyword">float</span> score<span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token punctuation">;</span><span class="token keyword">void</span> <span class="token function">myprint2</span><span class="token punctuation">(</span><span class="token keyword">const</span> Student<span class="token operator">*</span> s<span class="token punctuation">)</span><span class="token punctuation">{</span>    <span class="token comment" spellcheck="true">// s->age = 150; 报错</span>    cout <span class="token operator">&lt;&lt;</span> s<span class="token operator">-</span><span class="token operator">></span>name <span class="token operator">&lt;&lt;</span> s<span class="token operator">-</span><span class="token operator">></span>age <span class="token operator">&lt;&lt;</span> s<span class="token operator">-</span><span class="token operator">></span>score <span class="token operator">&lt;&lt;</span> endl<span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token keyword">struct</span> Student s1 <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">"李四"</span><span class="token punctuation">,</span> <span class="token number">19</span><span class="token punctuation">,</span> <span class="token number">80.5</span><span class="token punctuation">}</span><span class="token punctuation">;</span> <span class="token function">myprint2</span><span class="token punctuation">(</span>s<span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> 编程语言 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> C++ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Python打包分发工具：setuptools</title>
      <link href="/2023/04/14/python-zhi-shi/python-da-bao-fen-fa-gong-ju/"/>
      <url>/2023/04/14/python-zhi-shi/python-da-bao-fen-fa-gong-ju/</url>
      
        <content type="html"><![CDATA[<h1 id="Python打包工具setuptools介绍"><a href="#Python打包工具setuptools介绍" class="headerlink" title="Python打包工具setuptools介绍"></a>Python打包工具setuptools介绍</h1><p>setuptools库的前身是distutils（一个python标准库），<strong>setuptools本身不是标准库，所以需要自行安装</strong>。setuptools提供的主要的功能有：</p><ul><li><strong>python库的打包分发</strong></li><li><strong>依赖包安装与版本管理</strong></li><li><strong>python环境限制</strong></li><li><strong>生成脚本</strong></li><li><strong>c&#x2F;c++ 拓展</strong></li></ul><h2 id="库的打包分发"><a href="#库的打包分发" class="headerlink" title="库的打包分发"></a>库的打包分发</h2><p>python库的打包分发方式有两种：<strong>源码包source dist</strong>（简称sdist）、<strong>二进制包binary dist</strong>（简称bdist）。<br>源码包sdist就是我们熟悉的 .zip 、.tar.gz 等后缀文件。就是一个压缩包，里面包含了所需要的的所有源码文件以及一些静态文件（txt文本、css、图片等）。常见的格式有：</p><table><thead><tr><th>格式</th><th>后缀</th></tr></thead><tbody><tr><td>zip</td><td>.zip</td></tr><tr><td>gztar</td><td>.tar.gz</td></tr><tr><td>bztar</td><td>.tar.bz2</td></tr><tr><td>ztar</td><td>.tar.Z</td></tr><tr><td>tar</td><td>.tar</td></tr></tbody></table><p>二进制包格式是wheel（.whl后缀），它的前身是egg。wheel本质也还是一个压缩包，可以像像zip一样解压缩。<strong>与源码包相比，二进制包的特点是不用再编译，也就是安装更快！</strong></p><table><thead><tr><th>格式</th><th>后缀</th></tr></thead><tbody><tr><td>egg</td><td>.egg</td></tr><tr><td>wheel</td><td>.whl</td></tr></tbody></table><h3 id="源码包sdist"><a href="#源码包sdist" class="headerlink" title="源码包sdist"></a>源码包sdist</h3><p>打包分发源码包命令</p><pre class="line-numbers language-shell"><code class="language-shell">$ python setup.py sdist --formats=gztar<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><code>setup.py</code>指定了打包分发的配置信息。<code>--formats</code> 参数用来指定压缩格式，若不指定format格式，那么 sdist 将根据当前平台创建默认格式：在类 Unix 平台上，将创建后缀名为.tar.gz分发包，而在Windows上为 .zip 文件。<br>安装源码包命令。安装源码包有两种方法，先解压缩源码包，或者直接安装源码包。</p><ol><li>先解压缩源码包，再执行setup.py。</li></ol><pre class="line-numbers language-shell"><code class="language-shell">$ python setup.py install等价于$ python setup.py build$ python setup.py install<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><ol start="2"><li>直接pip安装源码包</li></ol><pre class="line-numbers language-shell"><code class="language-shell">$ pip install  xxx.tar.gz<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="二进制包bdist"><a href="#二进制包bdist" class="headerlink" title="二进制包bdist"></a>二进制包bdist</h3><p>打包分发二进制包命令。</p><table><thead><tr><th>命令</th><th>format参数</th><th>note</th></tr></thead><tbody><tr><td>bdist_dumb</td><td>tar,gztar,zip……</td><td>windows默认zip，Unix默认gztar</td></tr><tr><td>bdist_rpm</td><td>rpm,srpm</td><td></td></tr><tr><td>bdist_wininst</td><td>wininst</td><td></td></tr><tr><td>bdist_wheel</td><td>wheel</td><td>目前主流的二进制包，需要先安装wheel</td></tr><tr><td>bdist_egg</td><td>egg</td><td></td></tr></tbody></table><pre class="line-numbers language-shell"><code class="language-shell">$ python setup.py bdist_wheel<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>安装二进制包命令</p><pre class="line-numbers language-shell"><code class="language-shell">$ pip install xxx.whl<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="eggs-与-wheels-有什么区别？"><a href="#eggs-与-wheels-有什么区别？" class="headerlink" title="eggs 与 wheels 有什么区别？"></a>eggs 与 wheels 有什么区别？</h3><p>Egg 格式是由 setuptools 在 2004 年引入，而 Wheel 格式是由 PEP427 在 2012 年定义。Wheel 的出现是为了替代 Egg，它的本质是一个zip包，其现在被认为是 Python 的二进制包的标准格式。<br>以下是 Wheel 和 Egg 的主要区别：</p><ul><li>Wheel 有一个官方的 PEP427 来定义，而 Egg 没有 PEP 定义</li><li>Wheel 是一种分发格式，即打包格式。而 Egg 既是一种分发格式，也是一种运行时安装的格式，并且是可以被直接 import</li><li>Wheel 文件不会包含 .pyc 文件</li><li>Wheel 使用和 PEP376 兼容的 .dist-info 目录，而 Egg 使用 .egg-info 目录</li><li>Wheel 有着更丰富的命名规则。</li><li>Wheel 是有版本的。每个 Wheel 文件都包含 wheel 规范的版本和打包的实现</li><li>Wheel 在内部被 sysconfig path type 管理，因此转向其他格式也更容易</li></ul><p>上面我们讲述了python打包分发的两种方法，很容易发现整个打包过程最重要的就是setup.py，它指定了重要的配置信息。包含以下信息：</p><ul><li><strong>python库的基本信息（作者、联系方式、当前库的版本等）</strong></li><li><strong>需要打包的文件</strong></li><li><strong>依赖包安装与版本管理</strong></li><li><strong>python环境限制</strong></li><li><strong>生成脚本</strong></li><li><strong>c&#x2F;c++ 拓展</strong></li><li><strong>cmdclass自定义命令行为</strong></li></ul><h2 id="setup函数的配置信息"><a href="#setup函数的配置信息" class="headerlink" title="setup函数的配置信息"></a>setup函数的配置信息</h2><p>setup.py 的参数非常多，能够不借助文档写好一个setup.py好像没那么简单。<br><img src="/images/setuptools.png"></p><h3 id="python库的基本信息"><a href="#python库的基本信息" class="headerlink" title="python库的基本信息"></a><strong>python库的基本信息</strong></h3><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> setuptools <span class="token keyword">import</span> setup<span class="token keyword">def</span> <span class="token function">readme</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">with</span> open<span class="token punctuation">(</span><span class="token string">'README.md'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>        content <span class="token operator">=</span> f<span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> contentsetup<span class="token punctuation">(</span>    name <span class="token operator">=</span> <span class="token string">'myapp'</span><span class="token punctuation">,</span> <span class="token comment" spellcheck="true"># 包名称</span>    version <span class="token operator">=</span> <span class="token string">'1.0'</span><span class="token punctuation">,</span> <span class="token comment" spellcheck="true"># 版本</span>    author <span class="token operator">=</span> <span class="token string">'lihua'</span><span class="token punctuation">,</span> <span class="token comment" spellcheck="true"># 作者</span>    author_email <span class="token operator">=</span> <span class="token string">'lihua@163.com'</span><span class="token punctuation">,</span> <span class="token comment" spellcheck="true"># 作者邮箱</span>    description<span class="token operator">=</span><span class="token string">'a example for pack python'</span><span class="token punctuation">,</span> <span class="token comment" spellcheck="true"># 描述</span>    long_description<span class="token operator">=</span>readme<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token comment" spellcheck="true"># 长文描述</span>    long_description_content_type<span class="token operator">=</span><span class="token string">'text/markdown'</span><span class="token punctuation">,</span> <span class="token comment" spellcheck="true"># 长文描述的文本格式</span>    keywords<span class="token operator">=</span><span class="token string">'pack'</span><span class="token punctuation">,</span> <span class="token comment" spellcheck="true"># 关键词</span>    url<span class="token operator">=</span><span class="token string">'https://github.com/lihua/myapp'</span><span class="token punctuation">,</span> <span class="token comment" spellcheck="true"># 项目主页</span>    classifiers<span class="token operator">=</span><span class="token punctuation">[</span> <span class="token comment" spellcheck="true"># 包的分类信息，见https://pypi.org/pypi?%3Aaction=list_classifiers</span>            <span class="token string">'Development Status :: 5 - Production/Stable'</span><span class="token punctuation">,</span>            <span class="token string">'License :: OSI Approved :: Apache Software License'</span><span class="token punctuation">,</span>            <span class="token string">'Operating System :: OS Independent'</span><span class="token punctuation">,</span>            <span class="token string">'Programming Language :: Python :: 3'</span><span class="token punctuation">,</span>            <span class="token string">'Programming Language :: Python :: 3.6'</span><span class="token punctuation">,</span>            <span class="token string">'Programming Language :: Python :: 3.7'</span><span class="token punctuation">,</span>            <span class="token string">'Programming Language :: Python :: 3.8'</span><span class="token punctuation">,</span>            <span class="token string">'Programming Language :: Python :: 3.9'</span><span class="token punctuation">,</span>        <span class="token punctuation">]</span><span class="token punctuation">,</span>    license<span class="token operator">=</span><span class="token string">'Apache License 2.0'</span><span class="token punctuation">,</span> <span class="token comment" spellcheck="true"># 许可证</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="需要打包的文件"><a href="#需要打包的文件" class="headerlink" title="需要打包的文件"></a>需要打包的文件</h2><p>通过setup函数的这些参数<code>packages</code>、<code>include_package_data</code>（其实就是MANIFEST.in文件）、<code>exclude_package_data</code>、<code>package_data</code>、<code>data_files</code>来指定需要打包的文件。<br>包含的文件如下：</p><ul><li><code>py_modules</code>和<code>packages</code>参数中所有 Python 源文件</li><li><code>ext_modules</code>或是<code>libraries</code> 参数中提到的所有 C 源文件</li><li><code>scripts</code> 参数指定的脚本</li><li><code>package_data</code>和<code>data_files</code> 参数指定的所有文件</li><li><code>setup.cfg</code>和<code>setup.py</code></li><li>类似于readme的文件（如README、README.txt、 README.rst、README.md）</li><li><code>MANIFEST.in</code> 中指定的所有文件</li></ul><h3 id="packages参数"><a href="#packages参数" class="headerlink" title="packages参数"></a>packages参数</h3><p>packages参数就是用来指示打包分发时需要包含的package，类型<strong>为list[str]<strong>。</strong>但是它不会递归的打包子package！只打包当前package！</strong><br>所以setuptools提供了两个函数<code>find_namespace_packages()</code>，<code>find_packages</code>来快速找到所有的package。<br><strong>python中的packages有两种</strong>，一种是包含__init__.py的文件夹（姑且叫做<strong>普通package</strong>），一种是不含__init__.py的文件夹（这是python3引入的<strong>Namespace Packages</strong>命名空间包）。<br>顾名思义，<code>find_packages</code>只会打包内含__init__.py的package。可以给<code>find_namespace_packages</code>传递参数以指定在哪个文件夹下进行搜索，比如<code>setup(packages=find_namespace_packages(&#39;src&#39;))</code>。</p><h3 id="打包非源码文件"><a href="#打包非源码文件" class="headerlink" title="打包非源码文件"></a>打包非源码文件</h3><p>上面这些例子中都没有包含非源码文件（如.dat和.txt文件），需要通过别的参数<code>include_package_data</code>（其实就是<code>MANIFEST.in</code>文件）、<code>exclude_package_data</code>、<code>package_data</code>来打包<strong>非源码文件。</strong></p><h4 id="include-package-data参数"><a href="#include-package-data参数" class="headerlink" title="include_package_data参数"></a>include_package_data参数</h4><p>include_package_data是bool类型，默认值为True。<strong>当为True时，将根据</strong><code>MANIFEST.in</code><strong>文件来打包分发库</strong>。<br><code>MANIFEST.in</code>文件指定了一些语法规则，主要是用来打包非源码文件的，语法规则如下：</p><table><thead><tr><th>命令</th><th>描述</th></tr></thead><tbody><tr><td>include pat1 pat2 …</td><td>添加与任何列出的模式匹配的所有文件（文件必须作为相对于项目根目录的路径给出）</td></tr><tr><td>exclude pat1 pat2 …</td><td>删除与任何列出的模式匹配的所有文件（文件必须作为相对于项目根目录的路径给出）</td></tr><tr><td>recursive-include dir-pattern pat1 pat2 …</td><td>递归dir-pattern及其子文件夹，添加与任何列出的模式匹配的目录下的所有文件</td></tr><tr><td>recursive-exclude dir-pattern pat1 pat2 …</td><td>递归dir-pattern及其子文件夹，删除与任何列出的模式匹配的目录下的所有文件</td></tr><tr><td>global-include pat1 pat2 …</td><td>在源树中的任何位置添加与任何列出的模式匹配的所有文件</td></tr><tr><td>global-exclude pat1 pat2 …</td><td>删除源树中与任何列出的模式匹配的所有文件</td></tr><tr><td>graft dir-pattern</td><td>添加匹配目录下的所有文件 dir-pattern</td></tr><tr><td>prune dir-pattern</td><td>删除匹配目录下的所有文件 dir-pattern</td></tr></tbody></table><pre class="line-numbers language-txt"><code class="language-txt">└── D:\workplace\python\pack_test    ├──setup.py    ├──MANIFEST.in    ├──debug    │   ├──debug.py    ├──src    │   ├──__init__.py    │   ├──pack1        │    ├──__init__.py        │    ├──main.py        │    ├──config.txt             ├──data             │   ├──main.py             │   ├──a.dat<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>则<code>MANIFEST.in</code>文件的内容如下：</p><pre class="line-numbers language-txt"><code class="language-txt"># 递归遍历当前文件夹，找到符合*.dat、*.txt的文件recursive-include . *.txt *.dat # 或者include src/pack1/*.txtinclude src/pack1/data/*.dat<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="package-data参数"><a href="#package-data参数" class="headerlink" title="package_data参数"></a>package_data参数</h4><p>还可以通过package_data参数来指定，这边建议还是统一用<code>MANIFEST.in</code>文件的方式，免得造成不一致性。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> setuptools <span class="token keyword">import</span> setupsetup<span class="token punctuation">(</span>package_data<span class="token operator">=</span><span class="token punctuation">{</span><span class="token string">''</span><span class="token punctuation">:</span><span class="token punctuation">[</span><span class="token string">'*.txt'</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token string">'src.pk1'</span><span class="token punctuation">:</span><span class="token punctuation">[</span><span class="token string">'*.dat'</span><span class="token punctuation">]</span><span class="token punctuation">}</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 其中''表示所有文件夹下</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h4 id="exclude-package-data参数"><a href="#exclude-package-data参数" class="headerlink" title="exclude_package_data参数"></a>exclude_package_data参数</h4><p>顾名思义就是去除文件</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> setuptools <span class="token keyword">import</span> setupsetup<span class="token punctuation">(</span>exclude_package_data<span class="token operator">=</span><span class="token punctuation">{</span><span class="token string">'src.pk1'</span><span class="token punctuation">:</span><span class="token punctuation">[</span><span class="token string">'*.txt'</span><span class="token punctuation">]</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h2 id="依赖包安装与版本管理"><a href="#依赖包安装与版本管理" class="headerlink" title="依赖包安装与版本管理"></a><strong>依赖包安装与版本管理</strong></h2><p>一个项目库可能会依赖于很多其他库，比如安装pandas，该库依赖于numpy。当用pip或conda这些命令安装时，从来不用操心哪些依赖包需要安装，它们的版本限制是怎么样的，而这些信息是setuptools打包分发库时就确定的。所以当setuptools打包分发库时，<strong>要指定依赖包有哪些？它们又有什么限制？</strong><br>针对依赖包安装与版本管理这项功能，setup函数提供了一些参数<code>install_requires</code>、<code> setup_requires</code>、<code>tests_require</code> 、<code>extras_require</code>。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> setuptools <span class="token keyword">import</span> setup<span class="token punctuation">,</span> find_packagessetup<span class="token punctuation">(</span>    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>    <span class="token comment" spellcheck="true"># 表明当前模块依赖哪些包，若环境中没有，则会从pypi中自动下载安装！！！</span>    install_requires<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'docutils>=0.3'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>    <span class="token comment" spellcheck="true"># setup.py 本身要依赖的包，这通常是为一些setuptools的插件准备的配置，这里列出的包，不会自动安装。</span>    setup_requires<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'pbr'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>    <span class="token comment" spellcheck="true"># 仅在测试时需要使用的依赖，在正常发布的代码中是没有用的。</span>    <span class="token comment" spellcheck="true"># 在执行python setup.py test时，可以自动安装这三个库，确保测试的正常运行。</span>    tests_require<span class="token operator">=</span><span class="token punctuation">[</span>        <span class="token string">'pytest>=3.3.1'</span><span class="token punctuation">,</span>        <span class="token string">'pytest-cov>=2.5.1'</span><span class="token punctuation">,</span>    <span class="token punctuation">]</span><span class="token punctuation">,</span>    <span class="token comment" spellcheck="true"># install_requires 在安装模块时会自动安装依赖包</span>    <span class="token comment" spellcheck="true"># 而 extras_require 不会，这里仅表示该模块会依赖这些包</span>    <span class="token comment" spellcheck="true"># 但是这些包通常不会使用到，只有当你深度使用模块时，才会用到，这里需要你手动安装</span>    extras_require<span class="token operator">=</span><span class="token punctuation">{</span>        <span class="token string">'PDF'</span><span class="token punctuation">:</span>  <span class="token punctuation">[</span><span class="token string">"ReportLab>=1.2"</span><span class="token punctuation">,</span> <span class="token string">"RXP"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token string">'reST'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">"docutils>=0.3"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>    <span class="token punctuation">}</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>关于 install_requires， 有以下四种常用的表示方法：</p><ol><li><code>argparse</code>：只包含包名。 这种形式只检查包的存在性，不检查版本。 方便，但不利于控制风险。</li><li><code>setuptools==38.2.4</code>，指定版本。 这种形式把风险降到了最低，确保了开发、测试与部署的版本一致，不会出现意外。 缺点是不利于更新，每次更新都需要改动代码。</li><li><code>docutils &gt;= 0.3</code>，这是比较常用的形式。 当对某个库比较信任时，这种形式可以自动保持版本为最新。</li><li><code>Django &gt;= 1.11, != 1.11.1, &lt;= 2</code>，这是比较复杂的形式。 如这个例子，保证了Django的大版本在1.11和2之间，也即1.11.x；并且，排除了已知有问题的版本1.11.1（仅举例）。 对于一些大型、复杂的库，这种形式是最合适的。</li></ol><h3 id="python环境限制"><a href="#python环境限制" class="headerlink" title="python环境限制"></a>python环境限制</h3><pre class="line-numbers language-python"><code class="language-python">setup<span class="token punctuation">(</span>python_requires<span class="token operator">=</span><span class="token string">'>=2.7, &lt;=3'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="生成脚本"><a href="#生成脚本" class="headerlink" title="生成脚本"></a>生成脚本</h2><p>有时候我们的库包含了一些非常重要的功能，每次都提供python XXX.py来运行不太方便，最好是把脚本放入系统环境path，以命令行的形式来执行。比如tensorRT就提供了trtexec命令。<br>那么setup函数提供了entry_points和scripts这两个参数。它们的区别在于：</p><ul><li>entry_points是把<strong>python文件中的函数</strong>自动生成为可执行脚本</li><li>scripts是把**.sh、.py等可执行脚本**生成到系统path中</li></ul><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> setuptools <span class="token keyword">import</span> setupsetup<span class="token punctuation">(</span>    …………    <span class="token comment" spellcheck="true"># 把python中的函数自动生成为一个可执行的脚本</span>    <span class="token comment" spellcheck="true"># 如下：把fool.main文件中的main函数自动生成为一个可执行脚本，可以通过命令foo执行该脚本</span>    entry_points<span class="token operator">=</span><span class="token punctuation">{</span>        <span class="token string">'console_scripts'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span> <span class="token comment" spellcheck="true"># key值为console_scripts</span>            <span class="token string">'foo = foo.main:main'</span> <span class="token comment" spellcheck="true"># 格式为'命令名 = 模块名:函数名'</span>        <span class="token punctuation">]</span>    <span class="token punctuation">}</span><span class="token punctuation">,</span>    <span class="token comment" spellcheck="true"># 将 bin/foo.sh 和 bar.py 脚本，生成到系统 PATH中</span>    <span class="token comment" spellcheck="true"># 执行 python setup.py install 后</span>    <span class="token comment" spellcheck="true"># 会生成 如 /usr/bin/foo.sh 和 如 /usr/bin/bar.py</span>    scripts<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'bin/foo.sh'</span><span class="token punctuation">,</span> <span class="token string">'bar.py'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="C-C-扩展"><a href="#C-C-扩展" class="headerlink" title="C&#x2F;C++扩展"></a>C&#x2F;C++扩展</h2><p>编译c&#x2F;c++拓展源码的命令为：<code>python setup.py build_ext --inplace</code>。或者直接<code>python setup.py build</code>该命令包括了build_ext步骤。那么我们该如何指导编译器编译c&#x2F;c++源码呢。<br>本质上setuptools是根据setup.py配置来<strong>指导生成gcc命令行</strong>，当然你也可以粗暴地直接用gcc命令行来编译c&#x2F;c++拓展源码，但工程量太大，setuptools支持很多混合编程技术cython、SWIG等等。所以甭管你采用什么混合编程技术，绕不开setuptools。setuptools编译c&#x2F;c++拓展源码的过程主要是把<strong>源代码</strong>编译成<strong>动态连接库</strong>（linux下是**.so<strong>，windows下是</strong>.pyd<strong>）。这样就可以在.py中愉快import并使用拓展模块了。<br>主要看setup函数的</strong>ext_modules<strong>参数，该参数type为list[setuptools.Extension]。所以编译核心就在于这个</strong>setuptools.Extension<strong>类，该类只支持</strong>c&#x2F;c++**拓展，要实现cuda拓展需要自定义Extension类，如pytorch的CUDAExtension。<br>setuptools.Extension类有几个重要的构造参数。</p><ul><li>name：在python中import该拓展的名称</li><li>sources：源代码文件名</li><li>language：默认’c’，如果要用C++，改成’c++’</li><li>include_dirs：其实就是传递给 gcc 的 -I(大写i)指定include的头文件目录</li><li>library_dirs：其实就是传递给 gcc 的 -L 指定连接文件的目录</li><li>libraries：其实就是传给 gcc 的 -l(小写的L)指定连接文件，在L指定的位置找</li><li>extra_compile_args：其实传给 gcc 的额外的编译参数，比方’-std&#x3D;c++11’</li><li>extra_link_args：其实传给 gcc 的额外的链接参数（生成动态链接库）</li><li>define_macros：定义宏</li><li>undef_macros：取消定义宏</li></ul><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> setuptools <span class="token keyword">import</span> setup<span class="token punctuation">,</span>Extensionsetup<span class="token punctuation">(</span> ext_modules<span class="token operator">=</span><span class="token punctuation">[</span>    Extension<span class="token punctuation">(</span>        name<span class="token operator">=</span><span class="token string">'foo'</span><span class="token punctuation">,</span>  <span class="token comment" spellcheck="true"># type=str。并且还支持层级命名，如myapp.foo</span>        <span class="token comment" spellcheck="true"># type=list[str]。源代码的文件名，可以用glob.glob查找所有.c文件</span>        sources<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'foo/csrc/foo1.c'</span><span class="token punctuation">,</span><span class="token string">'foo/csrc/foo2.c'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>          include_dirs<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'foo'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token comment" spellcheck="true"># type=list[str]。拓展include头文件，相当于传递给gcc -I </span>        <span class="token punctuation">)</span><span class="token punctuation">]</span>    <span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>setuptools.Extension用define_macros 和 undef_macros构造参数来定义或取消定义宏。define_macros的type为list[tuple( name:str , value:str|None )] 。值为 None 的宏 FOO 等价于#define FOO ，否则等价于# define FOO value值 。undef_macros 同理，等价于#undef FOO 。</p><pre class="line-numbers language-python"><code class="language-python">Extension<span class="token punctuation">(</span>define_macros<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token string">'NDEBUG'</span><span class="token punctuation">,</span> <span class="token string">'1'</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token string">'HAVE_STRFTIME'</span><span class="token punctuation">,</span> None<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span>          undef_macros<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'HAVE_FOO'</span><span class="token punctuation">,</span> <span class="token string">'HAVE_BAR'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>上面的代码相当于在每个C文件前加上了：</p><pre class="line-numbers language-c"><code class="language-c"><span class="token macro property">#<span class="token directive keyword">define</span> NDEBUG 1</span><span class="token macro property">#<span class="token directive keyword">define</span> HAVE_STRFTIME</span><span class="token macro property">#<span class="token directive keyword">undef</span> HAVE_FOO</span><span class="token macro property">#<span class="token directive keyword">undef</span> HAVE_BAR</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> 编程语言 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
            <tag> 工具 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Pytorch|动态计算图</title>
      <link href="/2023/04/10/pytorch-ji-chu-zhi-shi/05-dong-tai-ji-suan-tu/"/>
      <url>/2023/04/10/pytorch-ji-chu-zhi-shi/05-dong-tai-ji-suan-tu/</url>
      
        <content type="html"><![CDATA[<h1 id="Pytorch的动态图简介"><a href="#Pytorch的动态图简介" class="headerlink" title="Pytorch的动态图简介"></a>Pytorch的动态图简介</h1><p>本节我们将介绍 Pytorch的动态计算图。<br>包括： </p><ul><li>动态计算图简介</li><li>计算图中的Function</li><li>计算图和反向传播</li><li>叶子节点和非叶子节点</li></ul><h2 id="动态计算图简介"><a href="#动态计算图简介" class="headerlink" title="动态计算图简介"></a>动态计算图简介</h2><p>Pytorch的计算图由节点和边组成，节点表示张量或者Function，边表示张量和Function之间的依赖关系。<br>Pytorch中的计算图是动态图。这里的动态主要有两重含义。</p><ol><li>计算图的正向传播是立即执行的。无需等待完整的计算图创建完毕，每条语句都会在计算图中动态添加节点和边，并立即执行正向传播得到计算结果。</li><li>计算图在反向传播后立即销毁，下次调用需要重新构建计算图。如果在程序中使用了backward方法执行了反向传播，或者利用torch.autograd.grad方法计算了梯度，那么创建的计算图会被立即销毁，释放存储空间，下次调用需要重新创建。</li></ol><p><strong>计算图的正向传播是立即执行的</strong>。</p><pre class="line-numbers language-python"><code class="language-python">w <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">3.0</span><span class="token punctuation">,</span><span class="token number">1.0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>b <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">3.0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>X <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span>Y <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>Y_hat <span class="token operator">=</span> X@w<span class="token punctuation">.</span>t<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> b  <span class="token comment" spellcheck="true"># Y_hat定义后其正向传播被立即执行，与其后面的loss创建语句无关</span>loss <span class="token operator">=</span> torch<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>pow<span class="token punctuation">(</span>Y_hat<span class="token operator">-</span>Y<span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>loss<span class="token punctuation">.</span>data<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>Y_hat<span class="token punctuation">.</span>data<span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span>Output<span class="token punctuation">:</span>tensor<span class="token punctuation">(</span><span class="token number">36.4831</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.0435</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">3.1951</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">5.3738</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">4.2230</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">14.0631</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">1.2098</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">4.8157</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">2.8586</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">3.0681</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">8.1599</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>计算图在反向传播后立即销毁。</strong><br>计算图在反向传播后立即销毁，如果需要保留计算图, 需要设置<code>retain_graph = True</code>。</p><pre class="line-numbers language-python"><code class="language-python">w <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">3.0</span><span class="token punctuation">,</span><span class="token number">1.0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>b <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">3.0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>X <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span>Y <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>Y_hat <span class="token operator">=</span> X@w<span class="token punctuation">.</span>t<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> b  <span class="token comment" spellcheck="true"># Y_hat定义后其正向传播被立即执行，与其后面的loss创建语句无关</span>loss <span class="token operator">=</span> torch<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>pow<span class="token punctuation">(</span>Y_hat<span class="token operator">-</span>Y<span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true">#loss.backward(retain_graph = True) </span><span class="token comment" spellcheck="true">#loss.backward() #如果再次执行反向传播将报错</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="计算图中的Function"><a href="#计算图中的Function" class="headerlink" title="计算图中的Function"></a>计算图中的Function</h2><p>计算图中的张量我们已经比较熟悉了，计算图中的另外一种节点是Function，实际上就是 Pytorch中各种对张量操作的函数。<br>这些Function和我们Python中的函数有一个较大的区别，那就是它同时包括正向计算逻辑和反向传播的逻辑。我们可以通过继承<code>torch.autograd.Function</code>来创建这种支持反向传播的Function。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">MyReLU</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>autograd<span class="token punctuation">.</span>Function<span class="token punctuation">)</span><span class="token punctuation">:</span>       <span class="token comment" spellcheck="true">#正向传播逻辑，可以用ctx存储一些值，供反向传播使用。</span>    @staticmethod    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>ctx<span class="token punctuation">,</span> input<span class="token punctuation">)</span><span class="token punctuation">:</span>        ctx<span class="token punctuation">.</span>save_for_backward<span class="token punctuation">(</span>input<span class="token punctuation">)</span>        <span class="token keyword">return</span> input<span class="token punctuation">.</span>clamp<span class="token punctuation">(</span>min<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">#反向传播逻辑</span>    @staticmethod    <span class="token keyword">def</span> <span class="token function">backward</span><span class="token punctuation">(</span>ctx<span class="token punctuation">,</span> grad_output<span class="token punctuation">)</span><span class="token punctuation">:</span>        input<span class="token punctuation">,</span> <span class="token operator">=</span> ctx<span class="token punctuation">.</span>saved_tensors        grad_input <span class="token operator">=</span> grad_output<span class="token punctuation">.</span>clone<span class="token punctuation">(</span><span class="token punctuation">)</span>        grad_input<span class="token punctuation">[</span>input <span class="token operator">&lt;</span> <span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0</span>        <span class="token keyword">return</span> grad_input<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python">w <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">3.0</span><span class="token punctuation">,</span><span class="token number">1.0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>b <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">3.0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>X <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1.0</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">1.0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">1.0</span><span class="token punctuation">,</span><span class="token number">1.0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>Y <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">2.0</span><span class="token punctuation">,</span><span class="token number">3.0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>relu <span class="token operator">=</span> MyReLU<span class="token punctuation">.</span>apply <span class="token comment" spellcheck="true"># relu现在也可以具有正向传播和反向传播功能</span>Y_hat <span class="token operator">=</span> relu<span class="token punctuation">(</span>X@w<span class="token punctuation">.</span>t<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> b<span class="token punctuation">)</span>loss <span class="token operator">=</span> torch<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>pow<span class="token punctuation">(</span>Y_hat<span class="token operator">-</span>Y<span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>w<span class="token punctuation">.</span>grad<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>b<span class="token punctuation">.</span>grad<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>Y_hat<span class="token punctuation">.</span>grad_fn<span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span>Output<span class="token punctuation">:</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">4.5000</span><span class="token punctuation">,</span> <span class="token number">4.5000</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">4.5000</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">&lt;</span>torch<span class="token punctuation">.</span>autograd<span class="token punctuation">.</span>function<span class="token punctuation">.</span>MyReLUBackward object at <span class="token number">0x7f6979f47200</span><span class="token operator">></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="计算图与反向传播"><a href="#计算图与反向传播" class="headerlink" title="计算图与反向传播"></a>计算图与反向传播</h2><p>了解了Function的功能，我们可以简单地理解一下反向传播的原理和过程。理解该部分原理需要一些高等数学中求导链式法则的基础知识。</p><pre class="line-numbers language-python"><code class="language-python">x <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token number">3.0</span><span class="token punctuation">,</span>requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>y1 <span class="token operator">=</span> x <span class="token operator">+</span> <span class="token number">1</span>y2 <span class="token operator">=</span> <span class="token number">2</span><span class="token operator">*</span>xloss <span class="token operator">=</span> <span class="token punctuation">(</span>y1<span class="token operator">-</span>y2<span class="token punctuation">)</span><span class="token operator">**</span><span class="token number">2</span>loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><code>loss.backward()</code>语句调用后，依次发生以下计算过程。</p><ol><li>loss自己的grad梯度赋值为1，即对自身的梯度为1。</li><li>loss根据其自身梯度以及关联的backward方法，计算出其对应的自变量即y1和y2的梯度，将该值赋值到y1.grad和y2.grad。</li><li>y2和y1根据其自身梯度以及关联的backward方法, 分别计算出其对应的自变量x的梯度，x.grad将其收到的多个梯度值累加。</li></ol><p>注意，1,2,3步骤的求梯度顺序和对多个梯度值的累加规则恰好是求导链式法则的程序表述。<br>正因为求导链式法则衍生的梯度累加规则，张量的grad梯度不会自动清零，在需要的时候需要手动置零。</p><h2 id="叶子节点和非叶子节点"><a href="#叶子节点和非叶子节点" class="headerlink" title="叶子节点和非叶子节点"></a>叶子节点和非叶子节点</h2><p>执行下面代码，我们会发现 loss.grad并不是我们期望的1，而是 None。类似地 y1.grad 以及 y2.grad也是 None。<br>这是为什么呢？这是由于它们不是叶子节点张量。<br>在反向传播过程中，只有 is_leaf&#x3D;True 的叶子节点，需要求导的张量的导数结果才会被最后保留下来。那么什么是叶子节点张量呢？叶子节点张量需要满足两个条件。</p><ol><li>叶子节点张量是由用户直接创建的张量，而非由某个Function通过计算得到的张量。</li><li>叶子节点张量的 requires_grad属性必须为True.</li></ol><p>Pytorch设计这样的规则主要是为了节约内存或者显存空间，因为几乎所有的时候，用户只会关心他自己直接创建的张量的梯度。<br>所有依赖于叶子节点张量的张量, 其requires_grad 属性必定是True的，但其梯度值只在计算过程中被用到，不会最终存储到grad属性中。<br>如果需要保留中间计算结果的梯度到grad属性中，可以使用 retain_grad方法。如果仅仅是为了调试代码查看梯度值，可以利用register_hook打印日志。</p><pre class="line-numbers language-python"><code class="language-python">x <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token number">3.0</span><span class="token punctuation">,</span>requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>y1 <span class="token operator">=</span> x <span class="token operator">+</span> <span class="token number">1</span>y2 <span class="token operator">=</span> <span class="token number">2</span><span class="token operator">*</span>xloss <span class="token operator">=</span> <span class="token punctuation">(</span>y1<span class="token operator">-</span>y2<span class="token punctuation">)</span><span class="token operator">**</span><span class="token number">2</span>loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"loss.grad:"</span><span class="token punctuation">,</span> loss<span class="token punctuation">.</span>grad<span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># non-leaf</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"y1.grad:"</span><span class="token punctuation">,</span> y1<span class="token punctuation">.</span>grad<span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># non-leaf</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"y2.grad:"</span><span class="token punctuation">,</span> y2<span class="token punctuation">.</span>grad<span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># non-leaf</span><span class="token keyword">print</span><span class="token punctuation">(</span>x<span class="token punctuation">.</span>grad<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>x<span class="token punctuation">.</span>is_leaf<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>y1<span class="token punctuation">.</span>is_leaf<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>y2<span class="token punctuation">.</span>is_leaf<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>loss<span class="token punctuation">.</span>is_leaf<span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span>Output<span class="token punctuation">:</span>loss<span class="token punctuation">.</span>grad<span class="token punctuation">:</span> Noney1<span class="token punctuation">.</span>grad<span class="token punctuation">:</span> Noney2<span class="token punctuation">.</span>grad<span class="token punctuation">:</span> Nonetensor<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token boolean">True</span><span class="token boolean">False</span><span class="token boolean">False</span><span class="token boolean">False</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>利用<code>retain_grad</code>可以保留非叶子节点的梯度值。利用<code>register_hook</code>可以查看非叶子节点的梯度值。</p><pre class="line-numbers language-python"><code class="language-python">x <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token number">3.0</span><span class="token punctuation">,</span>requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>y1 <span class="token operator">=</span> x <span class="token operator">+</span> <span class="token number">1</span>y2 <span class="token operator">=</span> <span class="token number">2</span><span class="token operator">*</span>xloss <span class="token operator">=</span> <span class="token punctuation">(</span>y1<span class="token operator">-</span>y2<span class="token punctuation">)</span><span class="token operator">**</span><span class="token number">2</span><span class="token comment" spellcheck="true"># 非叶子节点梯度显示控制</span>y1<span class="token punctuation">.</span>register_hook<span class="token punctuation">(</span><span class="token keyword">lambda</span> grad<span class="token punctuation">:</span> <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'y1 grad: '</span><span class="token punctuation">,</span> grad<span class="token punctuation">)</span><span class="token punctuation">)</span>y2<span class="token punctuation">.</span>register_hook<span class="token punctuation">(</span><span class="token keyword">lambda</span> grad<span class="token punctuation">:</span> <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'y2 grad: '</span><span class="token punctuation">,</span> grad<span class="token punctuation">)</span><span class="token punctuation">)</span>loss<span class="token punctuation">.</span>retain_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 反向传播</span>loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"loss.grad:"</span><span class="token punctuation">,</span> loss<span class="token punctuation">.</span>grad<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"x.grad:"</span><span class="token punctuation">,</span> x<span class="token punctuation">.</span>grad<span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span>Output<span class="token punctuation">:</span>y2 grad<span class="token punctuation">:</span>  tensor<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">.</span><span class="token punctuation">)</span>y1 grad<span class="token punctuation">:</span>  tensor<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">4</span><span class="token punctuation">.</span><span class="token punctuation">)</span>loss<span class="token punctuation">.</span>grad<span class="token punctuation">:</span> tensor<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">)</span>x<span class="token punctuation">.</span>grad<span class="token punctuation">:</span> tensor<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> Pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 基础知识 </tag>
            
            <tag> Pytorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Pytorch|自动微分和反向求导</title>
      <link href="/2023/04/08/pytorch-ji-chu-zhi-shi/04-zi-dong-wei-fen-yu-backward/"/>
      <url>/2023/04/08/pytorch-ji-chu-zhi-shi/04-zi-dong-wei-fen-yu-backward/</url>
      
        <content type="html"><![CDATA[<h1 id="Pytorch自动微分简介"><a href="#Pytorch自动微分简介" class="headerlink" title="Pytorch自动微分简介"></a>Pytorch自动微分简介</h1><p>神经网络通常依赖反向传播求梯度来更新网络参数，求梯度过程通常是一件非常复杂而容易出错的事情。而深度学习框架可以帮助我们自动地完成这种求梯度运算。<br>Pytorch一般通过反向传播<code>backward()</code>方法实现这种求梯度计算。该方法求得的梯度将存在对应自变量张量的<code>grad</code>属性下。除此之外，也能够调用<code>torch.autograd.grad()</code>函数来实现求梯度计算。这就是Pytorch的自动微分机制。</p><h2 id="求导数的例子"><a href="#求导数的例子" class="headerlink" title="求导数的例子"></a>求导数的例子</h2><h3 id="利用backward方法求导数"><a href="#利用backward方法求导数" class="headerlink" title="利用backward方法求导数"></a>利用backward方法求导数</h3><p><code>backward()</code>方法通常在一个标量张量上调用，该方法求得的梯度将存在对应自变量张量的<code>grad</code>属性下。<br>如果调用的张量非标量，则要传入一个和它同形状的<code>gradient</code>参数张量。相当于用该<code>gradient</code>参数张量与调用张量<strong>作向量点乘再求和</strong>，得到的标量结果再反向传播。</p><h4 id="标量的反向传播"><a href="#标量的反向传播" class="headerlink" title="标量的反向传播"></a><strong>标量的反向传播</strong></h4><p>求$f(x) &#x3D; a\times x^2 + b \times x + c$的导数。<br>$f(x)$的导数是$f’(x) &#x3D; 2ax+b$。<br>当$x&#x3D;0$时导数为-2。<br>当$x&#x3D;2$时导数为2。<br>当$x&#x3D;-2$时导数为-6。</p><pre class="line-numbers language-python"><code class="language-python">x <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token number">0.0</span><span class="token punctuation">,</span> requires_grad <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># x需要被求导</span>a <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token number">1.0</span><span class="token punctuation">)</span>b <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">2.0</span><span class="token punctuation">)</span>c <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token number">1.0</span><span class="token punctuation">)</span>y <span class="token operator">=</span> a<span class="token operator">*</span>torch<span class="token punctuation">.</span>pow<span class="token punctuation">(</span>x<span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span> <span class="token operator">+</span> b<span class="token operator">*</span>x <span class="token operator">+</span> c <span class="token keyword">print</span><span class="token punctuation">(</span>y<span class="token punctuation">)</span>y<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>dy_dx <span class="token operator">=</span> x<span class="token punctuation">.</span>grad<span class="token keyword">print</span><span class="token punctuation">(</span>dy_dx<span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span>Output<span class="token punctuation">:</span>tensor<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> grad_fn<span class="token operator">=</span><span class="token operator">&lt;</span>AddBackward0<span class="token operator">></span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="非标量的反向传播"><a href="#非标量的反向传播" class="headerlink" title="非标量的反向传播"></a><strong>非标量的反向传播</strong></h4><p>求$f(x) &#x3D; a\times x^2 + b \times x + c$的导数。</p><pre class="line-numbers language-python"><code class="language-python">x <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.0</span><span class="token punctuation">,</span><span class="token number">0.0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">1.0</span><span class="token punctuation">,</span><span class="token number">2.0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>requires_grad <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># x需要被求导</span>a <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token number">1.0</span><span class="token punctuation">)</span>b <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">2.0</span><span class="token punctuation">)</span>c <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token number">1.0</span><span class="token punctuation">)</span>y <span class="token operator">=</span> a<span class="token operator">*</span>torch<span class="token punctuation">.</span>pow<span class="token punctuation">(</span>x<span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span> <span class="token operator">+</span> b<span class="token operator">*</span>x <span class="token operator">+</span> c gradient <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1.0</span><span class="token punctuation">,</span><span class="token number">1.0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">1.0</span><span class="token punctuation">,</span><span class="token number">1.0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"x:\n"</span><span class="token punctuation">,</span>x<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"y:\n"</span><span class="token punctuation">,</span>y<span class="token punctuation">)</span>y<span class="token punctuation">.</span>backward<span class="token punctuation">(</span>gradient <span class="token operator">=</span> gradient<span class="token punctuation">)</span>x_grad <span class="token operator">=</span> x<span class="token punctuation">.</span>grad<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"x_grad:\n"</span><span class="token punctuation">,</span>x_grad<span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span>Output<span class="token punctuation">:</span>x<span class="token punctuation">:</span> tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>y<span class="token punctuation">:</span> tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> grad_fn<span class="token operator">=</span><span class="token operator">&lt;</span>AddBackward0<span class="token operator">></span><span class="token punctuation">)</span>x_grad<span class="token punctuation">:</span> tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span>  <span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="用标量的反向传播实现非标量的反向传播"><a href="#用标量的反向传播实现非标量的反向传播" class="headerlink" title="用标量的反向传播实现非标量的反向传播"></a><strong>用标量的反向传播实现</strong><strong>非标量的反向传播</strong></h4><p>求$f(x) &#x3D; a\times x^2 + b \times x + c$的导数。</p><pre class="line-numbers language-python"><code class="language-python">x <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.0</span><span class="token punctuation">,</span><span class="token number">0.0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">1.0</span><span class="token punctuation">,</span><span class="token number">2.0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>requires_grad <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># x需要被求导</span>a <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token number">1.0</span><span class="token punctuation">)</span>b <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">2.0</span><span class="token punctuation">)</span>c <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token number">1.0</span><span class="token punctuation">)</span>y <span class="token operator">=</span> a<span class="token operator">*</span>torch<span class="token punctuation">.</span>pow<span class="token punctuation">(</span>x<span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span> <span class="token operator">+</span> b<span class="token operator">*</span>x <span class="token operator">+</span> c gradient <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1.0</span><span class="token punctuation">,</span><span class="token number">1.0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">1.0</span><span class="token punctuation">,</span><span class="token number">1.0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>z <span class="token operator">=</span> torch<span class="token punctuation">.</span>sum<span class="token punctuation">(</span>y<span class="token operator">*</span>gradient<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"x:"</span><span class="token punctuation">,</span>x<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"y:"</span><span class="token punctuation">,</span>y<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>z<span class="token punctuation">)</span>z<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>x_grad <span class="token operator">=</span> x<span class="token punctuation">.</span>grad<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"x_grad:\n"</span><span class="token punctuation">,</span>x_grad<span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span>Output<span class="token punctuation">:</span>x<span class="token punctuation">:</span> tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>y<span class="token punctuation">:</span> tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> grad_fn<span class="token operator">=</span><span class="token operator">&lt;</span>AddBackward0<span class="token operator">></span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">.</span><span class="token punctuation">,</span> grad_fn<span class="token operator">=</span><span class="token operator">&lt;</span>SumBackward0<span class="token operator">></span><span class="token punctuation">)</span>x_grad<span class="token punctuation">:</span> tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span>  <span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="利用autograd-grad方法求导数"><a href="#利用autograd-grad方法求导数" class="headerlink" title="利用autograd.grad方法求导数"></a>利用autograd.grad方法求导数</h3><p>求$f(x) &#x3D; a\times x^2 + b \times x + c$的导数。<br>$f(x)$的一阶导数是$f’(x) &#x3D; 2ax+b$。<br>$f(x)$的二阶导数是$f’’(x)&#x3D;2a$。<br><code>torch.autograd.grad</code>方法中<code>create_graph</code>参数设置为 True 将允许创建更高阶的导数 。</p><pre class="line-numbers language-python"><code class="language-python">x <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token number">0.0</span><span class="token punctuation">,</span>requires_grad <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># x需要被求导</span>a <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token number">1.0</span><span class="token punctuation">)</span>b <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">2.0</span><span class="token punctuation">)</span>c <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token number">1.0</span><span class="token punctuation">)</span>y <span class="token operator">=</span> a<span class="token operator">*</span>torch<span class="token punctuation">.</span>pow<span class="token punctuation">(</span>x<span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span> <span class="token operator">+</span> b<span class="token operator">*</span>x <span class="token operator">+</span> cgradient <span class="token operator">=</span> torch<span class="token punctuation">.</span>autograd<span class="token punctuation">.</span>grad<span class="token punctuation">(</span>y<span class="token punctuation">,</span>x<span class="token punctuation">,</span>create_graph<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>gradient<span class="token punctuation">)</span>dy_dx <span class="token operator">=</span> gradient<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token keyword">print</span><span class="token punctuation">(</span>dy_dx<span class="token punctuation">.</span>data<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 求二阶导数</span>dy2_dx2 <span class="token operator">=</span> torch<span class="token punctuation">.</span>autograd<span class="token punctuation">.</span>grad<span class="token punctuation">(</span>dy_dx<span class="token punctuation">,</span>x<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token keyword">print</span><span class="token punctuation">(</span>dy2_dx2<span class="token punctuation">.</span>data<span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span>Output<span class="token punctuation">:</span><span class="token punctuation">(</span>tensor<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">,</span> grad_fn<span class="token operator">=</span><span class="token operator">&lt;</span>AddBackward0<span class="token operator">></span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><code>torch.autograd.grad</code>允许同时对多个自变量求导数。如果有多个因变量，相当于把多个因变量的<strong>梯度结果求和</strong>。<br>$y_1 &#x3D; x_1 \times x_2$<br>$y_2&#x3D;x_1+x_2$<br>$\begin{aligned} \frac{\partial y_1}{\partial X} &#x3D; \left[ \frac{\partial y_1}{\partial x_1} , \frac{\partial y_1}{\partial x_2} \right]&#x3D; \left[x_2, x_1 \right] \end{aligned}$<br>$\begin{aligned} \frac{\partial Y}{\partial X} &#x3D; \begin{bmatrix} \frac{\partial y_1}{\partial x_1} , \frac{\partial y_1}{\partial x_2} \\ \frac{\partial y_2}{\partial x_1} , \frac{\partial y_2}{\partial x_2} \end{bmatrix}&#x3D; \begin{bmatrix}<br>x_2 &amp; x_1 \\ 1 &amp; 1 \end{bmatrix} \end{aligned}$</p><pre class="line-numbers language-python"><code class="language-python">x1 <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token number">1.0</span><span class="token punctuation">,</span>requires_grad <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span>x2 <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token number">2.0</span><span class="token punctuation">,</span>requires_grad <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span>y1 <span class="token operator">=</span> x1<span class="token operator">*</span>x2y2 <span class="token operator">=</span> x1<span class="token operator">+</span>x2<span class="token punctuation">(</span>dy1_dx1<span class="token punctuation">,</span>dy1_dx2<span class="token punctuation">)</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>autograd<span class="token punctuation">.</span>grad<span class="token punctuation">(</span>outputs<span class="token operator">=</span>y1<span class="token punctuation">,</span>inputs <span class="token operator">=</span> <span class="token punctuation">[</span>x1<span class="token punctuation">,</span>x2<span class="token punctuation">]</span><span class="token punctuation">,</span>retain_graph <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>dy1_dx1<span class="token punctuation">,</span> dy1_dx2<span class="token punctuation">)</span><span class="token punctuation">(</span>dy12_dx1<span class="token punctuation">,</span>dy12_dx2<span class="token punctuation">)</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>autograd<span class="token punctuation">.</span>grad<span class="token punctuation">(</span>outputs<span class="token operator">=</span><span class="token punctuation">[</span>y1<span class="token punctuation">,</span>y2<span class="token punctuation">]</span><span class="token punctuation">,</span>inputs <span class="token operator">=</span> <span class="token punctuation">[</span>x1<span class="token punctuation">,</span>x2<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>dy12_dx1<span class="token punctuation">,</span> dy12_dx2<span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span>Output<span class="token punctuation">:</span>tensor<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">)</span> tensor<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">.</span><span class="token punctuation">)</span> tensor<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="利用自动微分和优化器求最小值"><a href="#利用自动微分和优化器求最小值" class="headerlink" title="利用自动微分和优化器求最小值"></a>利用自动微分和优化器求最小值</h2><p>求$f(x) &#x3D; a\times x^2 + b \times x + c$的最小值。</p><pre class="line-numbers language-python"><code class="language-python">x <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token number">0.0</span><span class="token punctuation">,</span>requires_grad <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># x需要被求导</span>a <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token number">1.0</span><span class="token punctuation">)</span>b <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">2.0</span><span class="token punctuation">)</span>c <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token number">1.0</span><span class="token punctuation">)</span>optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>params<span class="token operator">=</span><span class="token punctuation">[</span>x<span class="token punctuation">]</span><span class="token punctuation">,</span>lr <span class="token operator">=</span> <span class="token number">0.1</span><span class="token punctuation">)</span><span class="token keyword">for</span> param <span class="token keyword">in</span> optimizer<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>param<span class="token punctuation">,</span> optimizer<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span>param<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">f</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>    result <span class="token operator">=</span> a<span class="token operator">*</span>torch<span class="token punctuation">.</span>pow<span class="token punctuation">(</span>x<span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span> <span class="token operator">+</span> b<span class="token operator">*</span>x <span class="token operator">+</span> c     <span class="token keyword">return</span><span class="token punctuation">(</span>result<span class="token punctuation">)</span><span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>    y <span class="token operator">=</span> f<span class="token punctuation">(</span>x<span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>y<span class="token punctuation">)</span>    y<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>    optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>optimizer<span class="token punctuation">.</span>param_groups<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"y="</span><span class="token punctuation">,</span>f<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">.</span>data<span class="token punctuation">,</span><span class="token string">";"</span><span class="token punctuation">,</span><span class="token string">"x="</span><span class="token punctuation">,</span>x<span class="token punctuation">.</span>data<span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span>Output<span class="token punctuation">:</span>state <span class="token punctuation">{</span><span class="token punctuation">}</span>param_groups <span class="token punctuation">[</span><span class="token punctuation">{</span><span class="token string">'lr'</span><span class="token punctuation">:</span> <span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token string">'momentum'</span><span class="token punctuation">:</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token string">'dampening'</span><span class="token punctuation">:</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token string">'weight_decay'</span><span class="token punctuation">:</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token string">'nesterov'</span><span class="token punctuation">:</span> <span class="token boolean">False</span><span class="token punctuation">,</span> <span class="token string">'params'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">}</span><span class="token punctuation">]</span>tensor<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> grad_fn<span class="token operator">=</span><span class="token operator">&lt;</span>AddBackward0<span class="token operator">></span><span class="token punctuation">)</span><span class="token punctuation">{</span><span class="token string">'params'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span>tensor<span class="token punctuation">(</span><span class="token number">0.2000</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'lr'</span><span class="token punctuation">:</span> <span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token string">'momentum'</span><span class="token punctuation">:</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token string">'dampening'</span><span class="token punctuation">:</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token string">'weight_decay'</span><span class="token punctuation">:</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token string">'nesterov'</span><span class="token punctuation">:</span> <span class="token boolean">False</span><span class="token punctuation">}</span>tensor<span class="token punctuation">(</span><span class="token number">0.6400</span><span class="token punctuation">,</span> grad_fn<span class="token operator">=</span><span class="token operator">&lt;</span>AddBackward0<span class="token operator">></span><span class="token punctuation">)</span><span class="token punctuation">{</span><span class="token string">'params'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span>tensor<span class="token punctuation">(</span><span class="token number">0.3600</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'lr'</span><span class="token punctuation">:</span> <span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token string">'momentum'</span><span class="token punctuation">:</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token string">'dampening'</span><span class="token punctuation">:</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token string">'weight_decay'</span><span class="token punctuation">:</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token string">'nesterov'</span><span class="token punctuation">:</span> <span class="token boolean">False</span><span class="token punctuation">}</span>tensor<span class="token punctuation">(</span><span class="token number">0.4096</span><span class="token punctuation">,</span> grad_fn<span class="token operator">=</span><span class="token operator">&lt;</span>AddBackward0<span class="token operator">></span><span class="token punctuation">)</span><span class="token punctuation">{</span><span class="token string">'params'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span>tensor<span class="token punctuation">(</span><span class="token number">0.4880</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'lr'</span><span class="token punctuation">:</span> <span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token string">'momentum'</span><span class="token punctuation">:</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token string">'dampening'</span><span class="token punctuation">:</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token string">'weight_decay'</span><span class="token punctuation">:</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token string">'nesterov'</span><span class="token punctuation">:</span> <span class="token boolean">False</span><span class="token punctuation">}</span>tensor<span class="token punctuation">(</span><span class="token number">0.2621</span><span class="token punctuation">,</span> grad_fn<span class="token operator">=</span><span class="token operator">&lt;</span>AddBackward0<span class="token operator">></span><span class="token punctuation">)</span><span class="token punctuation">{</span><span class="token string">'params'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span>tensor<span class="token punctuation">(</span><span class="token number">0.5904</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'lr'</span><span class="token punctuation">:</span> <span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token string">'momentum'</span><span class="token punctuation">:</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token string">'dampening'</span><span class="token punctuation">:</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token string">'weight_decay'</span><span class="token punctuation">:</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token string">'nesterov'</span><span class="token punctuation">:</span> <span class="token boolean">False</span><span class="token punctuation">}</span>tensor<span class="token punctuation">(</span><span class="token number">0.1678</span><span class="token punctuation">,</span> grad_fn<span class="token operator">=</span><span class="token operator">&lt;</span>AddBackward0<span class="token operator">></span><span class="token punctuation">)</span><span class="token punctuation">{</span><span class="token string">'params'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span>tensor<span class="token punctuation">(</span><span class="token number">0.6723</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'lr'</span><span class="token punctuation">:</span> <span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token string">'momentum'</span><span class="token punctuation">:</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token string">'dampening'</span><span class="token punctuation">:</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token string">'weight_decay'</span><span class="token punctuation">:</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token string">'nesterov'</span><span class="token punctuation">:</span> <span class="token boolean">False</span><span class="token punctuation">}</span>tensor<span class="token punctuation">(</span><span class="token number">0.1074</span><span class="token punctuation">,</span> grad_fn<span class="token operator">=</span><span class="token operator">&lt;</span>AddBackward0<span class="token operator">></span><span class="token punctuation">)</span><span class="token punctuation">{</span><span class="token string">'params'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span>tensor<span class="token punctuation">(</span><span class="token number">0.7379</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'lr'</span><span class="token punctuation">:</span> <span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token string">'momentum'</span><span class="token punctuation">:</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token string">'dampening'</span><span class="token punctuation">:</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token string">'weight_decay'</span><span class="token punctuation">:</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token string">'nesterov'</span><span class="token punctuation">:</span> <span class="token boolean">False</span><span class="token punctuation">}</span>tensor<span class="token punctuation">(</span><span class="token number">0.0687</span><span class="token punctuation">,</span> grad_fn<span class="token operator">=</span><span class="token operator">&lt;</span>AddBackward0<span class="token operator">></span><span class="token punctuation">)</span><span class="token punctuation">{</span><span class="token string">'params'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span>tensor<span class="token punctuation">(</span><span class="token number">0.7903</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'lr'</span><span class="token punctuation">:</span> <span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token string">'momentum'</span><span class="token punctuation">:</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token string">'dampening'</span><span class="token punctuation">:</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token string">'weight_decay'</span><span class="token punctuation">:</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token string">'nesterov'</span><span class="token punctuation">:</span> <span class="token boolean">False</span><span class="token punctuation">}</span>tensor<span class="token punctuation">(</span><span class="token number">0.0440</span><span class="token punctuation">,</span> grad_fn<span class="token operator">=</span><span class="token operator">&lt;</span>AddBackward0<span class="token operator">></span><span class="token punctuation">)</span><span class="token punctuation">{</span><span class="token string">'params'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span>tensor<span class="token punctuation">(</span><span class="token number">0.8322</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'lr'</span><span class="token punctuation">:</span> <span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token string">'momentum'</span><span class="token punctuation">:</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token string">'dampening'</span><span class="token punctuation">:</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token string">'weight_decay'</span><span class="token punctuation">:</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token string">'nesterov'</span><span class="token punctuation">:</span> <span class="token boolean">False</span><span class="token punctuation">}</span>tensor<span class="token punctuation">(</span><span class="token number">0.0281</span><span class="token punctuation">,</span> grad_fn<span class="token operator">=</span><span class="token operator">&lt;</span>AddBackward0<span class="token operator">></span><span class="token punctuation">)</span><span class="token punctuation">{</span><span class="token string">'params'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span>tensor<span class="token punctuation">(</span><span class="token number">0.8658</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'lr'</span><span class="token punctuation">:</span> <span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token string">'momentum'</span><span class="token punctuation">:</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token string">'dampening'</span><span class="token punctuation">:</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token string">'weight_decay'</span><span class="token punctuation">:</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token string">'nesterov'</span><span class="token punctuation">:</span> <span class="token boolean">False</span><span class="token punctuation">}</span>tensor<span class="token punctuation">(</span><span class="token number">0.0180</span><span class="token punctuation">,</span> grad_fn<span class="token operator">=</span><span class="token operator">&lt;</span>AddBackward0<span class="token operator">></span><span class="token punctuation">)</span><span class="token punctuation">{</span><span class="token string">'params'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span>tensor<span class="token punctuation">(</span><span class="token number">0.8926</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'lr'</span><span class="token punctuation">:</span> <span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token string">'momentum'</span><span class="token punctuation">:</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token string">'dampening'</span><span class="token punctuation">:</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token string">'weight_decay'</span><span class="token punctuation">:</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token string">'nesterov'</span><span class="token punctuation">:</span> <span class="token boolean">False</span><span class="token punctuation">}</span>y<span class="token operator">=</span> tensor<span class="token punctuation">(</span><span class="token number">0.0115</span><span class="token punctuation">)</span> <span class="token punctuation">;</span> x<span class="token operator">=</span> tensor<span class="token punctuation">(</span><span class="token number">0.8926</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="反向传播的梯度累加"><a href="#反向传播的梯度累加" class="headerlink" title="反向传播的梯度累加"></a>反向传播的梯度累加</h2><p>以下面的计算过程为例，进行反向传播计算。<br>$x_2 &#x3D; x_1 \times w_1$<br>$y &#x3D; x_2 \times w_2$<br>$L &#x3D; Y-y$</p><pre class="line-numbers language-python"><code class="language-python">x1 <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span><span class="token number">2</span><span class="token operator">*</span>np<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>np<span class="token punctuation">.</span>float32<span class="token punctuation">)</span><span class="token punctuation">)</span>x1<span class="token punctuation">.</span>requires_grad_<span class="token punctuation">(</span><span class="token boolean">True</span><span class="token punctuation">)</span>w1 <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span><span class="token number">5</span><span class="token operator">*</span>np<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>np<span class="token punctuation">.</span>float32<span class="token punctuation">)</span><span class="token punctuation">)</span>w1<span class="token punctuation">.</span>requires_grad_<span class="token punctuation">(</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"x1 = "</span><span class="token punctuation">,</span> x1<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"w1 = "</span><span class="token punctuation">,</span> w1<span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span>Output<span class="token punctuation">:</span>x1 <span class="token operator">=</span>  tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>w1 <span class="token operator">=</span>  tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python">x2 <span class="token operator">=</span> x1 <span class="token operator">*</span> w1w2 <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span><span class="token number">6</span><span class="token operator">*</span>np<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>np<span class="token punctuation">.</span>float32<span class="token punctuation">)</span><span class="token punctuation">)</span>w2<span class="token punctuation">.</span>requires_grad_<span class="token punctuation">(</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"x2 = "</span><span class="token punctuation">,</span> x2<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"w2 = "</span><span class="token punctuation">,</span> w2<span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span>Output<span class="token punctuation">:</span>x2 <span class="token operator">=</span>  tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">10</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">10</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> grad_fn<span class="token operator">=</span><span class="token operator">&lt;</span>MulBackward0<span class="token operator">></span><span class="token punctuation">)</span>w2 <span class="token operator">=</span>  tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">6</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">6</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python">y <span class="token operator">=</span> x2 <span class="token operator">*</span> w2Y <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span><span class="token number">10</span><span class="token operator">*</span>np<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>np<span class="token punctuation">.</span>float32<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"y = "</span><span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Y = "</span><span class="token punctuation">,</span> Y<span class="token punctuation">)</span>L <span class="token operator">=</span> Y<span class="token operator">-</span>y<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Loss = "</span><span class="token punctuation">,</span> L<span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span>Output<span class="token punctuation">:</span>y <span class="token operator">=</span>  tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">60</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">60</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">60</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">60</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> grad_fn<span class="token operator">=</span><span class="token operator">&lt;</span>MulBackward0<span class="token operator">></span><span class="token punctuation">)</span>Y <span class="token operator">=</span>  tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">10</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">10</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>Loss <span class="token operator">=</span>  tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">50</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">50</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">50</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">50</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> grad_fn<span class="token operator">=</span><span class="token operator">&lt;</span>SubBackward0<span class="token operator">></span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>$\begin{aligned} L &#x3D; Y-y&#x3D;Y-x_1 \times w_1 \times w2 \end{aligned}$<br>$\begin{aligned} \frac{\partial L}{\partial x_1} &#x3D; \frac{\partial L}{\partial y} \times \frac{\partial y}{\partial x_1}&#x3D;-w_1 \times w_2 \end{aligned}$<br>$\begin{aligned} \frac{\partial L}{\partial w_1} &#x3D; \frac{\partial L}{\partial y} \times  \frac{\partial y}{\partial w_1}&#x3D;-x_1 \times w_2 \end{aligned}$<br>$\begin{aligned} \frac{\partial L}{\partial w_2} &#x3D; \frac{\partial L}{\partial y} \times \frac{\partial y}{\partial w_2}&#x3D;-x_1 \times w_1 \end{aligned}$</p><pre class="line-numbers language-python"><code class="language-python">grad <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span>dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float<span class="token punctuation">)</span>L<span class="token punctuation">.</span>backward<span class="token punctuation">(</span>grad<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"x1.grad = "</span><span class="token punctuation">,</span> x1<span class="token punctuation">.</span>grad<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"w1.grad = "</span><span class="token punctuation">,</span> w1<span class="token punctuation">.</span>grad<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"w2.grad = "</span><span class="token punctuation">,</span> w2<span class="token punctuation">.</span>grad<span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span>Output<span class="token punctuation">:</span>x1<span class="token punctuation">.</span>grad <span class="token operator">=</span>  tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">30</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">30</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">30</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">30</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>w1<span class="token punctuation">.</span>grad <span class="token operator">=</span>  tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">12</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">12</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">12</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">12</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>w2<span class="token punctuation">.</span>grad <span class="token operator">=</span>  tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">10</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">10</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">10</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">10</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>张量的梯度是累加的，如果不对梯度清零，梯度会一直累加下去。<br>此时进行新的运算，并查看$x_1$的梯度。<br>$\begin{aligned} L_2 &#x3D; x_1 \times x_1 \end{aligned}$<br>$\begin{aligned} \frac{\partial L_2}{\partial x_1} &#x3D; 2 \times x_1 \end{aligned}$<br>经过第一轮运算后$x_1$的梯度是$\begin{bmatrix} -30 &amp; -30 \\ -30 &amp; -30 \end{bmatrix}$，新的运算后计算得到$x_1$的梯度是$\begin{bmatrix} 4 &amp; 4 \\ 4 &amp; 4 \end{bmatrix}$，则累加后的$x_1$的最终梯度是$\begin{bmatrix} -26 &amp; -26 \\ -26 &amp; -26 \end{bmatrix}$。</p><pre class="line-numbers language-python"><code class="language-python">L2 <span class="token operator">=</span> x1<span class="token operator">*</span>x1L2<span class="token punctuation">.</span>backward<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"x1.grad = "</span><span class="token punctuation">,</span> x1<span class="token punctuation">.</span>grad<span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span>Output<span class="token punctuation">:</span>x1<span class="token punctuation">.</span>grad <span class="token operator">=</span>  tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">26</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">26</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">26</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">26</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> Pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 基础知识 </tag>
            
            <tag> Pytorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Pytorch|模型和参数</title>
      <link href="/2023/04/06/pytorch-ji-chu-zhi-shi/03function-he-module/"/>
      <url>/2023/04/06/pytorch-ji-chu-zhi-shi/03function-he-module/</url>
      
        <content type="html"><![CDATA[<h1 id="Pytorch中的Module和function"><a href="#Pytorch中的Module和function" class="headerlink" title="Pytorch中的Module和function"></a>Pytorch中的Module和function</h1><p>这里的function和Module是指<code>nn.functional</code>和<code>nn.Module</code>。<br>Pytorch和神经网络相关的功能组件大多都封装在<code>torch.nn</code>模块下。这些功能组件的绝大部分既有<strong>函数形式</strong>实现，也有<strong>类形式</strong>实现。<br>其中<code>nn.functional</code>(一般引入后改名为F)有各种功能组件的<strong>函数实现</strong>。为了便于对参数进行管理，一般通过继承<code>nn.Module</code>转换成为<strong>类的实现形式</strong>，并直接封装在 nn 模块下。例如：</p><table><thead><tr><th></th><th><code>nn.functional</code></th><th><code>nn.Module</code></th></tr></thead><tbody><tr><td>激活函数</td><td>F.relu</td><td>nn.ReLU</td></tr><tr><td></td><td>F.sigmoid</td><td>nn.Sigmoid</td></tr><tr><td>模型层</td><td>F.linear</td><td>nn.Linear</td></tr><tr><td></td><td>F.conv2d</td><td>nn.Conv2d</td></tr><tr><td>损失函数</td><td>F.binary_cross_entropy</td><td>nn.BCELoss</td></tr><tr><td></td><td>F.mse_loss</td><td>nn.MSELoss</td></tr><tr><td></td><td>F.cross_entropy</td><td>nn.CrossEntropyLoss</td></tr></tbody></table><p>实际上<code>nn.Module</code>除了可以管理其引用的各种参数，还可以管理其引用的子模块，功能十分强大。</p><h2 id="使用nn-Module来管理参数"><a href="#使用nn-Module来管理参数" class="headerlink" title="使用nn.Module来管理参数"></a>使用nn.Module来管理参数</h2><p>在Pytorch中，模型的参数是需要被优化器训练的，因此，通常要设置其参数为<code>requires_grad = True</code>的张量。同时，在一个模型中，往往有许多的参数，要手动管理这些参数并不是一件容易的事情。<br>Pytorch一般将参数用<code>nn.Parameter</code>来表示，并且用<code>nn.Module</code>来管理其结构下的所有参数。<br><code>nn.Parameter</code>具有<code>requires_grad = True</code>属性。</p><pre class="line-numbers language-python"><code class="language-python">w <span class="token operator">=</span> nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>w<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>w<span class="token punctuation">.</span>requires_grad<span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span>Output<span class="token punctuation">:</span>Parameter containing<span class="token punctuation">:</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0.3544</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.1643</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">1.2302</span><span class="token punctuation">,</span>  <span class="token number">1.3952</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token boolean">True</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><code>nn.ParameterList</code>可以将多个nn.Parameter组成一个列表。</p><pre class="line-numbers language-python"><code class="language-python">params_list <span class="token operator">=</span> nn<span class="token punctuation">.</span>ParameterList<span class="token punctuation">(</span><span class="token punctuation">[</span>    nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">8</span><span class="token punctuation">,</span>i<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span>    <span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>params_list<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>params_list<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>requires_grad<span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span>Output<span class="token punctuation">:</span>ParameterList<span class="token punctuation">(</span>    <span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span> Parameter containing<span class="token punctuation">:</span> <span class="token punctuation">[</span>torch<span class="token punctuation">.</span>FloatTensor of size 8x1<span class="token punctuation">]</span>    <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span> Parameter containing<span class="token punctuation">:</span> <span class="token punctuation">[</span>torch<span class="token punctuation">.</span>FloatTensor of size 8x2<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token boolean">True</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><code>nn.ParameterDict</code>可以将多个nn.Parameter组成一个字典。</p><pre class="line-numbers language-python"><code class="language-python">params_dict <span class="token operator">=</span> nn<span class="token punctuation">.</span>ParameterDict<span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">"a"</span><span class="token punctuation">:</span>nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                               <span class="token string">"b"</span><span class="token punctuation">:</span>nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>params_dict<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>params_dict<span class="token punctuation">[</span><span class="token string">"a"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>requires_grad<span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span>Output<span class="token punctuation">:</span>ParameterDict<span class="token punctuation">(</span>    <span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token punctuation">:</span> Parameter containing<span class="token punctuation">:</span> <span class="token punctuation">[</span>torch<span class="token punctuation">.</span>FloatTensor of size 2x2<span class="token punctuation">]</span>    <span class="token punctuation">(</span>b<span class="token punctuation">)</span><span class="token punctuation">:</span> Parameter containing<span class="token punctuation">:</span> <span class="token punctuation">[</span>torch<span class="token punctuation">.</span>FloatTensor of size <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token boolean">True</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>可以用Module将它们管理起来。<br><code>module.parameters()</code>返回一个生成器，包括其结构下的所有Parameter 。</p><pre class="line-numbers language-python"><code class="language-python">module <span class="token operator">=</span> nn<span class="token punctuation">.</span>Module<span class="token punctuation">(</span><span class="token punctuation">)</span>module<span class="token punctuation">.</span>w <span class="token operator">=</span> wmodule<span class="token punctuation">.</span>params_list <span class="token operator">=</span> params_listmodule<span class="token punctuation">.</span>params_dict <span class="token operator">=</span> params_dictnum_param <span class="token operator">=</span> <span class="token number">0</span><span class="token keyword">for</span> param <span class="token keyword">in</span> module<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>param<span class="token punctuation">,</span><span class="token string">"\n"</span><span class="token punctuation">)</span>    num_param <span class="token operator">=</span> num_param <span class="token operator">+</span> <span class="token number">1</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"number of Parameters ="</span><span class="token punctuation">,</span>num_param<span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span>Output<span class="token punctuation">:</span>Parameter containing<span class="token punctuation">:</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0.3544</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.1643</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">1.2302</span><span class="token punctuation">,</span>  <span class="token number">1.3952</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span> Parameter containing<span class="token punctuation">:</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.9391</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">0.7590</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">0.6899</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">0.4786</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">0.2392</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">0.9645</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">0.1968</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">0.1353</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span> Parameter containing<span class="token punctuation">:</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.8012</span><span class="token punctuation">,</span> <span class="token number">0.9587</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">0.0276</span><span class="token punctuation">,</span> <span class="token number">0.5995</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">0.7338</span><span class="token punctuation">,</span> <span class="token number">0.5559</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">0.1704</span><span class="token punctuation">,</span> <span class="token number">0.5814</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">0.7626</span><span class="token punctuation">,</span> <span class="token number">0.1179</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">0.4945</span><span class="token punctuation">,</span> <span class="token number">0.2408</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">0.7179</span><span class="token punctuation">,</span> <span class="token number">0.0575</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">0.3418</span><span class="token punctuation">,</span> <span class="token number">0.7291</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span> Parameter containing<span class="token punctuation">:</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.7729</span><span class="token punctuation">,</span> <span class="token number">0.2383</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">0.7054</span><span class="token punctuation">,</span> <span class="token number">0.9937</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span> Parameter containing<span class="token punctuation">:</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span> number of Parameters <span class="token operator">=</span> <span class="token number">5</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>下面以nn.Linear观察其参数。</p><pre class="line-numbers language-python"><code class="language-python">linear <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token keyword">for</span> param <span class="token keyword">in</span> linear<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>param<span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>param<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> param<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>param<span class="token punctuation">.</span>requires_grad<span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>param<span class="token punctuation">.</span>numel<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span>Output<span class="token punctuation">:</span>Parameter containing<span class="token punctuation">:</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.2206</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.0732</span><span class="token punctuation">,</span>  <span class="token number">0.2090</span><span class="token punctuation">,</span>  <span class="token number">0.0789</span><span class="token punctuation">,</span>  <span class="token number">0.0329</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.1918</span><span class="token punctuation">,</span>  <span class="token number">0.1738</span><span class="token punctuation">,</span>  <span class="token number">0.1015</span><span class="token punctuation">,</span>          <span class="token number">0.1667</span><span class="token punctuation">,</span>  <span class="token number">0.0078</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.1058</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.1306</span><span class="token punctuation">,</span>  <span class="token number">0.0223</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.0715</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.0484</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.0651</span><span class="token punctuation">,</span>          <span class="token number">0.1581</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.0084</span><span class="token punctuation">,</span>  <span class="token number">0.0357</span><span class="token punctuation">,</span>  <span class="token number">0.1935</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.0515</span><span class="token punctuation">,</span>  <span class="token number">0.2016</span><span class="token punctuation">,</span>  <span class="token number">0.2110</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.1053</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.0663</span><span class="token punctuation">,</span>  <span class="token number">0.1520</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.0612</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.1197</span><span class="token punctuation">,</span>          <span class="token number">0.0597</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.0840</span><span class="token punctuation">,</span>  <span class="token number">0.1601</span><span class="token punctuation">,</span>  <span class="token number">0.0842</span><span class="token punctuation">,</span>  <span class="token number">0.0731</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.1282</span><span class="token punctuation">,</span>  <span class="token number">0.0515</span><span class="token punctuation">,</span>  <span class="token number">0.0054</span><span class="token punctuation">,</span>          <span class="token number">0.0433</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.1549</span><span class="token punctuation">,</span>  <span class="token number">0.1223</span><span class="token punctuation">,</span>  <span class="token number">0.0270</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">]</span><span class="token punctuation">)</span> torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token boolean">True</span><span class="token number">40</span>Parameter containing<span class="token punctuation">:</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.2008</span><span class="token punctuation">,</span> <span class="token number">0.2086</span><span class="token punctuation">]</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span> torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token boolean">True</span><span class="token number">2</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>实践当中，一般通过继承<code>nn.Module</code>来构建模块类，并将所有含有需要学习的参数的部分放在构造函数中。<br>以下范例为Pytorch中<code>nn.Linear</code>的源码的简化版本。可以看到它将需要学习的参数放在了<code>__init__</code>构造函数中，并在forward中调用F.linear函数来实现计算逻辑。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Linear</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    __constants__ <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'in_features'</span><span class="token punctuation">,</span> <span class="token string">'out_features'</span><span class="token punctuation">]</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_features<span class="token punctuation">,</span> out_features<span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>Linear<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>in_features <span class="token operator">=</span> in_features        self<span class="token punctuation">.</span>out_features <span class="token operator">=</span> out_features        self<span class="token punctuation">.</span>weight <span class="token operator">=</span> nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span>out_features<span class="token punctuation">,</span> in_features<span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">if</span> bias<span class="token punctuation">:</span>            self<span class="token punctuation">.</span>bias <span class="token operator">=</span> nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span>out_features<span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">else</span><span class="token punctuation">:</span>            self<span class="token punctuation">.</span>register_parameter<span class="token punctuation">(</span><span class="token string">'bias'</span><span class="token punctuation">,</span> None<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> input<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> F<span class="token punctuation">.</span>linear<span class="token punctuation">(</span>input<span class="token punctuation">,</span> self<span class="token punctuation">.</span>weight<span class="token punctuation">,</span> self<span class="token punctuation">.</span>bias<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="使用nn-Module来管理子模块"><a href="#使用nn-Module来管理子模块" class="headerlink" title="使用nn.Module来管理子模块"></a>使用nn.Module来管理子模块</h2><p>一般情况下，我们都很少直接使用<code>nn.Parameter</code>来定义参数构建模型，而是通过拼装一些常用的模型层来构造模型。<br>这些模型层也是继承自nn.Module的对象，本身也包括参数，属于我们要定义的模块的子模块。<br>nn.Module提供了一些方法可以管理这些子模块。</p><ul><li><code>children()</code>方法：返回一个生成器，包括模块下的所有子模块。</li><li><code>named_children()</code>方法：返回一个生成器，包括模块下的所有子模块，以及它们的名字。</li><li><code>modules()</code>方法：返回一个生成器，递归地找到模块下的所有各个层级的模块，包括模块本身。</li><li><code>named_modules()</code>方法：返回一个生成器，递归地找到模块下的所有各个层级的模块以及它们的名字，包括模块本身。</li></ul><p>其中<code>chidren()</code>方法和<code>named_children()</code>方法较多使用。<code>modules()</code>方法和<code>named_modules()</code>方法较少使用，其功能可以通过多个<code>named_children()</code>的嵌套使用实现。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Net</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>Net<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>embedding <span class="token operator">=</span> nn<span class="token punctuation">.</span>Embedding<span class="token punctuation">(</span>num_embeddings <span class="token operator">=</span> <span class="token number">10000</span><span class="token punctuation">,</span>embedding_dim <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">,</span>padding_idx <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">)</span>                self<span class="token punctuation">.</span>conv <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>conv<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">"conv_1"</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Conv1d<span class="token punctuation">(</span>in_channels <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">,</span>out_channels <span class="token operator">=</span> <span class="token number">16</span><span class="token punctuation">,</span>kernel_size <span class="token operator">=</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>conv<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">"pool_1"</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>MaxPool1d<span class="token punctuation">(</span>kernel_size <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>conv<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">"relu_1"</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>conv<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">"conv_2"</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Conv1d<span class="token punctuation">(</span>in_channels <span class="token operator">=</span> <span class="token number">16</span><span class="token punctuation">,</span>out_channels <span class="token operator">=</span> <span class="token number">128</span><span class="token punctuation">,</span>kernel_size <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>conv<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">"pool_2"</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>MaxPool1d<span class="token punctuation">(</span>kernel_size <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>conv<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">"relu_2"</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>dense <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>dense<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">"flatten"</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>dense<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">"linear"</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">6144</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>dense<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">"sigmoid"</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>embedding<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>conv<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        y <span class="token operator">=</span> self<span class="token punctuation">.</span>dense<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">return</span> ynet <span class="token operator">=</span> Net<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python">i <span class="token operator">=</span> <span class="token number">0</span><span class="token keyword">for</span> child <span class="token keyword">in</span> net<span class="token punctuation">.</span>children<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    i<span class="token operator">+=</span><span class="token number">1</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>child<span class="token punctuation">,</span><span class="token string">"\n"</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"child number"</span><span class="token punctuation">,</span>i<span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span>Output<span class="token punctuation">:</span>Embedding<span class="token punctuation">(</span><span class="token number">10000</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> padding_idx<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span> Sequential<span class="token punctuation">(</span>  <span class="token punctuation">(</span>conv_1<span class="token punctuation">)</span><span class="token punctuation">:</span> Conv1d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token punctuation">(</span>pool_1<span class="token punctuation">)</span><span class="token punctuation">:</span> MaxPool1d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> dilation<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> ceil_mode<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>  <span class="token punctuation">(</span>relu_1<span class="token punctuation">)</span><span class="token punctuation">:</span> ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token punctuation">(</span>conv_2<span class="token punctuation">)</span><span class="token punctuation">:</span> Conv1d<span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token punctuation">(</span>pool_2<span class="token punctuation">)</span><span class="token punctuation">:</span> MaxPool1d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> dilation<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> ceil_mode<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>  <span class="token punctuation">(</span>relu_2<span class="token punctuation">)</span><span class="token punctuation">:</span> ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> Sequential<span class="token punctuation">(</span>  <span class="token punctuation">(</span>flatten<span class="token punctuation">)</span><span class="token punctuation">:</span> Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token punctuation">(</span>linear<span class="token punctuation">)</span><span class="token punctuation">:</span> Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">6144</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>  <span class="token punctuation">(</span>sigmoid<span class="token punctuation">)</span><span class="token punctuation">:</span> Sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> child number <span class="token number">3</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python">i <span class="token operator">=</span> <span class="token number">0</span><span class="token keyword">for</span> name<span class="token punctuation">,</span>child <span class="token keyword">in</span> net<span class="token punctuation">.</span>named_children<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    i<span class="token operator">+=</span><span class="token number">1</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>name<span class="token punctuation">,</span><span class="token string">":"</span><span class="token punctuation">,</span>child<span class="token punctuation">,</span><span class="token string">"\n"</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"child number"</span><span class="token punctuation">,</span>i<span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span>Output<span class="token punctuation">:</span>embedding <span class="token punctuation">:</span> Embedding<span class="token punctuation">(</span><span class="token number">10000</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> padding_idx<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span> conv <span class="token punctuation">:</span> Sequential<span class="token punctuation">(</span>  <span class="token punctuation">(</span>conv_1<span class="token punctuation">)</span><span class="token punctuation">:</span> Conv1d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token punctuation">(</span>pool_1<span class="token punctuation">)</span><span class="token punctuation">:</span> MaxPool1d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> dilation<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> ceil_mode<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>  <span class="token punctuation">(</span>relu_1<span class="token punctuation">)</span><span class="token punctuation">:</span> ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token punctuation">(</span>conv_2<span class="token punctuation">)</span><span class="token punctuation">:</span> Conv1d<span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token punctuation">(</span>pool_2<span class="token punctuation">)</span><span class="token punctuation">:</span> MaxPool1d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> dilation<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> ceil_mode<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>  <span class="token punctuation">(</span>relu_2<span class="token punctuation">)</span><span class="token punctuation">:</span> ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> dense <span class="token punctuation">:</span> Sequential<span class="token punctuation">(</span>  <span class="token punctuation">(</span>flatten<span class="token punctuation">)</span><span class="token punctuation">:</span> Flatten<span class="token punctuation">(</span>start_dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> end_dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>  <span class="token punctuation">(</span>linear<span class="token punctuation">)</span><span class="token punctuation">:</span> Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">6144</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>  <span class="token punctuation">(</span>sigmoid<span class="token punctuation">)</span><span class="token punctuation">:</span> Sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> child number <span class="token number">3</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python">i <span class="token operator">=</span> <span class="token number">0</span><span class="token keyword">for</span> module <span class="token keyword">in</span> net<span class="token punctuation">.</span>modules<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    i<span class="token operator">+=</span><span class="token number">1</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>module<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"module number:"</span><span class="token punctuation">,</span>i<span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span>Output<span class="token punctuation">:</span>Net<span class="token punctuation">(</span>  <span class="token punctuation">(</span>embedding<span class="token punctuation">)</span><span class="token punctuation">:</span> Embedding<span class="token punctuation">(</span><span class="token number">10000</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> padding_idx<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>  <span class="token punctuation">(</span>conv<span class="token punctuation">)</span><span class="token punctuation">:</span> Sequential<span class="token punctuation">(</span>    <span class="token punctuation">(</span>conv_1<span class="token punctuation">)</span><span class="token punctuation">:</span> Conv1d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token punctuation">(</span>pool_1<span class="token punctuation">)</span><span class="token punctuation">:</span> MaxPool1d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> dilation<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> ceil_mode<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>    <span class="token punctuation">(</span>relu_1<span class="token punctuation">)</span><span class="token punctuation">:</span> ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token punctuation">(</span>conv_2<span class="token punctuation">)</span><span class="token punctuation">:</span> Conv1d<span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token punctuation">(</span>pool_2<span class="token punctuation">)</span><span class="token punctuation">:</span> MaxPool1d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> dilation<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> ceil_mode<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>    <span class="token punctuation">(</span>relu_2<span class="token punctuation">)</span><span class="token punctuation">:</span> ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token punctuation">)</span>  <span class="token punctuation">(</span>dense<span class="token punctuation">)</span><span class="token punctuation">:</span> Sequential<span class="token punctuation">(</span>    <span class="token punctuation">(</span>flatten<span class="token punctuation">)</span><span class="token punctuation">:</span> Flatten<span class="token punctuation">(</span>start_dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> end_dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>    <span class="token punctuation">(</span>linear<span class="token punctuation">)</span><span class="token punctuation">:</span> Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">6144</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>    <span class="token punctuation">(</span>sigmoid<span class="token punctuation">)</span><span class="token punctuation">:</span> Sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token punctuation">)</span><span class="token punctuation">)</span>Embedding<span class="token punctuation">(</span><span class="token number">10000</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> padding_idx<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>Sequential<span class="token punctuation">(</span>  <span class="token punctuation">(</span>conv_1<span class="token punctuation">)</span><span class="token punctuation">:</span> Conv1d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token punctuation">(</span>pool_1<span class="token punctuation">)</span><span class="token punctuation">:</span> MaxPool1d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> dilation<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> ceil_mode<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>  <span class="token punctuation">(</span>relu_1<span class="token punctuation">)</span><span class="token punctuation">:</span> ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token punctuation">(</span>conv_2<span class="token punctuation">)</span><span class="token punctuation">:</span> Conv1d<span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token punctuation">(</span>pool_2<span class="token punctuation">)</span><span class="token punctuation">:</span> MaxPool1d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> dilation<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> ceil_mode<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>  <span class="token punctuation">(</span>relu_2<span class="token punctuation">)</span><span class="token punctuation">:</span> ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>Conv1d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span>MaxPool1d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> dilation<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> ceil_mode<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span>Conv1d<span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span>MaxPool1d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> dilation<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> ceil_mode<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span>Sequential<span class="token punctuation">(</span>  <span class="token punctuation">(</span>flatten<span class="token punctuation">)</span><span class="token punctuation">:</span> Flatten<span class="token punctuation">(</span>start_dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> end_dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>  <span class="token punctuation">(</span>linear<span class="token punctuation">)</span><span class="token punctuation">:</span> Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">6144</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>  <span class="token punctuation">(</span>sigmoid<span class="token punctuation">)</span><span class="token punctuation">:</span> Sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>Flatten<span class="token punctuation">(</span>start_dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> end_dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">6144</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>Sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span>module number<span class="token punctuation">:</span> <span class="token number">13</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>下面我们通过<code>named_children()</code>方法找到embedding层，并将其参数设置为不可训练(相当于冻结embedding层)。</p><pre class="line-numbers language-python"><code class="language-python">children_dict <span class="token operator">=</span> <span class="token punctuation">{</span>name<span class="token punctuation">:</span>module <span class="token keyword">for</span> name<span class="token punctuation">,</span>module <span class="token keyword">in</span> net<span class="token punctuation">.</span>named_children<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token keyword">print</span><span class="token punctuation">(</span>children_dict<span class="token punctuation">)</span>embedding <span class="token operator">=</span> children_dict<span class="token punctuation">[</span><span class="token string">"embedding"</span><span class="token punctuation">]</span>embedding<span class="token punctuation">.</span>requires_grad_<span class="token punctuation">(</span><span class="token boolean">False</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">#冻结其参数</span><span class="token operator">>></span><span class="token operator">></span>Output<span class="token punctuation">:</span><span class="token punctuation">{</span><span class="token string">'embedding'</span><span class="token punctuation">:</span> Embedding<span class="token punctuation">(</span><span class="token number">10000</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> padding_idx<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token string">'conv'</span><span class="token punctuation">:</span> Sequential<span class="token punctuation">(</span>  <span class="token punctuation">(</span>conv_1<span class="token punctuation">)</span><span class="token punctuation">:</span> Conv1d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token punctuation">(</span>pool_1<span class="token punctuation">)</span><span class="token punctuation">:</span> MaxPool1d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> dilation<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> ceil_mode<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>  <span class="token punctuation">(</span>relu_1<span class="token punctuation">)</span><span class="token punctuation">:</span> ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token punctuation">(</span>conv_2<span class="token punctuation">)</span><span class="token punctuation">:</span> Conv1d<span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token punctuation">(</span>pool_2<span class="token punctuation">)</span><span class="token punctuation">:</span> MaxPool1d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> dilation<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> ceil_mode<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>  <span class="token punctuation">(</span>relu_2<span class="token punctuation">)</span><span class="token punctuation">:</span> ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>   <span class="token string">'dense'</span><span class="token punctuation">:</span> Sequential<span class="token punctuation">(</span>  <span class="token punctuation">(</span>flatten<span class="token punctuation">)</span><span class="token punctuation">:</span> Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token punctuation">(</span>linear<span class="token punctuation">)</span><span class="token punctuation">:</span> Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">6144</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>  <span class="token punctuation">(</span>sigmoid<span class="token punctuation">)</span><span class="token punctuation">:</span> Sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">for</span> param <span class="token keyword">in</span> embedding<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>param<span class="token punctuation">.</span>requires_grad<span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>param<span class="token punctuation">.</span>numel<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span>Output<span class="token punctuation">:</span><span class="token boolean">False</span><span class="token number">30000</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> Pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 基础知识 </tag>
            
            <tag> Pytorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Pytorch|构建数据管道</title>
      <link href="/2023/04/06/pytorch-ji-chu-zhi-shi/dataset-sampler-he-dataloader/"/>
      <url>/2023/04/06/pytorch-ji-chu-zhi-shi/dataset-sampler-he-dataloader/</url>
      
        <content type="html"><![CDATA[<h1 id="Pytorch数据管道构建简介"><a href="#Pytorch数据管道构建简介" class="headerlink" title="Pytorch数据管道构建简介"></a>Pytorch数据管道构建简介</h1><p>Pytorch通常使用Dataset和DataLoader这两个工具类来构建数据管道。<br>Dataset定义了数据集的内容，它相当于一个类似列表的数据结构，具有确定的长度，能够用索引获取数据集中的元素。<br>而DataLoader定义了按batch加载数据集的方法，它是一个实现了<code>__iter__</code>方法的可迭代对象，每次迭代输出一个batch的数据。<br>DataLoader能够控制batch的大小，batch中元素的采样方法，以及将batch结果整理成模型所需输入形式的方法，并且能够使用多进程读取数据。<br>在绝大部分情况下，用户只需实现Dataset的<code>__len__</code>方法和<code>__getitem__</code>方法，就可以轻松构建自己的数据集，并用默认数据管道进行加载。对于一些复杂的数据集，用户可能还要自己设计 DataLoader中的<code>collate_fn</code>方法以便将获取的一个批次的数据整理成模型需要的输入形式。</p><h2 id="深入理解Dataset和DataLoader原理"><a href="#深入理解Dataset和DataLoader原理" class="headerlink" title="深入理解Dataset和DataLoader原理"></a>深入理解Dataset和DataLoader原理</h2><h3 id="获取一个batch数据的步骤"><a href="#获取一个batch数据的步骤" class="headerlink" title="获取一个batch数据的步骤"></a><strong>获取一个batch数据的步骤</strong></h3><p>假定数据集的特征和标签分别表示为张量$X$和$Y$，数据集可以表示为$(X, Y)$，假定batch大小为$m$。</p><ol><li>首先我们要确定数据集的长度$n$。结果类似：$n &#x3D; 1000$。</li><li>然后我们从$0$到$n-1$的范围中抽样出$m$个数(batch大小)。假定$m&#x3D;4$，拿到的结果是一个列表，类似：<code>indices = [1,4,8,9]</code>。</li><li>接着我们从数据集中去取这$m$个数对应下标的元素。拿到的结果是一个元组列表，类似：<code>samples = [(X[1],Y[1]),(X[4],Y[4]),(X[8],Y[8]),(X[9],Y[9])]</code>。</li><li>最后我们将结果整理成<strong>两个张量</strong>作为输出。</li></ol><p>拿到的结果是两个张量，类似batch &#x3D; (features, labels)，其中<code>features = torch.stack([X[1],X[4],X[8],X[9]])</code>；<code>labels = torch.stack([Y[1],Y[4],Y[8],Y[9]])</code>。</p><h3 id="Dataset和DataLoader的功能分工"><a href="#Dataset和DataLoader的功能分工" class="headerlink" title="Dataset和DataLoader的功能分工"></a>Dataset和DataLoader的功能分工</h3><p>第1个步骤确定数据集的长度是由 Dataset的<code>__len__</code>方法实现的。<br>第2个步骤从$0$到$n-1$的范围中抽样出$m$个数的方法是由 DataLoader的<code>sampler</code>和<code>batch_sampler</code>参数指定的。<code>sampler</code>参数<strong>指定单个元素抽样方法</strong>，一般无需用户设置，程序默认在DataLoader的参数<code>shuffle=True</code>时采用随机抽样，<code>shuffle=False</code>时采用顺序抽样。<code>batch_sampler</code>参数<strong>将多个抽样的元素整理成一个列表</strong>，一般无需用户设置，默认方法在DataLoader的参数<code>drop_last=True</code>时会丢弃数据集最后一个长度不能被batch大小整除的批次，在<code>drop_last=False</code>时保留最后一个批次。<br>第3个步骤的核心逻辑根据下标取数据集中的元素，是由 Dataset的<code>__getitem__</code>方法实现的。<br>第4个步骤的逻辑由DataLoader的参数<code>collate_fn</code>指定。一般情况下也无需用户设置。<br>Dataset和DataLoader的一般使用方式如下：</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> torch   <span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> TensorDataset<span class="token punctuation">,</span>Dataset<span class="token punctuation">,</span>DataLoader  <span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> RandomSampler<span class="token punctuation">,</span>BatchSampler       ds <span class="token operator">=</span> TensorDataset<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">1000</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                     torch<span class="token punctuation">.</span>randint<span class="token punctuation">(</span>low<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span>high<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span>size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1000</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>float<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  dl <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>ds<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">,</span> drop_last <span class="token operator">=</span> <span class="token boolean">False</span><span class="token punctuation">)</span>  features<span class="token punctuation">,</span> labels <span class="token operator">=</span> next<span class="token punctuation">(</span>iter<span class="token punctuation">(</span>dl<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"features = "</span><span class="token punctuation">,</span>features <span class="token punctuation">)</span>  <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"labels = "</span><span class="token punctuation">,</span>labels <span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>将DataLoader内部调用方式步骤拆解如下：</p><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># step1: 确定数据集长度 (Dataset的 __len__ 方法实现)  </span>ds <span class="token operator">=</span> TensorDataset<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">1000</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                     torch<span class="token punctuation">.</span>randint<span class="token punctuation">(</span>low<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span>high<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span>size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1000</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>float<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"n = "</span><span class="token punctuation">,</span> len<span class="token punctuation">(</span>ds<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># len(ds)等价于 ds.__len__()  </span>  <span class="token comment" spellcheck="true"># step2: 确定抽样indices (DataLoader中的 Sampler和BatchSampler实现)  </span>sampler <span class="token operator">=</span> RandomSampler<span class="token punctuation">(</span>data_source <span class="token operator">=</span> ds<span class="token punctuation">)</span>  batch_sampler <span class="token operator">=</span> BatchSampler<span class="token punctuation">(</span>sampler <span class="token operator">=</span> sampler<span class="token punctuation">,</span>                                batch_size <span class="token operator">=</span> <span class="token number">4</span><span class="token punctuation">,</span> drop_last <span class="token operator">=</span> <span class="token boolean">False</span><span class="token punctuation">)</span>  <span class="token keyword">for</span> idxs <span class="token keyword">in</span> batch_sampler<span class="token punctuation">:</span>      indices <span class="token operator">=</span> idxs      <span class="token keyword">break</span>   <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"indices = "</span><span class="token punctuation">,</span>indices<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># step3: 取出一批样本batch (Dataset的 __getitem__ 方法实现)  </span>batch <span class="token operator">=</span> <span class="token punctuation">[</span>ds<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token keyword">for</span> i <span class="token keyword">in</span>  indices<span class="token punctuation">]</span>  <span class="token comment" spellcheck="true">#  ds[i] 等价于 ds.__getitem__(i)  </span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"batch = "</span><span class="token punctuation">,</span> batch<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># step4: 整理成features和labels (DataLoader 的 collate_fn 方法实现)  </span><span class="token keyword">def</span> <span class="token function">collate_fn</span><span class="token punctuation">(</span>batch<span class="token punctuation">)</span><span class="token punctuation">:</span>      features <span class="token operator">=</span> torch<span class="token punctuation">.</span>stack<span class="token punctuation">(</span><span class="token punctuation">[</span>sample<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token keyword">for</span> sample <span class="token keyword">in</span> batch<span class="token punctuation">]</span><span class="token punctuation">)</span>      labels <span class="token operator">=</span> torch<span class="token punctuation">.</span>stack<span class="token punctuation">(</span><span class="token punctuation">[</span>sample<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token keyword">for</span> sample <span class="token keyword">in</span> batch<span class="token punctuation">]</span><span class="token punctuation">)</span>      <span class="token keyword">return</span> features<span class="token punctuation">,</span>labels     features<span class="token punctuation">,</span>labels <span class="token operator">=</span> collate_fn<span class="token punctuation">(</span>batch<span class="token punctuation">)</span>  <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"features = "</span><span class="token punctuation">,</span>features<span class="token punctuation">)</span>  <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"labels = "</span><span class="token punctuation">,</span>labels<span class="token punctuation">)</span> <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="Dataset和DataLoader的核心源码"><a href="#Dataset和DataLoader的核心源码" class="headerlink" title="Dataset和DataLoader的核心源码"></a><strong>Dataset和DataLoader的核心源码</strong></h3><p>以下是 Dataset和 DataLoader的核心源码，省略了为了提升性能而引入的诸如多进程读取数据相关的代码。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> torch  <span class="token keyword">class</span> <span class="token class-name">Dataset</span><span class="token punctuation">(</span>object<span class="token punctuation">)</span><span class="token punctuation">:</span>      <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>          <span class="token keyword">pass</span>            <span class="token keyword">def</span> <span class="token function">__len__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>          <span class="token keyword">raise</span> NotImplementedError                <span class="token keyword">def</span> <span class="token function">__getitem__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>index<span class="token punctuation">)</span><span class="token punctuation">:</span>          <span class="token keyword">raise</span> NotImplementedError            <span class="token keyword">class</span> <span class="token class-name">DataLoader</span><span class="token punctuation">(</span>object<span class="token punctuation">)</span><span class="token punctuation">:</span>      <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>dataset<span class="token punctuation">,</span>batch_size<span class="token punctuation">,</span>collate_fn <span class="token operator">=</span> None<span class="token punctuation">,</span>shuffle <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">,</span>drop_last <span class="token operator">=</span> <span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">:</span>          self<span class="token punctuation">.</span>dataset <span class="token operator">=</span> dataset          self<span class="token punctuation">.</span>sampler <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>RandomSampler <span class="token keyword">if</span> shuffle <span class="token keyword">else</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>SequentialSampler          self<span class="token punctuation">.</span>batch_sampler <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>BatchSampler          self<span class="token punctuation">.</span>sample_iter <span class="token operator">=</span> self<span class="token punctuation">.</span>batch_sampler<span class="token punctuation">(</span>self<span class="token punctuation">.</span>sampler<span class="token punctuation">(</span>self<span class="token punctuation">.</span>dataset<span class="token punctuation">)</span><span class="token punctuation">,</span>                          batch_size <span class="token operator">=</span> batch_size<span class="token punctuation">,</span> drop_last <span class="token operator">=</span> drop_last<span class="token punctuation">)</span>          self<span class="token punctuation">.</span>collate_fn <span class="token operator">=</span> collate_fn <span class="token keyword">if</span> collate_fn <span class="token keyword">is</span> <span class="token operator">not</span> None <span class="token keyword">else</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>_utils<span class="token punctuation">.</span>collate<span class="token punctuation">.</span>default_collate                <span class="token keyword">def</span> <span class="token function">__next__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>          indices <span class="token operator">=</span> next<span class="token punctuation">(</span>iter<span class="token punctuation">(</span>self<span class="token punctuation">.</span>sample_iter<span class="token punctuation">)</span><span class="token punctuation">)</span>          batch <span class="token operator">=</span> self<span class="token punctuation">.</span>collate_fn<span class="token punctuation">(</span><span class="token punctuation">[</span>self<span class="token punctuation">.</span>dataset<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> indices<span class="token punctuation">]</span><span class="token punctuation">)</span>          <span class="token keyword">return</span> batch            <span class="token keyword">def</span> <span class="token function">__iter__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>          <span class="token keyword">return</span> self <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="Sampler原理"><a href="#Sampler原理" class="headerlink" title="Sampler原理"></a>Sampler原理</h2><h3 id="Sampler参数传递"><a href="#Sampler参数传递" class="headerlink" title="Sampler参数传递"></a>Sampler参数传递</h3><p>假设数据是一组图像，每一张图像对应一个index，那么如果要读取数据就只需要对应的index即可，即上面代码中的indices，而选取index的方式有多种，有按顺序的，也有乱序的，所以这个工作需要Sampler完成。<br>首先看一下DataLoader的源代码长什么样。为方便理解只选取了num_works为0的情况（num_works简单理解就是能够并行化地读取数据）。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">DataLoader</span><span class="token punctuation">(</span>object<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> dataset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> sampler<span class="token operator">=</span>None<span class="token punctuation">,</span>                 batch_sampler<span class="token operator">=</span>None<span class="token punctuation">,</span> num_workers<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> collate_fn<span class="token operator">=</span>default_collate<span class="token punctuation">,</span>                 pin_memory<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> drop_last<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> timeout<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span>                 worker_init_fn<span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>        <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>    <span class="token keyword">def</span> <span class="token function">__next__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">if</span> self<span class="token punctuation">.</span>num_workers <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>              indices <span class="token operator">=</span> next<span class="token punctuation">(</span>self<span class="token punctuation">.</span>sample_iter<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># Sampler</span>            batch <span class="token operator">=</span> self<span class="token punctuation">.</span>collate_fn<span class="token punctuation">(</span><span class="token punctuation">[</span>self<span class="token punctuation">.</span>dataset<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> indices<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># Dataset</span>            <span class="token keyword">if</span> self<span class="token punctuation">.</span>pin_memory<span class="token punctuation">:</span>                batch <span class="token operator">=</span> _utils<span class="token punctuation">.</span>pin_memory<span class="token punctuation">.</span>pin_memory_batch<span class="token punctuation">(</span>batch<span class="token punctuation">)</span>            <span class="token keyword">return</span> batch<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>可以看到初始化参数里有两种sampler：<code>sampler</code>和<code>batch_sampler</code>，都默认为None。前者的作用是生成一系列的index，而batch_sampler则是将sampler生成的indices打包分组，得到一个又一个batch的index。例如下面示例中，<code>BatchSampler</code>将<code>SequentialSampler</code>生成的index按照指定的batch size分组。<br><code>collate_fn</code>的作用就是将一个batch的数据进行整理合并的操作。默认的<code>collate_fn</code>是将img和label分别合并成imgs和labels，所以如果你的__getitem__方法只是返回 img、label，那么你可以使用默认的collate_fn方法，但是如果你每次读取的数据有img，box，label等等，那么你就需要自定义<code>collate_fn</code>来将对应的数据合并成一个batch数据，这样方便后续的训练步骤。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span><span class="token keyword">in</span> <span class="token punctuation">:</span> list<span class="token punctuation">(</span>BatchSampler<span class="token punctuation">(</span>SequentialSampler<span class="token punctuation">(</span>range<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> drop_last<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span>out<span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">9</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>Pytorch中已经实现的Sampler有如下几种：</p><ul><li>SequentialSampler</li><li>RandomSampler</li><li>WeightedSampler</li><li>SubsetRandomSampler</li></ul><p>需要注意的是DataLoader的部分<strong>初始化参数之间存在互斥关系</strong>：</p><ul><li>如果自定义了<code>batch_sampler</code>，那么这些参数都必须使用默认值：batch_size，shuffle，sampler，drop_last.</li><li>如果自定义了<code>sampler</code>，那么<code>shuffle</code>需要设置为False</li><li>如果<code>sampler</code>和<code>batch_sampler</code>都为None，那么<code>batch_sampler</code>使用Pytorch已经实现好的BatchSampler，而sampler分两种情况：<ul><li>若<code>shuffle=True</code>，则<code>sampler=RandomSampler(dataset)</code></li><li>若<code>shuffle=False</code>，则<code>sampler=SequentialSampler(dataset)</code></li></ul></li></ul><h3 id="自定义Sampler和BatchSampler"><a href="#自定义Sampler和BatchSampler" class="headerlink" title="自定义Sampler和BatchSampler"></a>自定义Sampler和BatchSampler</h3><p>查看源代码其实可以发现，所有采样器其实都继承自同一个父类，即Sampler,其代码定义如下：</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Sampler</span><span class="token punctuation">(</span>object<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> data_source<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">pass</span>    <span class="token keyword">def</span> <span class="token function">__iter__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">raise</span> NotImplementedError            <span class="token keyword">def</span> <span class="token function">__len__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> len<span class="token punctuation">(</span>self<span class="token punctuation">.</span>data_source<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>所以要做的就是定义好<code>__iter__(self)</code>函数，不过要注意的是该函数的返回值需要是可迭代的。例如<code>SequentialSampler</code>返回的是<code>iter(range(len(self.data_source)))</code>。<br>另外<code>BatchSampler</code>与其他Sampler的主要区别是它需要将Sampler作为参数进行打包，进而每次迭代返回以batch_size为大小的index列表。也就是说在后面的读取数据过程中使用的都是batch sampler。</p><h2 id="创建数据集的3种方式"><a href="#创建数据集的3种方式" class="headerlink" title="创建数据集的3种方式"></a>创建数据集的3种方式</h2><p>Dataset创建数据集常用的方法有：</p><ol><li>使用<code>torch.utils.data.TensorDataset</code>根据Tensor创建数据集(numpy的array，Pandas的DataFrame需要先转换成Tensor)。</li><li>使用<code>torchvision.datasets.ImageFolder</code>根据图片目录创建图片数据集。</li><li>继承<code>torch.utils.data.Dataset</code>创建自定义数据集。</li></ol><p>此外，还可以通过</p><ul><li><code>torch.utils.data.random_split</code>将一个数据集分割成多份，常用于分割训练集，验证集和测试集。</li><li>调用Dataset的加法运算符($+$)将多个数据集合并成一个数据集。</li></ul><h3 id="根据Tensor创建数据集"><a href="#根据Tensor创建数据集" class="headerlink" title="根据Tensor创建数据集"></a><strong>根据Tensor创建数据集</strong></h3><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np   <span class="token keyword">import</span> torch   <span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> TensorDataset<span class="token punctuation">,</span>Dataset<span class="token punctuation">,</span>DataLoader<span class="token punctuation">,</span>random_split <span class="token comment" spellcheck="true"># 根据Tensor创建数据集  </span><span class="token keyword">from</span> sklearn <span class="token keyword">import</span> datasets   iris <span class="token operator">=</span> datasets<span class="token punctuation">.</span>load_iris<span class="token punctuation">(</span><span class="token punctuation">)</span>  ds_iris <span class="token operator">=</span> TensorDataset<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>iris<span class="token punctuation">.</span>data<span class="token punctuation">)</span><span class="token punctuation">,</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>iris<span class="token punctuation">.</span>target<span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 分割成训练集和预测集  </span>n_train <span class="token operator">=</span> int<span class="token punctuation">(</span>len<span class="token punctuation">(</span>ds_iris<span class="token punctuation">)</span><span class="token operator">*</span><span class="token number">0.8</span><span class="token punctuation">)</span>  n_val <span class="token operator">=</span> len<span class="token punctuation">(</span>ds_iris<span class="token punctuation">)</span> <span class="token operator">-</span> n_train  ds_train<span class="token punctuation">,</span> ds_val <span class="token operator">=</span> random_split<span class="token punctuation">(</span>ds_iris<span class="token punctuation">,</span><span class="token punctuation">[</span>n_train<span class="token punctuation">,</span>n_val<span class="token punctuation">]</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>type<span class="token punctuation">(</span>ds_iris<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token keyword">print</span><span class="token punctuation">(</span>type<span class="token punctuation">(</span>ds_train<span class="token punctuation">)</span><span class="token punctuation">)</span> <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 使用DataLoader加载数据集  </span>dl_train<span class="token punctuation">,</span>dl_val <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>ds_train<span class="token punctuation">,</span> batch_size <span class="token operator">=</span> <span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">,</span> DataLoader<span class="token punctuation">(</span>ds_val<span class="token punctuation">,</span> batch_size <span class="token operator">=</span> <span class="token number">8</span><span class="token punctuation">)</span>    <span class="token keyword">for</span> features<span class="token punctuation">,</span>labels <span class="token keyword">in</span> dl_train<span class="token punctuation">:</span>      <span class="token keyword">print</span><span class="token punctuation">(</span>features<span class="token punctuation">,</span>labels<span class="token punctuation">)</span>      <span class="token keyword">break</span>  <span class="token comment" spellcheck="true"># 演示加法运算符（`+`）的合并作用  </span>ds_data <span class="token operator">=</span> ds_train <span class="token operator">+</span> ds_val    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'len(ds_train) = '</span><span class="token punctuation">,</span>len<span class="token punctuation">(</span>ds_train<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'len(ds_valid) = '</span><span class="token punctuation">,</span>len<span class="token punctuation">(</span>ds_val<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'len(ds_train+ds_valid) = '</span><span class="token punctuation">,</span>len<span class="token punctuation">(</span>ds_data<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token keyword">print</span><span class="token punctuation">(</span>type<span class="token punctuation">(</span>ds_data<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="根据图片目录创建图片数据集"><a href="#根据图片目录创建图片数据集" class="headerlink" title="根据图片目录创建图片数据集"></a><strong>根据图片目录创建图片数据集</strong></h3><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np   <span class="token keyword">import</span> torch   <span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader  <span class="token keyword">from</span> torchvision <span class="token keyword">import</span> transforms<span class="token punctuation">,</span>datasets   <span class="token comment" spellcheck="true"># 定义图片增强操作  </span>transform_train <span class="token operator">=</span> transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>     transforms<span class="token punctuation">.</span>RandomHorizontalFlip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token comment" spellcheck="true">#随机水平翻转  </span>   transforms<span class="token punctuation">.</span>RandomVerticalFlip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token comment" spellcheck="true">#随机垂直翻转  </span>   transforms<span class="token punctuation">.</span>RandomRotation<span class="token punctuation">(</span><span class="token number">45</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment" spellcheck="true">#随机在45度角度内旋转  </span>   transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">#转换成张量并进行标准化</span>  <span class="token punctuation">]</span>  <span class="token punctuation">)</span>   transform_valid <span class="token operator">=</span> transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>      transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token punctuation">]</span>  <span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 根据图片目录创建数据集  </span><span class="token keyword">def</span> <span class="token function">transform_label</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>      <span class="token keyword">return</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span>x<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>float<span class="token punctuation">(</span><span class="token punctuation">)</span>    ds_train <span class="token operator">=</span> datasets<span class="token punctuation">.</span>ImageFolder<span class="token punctuation">(</span><span class="token string">"xx/xxx/cifar2/train/"</span><span class="token punctuation">,</span>              transform <span class="token operator">=</span> transform_train<span class="token punctuation">,</span> target_transform<span class="token operator">=</span> transform_label<span class="token punctuation">)</span>  ds_val <span class="token operator">=</span> datasets<span class="token punctuation">.</span>ImageFolder<span class="token punctuation">(</span><span class="token string">"xx/xxx/cifar2/test/"</span><span class="token punctuation">,</span>              transform <span class="token operator">=</span> transform_valid<span class="token punctuation">,</span> target_transform<span class="token operator">=</span> transform_label<span class="token punctuation">)</span>  <span class="token keyword">print</span><span class="token punctuation">(</span>ds_train<span class="token punctuation">.</span>class_to_idx<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 使用DataLoader加载数据集  </span>dl_train <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>ds_train<span class="token punctuation">,</span> batch_size <span class="token operator">=</span> <span class="token number">50</span><span class="token punctuation">,</span> shuffle <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span>  dl_val <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>ds_val<span class="token punctuation">,</span> batch_size <span class="token operator">=</span> <span class="token number">50</span><span class="token punctuation">,</span> shuffle <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span>    <span class="token keyword">for</span> features<span class="token punctuation">,</span>labels <span class="token keyword">in</span> dl_train<span class="token punctuation">:</span>      <span class="token keyword">print</span><span class="token punctuation">(</span>features<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>      <span class="token keyword">print</span><span class="token punctuation">(</span>labels<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>      <span class="token keyword">break</span>  <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="创建自定义数据集"><a href="#创建自定义数据集" class="headerlink" title="创建自定义数据集"></a><strong>创建自定义数据集</strong></h3><p>下面通过继承<code>torch.utils.data.Dataset</code>创建自定义数据集的方式来对 cifar2 构建数据管道。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> pathlib <span class="token keyword">import</span> Path   <span class="token keyword">from</span> PIL <span class="token keyword">import</span> Image     <span class="token keyword">class</span> <span class="token class-name">Cifar2Dataset</span><span class="token punctuation">(</span>Dataset<span class="token punctuation">)</span><span class="token punctuation">:</span>      <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>imgs_dir<span class="token punctuation">,</span> img_transform<span class="token punctuation">)</span><span class="token punctuation">:</span>          self<span class="token punctuation">.</span>files <span class="token operator">=</span> list<span class="token punctuation">(</span>Path<span class="token punctuation">(</span>imgs_dir<span class="token punctuation">)</span><span class="token punctuation">.</span>rglob<span class="token punctuation">(</span><span class="token string">"*.jpg"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>          self<span class="token punctuation">.</span>transform <span class="token operator">=</span> img_transform                <span class="token keyword">def</span> <span class="token function">__len__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">:</span>          <span class="token keyword">return</span> len<span class="token punctuation">(</span>self<span class="token punctuation">.</span>files<span class="token punctuation">)</span>            <span class="token keyword">def</span> <span class="token function">__getitem__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>i<span class="token punctuation">)</span><span class="token punctuation">:</span>          file_i <span class="token operator">=</span> str<span class="token punctuation">(</span>self<span class="token punctuation">.</span>files<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span>          img <span class="token operator">=</span> Image<span class="token punctuation">.</span>open<span class="token punctuation">(</span>file_i<span class="token punctuation">)</span>          tensor <span class="token operator">=</span> self<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>img<span class="token punctuation">)</span>          label <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1.0</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token keyword">if</span>  <span class="token string">"1_automobile"</span> <span class="token keyword">in</span> file_i <span class="token keyword">else</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>          <span class="token keyword">return</span> tensor<span class="token punctuation">,</span>label          <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python">train_dir <span class="token operator">=</span> <span class="token string">"xx/xxx/cifar2/train/"</span>  test_dir <span class="token operator">=</span> <span class="token string">"xx/xxx/cifar2/test/"</span> <span class="token comment" spellcheck="true"># 图片增强使用上一小节定义的</span>ds_train <span class="token operator">=</span> Cifar2Dataset<span class="token punctuation">(</span>train_dir<span class="token punctuation">,</span> transform_train<span class="token punctuation">)</span>  ds_val <span class="token operator">=</span> Cifar2Dataset<span class="token punctuation">(</span>test_dir<span class="token punctuation">,</span> transform_val<span class="token punctuation">)</span>    dl_train <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>ds_train<span class="token punctuation">,</span>batch_size <span class="token operator">=</span> <span class="token number">50</span><span class="token punctuation">,</span>shuffle <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span>  dl_val <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>ds_val<span class="token punctuation">,</span>batch_size <span class="token operator">=</span> <span class="token number">50</span><span class="token punctuation">,</span>shuffle <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span>  <span class="token keyword">for</span> features<span class="token punctuation">,</span>labels <span class="token keyword">in</span> dl_train<span class="token punctuation">:</span>      <span class="token keyword">print</span><span class="token punctuation">(</span>features<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>      <span class="token keyword">print</span><span class="token punctuation">(</span>labels<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>      <span class="token keyword">break</span>  <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="使用DataLoader加载数据集"><a href="#使用DataLoader加载数据集" class="headerlink" title="使用DataLoader加载数据集"></a>使用DataLoader加载数据集</h2><p>DataLoader能够控制batch的大小，batch中元素的采样方法，以及将batch结果整理成模型所需输入形式的方法，并且能够使用多进程读取数据。<br>DataLoader的函数签名如下。</p><pre class="line-numbers language-python"><code class="language-python">DataLoader<span class="token punctuation">(</span>      dataset<span class="token punctuation">,</span>      batch_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>      shuffle<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>      sampler<span class="token operator">=</span>None<span class="token punctuation">,</span>      batch_sampler<span class="token operator">=</span>None<span class="token punctuation">,</span>      num_workers<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span>      collate_fn<span class="token operator">=</span>None<span class="token punctuation">,</span>      pin_memory<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>      drop_last<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>      timeout<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span>      worker_init_fn<span class="token operator">=</span>None<span class="token punctuation">,</span>      multiprocessing_context<span class="token operator">=</span>None<span class="token punctuation">,</span>  <span class="token punctuation">)</span>  <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ul><li>dataset : 数据集</li><li>batch_size: 批次大小</li><li>shuffle: 是否乱序</li><li>sampler: 样本采样函数，一般无需设置。</li><li>batch_sampler: 批次采样函数，一般无需设置。</li><li>num_workers: 使用多进程读取数据，设置的进程数。</li><li>collate_fn: 整理一个批次数据的函数。</li><li>pin_memory: 是否设置为锁业内存。默认为False，锁业内存不会使用虚拟内存(硬盘)，从锁业内存拷贝到GPU上速度会更快。</li><li>drop_last: 是否丢弃最后一个样本数量不足batch_size批次数据。</li><li>timeout: 加载一个数据批次的最长等待时间，一般无需设置。</li><li>worker_init_fn: 每个worker中dataset的初始化函数，常用于IterableDataset。一般不使用。</li></ul><p>一般情况下，我们仅仅会配置<code>dataset</code>，<code>batch_size</code>，<code>shuffle</code>，<code>num_workers</code>，<code>pin_memory</code>，<code>drop_last</code>这六个参数，有时候对于一些复杂结构的数据集，还需要自定义collate_fn函数，其他参数一般使用默认值即可。<br>DataLoader除了可以加载我们前面讲的<code>torch.utils.data.Dataset</code>外，还能够加载另外一种数据集 <code>torch.utils.data.IterableDataset</code>。和Dataset数据集相当于一种列表结构不同，IterableDataset相当于一种迭代器结构。它更加复杂，一般较少使用。</p>]]></content>
      
      
      <categories>
          
          <category> Pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 基础知识 </tag>
            
            <tag> Pytorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Pytorch|构建模型的3种方式</title>
      <link href="/2023/04/05/pytorch-ji-chu-zhi-shi/02-gou-jian-mo-xing-de-3-chong-fang-shi/"/>
      <url>/2023/04/05/pytorch-ji-chu-zhi-shi/02-gou-jian-mo-xing-de-3-chong-fang-shi/</url>
      
        <content type="html"><![CDATA[<h1 id="Pytorch构建模型的方式"><a href="#Pytorch构建模型的方式" class="headerlink" title="Pytorch构建模型的方式"></a>Pytorch构建模型的方式</h1><p>可以使用以下3种方式构建模型：</p><ol><li>继承nn.Module基类构建自定义模型。</li><li>使用nn.Sequential按层顺序构建模型。</li><li>继承nn.Module基类构建模型，并辅助应用模型容器(nn.Sequential, nn.ModuleList, nn.ModuleDict)进行封装。</li></ol><p>模型的每一层最好有对应的名字，比如XXX_layer，这样可以通过<code>model.XXX_layer</code>访问到这一层，可以查看该层的具体信息，比如该层的权重<code>model.XXX_layer.weight</code>，卷积层的卷积核大小<code>model.XXX_layer.kernel_size</code>，这些信息的查看和定义层的类时传入的参数名一致。</p><h2 id="继承nn-Module类构建模型"><a href="#继承nn-Module类构建模型" class="headerlink" title="继承nn.Module类构建模型"></a>继承nn.Module类构建模型</h2><p>模型中的用到的层一般在<code>__init__()</code>函数中定义，然后在<code>forward()</code>方法中定义模型的正向传播逻辑。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Net</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>Net<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>pool1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">,</span>stride <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>out_channels<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>kernel_size <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>conv2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>out_channels<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span>kernel_size <span class="token operator">=</span> <span class="token number">5</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>dropout <span class="token operator">=</span> nn<span class="token punctuation">.</span>Dropout2d<span class="token punctuation">(</span>p <span class="token operator">=</span> <span class="token number">0.1</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>adaptive_pool <span class="token operator">=</span> nn<span class="token punctuation">.</span>AdaptiveMaxPool2d<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>flatten <span class="token operator">=</span> nn<span class="token punctuation">.</span>Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>linear1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>relu <span class="token operator">=</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>linear2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>sigmoid <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>pool1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>conv2<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>pool1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>dropout<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>adaptive_pool<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>flatten<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>linear1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>linear2<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        y <span class="token operator">=</span> self<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">return</span> ynet <span class="token operator">=</span> Net<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>net<span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span>Output<span class="token punctuation">:</span>Net<span class="token punctuation">(</span>  <span class="token punctuation">(</span>pool1<span class="token punctuation">)</span><span class="token punctuation">:</span> MaxPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> dilation<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> ceil_mode<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>  <span class="token punctuation">(</span>conv1<span class="token punctuation">)</span><span class="token punctuation">:</span> Conv2d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token punctuation">(</span>conv2<span class="token punctuation">)</span><span class="token punctuation">:</span> Conv2d<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token punctuation">(</span>dropout<span class="token punctuation">)</span><span class="token punctuation">:</span> Dropout2d<span class="token punctuation">(</span>p<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>  <span class="token punctuation">(</span>adaptive_pool<span class="token punctuation">)</span><span class="token punctuation">:</span> AdaptiveMaxPool2d<span class="token punctuation">(</span>output_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token punctuation">(</span>flatten<span class="token punctuation">)</span><span class="token punctuation">:</span> Flatten<span class="token punctuation">(</span>start_dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> end_dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>  <span class="token punctuation">(</span>linear1<span class="token punctuation">)</span><span class="token punctuation">:</span> Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>  <span class="token punctuation">(</span>relu<span class="token punctuation">)</span><span class="token punctuation">:</span> ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token punctuation">(</span>linear2<span class="token punctuation">)</span><span class="token punctuation">:</span> Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>  <span class="token punctuation">(</span>sigmoid<span class="token punctuation">)</span><span class="token punctuation">:</span> Sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="使用nn-Sequential按层顺序构建模型"><a href="#使用nn-Sequential按层顺序构建模型" class="headerlink" title="使用nn.Sequential按层顺序构建模型"></a>使用nn.Sequential按层顺序构建模型</h2><p>使用<code>nn.Sequential()</code>按层顺序构建模型<strong>无需定义forward方法</strong>。仅仅<strong>适合于简单的顺序模型</strong>。</p><h3 id="add-module方法"><a href="#add-module方法" class="headerlink" title="add_module方法"></a>add_module方法</h3><pre class="line-numbers language-python"><code class="language-python">net <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token punctuation">)</span>net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">"pool1"</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">,</span>stride <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">"conv1"</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>out_channels<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>kernel_size <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">"conv2"</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>out_channels<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span>kernel_size <span class="token operator">=</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">"dropout"</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Dropout2d<span class="token punctuation">(</span>p <span class="token operator">=</span> <span class="token number">0.1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">"adaptive_pool"</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>AdaptiveMaxPool2d<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">"flatten"</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">"linear1"</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">)</span>net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">"relu"</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">"linear2"</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">"sigmoid"</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="利用变长参数"><a href="#利用变长参数" class="headerlink" title="利用变长参数"></a>利用变长参数</h3><p>这种方式构建时<strong>不能给每个层指定名称</strong>。</p><pre class="line-numbers language-python"><code class="language-python">net <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>    nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>out_channels<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>kernel_size <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">,</span>stride <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>out_channels<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span>kernel_size <span class="token operator">=</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">,</span>stride <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    nn<span class="token punctuation">.</span>Dropout2d<span class="token punctuation">(</span>p <span class="token operator">=</span> <span class="token number">0.1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    nn<span class="token punctuation">.</span>AdaptiveMaxPool2d<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    nn<span class="token punctuation">.</span>Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    nn<span class="token punctuation">.</span>Sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>net<span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span>Output<span class="token punctuation">:</span>Sequential<span class="token punctuation">(</span>  <span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span> Conv2d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span> MaxPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> dilation<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> ceil_mode<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>  <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">:</span> Conv2d<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">:</span> MaxPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> dilation<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> ceil_mode<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>  <span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">:</span> Dropout2d<span class="token punctuation">(</span>p<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>  <span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">:</span> AdaptiveMaxPool2d<span class="token punctuation">(</span>output_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">:</span> Flatten<span class="token punctuation">(</span>start_dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> end_dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>  <span class="token punctuation">(</span><span class="token number">7</span><span class="token punctuation">)</span><span class="token punctuation">:</span> Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>  <span class="token punctuation">(</span><span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">:</span> ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token punctuation">(</span><span class="token number">9</span><span class="token punctuation">)</span><span class="token punctuation">:</span> Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>  <span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">:</span> Sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="利用OrderedDict"><a href="#利用OrderedDict" class="headerlink" title="利用OrderedDict"></a>利用OrderedDict</h3><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> collections <span class="token keyword">import</span> OrderedDictnet <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>        OrderedDict<span class="token punctuation">(</span>          <span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token string">"conv1"</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>out_channels<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>kernel_size <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            <span class="token punctuation">(</span><span class="token string">"pool1"</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">,</span>stride <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            <span class="token punctuation">(</span><span class="token string">"conv2"</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>out_channels<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span>kernel_size <span class="token operator">=</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            <span class="token punctuation">(</span><span class="token string">"pool2"</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">,</span>stride <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            <span class="token punctuation">(</span><span class="token string">"dropout"</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Dropout2d<span class="token punctuation">(</span>p <span class="token operator">=</span> <span class="token number">0.1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            <span class="token punctuation">(</span><span class="token string">"adaptive_pool"</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>AdaptiveMaxPool2d<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            <span class="token punctuation">(</span><span class="token string">"flatten"</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            <span class="token punctuation">(</span><span class="token string">"linear1"</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            <span class="token punctuation">(</span><span class="token string">"relu"</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            <span class="token punctuation">(</span><span class="token string">"linear2"</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            <span class="token punctuation">(</span><span class="token string">"sigmoid"</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>          <span class="token punctuation">]</span>        <span class="token punctuation">)</span>    <span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="继承nn-Module基类构建模型并应用模型容器进行封装"><a href="#继承nn-Module基类构建模型并应用模型容器进行封装" class="headerlink" title="继承nn.Module基类构建模型并应用模型容器进行封装"></a>继承nn.Module基类构建模型并应用模型容器进行封装</h2><p>当模型的结构比较复杂时，我们可以应用模型容器(<code>nn.Sequential</code>，<code>nn.ModuleList</code>，<code>nn.ModuleDict</code>)对模型的部分结构进行封装。这样做会让模型整体更加有层次感，有时候也能减少代码量。<br>注意，在下面的范例中我们每次仅仅使用一种模型容器，但实际上这些模型容器的使用是非常灵活的，可以在一个模型中任意组合任意嵌套使用。</p><h3 id="nn-Sequential作为模型容器"><a href="#nn-Sequential作为模型容器" class="headerlink" title="nn.Sequential作为模型容器"></a>nn.Sequential作为模型容器</h3><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Net</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>Net<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>conv <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>out_channels<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>kernel_size <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">,</span>stride <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>out_channels<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span>kernel_size <span class="token operator">=</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">,</span>stride <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Dropout2d<span class="token punctuation">(</span>p <span class="token operator">=</span> <span class="token number">0.1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>AdaptiveMaxPool2d<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token punctuation">)</span>        self<span class="token punctuation">.</span>dense <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token punctuation">)</span>            <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>conv<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        y <span class="token operator">=</span> self<span class="token punctuation">.</span>dense<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">return</span> y net <span class="token operator">=</span> Net<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>net<span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span>Output<span class="token punctuation">:</span>Net<span class="token punctuation">(</span>  <span class="token punctuation">(</span>conv<span class="token punctuation">)</span><span class="token punctuation">:</span> Sequential<span class="token punctuation">(</span>    <span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span> Conv2d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span> MaxPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> dilation<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> ceil_mode<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>    <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">:</span> Conv2d<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">:</span> MaxPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> dilation<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> ceil_mode<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>    <span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">:</span> Dropout2d<span class="token punctuation">(</span>p<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>    <span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">:</span> AdaptiveMaxPool2d<span class="token punctuation">(</span>output_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token punctuation">)</span>  <span class="token punctuation">(</span>dense<span class="token punctuation">)</span><span class="token punctuation">:</span> Sequential<span class="token punctuation">(</span>    <span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span> Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span> Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>    <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">:</span> ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">:</span> Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>    <span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">:</span> Sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="nn-ModuleList作为模型容器"><a href="#nn-ModuleList作为模型容器" class="headerlink" title="nn.ModuleList作为模型容器"></a>nn.ModuleList作为模型容器</h3><p>注意<code>ModuleList</code>不能用Python中的列表代替。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Net</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>Net<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>layers <span class="token operator">=</span> nn<span class="token punctuation">.</span>ModuleList<span class="token punctuation">(</span><span class="token punctuation">[</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>out_channels<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>kernel_size <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">,</span>stride <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>out_channels<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span>kernel_size <span class="token operator">=</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">,</span>stride <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Dropout2d<span class="token punctuation">(</span>p <span class="token operator">=</span> <span class="token number">0.1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>AdaptiveMaxPool2d<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span>        <span class="token punctuation">)</span>            <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">for</span> layer <span class="token keyword">in</span> self<span class="token punctuation">.</span>layers<span class="token punctuation">:</span>            x <span class="token operator">=</span> layer<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">return</span> x        net <span class="token operator">=</span> Net<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>net<span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span>Output<span class="token punctuation">:</span>Net<span class="token punctuation">(</span>  <span class="token punctuation">(</span>layers<span class="token punctuation">)</span><span class="token punctuation">:</span> ModuleList<span class="token punctuation">(</span>    <span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span> Conv2d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span> MaxPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> dilation<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> ceil_mode<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>    <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">:</span> Conv2d<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">:</span> MaxPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> dilation<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> ceil_mode<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>    <span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">:</span> Dropout2d<span class="token punctuation">(</span>p<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>    <span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">:</span> AdaptiveMaxPool2d<span class="token punctuation">(</span>output_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">:</span> Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token punctuation">(</span><span class="token number">7</span><span class="token punctuation">)</span><span class="token punctuation">:</span> Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>    <span class="token punctuation">(</span><span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">:</span> ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token punctuation">(</span><span class="token number">9</span><span class="token punctuation">)</span><span class="token punctuation">:</span> Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>    <span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">:</span> Sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="nn-ModuleDict作为模型容器"><a href="#nn-ModuleDict作为模型容器" class="headerlink" title="nn.ModuleDict作为模型容器"></a>nn.ModuleDict作为模型容器</h3><p>注意<code>的ModuleDict</code>不能用Python中的字典代替。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Net</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>Net<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>layers_dict <span class="token operator">=</span> nn<span class="token punctuation">.</span>ModuleDict<span class="token punctuation">(</span>            <span class="token punctuation">{</span><span class="token string">"conv1"</span><span class="token punctuation">:</span>nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>out_channels<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>kernel_size <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>               <span class="token string">"pool"</span><span class="token punctuation">:</span> nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">,</span>stride <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>               <span class="token string">"conv2"</span><span class="token punctuation">:</span>nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>out_channels<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span>kernel_size <span class="token operator">=</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span>               <span class="token string">"dropout"</span><span class="token punctuation">:</span> nn<span class="token punctuation">.</span>Dropout2d<span class="token punctuation">(</span>p <span class="token operator">=</span> <span class="token number">0.1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>               <span class="token string">"adaptive"</span><span class="token punctuation">:</span>nn<span class="token punctuation">.</span>AdaptiveMaxPool2d<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>               <span class="token string">"flatten"</span><span class="token punctuation">:</span> nn<span class="token punctuation">.</span>Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>               <span class="token string">"linear1"</span><span class="token punctuation">:</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">,</span>               <span class="token string">"relu"</span><span class="token punctuation">:</span>nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>               <span class="token string">"linear2"</span><span class="token punctuation">:</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>               <span class="token string">"sigmoid"</span><span class="token punctuation">:</span> nn<span class="token punctuation">.</span>Sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span>              <span class="token punctuation">}</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>        layers <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"conv1"</span><span class="token punctuation">,</span><span class="token string">"pool"</span><span class="token punctuation">,</span><span class="token string">"conv2"</span><span class="token punctuation">,</span><span class="token string">"pool"</span><span class="token punctuation">,</span><span class="token string">"dropout"</span><span class="token punctuation">,</span><span class="token string">"adaptive"</span><span class="token punctuation">,</span>                  <span class="token string">"flatten"</span><span class="token punctuation">,</span><span class="token string">"linear1"</span><span class="token punctuation">,</span><span class="token string">"relu"</span><span class="token punctuation">,</span><span class="token string">"linear2"</span><span class="token punctuation">,</span><span class="token string">"sigmoid"</span><span class="token punctuation">]</span>        <span class="token keyword">for</span> layer <span class="token keyword">in</span> layers<span class="token punctuation">:</span>            x <span class="token operator">=</span> self<span class="token punctuation">.</span>layers_dict<span class="token punctuation">[</span>layer<span class="token punctuation">]</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">return</span> x        net <span class="token operator">=</span> Net<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>net<span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span>Output<span class="token punctuation">:</span>Net<span class="token punctuation">(</span>  <span class="token punctuation">(</span>layers_dict<span class="token punctuation">)</span><span class="token punctuation">:</span> ModuleDict<span class="token punctuation">(</span>    <span class="token punctuation">(</span>adaptive<span class="token punctuation">)</span><span class="token punctuation">:</span> AdaptiveMaxPool2d<span class="token punctuation">(</span>output_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token punctuation">(</span>conv1<span class="token punctuation">)</span><span class="token punctuation">:</span> Conv2d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token punctuation">(</span>conv2<span class="token punctuation">)</span><span class="token punctuation">:</span> Conv2d<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token punctuation">(</span>dropout<span class="token punctuation">)</span><span class="token punctuation">:</span> Dropout2d<span class="token punctuation">(</span>p<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>    <span class="token punctuation">(</span>flatten<span class="token punctuation">)</span><span class="token punctuation">:</span> Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token punctuation">(</span>linear1<span class="token punctuation">)</span><span class="token punctuation">:</span> Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>    <span class="token punctuation">(</span>linear2<span class="token punctuation">)</span><span class="token punctuation">:</span> Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>    <span class="token punctuation">(</span>pool<span class="token punctuation">)</span><span class="token punctuation">:</span> MaxPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> dilation<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> ceil_mode<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>    <span class="token punctuation">(</span>relu<span class="token punctuation">)</span><span class="token punctuation">:</span> ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token punctuation">(</span>sigmoid<span class="token punctuation">)</span><span class="token punctuation">:</span> Sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> Pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 基础知识 </tag>
            
            <tag> Pytorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Pytorch|张量和张量操作</title>
      <link href="/2023/04/01/pytorch-ji-chu-zhi-shi/01-zhang-liang-he-zhang-liang-cao-zuo/"/>
      <url>/2023/04/01/pytorch-ji-chu-zhi-shi/01-zhang-liang-he-zhang-liang-cao-zuo/</url>
      
        <content type="html"><![CDATA[<h1 id="张量"><a href="#张量" class="headerlink" title="张量"></a>张量</h1><p>张量是基于向量和矩阵的推广，其本质就是多维数组。</p><h2 id="创建张量"><a href="#创建张量" class="headerlink" title="创建张量"></a>创建张量</h2><h3 id="常规方式创建"><a href="#常规方式创建" class="headerlink" title="常规方式创建"></a>常规方式创建</h3><p>常见的初始化有<code>torch.tensor</code>和<code>torch.Tensor</code>，其中的区别是</p><ul><li>tensor()：接收现有数据，通过numpy 或 list 的现有数据初始化</li><li>Tensor()：1. 接收数据的维度(, )生成随机数张量；2. 接收现有的数据[, ]生成指定数据张量</li></ul><pre class="line-numbers language-python"><code class="language-python">tensor<span class="token operator">=</span>torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">)</span>tensor<span class="token operator">=</span>torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>常见的创建方式还有<code>torch.as_tensor()</code>，<code>torch.from_numpy()</code>。这两种方式都是接收现有数据的，而且生成的张量与原有数据是<strong>内存共享</strong>的。</p><pre class="line-numbers language-python"><code class="language-python">a <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>a<span class="token punctuation">)</span>tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>as_tensor<span class="token punctuation">(</span>a<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>在不考虑性能方面，一般情况下使用torch.tensor()方法居多，那么如果要考虑性能方面，首先肯定是要从<strong>torch.as_tensor()和torch.from_numpy()两种方法中选择，因为在创建tensor的过程中，它俩是共享内存的，不需要额外创建一份数据</strong>。<br>两者的区别是torch.from_numpy()只能接收numpy数组，而torch.as_tensor()不仅可以接收numpy数组，还可以接收python的list类型数据。</p><h3 id="序列生成"><a href="#序列生成" class="headerlink" title="序列生成"></a>序列生成</h3><ul><li><code>torch.arange()</code>：接收参数：a,b,step，输出[a,b)范围内step步长的等差序列组成的tensor，数据类型为int。</li><li><code>torc.range()</code>：接收参数：a,b,step，输出[a,b]范围内step步长的等差序列组成的tensor，数据类型为float。</li></ul><p>arrange()方法和range()方法的区别在于：range()方法可以输出结果包含区间右侧b这个数值，且range()方法的数据类型为float。</p><pre class="line-numbers language-python"><code class="language-python">a <span class="token operator">=</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token punctuation">.</span>type<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>b <span class="token operator">=</span> torch<span class="token punctuation">.</span>range<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>b<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>b<span class="token punctuation">.</span>type<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span>Output<span class="token punctuation">:</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">]</span><span class="token punctuation">)</span>torch<span class="token punctuation">.</span>LongTensortensor<span class="token punctuation">(</span><span class="token punctuation">[</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span>  <span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">,</span>  <span class="token number">4</span><span class="token punctuation">.</span><span class="token punctuation">,</span>  <span class="token number">6</span><span class="token punctuation">.</span><span class="token punctuation">,</span>  <span class="token number">8</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">)</span>torch<span class="token punctuation">.</span>FloatTensor<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>生成一个0到n-1的n-1个整数的随机排列</p><pre class="line-numbers language-python"><code class="language-python">a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randperm<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span>Output<span class="token punctuation">:</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="使用随机数据创建"><a href="#使用随机数据创建" class="headerlink" title="使用随机数据创建"></a>使用随机数据创建</h3><ul><li><code>torch.rand()</code>：输入参数为一个shape，创建指定形状大小的tensor，数据为float32类型的随机数。产生[0,1]均匀分布的数据。</li><li><code>torch.randint()</code>：指定数据范围为[a, b)的随机tensor创建。输入参数为一个a,b,(x,y,…)，创建(x,y,…)大小的tensor，数据的范围为[a,b)，数据类型为整数值。</li><li><code>torch.rand_like()</code>：输入参数为一个<strong>浮点型</strong>的tensor，创建一个与输入tensor数据同大小的矩阵，数据为<strong>与原始tensor相同类型</strong>的<strong>浮点型</strong>随机数。产生[0,1]均匀分布的数据。</li></ul><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 等价于 a = torch.rand(2,3)</span>a <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token punctuation">)</span>c <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand_like<span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>c<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>c<span class="token punctuation">.</span>type<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>b <span class="token operator">=</span> torch<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>b<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>b<span class="token punctuation">.</span>type<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span>Output<span class="token punctuation">:</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.8703</span><span class="token punctuation">,</span> <span class="token number">0.8061</span><span class="token punctuation">,</span> <span class="token number">0.5126</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">0.6069</span><span class="token punctuation">,</span> <span class="token number">0.5985</span><span class="token punctuation">,</span> <span class="token number">0.4657</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.0937</span><span class="token punctuation">,</span> <span class="token number">0.1968</span><span class="token punctuation">,</span> <span class="token number">0.2269</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">0.3653</span><span class="token punctuation">,</span> <span class="token number">0.9386</span><span class="token punctuation">,</span> <span class="token number">0.9892</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>torch<span class="token punctuation">.</span>FloatTensortensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">9</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>torch<span class="token punctuation">.</span>LongTensor<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ul><li><code>torch.randn()</code>：接受参数为shape，输出一个数据满足标准正态分布<code>N(0,1)</code>的随机数tensor。</li><li><code>torch.normal()</code>：接受参数为：mean, std, shape，分别为所创建数据的均值，标准差和形状，输出一个满足上述参数的广义的正态分布tensor。</li></ul><pre class="line-numbers language-python"><code class="language-python">a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span>b <span class="token operator">=</span> torch<span class="token punctuation">.</span>normal<span class="token punctuation">(</span>mean <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> std <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span>Output<span class="token punctuation">:</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.6225</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.1253</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.1083</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.3199</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.5670</span><span class="token punctuation">,</span>  <span class="token number">0.2898</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.6500</span><span class="token punctuation">,</span>  <span class="token number">0.9275</span><span class="token punctuation">,</span>  <span class="token number">1.0377</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0.5507</span><span class="token punctuation">,</span>  <span class="token number">0.2704</span><span class="token punctuation">,</span>  <span class="token number">0.6472</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">0.2490</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.3354</span><span class="token punctuation">,</span>  <span class="token number">0.4564</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.6255</span><span class="token punctuation">,</span>  <span class="token number">0.4539</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.3740</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>使用<code>torch.Tensor()</code>创建随机数张量。</p><pre class="line-numbers language-python"><code class="language-python">a <span class="token operator">=</span> torch<span class="token punctuation">.</span>IntTensor<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span>Output<span class="token punctuation">:</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">241405024</span><span class="token punctuation">,</span>      <span class="token number">32635</span><span class="token punctuation">,</span> <span class="token number">1567730800</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span>     <span class="token number">22007</span><span class="token punctuation">,</span>         <span class="token number">32</span><span class="token punctuation">,</span>          <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>int32<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="特殊矩阵的创建"><a href="#特殊矩阵的创建" class="headerlink" title="特殊矩阵的创建"></a>特殊矩阵的创建</h3><p>在数学计算中会经常使用到全0矩阵、全1矩阵、单位矩阵。其创建方法如下：</p><ul><li>torch.zeros()：接收参数为shape，输出一个shape大小的全0 Tensor。torch.zeros_like(input, dtype)</li><li>torch.ones()：接收参数为shape，输出一个shape大小的全1 Tensor。torch.ones_like(input, dtype)</li><li>torch.eye()：接收参数为shape，输出一个shape大小的单位矩阵Tensor。</li></ul><pre class="line-numbers language-python"><code class="language-python">a <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token punctuation">.</span>type<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>b <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>b<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>b<span class="token punctuation">.</span>type<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>c <span class="token operator">=</span> torch<span class="token punctuation">.</span>eye<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>c<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>c<span class="token punctuation">.</span>type<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>eye<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span>Output<span class="token punctuation">:</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>torch<span class="token punctuation">.</span>FloatTensortensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>torch<span class="token punctuation">.</span>FloatTensortensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>torch<span class="token punctuation">.</span>FloatTensortensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><code>torch.full()</code>：接收参数为shape, x，输出一个shape大小的元素全为x的tensor。</p><pre class="line-numbers language-python"><code class="language-python">a <span class="token operator">=</span> torch<span class="token punctuation">.</span>full<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token punctuation">.</span>type<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>a <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dtype <span class="token operator">=</span> torch<span class="token punctuation">.</span>int<span class="token punctuation">)</span>torch<span class="token punctuation">.</span>fill_<span class="token punctuation">(</span>a<span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span> <span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span>Output<span class="token punctuation">:</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>torch<span class="token punctuation">.</span>LongTensortensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><code>torch.empty()</code>接收参数为shape，表示创建一个<strong>未初始化</strong>的张量。torch.empty_like(input, dtype)</p><pre class="line-numbers language-python"><code class="language-python">a <span class="token operator">=</span> torch<span class="token punctuation">.</span>empty<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 等价于 a = torch.empty([2,3])</span><span class="token operator">>></span><span class="token operator">></span>Output<span class="token punctuation">:</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">8.8319e+17</span><span class="token punctuation">,</span> <span class="token number">3.0838e-41</span><span class="token punctuation">,</span> <span class="token number">9.5811e+17</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">3.0838e-41</span><span class="token punctuation">,</span> <span class="token number">9.1995e-41</span><span class="token punctuation">,</span> <span class="token number">4.5989e-40</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="张量的数据类型"><a href="#张量的数据类型" class="headerlink" title="张量的数据类型"></a>张量的数据类型</h2><p>Pytorch的基本数据结构是张量Tensor。张量即多维数组。Pytorch的张量和numpy中的array很类似。</p><table><thead><tr><th>Data type</th><th>dtype</th><th>CPU tensor</th><th>GPU tensor</th></tr></thead><tbody><tr><td>16-bit floating point</td><td>torch.float16 or torch.half</td><td>torch.HalfTensor</td><td>torch.cuda.HalfTensor</td></tr><tr><td>32-bit floating point</td><td>torch.float32 or torch.float</td><td>torch.FloatTensor</td><td>torch.cuda.FloatTensor</td></tr><tr><td>64-bit floating point</td><td>torch.float64 or torch.double</td><td>torch.DoubleTensor</td><td>torch.cuda.DoubleTensor</td></tr><tr><td>8-bit integer (signed)</td><td>torch.int8</td><td>torch.CharTensor</td><td>torch.cuda.CharTensor</td></tr><tr><td>16-bit integer (signed)</td><td>torch.int16 or torch.short</td><td>torch.ShortTensor</td><td>torch.cuda.ShortTensor</td></tr><tr><td>32-bit integer (signed)</td><td>torch.int32 or torch.int</td><td>torch.IntTensor</td><td>torch.cuda.IntTensor</td></tr><tr><td>64-bit integer (signed)</td><td>torch.int64 or torch.long</td><td>torch.LongTensor</td><td>torch.cuda.LongTensor</td></tr><tr><td>8-bit integer (unsigned)</td><td>torch.uint8</td><td>torch.ByteTensor</td><td>torch.cuda.ByteTensor</td></tr></tbody></table><p>张量的数据类型和numpy.array基本一一对应，但是不支持str类型。包括:</p><ul><li>torch.float64(torch.double), </li><li><strong>torch.float32(torch.float)</strong>, </li><li>torch.float16, </li><li>torch.int64(torch.long), </li><li>torch.int32(torch.int), </li><li>torch.int16, </li><li>torch.int8, </li><li>torch.uint8, </li><li>torch.bool</li></ul><p>一般神经网络建模使用的都是torch.float32类型。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">import</span> torch <span class="token comment" spellcheck="true"># 自动推断数据类型</span>i <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">print</span><span class="token punctuation">(</span>i<span class="token punctuation">,</span> i<span class="token punctuation">.</span>dtype<span class="token punctuation">)</span>x <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token number">2.0</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">print</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> x<span class="token punctuation">.</span>dtype<span class="token punctuation">)</span>b <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">print</span><span class="token punctuation">(</span>b<span class="token punctuation">,</span> b<span class="token punctuation">.</span>dtype<span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span>Output<span class="token punctuation">:</span>tensor<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span> torch<span class="token punctuation">.</span>int64tensor<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">)</span> torch<span class="token punctuation">.</span>float32tensor<span class="token punctuation">(</span><span class="token boolean">True</span><span class="token punctuation">)</span> torch<span class="token punctuation">.</span>bool<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 指定数据类型</span>i <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> dtype <span class="token operator">=</span> torch<span class="token punctuation">.</span>int32<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">print</span><span class="token punctuation">(</span>i<span class="token punctuation">,</span>i<span class="token punctuation">.</span>dtype<span class="token punctuation">)</span>x <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token number">2.0</span><span class="token punctuation">,</span> dtype <span class="token operator">=</span> torch<span class="token punctuation">.</span>double<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">print</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span>x<span class="token punctuation">.</span>dtype<span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span>Output<span class="token punctuation">:</span>tensor<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>int32<span class="token punctuation">)</span> torch<span class="token punctuation">.</span>int32tensor<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float64<span class="token punctuation">)</span> torch<span class="token punctuation">.</span>float64<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 使用特定类型构造函数</span>i <span class="token operator">=</span> torch<span class="token punctuation">.</span>IntTensor<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">print</span><span class="token punctuation">(</span>i<span class="token punctuation">,</span>i<span class="token punctuation">.</span>dtype<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 等价于torch.FloatTensor</span>x <span class="token operator">=</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span>np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token number">2.0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">print</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span>x<span class="token punctuation">.</span>dtype<span class="token punctuation">)</span> b <span class="token operator">=</span> torch<span class="token punctuation">.</span>BoolTensor<span class="token punctuation">(</span>np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token keyword">print</span><span class="token punctuation">(</span>b<span class="token punctuation">,</span>b<span class="token punctuation">.</span>dtype<span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span>Output<span class="token punctuation">:</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>int32<span class="token punctuation">)</span> torch<span class="token punctuation">.</span>int32tensor<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">)</span> torch<span class="token punctuation">.</span>float32tensor<span class="token punctuation">(</span><span class="token punctuation">[</span> <span class="token boolean">True</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">,</span>  <span class="token boolean">True</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">]</span><span class="token punctuation">)</span> torch<span class="token punctuation">.</span>bool<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 不同类型进行转换</span>i <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token keyword">print</span><span class="token punctuation">(</span>i<span class="token punctuation">,</span>i<span class="token punctuation">.</span>dtype<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 调用 float方法转换成浮点类型</span>x <span class="token operator">=</span> i<span class="token punctuation">.</span>float<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token keyword">print</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span>x<span class="token punctuation">.</span>dtype<span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 使用type函数转换成浮点类型</span>y <span class="token operator">=</span> i<span class="token punctuation">.</span>type<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>float<span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token keyword">print</span><span class="token punctuation">(</span>y<span class="token punctuation">,</span>y<span class="token punctuation">.</span>dtype<span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 使用type_as方法转换成某个Tensor相同类型</span>z <span class="token operator">=</span> i<span class="token punctuation">.</span>type_as<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">print</span><span class="token punctuation">(</span>z<span class="token punctuation">,</span>z<span class="token punctuation">.</span>dtype<span class="token punctuation">)</span> <span class="token operator">>></span><span class="token operator">></span>Output<span class="token punctuation">:</span>tensor<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span> torch<span class="token punctuation">.</span>int64tensor<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">)</span> torch<span class="token punctuation">.</span>float32tensor<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">)</span> torch<span class="token punctuation">.</span>float32tensor<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">)</span> torch<span class="token punctuation">.</span>float32<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="张量的维度"><a href="#张量的维度" class="headerlink" title="张量的维度"></a>张量的维度</h2><p>不同类型的数据可以用不同维度(dimension)的张量来表示。标量为0维张量，向量为1维张量，矩阵为2维张量。彩色图像有rgb三个通道，可以表示为3维张量。视频还有时间维，可以表示为4维张量。<br>可以简单地总结为：有几层中括号，就是多少维的张量。</p><pre class="line-numbers language-python"><code class="language-python">scalar <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>scalar<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>scalar<span class="token punctuation">.</span>dim<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 标量，0维张量</span><span class="token operator">>></span><span class="token operator">></span>Output<span class="token punctuation">:</span>tensor<span class="token punctuation">(</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token number">0</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python">vector <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1.0</span><span class="token punctuation">,</span><span class="token number">2.0</span><span class="token punctuation">,</span><span class="token number">3.0</span><span class="token punctuation">,</span><span class="token number">4.0</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">#向量，1维张量</span><span class="token keyword">print</span><span class="token punctuation">(</span>vector<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>vector<span class="token punctuation">.</span>dim<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span>Output<span class="token punctuation">:</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token number">1</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python">matrix <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1.0</span><span class="token punctuation">,</span><span class="token number">2.0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">3.0</span><span class="token punctuation">,</span><span class="token number">4.0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">#矩阵, 2维张量</span><span class="token keyword">print</span><span class="token punctuation">(</span>matrix<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>matrix<span class="token punctuation">.</span>dim<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span>Output<span class="token punctuation">:</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token number">2</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python">tensor3 <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1.0</span><span class="token punctuation">,</span><span class="token number">2.0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">3.0</span><span class="token punctuation">,</span><span class="token number">4.0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">5.0</span><span class="token punctuation">,</span><span class="token number">6.0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">7.0</span><span class="token punctuation">,</span><span class="token number">8.0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 3维张量</span><span class="token keyword">print</span><span class="token punctuation">(</span>tensor3<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>tensor3<span class="token punctuation">.</span>dim<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span>Output<span class="token punctuation">:</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>         <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>         <span class="token punctuation">[</span><span class="token number">7</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token number">3</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python">tensor4 <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1.0</span><span class="token punctuation">,</span><span class="token number">1.0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">2.0</span><span class="token punctuation">,</span><span class="token number">2.0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">3.0</span><span class="token punctuation">,</span><span class="token number">3.0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">4.0</span><span class="token punctuation">,</span><span class="token number">4.0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                        <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">5.0</span><span class="token punctuation">,</span><span class="token number">5.0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">6.0</span><span class="token punctuation">,</span><span class="token number">6.0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">7.0</span><span class="token punctuation">,</span><span class="token number">7.0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">8.0</span><span class="token punctuation">,</span><span class="token number">8.0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 4维张量</span><span class="token keyword">print</span><span class="token punctuation">(</span>tensor4<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>tensor4<span class="token punctuation">.</span>dim<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span>Output<span class="token punctuation">:</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>          <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>         <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>          <span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>          <span class="token punctuation">[</span><span class="token number">6</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>         <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">7</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>          <span class="token punctuation">[</span><span class="token number">8</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token number">4</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="张量的尺寸"><a href="#张量的尺寸" class="headerlink" title="张量的尺寸"></a>张量的尺寸</h2><p>可以使用<code>**shape**</code><strong>属性</strong>或者<code>**size()**</code><strong>方法</strong>查看张量在每一维的长度。<br>可以使用<code>view()</code>方法改变张量的尺寸。如果<code>view()</code>方法改变尺寸失败，可以使用<code>reshape()</code>方法。</p><pre class="line-numbers language-python"><code class="language-python">scalar <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>scalar<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>scalar<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span>Output<span class="token punctuation">:</span>torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span>torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python">vector <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1.0</span><span class="token punctuation">,</span> <span class="token number">2.0</span><span class="token punctuation">,</span> <span class="token number">3.0</span><span class="token punctuation">,</span> <span class="token number">4.0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>vector<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>vector<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span>Output<span class="token punctuation">:</span>torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">)</span>torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python">matrix <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1.0</span><span class="token punctuation">,</span><span class="token number">2.0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">3.0</span><span class="token punctuation">,</span><span class="token number">4.0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>matrix<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>matrix<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span>Output<span class="token punctuation">:</span>torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span>torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>使用view可以改变张量尺寸</p><pre class="line-numbers language-python"><code class="language-python">vector <span class="token operator">=</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">12</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>vector<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>vector<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>matrix34 <span class="token operator">=</span> vector<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>matrix34<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>matrix34<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>matrix43 <span class="token operator">=</span> vector<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">#-1表示该位置长度由程序自动推断</span><span class="token keyword">print</span><span class="token punctuation">(</span>matrix43<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>matrix43<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span>Output<span class="token punctuation">:</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span> <span class="token number">0</span><span class="token punctuation">,</span>  <span class="token number">1</span><span class="token punctuation">,</span>  <span class="token number">2</span><span class="token punctuation">,</span>  <span class="token number">3</span><span class="token punctuation">,</span>  <span class="token number">4</span><span class="token punctuation">,</span>  <span class="token number">5</span><span class="token punctuation">,</span>  <span class="token number">6</span><span class="token punctuation">,</span>  <span class="token number">7</span><span class="token punctuation">,</span>  <span class="token number">8</span><span class="token punctuation">,</span>  <span class="token number">9</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">11</span><span class="token punctuation">]</span><span class="token punctuation">)</span>torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">12</span><span class="token punctuation">]</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0</span><span class="token punctuation">,</span>  <span class="token number">1</span><span class="token punctuation">,</span>  <span class="token number">2</span><span class="token punctuation">,</span>  <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">4</span><span class="token punctuation">,</span>  <span class="token number">5</span><span class="token punctuation">,</span>  <span class="token number">6</span><span class="token punctuation">,</span>  <span class="token number">7</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">8</span><span class="token punctuation">,</span>  <span class="token number">9</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">11</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0</span><span class="token punctuation">,</span>  <span class="token number">1</span><span class="token punctuation">,</span>  <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">3</span><span class="token punctuation">,</span>  <span class="token number">4</span><span class="token punctuation">,</span>  <span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">6</span><span class="token punctuation">,</span>  <span class="token number">7</span><span class="token punctuation">,</span>  <span class="token number">8</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">9</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">11</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>有些操作会让张量存储结构扭曲，直接使用view会失败，可以用reshape方法。</p><pre class="line-numbers language-python"><code class="language-python">matrix26 <span class="token operator">=</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">12</span><span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>matrix26<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>matrix26<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 转置操作让张量存储结构扭曲</span>matrix62 <span class="token operator">=</span> matrix26<span class="token punctuation">.</span>t<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>matrix62<span class="token punctuation">.</span>is_contiguous<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 直接使用view方法会失败，可以使用reshape方法</span><span class="token comment" spellcheck="true"># matrix34 = matrix62.view(3,4) # error!</span><span class="token comment" spellcheck="true"># 等价于matrix34 = matrix62.contiguous().view(3,4)。</span><span class="token comment" spellcheck="true"># contiguous()函数，把tensor变成在内存中连续分布的形式。</span>matrix34 <span class="token operator">=</span> matrix62<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span> <span class="token keyword">print</span><span class="token punctuation">(</span>matrix34<span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span>Output<span class="token punctuation">:</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0</span><span class="token punctuation">,</span>  <span class="token number">1</span><span class="token punctuation">,</span>  <span class="token number">2</span><span class="token punctuation">,</span>  <span class="token number">3</span><span class="token punctuation">,</span>  <span class="token number">4</span><span class="token punctuation">,</span>  <span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">6</span><span class="token punctuation">,</span>  <span class="token number">7</span><span class="token punctuation">,</span>  <span class="token number">8</span><span class="token punctuation">,</span>  <span class="token number">9</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">11</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token boolean">False</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0</span><span class="token punctuation">,</span>  <span class="token number">6</span><span class="token punctuation">,</span>  <span class="token number">1</span><span class="token punctuation">,</span>  <span class="token number">7</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">2</span><span class="token punctuation">,</span>  <span class="token number">8</span><span class="token punctuation">,</span>  <span class="token number">3</span><span class="token punctuation">,</span>  <span class="token number">9</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span>  <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">11</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="张量和numpy数组"><a href="#张量和numpy数组" class="headerlink" title="张量和numpy数组"></a>张量和numpy数组</h2><p>可以用<code>numpy()</code>方法从Tensor得到numpy数组，也可以用<code>torch.from_numpy()</code>从numpy数组得到Tensor。这两种方法关联的Tensor和numpy数组是<strong>共享数据内存</strong>的。如果改变其中一个，另外一个的值也会发生改变。<br>如果有需要，可以用张量的<code>clone()</code>方法拷贝张量，中断这种关联。<br>此外，还可以使用<code>item()</code>方法从标量张量得到对应的Python数值。使用<code>tolist()</code>方法从张量得到对应的Python数值列表。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#torch.from_numpy函数从numpy数组得到Tensor</span>arr <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span>tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>arr<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"before add 1:"</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>arr<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>tensor<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"\nafter add 1:"</span><span class="token punctuation">)</span>np<span class="token punctuation">.</span>add<span class="token punctuation">(</span>arr<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span> out <span class="token operator">=</span> arr<span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 给 arr增加1，tensor也随之改变</span><span class="token keyword">print</span><span class="token punctuation">(</span>arr<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>tensor<span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span>Output<span class="token punctuation">:</span>before add <span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">.</span> <span class="token number">0</span><span class="token punctuation">.</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float64<span class="token punctuation">)</span>after add <span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span> <span class="token number">1</span><span class="token punctuation">.</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">]</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float64<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># numpy方法从Tensor得到numpy数组</span>tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span>arr <span class="token operator">=</span> tensor<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"before add 1:"</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>tensor<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>arr<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"\nafter add 1:"</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 使用带下划线的方法表示计算结果会返回给调用 张量</span>tensor<span class="token punctuation">.</span>add_<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">#给 tensor增加1，arr也随之改变 </span><span class="token comment" spellcheck="true"># 或： torch.add(tensor,1,out = tensor)</span><span class="token keyword">print</span><span class="token punctuation">(</span>tensor<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>arr<span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span>Output<span class="token punctuation">:</span>before add <span class="token number">1</span><span class="token punctuation">:</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">.</span> <span class="token number">0</span><span class="token punctuation">.</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span>after add <span class="token number">1</span><span class="token punctuation">:</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span> <span class="token number">1</span><span class="token punctuation">.</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 可以用clone() 方法拷贝张量，中断这种关联</span>tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 使用clone方法拷贝张量, 拷贝后的张量和原始张量内存独立</span>arr <span class="token operator">=</span> tensor<span class="token punctuation">.</span>clone<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 也可以使用tensor.data.numpy()</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"before add 1:"</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>tensor<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>arr<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"\nafter add 1:"</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#使用 带下划线的方法表示计算结果会返回给调用 张量</span>tensor<span class="token punctuation">.</span>add_<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">#给 tensor增加1，arr不再随之改变</span><span class="token keyword">print</span><span class="token punctuation">(</span>tensor<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>arr<span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span>Output<span class="token punctuation">:</span>before add <span class="token number">1</span><span class="token punctuation">:</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">.</span> <span class="token number">0</span><span class="token punctuation">.</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span>after add <span class="token number">1</span><span class="token punctuation">:</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">.</span> <span class="token number">0</span><span class="token punctuation">.</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># item方法和tolist方法可以将张量转换成Python数值和数值列表</span>scalar <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token number">1.0</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>scalar<span class="token punctuation">)</span>s <span class="token operator">=</span> scalar<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>s<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>type<span class="token punctuation">(</span>s<span class="token punctuation">)</span><span class="token punctuation">)</span>tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span>t <span class="token operator">=</span> tensor<span class="token punctuation">.</span>tolist<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>t<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>type<span class="token punctuation">(</span>t<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span>Output<span class="token punctuation">:</span>tensor<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token number">1.0</span><span class="token operator">&lt;</span><span class="token keyword">class</span> <span class="token string">'float'</span><span class="token operator">></span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.8211846351623535</span><span class="token punctuation">,</span> <span class="token number">0.20020723342895508</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0.011571824550628662</span><span class="token punctuation">,</span> <span class="token number">0.2906131148338318</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token operator">&lt;</span><span class="token keyword">class</span> <span class="token string">'list'</span><span class="token operator">></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="张量的操作"><a href="#张量的操作" class="headerlink" title="张量的操作"></a>张量的操作</h2><p>张量的操作主要包括张量的结构操作和张量的数学运算。</p><ul><li>张量结构操作诸如：张量创建，索引切片，维度变换，合并分割。</li><li>张量数学运算主要有：标量运算，向量运算，矩阵运算，张量运算的广播机制。</li></ul><h3 id="张量的结构操作"><a href="#张量的结构操作" class="headerlink" title="张量的结构操作"></a>张量的结构操作</h3><h4 id="张量创建"><a href="#张量创建" class="headerlink" title="张量创建"></a>张量创建</h4><p>张量创建的许多方法和numpy中创建array的方法很像。也可参考【创建张量】</p><pre class="line-numbers language-python"><code class="language-python">a <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span>dtype <span class="token operator">=</span> torch<span class="token punctuation">.</span>float<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token punctuation">)</span>b <span class="token operator">=</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">,</span>step <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>b<span class="token punctuation">)</span>c <span class="token operator">=</span> torch<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span><span class="token number">0.0</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token operator">*</span><span class="token number">3.14</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>c<span class="token punctuation">)</span>d <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>d<span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span>Output<span class="token punctuation">:</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">]</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.0000</span><span class="token punctuation">,</span> <span class="token number">0.6978</span><span class="token punctuation">,</span> <span class="token number">1.3956</span><span class="token punctuation">,</span> <span class="token number">2.0933</span><span class="token punctuation">,</span> <span class="token number">2.7911</span><span class="token punctuation">,</span> <span class="token number">3.4889</span><span class="token punctuation">,</span> <span class="token number">4.1867</span><span class="token punctuation">,</span> <span class="token number">4.8844</span><span class="token punctuation">,</span> <span class="token number">5.5822</span><span class="token punctuation">,</span>        <span class="token number">6.2800</span><span class="token punctuation">]</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python">a <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dtype <span class="token operator">=</span> torch<span class="token punctuation">.</span>int<span class="token punctuation">)</span>b <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros_like<span class="token punctuation">(</span>a<span class="token punctuation">,</span> dtype <span class="token operator">=</span> torch<span class="token punctuation">.</span>float<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>b<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 等价于 b.fill_(5)</span>torch<span class="token punctuation">.</span>fill_<span class="token punctuation">(</span>b<span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span> <span class="token keyword">print</span><span class="token punctuation">(</span>b<span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span>Output<span class="token punctuation">:</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>int32<span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 均匀随机分布</span>minval<span class="token punctuation">,</span>maxval <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">,</span><span class="token number">10</span>a <span class="token operator">=</span> minval <span class="token operator">+</span> <span class="token punctuation">(</span>maxval<span class="token operator">-</span>minval<span class="token punctuation">)</span><span class="token operator">*</span>torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 正态分布随机</span>b <span class="token operator">=</span> torch<span class="token punctuation">.</span>normal<span class="token punctuation">(</span>mean <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> std <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>b<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 正态分布随机</span>mean<span class="token punctuation">,</span>std <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">,</span><span class="token number">5</span>c <span class="token operator">=</span> std<span class="token operator">*</span>torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">+</span>mean<span class="token keyword">print</span><span class="token punctuation">(</span>c<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 整数随机排列</span>d <span class="token operator">=</span> torch<span class="token punctuation">.</span>randperm<span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>d<span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span>Output<span class="token punctuation">:</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">4.9626</span><span class="token punctuation">,</span> <span class="token number">7.6822</span><span class="token punctuation">,</span> <span class="token number">0.8848</span><span class="token punctuation">,</span> <span class="token number">1.3203</span><span class="token punctuation">,</span> <span class="token number">3.0742</span><span class="token punctuation">]</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0.5507</span><span class="token punctuation">,</span>  <span class="token number">0.2704</span><span class="token punctuation">,</span>  <span class="token number">0.6472</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">0.2490</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.3354</span><span class="token punctuation">,</span>  <span class="token number">0.4564</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.6255</span><span class="token punctuation">,</span>  <span class="token number">0.4539</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.3740</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">16.2371</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.6612</span><span class="token punctuation">,</span>  <span class="token number">3.9163</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">7.4999</span><span class="token punctuation">,</span>  <span class="token number">1.5616</span><span class="token punctuation">,</span>  <span class="token number">4.0768</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">5.2128</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">8.9407</span><span class="token punctuation">,</span>  <span class="token number">6.4601</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">17</span><span class="token punctuation">,</span>  <span class="token number">9</span><span class="token punctuation">,</span> <span class="token number">19</span><span class="token punctuation">,</span>  <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">18</span><span class="token punctuation">,</span>  <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">13</span><span class="token punctuation">,</span> <span class="token number">15</span><span class="token punctuation">,</span> <span class="token number">12</span><span class="token punctuation">,</span>  <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span>  <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">11</span><span class="token punctuation">,</span>  <span class="token number">2</span><span class="token punctuation">,</span>  <span class="token number">5</span><span class="token punctuation">,</span>  <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span>         <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">14</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python">I <span class="token operator">=</span> torch<span class="token punctuation">.</span>eye<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">#单位矩阵</span><span class="token keyword">print</span><span class="token punctuation">(</span>I<span class="token punctuation">)</span>t <span class="token operator">=</span> torch<span class="token punctuation">.</span>diag<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">#对角矩阵</span><span class="token keyword">print</span><span class="token punctuation">(</span>t<span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span>Output<span class="token punctuation">:</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="索引切片"><a href="#索引切片" class="headerlink" title="索引切片"></a>索引切片</h4><p>张量的索引切片方式和numpy几乎是一样的。切片时支持缺省参数和省略号。可以通过索引和切片对部分元素进行修改。<br>此外，对于不规则的切片提取，可以使用<code>torch.index_select</code>，<code>torch.masked_select</code>，<code>torch.take</code>。<br>如果要通过修改张量的某些元素得到新的张量，可以使用<code>torch.where</code>，<code>torch.masked_fill</code>，<code>torch.index_fill</code>。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 均匀随机分布</span>torch<span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>minval<span class="token punctuation">,</span>maxval <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">,</span><span class="token number">10</span>t <span class="token operator">=</span> torch<span class="token punctuation">.</span>floor<span class="token punctuation">(</span>minval <span class="token operator">+</span> <span class="token punctuation">(</span>maxval<span class="token operator">-</span>minval<span class="token punctuation">)</span><span class="token operator">*</span>torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>int<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>t<span class="token punctuation">)</span><span class="token comment" spellcheck="true">#第1行</span><span class="token keyword">print</span><span class="token punctuation">(</span>t<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#倒数第一行</span><span class="token keyword">print</span><span class="token punctuation">(</span>t<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#第2行第4列</span><span class="token keyword">print</span><span class="token punctuation">(</span>t<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>t<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#第1行至第3行</span><span class="token keyword">print</span><span class="token punctuation">(</span>t<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#第1行至最后一行，第0列到最后一列每隔两列取一列</span><span class="token keyword">print</span><span class="token punctuation">(</span>t<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token number">4</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span>Output<span class="token punctuation">:</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>int32<span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>int32<span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>int32<span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>int32<span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>int32<span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>int32<span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>int32<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#可以使用索引和切片修改部分元素</span>x <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>dtype <span class="token operator">=</span> torch<span class="token punctuation">.</span>float32<span class="token punctuation">,</span>requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>x<span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.0</span><span class="token punctuation">,</span><span class="token number">0.0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span>Output<span class="token punctuation">:</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python">a <span class="token operator">=</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">27</span><span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token comment" spellcheck="true">#省略号可以表示多个冒号</span><span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span>Output<span class="token punctuation">:</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0</span><span class="token punctuation">,</span>  <span class="token number">1</span><span class="token punctuation">,</span>  <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span>         <span class="token punctuation">[</span> <span class="token number">3</span><span class="token punctuation">,</span>  <span class="token number">4</span><span class="token punctuation">,</span>  <span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">,</span>         <span class="token punctuation">[</span> <span class="token number">6</span><span class="token punctuation">,</span>  <span class="token number">7</span><span class="token punctuation">,</span>  <span class="token number">8</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">9</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">11</span><span class="token punctuation">]</span><span class="token punctuation">,</span>         <span class="token punctuation">[</span><span class="token number">12</span><span class="token punctuation">,</span> <span class="token number">13</span><span class="token punctuation">,</span> <span class="token number">14</span><span class="token punctuation">]</span><span class="token punctuation">,</span>         <span class="token punctuation">[</span><span class="token number">15</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">17</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">18</span><span class="token punctuation">,</span> <span class="token number">19</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">]</span><span class="token punctuation">,</span>         <span class="token punctuation">[</span><span class="token number">21</span><span class="token punctuation">,</span> <span class="token number">22</span><span class="token punctuation">,</span> <span class="token number">23</span><span class="token punctuation">]</span><span class="token punctuation">,</span>         <span class="token punctuation">[</span><span class="token number">24</span><span class="token punctuation">,</span> <span class="token number">25</span><span class="token punctuation">,</span> <span class="token number">26</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">1</span><span class="token punctuation">,</span>  <span class="token number">4</span><span class="token punctuation">,</span>  <span class="token number">7</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">13</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">19</span><span class="token punctuation">,</span> <span class="token number">22</span><span class="token punctuation">,</span> <span class="token number">25</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>以上切片方式相对规则，对于不规则的切片提取，可以使用<code>torch.index_select</code>，<code>torch.masked_select</code>，<code>torch.take</code>，<code>torch.gather</code>。<br>以班级成绩册为例子，有4个班级，每个班级10个学生，每个学生7门科目成绩。可以用一个4×10×7的张量来表示。</p><pre class="line-numbers language-python"><code class="language-python">minval<span class="token operator">=</span><span class="token number">0</span>maxval<span class="token operator">=</span><span class="token number">100</span>scores <span class="token operator">=</span> torch<span class="token punctuation">.</span>floor<span class="token punctuation">(</span>minval <span class="token operator">+</span> <span class="token punctuation">(</span>maxval<span class="token operator">-</span>minval<span class="token punctuation">)</span><span class="token operator">*</span>torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token number">7</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>int<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>scores<span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span>Output<span class="token punctuation">:</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">55</span><span class="token punctuation">,</span> <span class="token number">95</span><span class="token punctuation">,</span>  <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">18</span><span class="token punctuation">,</span> <span class="token number">37</span><span class="token punctuation">,</span> <span class="token number">30</span><span class="token punctuation">,</span> <span class="token number">93</span><span class="token punctuation">]</span><span class="token punctuation">,</span>         <span class="token punctuation">[</span><span class="token number">17</span><span class="token punctuation">,</span> <span class="token number">26</span><span class="token punctuation">,</span> <span class="token number">15</span><span class="token punctuation">,</span>  <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">,</span> <span class="token number">92</span><span class="token punctuation">,</span> <span class="token number">72</span><span class="token punctuation">]</span><span class="token punctuation">,</span>         <span class="token punctuation">[</span><span class="token number">74</span><span class="token punctuation">,</span> <span class="token number">52</span><span class="token punctuation">,</span> <span class="token number">24</span><span class="token punctuation">,</span> <span class="token number">58</span><span class="token punctuation">,</span>  <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">13</span><span class="token punctuation">,</span> <span class="token number">24</span><span class="token punctuation">]</span><span class="token punctuation">,</span>         <span class="token punctuation">[</span><span class="token number">81</span><span class="token punctuation">,</span> <span class="token number">79</span><span class="token punctuation">,</span> <span class="token number">27</span><span class="token punctuation">,</span> <span class="token number">48</span><span class="token punctuation">,</span> <span class="token number">81</span><span class="token punctuation">,</span> <span class="token number">99</span><span class="token punctuation">,</span> <span class="token number">69</span><span class="token punctuation">]</span><span class="token punctuation">,</span>         <span class="token punctuation">[</span><span class="token number">56</span><span class="token punctuation">,</span> <span class="token number">83</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">,</span> <span class="token number">59</span><span class="token punctuation">,</span> <span class="token number">11</span><span class="token punctuation">,</span> <span class="token number">15</span><span class="token punctuation">,</span> <span class="token number">24</span><span class="token punctuation">]</span><span class="token punctuation">,</span>         <span class="token punctuation">[</span><span class="token number">72</span><span class="token punctuation">,</span> <span class="token number">70</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">,</span> <span class="token number">65</span><span class="token punctuation">,</span> <span class="token number">77</span><span class="token punctuation">,</span> <span class="token number">43</span><span class="token punctuation">,</span> <span class="token number">51</span><span class="token punctuation">]</span><span class="token punctuation">,</span>         <span class="token punctuation">[</span><span class="token number">61</span><span class="token punctuation">,</span> <span class="token number">81</span><span class="token punctuation">,</span> <span class="token number">98</span><span class="token punctuation">,</span> <span class="token number">11</span><span class="token punctuation">,</span> <span class="token number">31</span><span class="token punctuation">,</span> <span class="token number">69</span><span class="token punctuation">,</span> <span class="token number">91</span><span class="token punctuation">]</span><span class="token punctuation">,</span>         <span class="token punctuation">[</span><span class="token number">93</span><span class="token punctuation">,</span> <span class="token number">94</span><span class="token punctuation">,</span> <span class="token number">59</span><span class="token punctuation">,</span>  <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">54</span><span class="token punctuation">,</span> <span class="token number">18</span><span class="token punctuation">,</span>  <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span>         <span class="token punctuation">[</span><span class="token number">94</span><span class="token punctuation">,</span> <span class="token number">88</span><span class="token punctuation">,</span>  <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">59</span><span class="token punctuation">,</span> <span class="token number">41</span><span class="token punctuation">,</span> <span class="token number">41</span><span class="token punctuation">,</span> <span class="token number">27</span><span class="token punctuation">]</span><span class="token punctuation">,</span>         <span class="token punctuation">[</span><span class="token number">69</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">,</span> <span class="token number">68</span><span class="token punctuation">,</span> <span class="token number">75</span><span class="token punctuation">,</span> <span class="token number">85</span><span class="token punctuation">,</span> <span class="token number">68</span><span class="token punctuation">,</span>  <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">17</span><span class="token punctuation">,</span> <span class="token number">74</span><span class="token punctuation">,</span> <span class="token number">60</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">21</span><span class="token punctuation">,</span> <span class="token number">97</span><span class="token punctuation">,</span> <span class="token number">83</span><span class="token punctuation">]</span><span class="token punctuation">,</span>         <span class="token punctuation">[</span><span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">37</span><span class="token punctuation">,</span>  <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">49</span><span class="token punctuation">,</span> <span class="token number">12</span><span class="token punctuation">,</span> <span class="token number">11</span><span class="token punctuation">,</span> <span class="token number">47</span><span class="token punctuation">]</span><span class="token punctuation">,</span>         <span class="token punctuation">[</span><span class="token number">57</span><span class="token punctuation">,</span> <span class="token number">29</span><span class="token punctuation">,</span> <span class="token number">79</span><span class="token punctuation">,</span> <span class="token number">19</span><span class="token punctuation">,</span> <span class="token number">95</span><span class="token punctuation">,</span> <span class="token number">84</span><span class="token punctuation">,</span>  <span class="token number">7</span><span class="token punctuation">]</span><span class="token punctuation">,</span>         <span class="token punctuation">[</span><span class="token number">37</span><span class="token punctuation">,</span> <span class="token number">52</span><span class="token punctuation">,</span> <span class="token number">57</span><span class="token punctuation">,</span> <span class="token number">61</span><span class="token punctuation">,</span> <span class="token number">69</span><span class="token punctuation">,</span> <span class="token number">52</span><span class="token punctuation">,</span> <span class="token number">25</span><span class="token punctuation">]</span><span class="token punctuation">,</span>         <span class="token punctuation">[</span><span class="token number">73</span><span class="token punctuation">,</span>  <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">,</span> <span class="token number">37</span><span class="token punctuation">,</span> <span class="token number">25</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span>  <span class="token number">9</span><span class="token punctuation">]</span><span class="token punctuation">,</span>         <span class="token punctuation">[</span><span class="token number">39</span><span class="token punctuation">,</span> <span class="token number">60</span><span class="token punctuation">,</span> <span class="token number">17</span><span class="token punctuation">,</span> <span class="token number">47</span><span class="token punctuation">,</span> <span class="token number">85</span><span class="token punctuation">,</span> <span class="token number">44</span><span class="token punctuation">,</span> <span class="token number">51</span><span class="token punctuation">]</span><span class="token punctuation">,</span>         <span class="token punctuation">[</span><span class="token number">45</span><span class="token punctuation">,</span> <span class="token number">60</span><span class="token punctuation">,</span> <span class="token number">81</span><span class="token punctuation">,</span> <span class="token number">97</span><span class="token punctuation">,</span> <span class="token number">81</span><span class="token punctuation">,</span> <span class="token number">97</span><span class="token punctuation">,</span> <span class="token number">46</span><span class="token punctuation">]</span><span class="token punctuation">,</span>         <span class="token punctuation">[</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">26</span><span class="token punctuation">,</span> <span class="token number">84</span><span class="token punctuation">,</span> <span class="token number">49</span><span class="token punctuation">,</span> <span class="token number">25</span><span class="token punctuation">,</span> <span class="token number">11</span><span class="token punctuation">,</span>  <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span>         <span class="token punctuation">[</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">39</span><span class="token punctuation">,</span> <span class="token number">77</span><span class="token punctuation">,</span> <span class="token number">77</span><span class="token punctuation">,</span>  <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">81</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">,</span>         <span class="token punctuation">[</span><span class="token number">39</span><span class="token punctuation">,</span> <span class="token number">29</span><span class="token punctuation">,</span> <span class="token number">40</span><span class="token punctuation">,</span> <span class="token number">40</span><span class="token punctuation">,</span>  <span class="token number">5</span><span class="token punctuation">,</span>  <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">42</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">50</span><span class="token punctuation">,</span> <span class="token number">27</span><span class="token punctuation">,</span> <span class="token number">68</span><span class="token punctuation">,</span>  <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">46</span><span class="token punctuation">,</span> <span class="token number">93</span><span class="token punctuation">,</span> <span class="token number">29</span><span class="token punctuation">]</span><span class="token punctuation">,</span>         <span class="token punctuation">[</span><span class="token number">95</span><span class="token punctuation">,</span> <span class="token number">68</span><span class="token punctuation">,</span>  <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">81</span><span class="token punctuation">,</span> <span class="token number">44</span><span class="token punctuation">,</span> <span class="token number">27</span><span class="token punctuation">,</span> <span class="token number">89</span><span class="token punctuation">]</span><span class="token punctuation">,</span>         <span class="token punctuation">[</span> <span class="token number">9</span><span class="token punctuation">,</span> <span class="token number">55</span><span class="token punctuation">,</span> <span class="token number">39</span><span class="token punctuation">,</span> <span class="token number">85</span><span class="token punctuation">,</span> <span class="token number">63</span><span class="token punctuation">,</span> <span class="token number">74</span><span class="token punctuation">,</span> <span class="token number">67</span><span class="token punctuation">]</span><span class="token punctuation">,</span>         <span class="token punctuation">[</span><span class="token number">37</span><span class="token punctuation">,</span> <span class="token number">39</span><span class="token punctuation">,</span>  <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">77</span><span class="token punctuation">,</span> <span class="token number">89</span><span class="token punctuation">,</span> <span class="token number">84</span><span class="token punctuation">,</span> <span class="token number">14</span><span class="token punctuation">]</span><span class="token punctuation">,</span>         <span class="token punctuation">[</span><span class="token number">52</span><span class="token punctuation">,</span> <span class="token number">14</span><span class="token punctuation">,</span> <span class="token number">22</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">,</span> <span class="token number">67</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">,</span> <span class="token number">48</span><span class="token punctuation">]</span><span class="token punctuation">,</span>         <span class="token punctuation">[</span><span class="token number">52</span><span class="token punctuation">,</span> <span class="token number">82</span><span class="token punctuation">,</span> <span class="token number">12</span><span class="token punctuation">,</span> <span class="token number">15</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">,</span> <span class="token number">84</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">]</span><span class="token punctuation">,</span>         <span class="token punctuation">[</span><span class="token number">92</span><span class="token punctuation">,</span> <span class="token number">68</span><span class="token punctuation">,</span> <span class="token number">56</span><span class="token punctuation">,</span> <span class="token number">49</span><span class="token punctuation">,</span> <span class="token number">40</span><span class="token punctuation">,</span> <span class="token number">56</span><span class="token punctuation">,</span> <span class="token number">38</span><span class="token punctuation">]</span><span class="token punctuation">,</span>         <span class="token punctuation">[</span><span class="token number">49</span><span class="token punctuation">,</span> <span class="token number">56</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">23</span><span class="token punctuation">,</span> <span class="token number">90</span><span class="token punctuation">,</span>  <span class="token number">9</span><span class="token punctuation">,</span> <span class="token number">46</span><span class="token punctuation">]</span><span class="token punctuation">,</span>         <span class="token punctuation">[</span><span class="token number">99</span><span class="token punctuation">,</span> <span class="token number">68</span><span class="token punctuation">,</span> <span class="token number">51</span><span class="token punctuation">,</span>  <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">74</span><span class="token punctuation">,</span> <span class="token number">14</span><span class="token punctuation">,</span> <span class="token number">35</span><span class="token punctuation">]</span><span class="token punctuation">,</span>         <span class="token punctuation">[</span><span class="token number">33</span><span class="token punctuation">,</span> <span class="token number">42</span><span class="token punctuation">,</span> <span class="token number">50</span><span class="token punctuation">,</span> <span class="token number">91</span><span class="token punctuation">,</span> <span class="token number">56</span><span class="token punctuation">,</span> <span class="token number">94</span><span class="token punctuation">,</span> <span class="token number">80</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">18</span><span class="token punctuation">,</span> <span class="token number">72</span><span class="token punctuation">,</span> <span class="token number">14</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">66</span><span class="token punctuation">,</span> <span class="token number">87</span><span class="token punctuation">]</span><span class="token punctuation">,</span>         <span class="token punctuation">[</span><span class="token number">33</span><span class="token punctuation">,</span> <span class="token number">50</span><span class="token punctuation">,</span> <span class="token number">75</span><span class="token punctuation">,</span>  <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">86</span><span class="token punctuation">,</span>  <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">50</span><span class="token punctuation">]</span><span class="token punctuation">,</span>         <span class="token punctuation">[</span><span class="token number">41</span><span class="token punctuation">,</span> <span class="token number">23</span><span class="token punctuation">,</span> <span class="token number">56</span><span class="token punctuation">,</span> <span class="token number">91</span><span class="token punctuation">,</span> <span class="token number">35</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">,</span> <span class="token number">31</span><span class="token punctuation">]</span><span class="token punctuation">,</span>         <span class="token punctuation">[</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">72</span><span class="token punctuation">,</span> <span class="token number">25</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">21</span><span class="token punctuation">,</span> <span class="token number">78</span><span class="token punctuation">,</span> <span class="token number">76</span><span class="token punctuation">]</span><span class="token punctuation">,</span>         <span class="token punctuation">[</span><span class="token number">88</span><span class="token punctuation">,</span> <span class="token number">68</span><span class="token punctuation">,</span> <span class="token number">33</span><span class="token punctuation">,</span> <span class="token number">36</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">91</span><span class="token punctuation">,</span> <span class="token number">63</span><span class="token punctuation">]</span><span class="token punctuation">,</span>         <span class="token punctuation">[</span><span class="token number">26</span><span class="token punctuation">,</span> <span class="token number">26</span><span class="token punctuation">,</span>  <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">60</span><span class="token punctuation">,</span> <span class="token number">21</span><span class="token punctuation">,</span>  <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">93</span><span class="token punctuation">]</span><span class="token punctuation">,</span>         <span class="token punctuation">[</span><span class="token number">17</span><span class="token punctuation">,</span> <span class="token number">44</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">51</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span>  <span class="token number">9</span><span class="token punctuation">,</span> <span class="token number">89</span><span class="token punctuation">]</span><span class="token punctuation">,</span>         <span class="token punctuation">[</span><span class="token number">58</span><span class="token punctuation">,</span> <span class="token number">91</span><span class="token punctuation">,</span> <span class="token number">33</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">38</span><span class="token punctuation">,</span> <span class="token number">47</span><span class="token punctuation">,</span> <span class="token number">19</span><span class="token punctuation">]</span><span class="token punctuation">,</span>         <span class="token punctuation">[</span><span class="token number">66</span><span class="token punctuation">,</span> <span class="token number">65</span><span class="token punctuation">,</span> <span class="token number">48</span><span class="token punctuation">,</span> <span class="token number">38</span><span class="token punctuation">,</span> <span class="token number">19</span><span class="token punctuation">,</span> <span class="token number">84</span><span class="token punctuation">,</span> <span class="token number">12</span><span class="token punctuation">]</span><span class="token punctuation">,</span>         <span class="token punctuation">[</span><span class="token number">70</span><span class="token punctuation">,</span> <span class="token number">33</span><span class="token punctuation">,</span> <span class="token number">25</span><span class="token punctuation">,</span> <span class="token number">58</span><span class="token punctuation">,</span> <span class="token number">24</span><span class="token punctuation">,</span> <span class="token number">61</span><span class="token punctuation">,</span> <span class="token number">59</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>int32<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>抽取每个班级第0个学生，第5个学生，第9个学生的全部成绩</p><pre class="line-numbers language-python"><code class="language-python">torch<span class="token punctuation">.</span>index_select<span class="token punctuation">(</span>scores<span class="token punctuation">,</span> dim <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">,</span> index <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">9</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span>Output<span class="token punctuation">:</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">55</span><span class="token punctuation">,</span> <span class="token number">95</span><span class="token punctuation">,</span>  <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">18</span><span class="token punctuation">,</span> <span class="token number">37</span><span class="token punctuation">,</span> <span class="token number">30</span><span class="token punctuation">,</span> <span class="token number">93</span><span class="token punctuation">]</span><span class="token punctuation">,</span>         <span class="token punctuation">[</span><span class="token number">72</span><span class="token punctuation">,</span> <span class="token number">70</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">,</span> <span class="token number">65</span><span class="token punctuation">,</span> <span class="token number">77</span><span class="token punctuation">,</span> <span class="token number">43</span><span class="token punctuation">,</span> <span class="token number">51</span><span class="token punctuation">]</span><span class="token punctuation">,</span>         <span class="token punctuation">[</span><span class="token number">69</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">,</span> <span class="token number">68</span><span class="token punctuation">,</span> <span class="token number">75</span><span class="token punctuation">,</span> <span class="token number">85</span><span class="token punctuation">,</span> <span class="token number">68</span><span class="token punctuation">,</span>  <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">17</span><span class="token punctuation">,</span> <span class="token number">74</span><span class="token punctuation">,</span> <span class="token number">60</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">21</span><span class="token punctuation">,</span> <span class="token number">97</span><span class="token punctuation">,</span> <span class="token number">83</span><span class="token punctuation">]</span><span class="token punctuation">,</span>         <span class="token punctuation">[</span><span class="token number">39</span><span class="token punctuation">,</span> <span class="token number">60</span><span class="token punctuation">,</span> <span class="token number">17</span><span class="token punctuation">,</span> <span class="token number">47</span><span class="token punctuation">,</span> <span class="token number">85</span><span class="token punctuation">,</span> <span class="token number">44</span><span class="token punctuation">,</span> <span class="token number">51</span><span class="token punctuation">]</span><span class="token punctuation">,</span>         <span class="token punctuation">[</span><span class="token number">39</span><span class="token punctuation">,</span> <span class="token number">29</span><span class="token punctuation">,</span> <span class="token number">40</span><span class="token punctuation">,</span> <span class="token number">40</span><span class="token punctuation">,</span>  <span class="token number">5</span><span class="token punctuation">,</span>  <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">42</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">50</span><span class="token punctuation">,</span> <span class="token number">27</span><span class="token punctuation">,</span> <span class="token number">68</span><span class="token punctuation">,</span>  <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">46</span><span class="token punctuation">,</span> <span class="token number">93</span><span class="token punctuation">,</span> <span class="token number">29</span><span class="token punctuation">]</span><span class="token punctuation">,</span>         <span class="token punctuation">[</span><span class="token number">52</span><span class="token punctuation">,</span> <span class="token number">82</span><span class="token punctuation">,</span> <span class="token number">12</span><span class="token punctuation">,</span> <span class="token number">15</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">,</span> <span class="token number">84</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">]</span><span class="token punctuation">,</span>         <span class="token punctuation">[</span><span class="token number">33</span><span class="token punctuation">,</span> <span class="token number">42</span><span class="token punctuation">,</span> <span class="token number">50</span><span class="token punctuation">,</span> <span class="token number">91</span><span class="token punctuation">,</span> <span class="token number">56</span><span class="token punctuation">,</span> <span class="token number">94</span><span class="token punctuation">,</span> <span class="token number">80</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">18</span><span class="token punctuation">,</span> <span class="token number">72</span><span class="token punctuation">,</span> <span class="token number">14</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">66</span><span class="token punctuation">,</span> <span class="token number">87</span><span class="token punctuation">]</span><span class="token punctuation">,</span>         <span class="token punctuation">[</span><span class="token number">26</span><span class="token punctuation">,</span> <span class="token number">26</span><span class="token punctuation">,</span>  <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">60</span><span class="token punctuation">,</span> <span class="token number">21</span><span class="token punctuation">,</span>  <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">93</span><span class="token punctuation">]</span><span class="token punctuation">,</span>         <span class="token punctuation">[</span><span class="token number">70</span><span class="token punctuation">,</span> <span class="token number">33</span><span class="token punctuation">,</span> <span class="token number">25</span><span class="token punctuation">,</span> <span class="token number">58</span><span class="token punctuation">,</span> <span class="token number">24</span><span class="token punctuation">,</span> <span class="token number">61</span><span class="token punctuation">,</span> <span class="token number">59</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>int32<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>抽取每个班级第0个学生，第5个学生，第9个学生的第1门课程，第3门课程，第6门课程成绩</p><pre class="line-numbers language-python"><code class="language-python">q <span class="token operator">=</span> torch<span class="token punctuation">.</span>index_select<span class="token punctuation">(</span>        torch<span class="token punctuation">.</span>index_select<span class="token punctuation">(</span>scores<span class="token punctuation">,</span>dim <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">,</span>index <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">9</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        dim<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> index <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    <span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>抽取第0个班级第0个学生的第0门课程，第2个班级的第4个学生的第1门课程，第3个班级的第9个学生第6门课程成绩。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># take将输入看成一维数组，输出和index同形状</span>s <span class="token operator">=</span> torch<span class="token punctuation">.</span>take<span class="token punctuation">(</span>scores<span class="token punctuation">,</span>torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token operator">*</span><span class="token number">10</span><span class="token operator">*</span><span class="token number">7</span><span class="token operator">+</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token operator">*</span><span class="token number">10</span><span class="token operator">*</span><span class="token number">7</span><span class="token operator">+</span><span class="token number">4</span><span class="token operator">*</span><span class="token number">7</span><span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token operator">*</span><span class="token number">10</span><span class="token operator">*</span><span class="token number">7</span><span class="token operator">+</span><span class="token number">9</span><span class="token operator">*</span><span class="token number">7</span><span class="token operator">+</span><span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>s<span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span>Output<span class="token punctuation">:</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">55</span><span class="token punctuation">,</span> <span class="token number">14</span><span class="token punctuation">,</span> <span class="token number">59</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>int32<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>抽取分数大于等于80分的分数（布尔索引）</p><pre class="line-numbers language-python"><code class="language-python">g <span class="token operator">=</span> torch<span class="token punctuation">.</span>masked_select<span class="token punctuation">(</span>scores<span class="token punctuation">,</span> scores<span class="token operator">>=</span><span class="token number">80</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>g<span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 结果是1维张量</span><span class="token operator">>></span><span class="token operator">></span>Output<span class="token punctuation">:</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">95</span><span class="token punctuation">,</span> <span class="token number">93</span><span class="token punctuation">,</span> <span class="token number">92</span><span class="token punctuation">,</span> <span class="token number">81</span><span class="token punctuation">,</span> <span class="token number">81</span><span class="token punctuation">,</span> <span class="token number">99</span><span class="token punctuation">,</span> <span class="token number">83</span><span class="token punctuation">,</span> <span class="token number">81</span><span class="token punctuation">,</span> <span class="token number">98</span><span class="token punctuation">,</span> <span class="token number">91</span><span class="token punctuation">,</span> <span class="token number">93</span><span class="token punctuation">,</span> <span class="token number">94</span><span class="token punctuation">,</span> <span class="token number">94</span><span class="token punctuation">,</span> <span class="token number">88</span><span class="token punctuation">,</span> <span class="token number">85</span><span class="token punctuation">,</span> <span class="token number">97</span><span class="token punctuation">,</span> <span class="token number">83</span><span class="token punctuation">,</span> <span class="token number">95</span><span class="token punctuation">,</span>        <span class="token number">84</span><span class="token punctuation">,</span> <span class="token number">85</span><span class="token punctuation">,</span> <span class="token number">81</span><span class="token punctuation">,</span> <span class="token number">97</span><span class="token punctuation">,</span> <span class="token number">81</span><span class="token punctuation">,</span> <span class="token number">97</span><span class="token punctuation">,</span> <span class="token number">84</span><span class="token punctuation">,</span> <span class="token number">81</span><span class="token punctuation">,</span> <span class="token number">93</span><span class="token punctuation">,</span> <span class="token number">95</span><span class="token punctuation">,</span> <span class="token number">81</span><span class="token punctuation">,</span> <span class="token number">89</span><span class="token punctuation">,</span> <span class="token number">85</span><span class="token punctuation">,</span> <span class="token number">89</span><span class="token punctuation">,</span> <span class="token number">84</span><span class="token punctuation">,</span> <span class="token number">82</span><span class="token punctuation">,</span> <span class="token number">84</span><span class="token punctuation">,</span> <span class="token number">92</span><span class="token punctuation">,</span>        <span class="token number">90</span><span class="token punctuation">,</span> <span class="token number">99</span><span class="token punctuation">,</span> <span class="token number">91</span><span class="token punctuation">,</span> <span class="token number">94</span><span class="token punctuation">,</span> <span class="token number">80</span><span class="token punctuation">,</span> <span class="token number">87</span><span class="token punctuation">,</span> <span class="token number">86</span><span class="token punctuation">,</span> <span class="token number">91</span><span class="token punctuation">,</span> <span class="token number">88</span><span class="token punctuation">,</span> <span class="token number">91</span><span class="token punctuation">,</span> <span class="token number">93</span><span class="token punctuation">,</span> <span class="token number">89</span><span class="token punctuation">,</span> <span class="token number">91</span><span class="token punctuation">,</span> <span class="token number">84</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>int32<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>以上这些方法仅能提取张量的部分元素值，但不能更改张量的部分元素值得到新的张量。<br>如果要通过修改张量的部分元素值得到新的张量，可以使用<code>torch.where</code>，<code>torch.index_fill</code>和 <code>torch.masked_fill</code>。<br><code>torch.where</code>可以理解为if的张量版本。<br><code>torch.index_fill</code>的选取元素逻辑和<code>torch.index_select</code>相同。<br><code>torch.masked_fill</code>的选取元素逻辑和<code>torch.masked_select</code>相同。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#如果分数大于60分，赋值成1，否则赋值成0</span>ifpass <span class="token operator">=</span> torch<span class="token punctuation">.</span>where<span class="token punctuation">(</span>scores<span class="token operator">></span><span class="token number">60</span><span class="token punctuation">,</span>torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 将每个班级第0个学生，第5个学生，第9个学生的全部成绩赋值成满分</span>full <span class="token operator">=</span> torch<span class="token punctuation">.</span>index_fill<span class="token punctuation">(</span>scores<span class="token punctuation">,</span>dim <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">,</span>index <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">9</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>value <span class="token operator">=</span> <span class="token number">100</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#将分数小于60分的分数赋值成60分</span>b <span class="token operator">=</span> torch<span class="token punctuation">.</span>masked_fill<span class="token punctuation">(</span>scores<span class="token punctuation">,</span>scores<span class="token operator">&lt;</span><span class="token number">60</span><span class="token punctuation">,</span><span class="token number">60</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="维度变换"><a href="#维度变换" class="headerlink" title="维度变换"></a>维度变换</h4><p>维度变换相关函数主要有<code>torch.reshape</code>(或者调用张量的<code>view()</code>方法), <code>torch.squeeze()</code>, <code>torch.unsqueeze()</code>, <code>torch.transpose()</code>。</p><ul><li>torch.reshape 可以改变张量的形状。</li><li>torch.squeeze 可以减少维度。</li><li>torch.unsqueeze 可以增加维度。</li><li>torch.transpose 可以交换维度。</li></ul><p>张量的view方法有时候会调用失败，可以使用reshape方法。</p><pre class="line-numbers language-python"><code class="language-python">minval<span class="token punctuation">,</span>maxval <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">,</span><span class="token number">255</span>a <span class="token operator">=</span> <span class="token punctuation">(</span>minval <span class="token operator">+</span> <span class="token punctuation">(</span>maxval<span class="token operator">-</span>minval<span class="token punctuation">)</span><span class="token operator">*</span>torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>int<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 改成（3,6）形状的张量</span>b <span class="token operator">=</span> a<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># torch.reshape(a,[3,6])</span><span class="token keyword">print</span><span class="token punctuation">(</span>b<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>b<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 改回成 [1,3,3,2] 形状的张量</span>c <span class="token operator">=</span> torch<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>b<span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># b.view([1,3,3,2]) </span><span class="token operator">>></span><span class="token operator">></span>Output<span class="token punctuation">:</span>torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">126</span><span class="token punctuation">,</span> <span class="token number">195</span><span class="token punctuation">]</span><span class="token punctuation">,</span>          <span class="token punctuation">[</span> <span class="token number">22</span><span class="token punctuation">,</span>  <span class="token number">33</span><span class="token punctuation">]</span><span class="token punctuation">,</span>          <span class="token punctuation">[</span> <span class="token number">78</span><span class="token punctuation">,</span> <span class="token number">161</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>         <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">124</span><span class="token punctuation">,</span> <span class="token number">228</span><span class="token punctuation">]</span><span class="token punctuation">,</span>          <span class="token punctuation">[</span><span class="token number">116</span><span class="token punctuation">,</span> <span class="token number">161</span><span class="token punctuation">]</span><span class="token punctuation">,</span>          <span class="token punctuation">[</span> <span class="token number">88</span><span class="token punctuation">,</span> <span class="token number">102</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>         <span class="token punctuation">[</span><span class="token punctuation">[</span>  <span class="token number">5</span><span class="token punctuation">,</span>  <span class="token number">43</span><span class="token punctuation">]</span><span class="token punctuation">,</span>          <span class="token punctuation">[</span> <span class="token number">74</span><span class="token punctuation">,</span> <span class="token number">132</span><span class="token punctuation">]</span><span class="token punctuation">,</span>          <span class="token punctuation">[</span><span class="token number">177</span><span class="token punctuation">,</span> <span class="token number">204</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>int32<span class="token punctuation">)</span>torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">126</span><span class="token punctuation">,</span> <span class="token number">195</span><span class="token punctuation">,</span>  <span class="token number">22</span><span class="token punctuation">,</span>  <span class="token number">33</span><span class="token punctuation">,</span>  <span class="token number">78</span><span class="token punctuation">,</span> <span class="token number">161</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">124</span><span class="token punctuation">,</span> <span class="token number">228</span><span class="token punctuation">,</span> <span class="token number">116</span><span class="token punctuation">,</span> <span class="token number">161</span><span class="token punctuation">,</span>  <span class="token number">88</span><span class="token punctuation">,</span> <span class="token number">102</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span>  <span class="token number">5</span><span class="token punctuation">,</span>  <span class="token number">43</span><span class="token punctuation">,</span>  <span class="token number">74</span><span class="token punctuation">,</span> <span class="token number">132</span><span class="token punctuation">,</span> <span class="token number">177</span><span class="token punctuation">,</span> <span class="token number">204</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>int32<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>如果张量在某个维度上的维度是1，利用<code>torch.squeeze()</code>可以消除这个维度。<code>torch.unsqueeze()</code>的作用和<code>torch.squeeze()</code>的作用相反。</p><pre class="line-numbers language-python"><code class="language-python">a <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1.0</span><span class="token punctuation">,</span> <span class="token number">2.0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>s <span class="token operator">=</span> torch<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>s<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>s<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span>Output<span class="token punctuation">:</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">)</span>torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>在张量的第0维插入一个维度</p><pre class="line-numbers language-python"><code class="language-python">d <span class="token operator">=</span> torch<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span>s<span class="token punctuation">,</span>axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>  <span class="token keyword">print</span><span class="token punctuation">(</span>d<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>d<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span>Output<span class="token punctuation">:</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><code>torch.transpose()</code>可以交换张量的维度，<code>torch.transpose()</code>常用于图片存储格式的变换上。<br>如果是二维的矩阵，通常会调用矩阵的转置方法 <code>matrix.t()</code>，等价于 <code>torch.transpose(matrix, 0, 1)</code>。</p><pre class="line-numbers language-python"><code class="language-python">minval<span class="token operator">=</span><span class="token number">0</span>maxval<span class="token operator">=</span><span class="token number">255</span><span class="token comment" spellcheck="true"># Batch,Height,Width,Channel</span>data <span class="token operator">=</span> torch<span class="token punctuation">.</span>floor<span class="token punctuation">(</span>minval <span class="token operator">+</span> <span class="token punctuation">(</span>maxval<span class="token operator">-</span>minval<span class="token punctuation">)</span><span class="token operator">*</span>torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span><span class="token number">256</span><span class="token punctuation">,</span><span class="token number">256</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>int<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>data<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 转换成 Pytorch默认的图片格式 Batch,Channel,Height,Width </span><span class="token comment" spellcheck="true"># 需要交换两次</span>data_t <span class="token operator">=</span> torch<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span>data<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>data_t<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>matrix <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>matrix<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>matrix<span class="token punctuation">.</span>t<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 等价于torch.transpose(matrix,0,1)</span><span class="token operator">>></span><span class="token operator">></span>Output<span class="token punctuation">:</span>torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">)</span>torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">]</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="合并分割"><a href="#合并分割" class="headerlink" title="合并分割"></a>合并分割</h4><p>可以用<code>torch.cat()</code>方法和<code>torch.stack()</code>方法将多个张量合并，可以用<code>torch.split()</code>方法把一个张量分割成多个张量。<br><code>torch.cat()</code>和<code>torch.stack()</code>有略微的区别：</p><ul><li>torch.cat是连接，不会增加维度</li><li>torch.stack是堆叠，会增加维度。</li></ul><p><strong>torch中dim和axis参数名可以混用</strong>。</p><pre class="line-numbers language-python"><code class="language-python">a <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1.0</span><span class="token punctuation">,</span><span class="token number">2.0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">3.0</span><span class="token punctuation">,</span><span class="token number">4.0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>b <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">5.0</span><span class="token punctuation">,</span><span class="token number">6.0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">7.0</span><span class="token punctuation">,</span><span class="token number">8.0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>c <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">9.0</span><span class="token punctuation">,</span><span class="token number">10.0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">11.0</span><span class="token punctuation">,</span><span class="token number">12.0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>abc_cat <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>a<span class="token punctuation">,</span>b<span class="token punctuation">,</span>c<span class="token punctuation">]</span><span class="token punctuation">,</span> dim <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>abc_cat<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>abc_cat<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># torch中dim和axis参数名可以混用</span>abc_stack <span class="token operator">=</span> torch<span class="token punctuation">.</span>stack<span class="token punctuation">(</span><span class="token punctuation">[</span>a<span class="token punctuation">,</span>b<span class="token punctuation">,</span>c<span class="token punctuation">]</span><span class="token punctuation">,</span> axis <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token keyword">print</span><span class="token punctuation">(</span>abc_stack<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>abc_stack<span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span>Output<span class="token punctuation">:</span>torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span>  <span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">3</span><span class="token punctuation">.</span><span class="token punctuation">,</span>  <span class="token number">4</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">5</span><span class="token punctuation">.</span><span class="token punctuation">,</span>  <span class="token number">6</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">7</span><span class="token punctuation">.</span><span class="token punctuation">,</span>  <span class="token number">8</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">9</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">11</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">12</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span>  <span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>         <span class="token punctuation">[</span> <span class="token number">3</span><span class="token punctuation">.</span><span class="token punctuation">,</span>  <span class="token number">4</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">5</span><span class="token punctuation">.</span><span class="token punctuation">,</span>  <span class="token number">6</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>         <span class="token punctuation">[</span> <span class="token number">7</span><span class="token punctuation">.</span><span class="token punctuation">,</span>  <span class="token number">8</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">9</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>         <span class="token punctuation">[</span><span class="token number">11</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">12</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python">cat <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>a<span class="token punctuation">,</span>b<span class="token punctuation">,</span>c<span class="token punctuation">]</span><span class="token punctuation">,</span>axis <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">)</span>stack <span class="token operator">=</span> torch<span class="token punctuation">.</span>stack<span class="token punctuation">(</span><span class="token punctuation">[</span>a<span class="token punctuation">,</span>b<span class="token punctuation">,</span>c<span class="token punctuation">]</span><span class="token punctuation">,</span>axis <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span>Output<span class="token punctuation">:</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span>  <span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">,</span>  <span class="token number">5</span><span class="token punctuation">.</span><span class="token punctuation">,</span>  <span class="token number">6</span><span class="token punctuation">.</span><span class="token punctuation">,</span>  <span class="token number">9</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">3</span><span class="token punctuation">.</span><span class="token punctuation">,</span>  <span class="token number">4</span><span class="token punctuation">.</span><span class="token punctuation">,</span>  <span class="token number">7</span><span class="token punctuation">.</span><span class="token punctuation">,</span>  <span class="token number">8</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">11</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">12</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span>  <span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>         <span class="token punctuation">[</span> <span class="token number">5</span><span class="token punctuation">.</span><span class="token punctuation">,</span>  <span class="token number">6</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>         <span class="token punctuation">[</span> <span class="token number">9</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">3</span><span class="token punctuation">.</span><span class="token punctuation">,</span>  <span class="token number">4</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>         <span class="token punctuation">[</span> <span class="token number">7</span><span class="token punctuation">.</span><span class="token punctuation">,</span>  <span class="token number">8</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>         <span class="token punctuation">[</span><span class="token number">11</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">12</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><code>torch.split()</code>是<code>torch.cat()</code>的逆运算，可以指定分割份数平均分割，也可以通过指定每份的记录数量进行分割。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">print</span><span class="token punctuation">(</span>abc_cat<span class="token punctuation">)</span>a<span class="token punctuation">,</span>b<span class="token punctuation">,</span>c <span class="token operator">=</span> torch<span class="token punctuation">.</span>split<span class="token punctuation">(</span>abc_cat<span class="token punctuation">,</span>split_size_or_sections <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">,</span>dim <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">#每份2个进行分割</span><span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>b<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>c<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 每份分别为[4,1,1]</span>p<span class="token punctuation">,</span>q<span class="token punctuation">,</span>r <span class="token operator">=</span> torch<span class="token punctuation">.</span>split<span class="token punctuation">(</span>abc_cat<span class="token punctuation">,</span>split_size_or_sections <span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>dim <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token keyword">print</span><span class="token punctuation">(</span>p<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>q<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>r<span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span>Output<span class="token punctuation">:</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span>  <span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">3</span><span class="token punctuation">.</span><span class="token punctuation">,</span>  <span class="token number">4</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">5</span><span class="token punctuation">.</span><span class="token punctuation">,</span>  <span class="token number">6</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">7</span><span class="token punctuation">.</span><span class="token punctuation">,</span>  <span class="token number">8</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">9</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">11</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">12</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">7</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">9</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">11</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">12</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">7</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">9</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">11</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">12</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="张量的数学运算"><a href="#张量的数学运算" class="headerlink" title="张量的数学运算"></a>张量的数学运算</h3><p>张量的数学运算符可以分为标量运算符、向量运算符、以及矩阵运算符。</p><h4 id="标量运算"><a href="#标量运算" class="headerlink" title="标量运算"></a>标量运算</h4><p>加减乘除乘方，以及三角函数，指数，对数等常见函数，逻辑比较运算符等都是标量运算符。<br><strong>标量运算符的特点是对张量实施逐元素运算</strong>。有些标量运算符对常用的数学运算符进行了重载。并且支持类似numpy的广播特性。</p><pre class="line-numbers language-python"><code class="language-python">a <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1.0</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4.0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>b <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">5.0</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">7.0</span><span class="token punctuation">,</span><span class="token number">8.0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 逐元素运算</span>a<span class="token operator">+</span>b  <span class="token comment" spellcheck="true">#运算符重载</span>a<span class="token operator">-</span>b a<span class="token operator">*</span>b a<span class="token operator">/</span>ba<span class="token operator">**</span><span class="token number">2</span>a<span class="token operator">**</span><span class="token number">0.5</span>a<span class="token operator">%</span><span class="token number">3</span>a<span class="token operator">//</span><span class="token number">3</span>torch<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token operator">>=</span><span class="token number">2</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># torch.ge(a,2)  #ge: greater_equal缩写</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token punctuation">(</span>a<span class="token operator">>=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token operator">&amp;</span><span class="token punctuation">(</span>a<span class="token operator">&lt;=</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token punctuation">(</span>a<span class="token operator">>=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token operator">|</span><span class="token punctuation">(</span>a<span class="token operator">&lt;=</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token operator">==</span><span class="token number">5</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># torch.eq(a,5)  # eq: equal缩写</span><span class="token operator">>></span><span class="token operator">></span>Output<span class="token punctuation">:</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token boolean">False</span><span class="token punctuation">,</span>  <span class="token boolean">True</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token boolean">False</span><span class="token punctuation">,</span>  <span class="token boolean">True</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token boolean">False</span><span class="token punctuation">,</span>  <span class="token boolean">True</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token boolean">False</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token boolean">True</span><span class="token punctuation">,</span> <span class="token boolean">True</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token boolean">True</span><span class="token punctuation">,</span> <span class="token boolean">True</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token boolean">False</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token boolean">False</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python">a <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1.0</span><span class="token punctuation">,</span><span class="token number">8.0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>b <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">5.0</span><span class="token punctuation">,</span><span class="token number">6.0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>c <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">6.0</span><span class="token punctuation">,</span><span class="token number">7.0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>d <span class="token operator">=</span> a<span class="token operator">+</span>b<span class="token operator">+</span>c<span class="token keyword">print</span><span class="token punctuation">(</span>d<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>max<span class="token punctuation">(</span>a<span class="token punctuation">,</span>b<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>min<span class="token punctuation">(</span>a<span class="token punctuation">,</span>b<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span>Output<span class="token punctuation">:</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">12</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">21</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><code>torch.round()</code>：保留整数部分，四舍五入。<br><code>torch.floor()</code>：保留整数部分，向下取整。<br><code>torch.ceil()</code>：保留整数部分，向上取整。<br><code>torch.trunc()</code>：保留整数部分，向0归整。<br><code>torch.fmod()</code>：作除法取余数。<br><code>torch.remainder()</code>：作除法取剩余的部分，结果恒正。</p><pre class="line-numbers language-python"><code class="language-python">x <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2.6</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">2.7</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>round<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">print</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>floor<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">print</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>ceil<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token keyword">print</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>trunc<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">print</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>fmod<span class="token punctuation">(</span>x<span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">print</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>remainder<span class="token punctuation">(</span>x<span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">>></span><span class="token operator">></span>Output<span class="token punctuation">:</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span> <span class="token number">3</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">3</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span> <span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">3</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span> <span class="token number">3</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span> <span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span> <span class="token number">0.6000</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.7000</span><span class="token punctuation">]</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.6000</span><span class="token punctuation">,</span> <span class="token number">1.3000</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python">x <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.9</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">0.8</span><span class="token punctuation">,</span><span class="token number">100.0</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">20.0</span><span class="token punctuation">,</span><span class="token number">0.7</span><span class="token punctuation">]</span><span class="token punctuation">)</span>y <span class="token operator">=</span> torch<span class="token punctuation">.</span>clamp<span class="token punctuation">(</span>x<span class="token punctuation">,</span>min<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span>max <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">)</span>z <span class="token operator">=</span> torch<span class="token punctuation">.</span>clamp<span class="token punctuation">(</span>x<span class="token punctuation">,</span>max <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>y<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>z<span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span>Output<span class="token punctuation">:</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span> <span class="token number">0.9000</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.8000</span><span class="token punctuation">,</span>  <span class="token number">1.0000</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.0000</span><span class="token punctuation">,</span>  <span class="token number">0.7000</span><span class="token punctuation">]</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span>  <span class="token number">0.9000</span><span class="token punctuation">,</span>  <span class="token operator">-</span><span class="token number">0.8000</span><span class="token punctuation">,</span>   <span class="token number">1.0000</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">20.0000</span><span class="token punctuation">,</span>   <span class="token number">0.7000</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="向量运算"><a href="#向量运算" class="headerlink" title="向量运算"></a>向量运算</h4><p>向量运算符只在一个特定轴上运算，将一个向量映射到一个标量或者另外一个向量。</p><pre class="line-numbers language-python"><code class="language-python">a <span class="token operator">=</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">.</span>float<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>sum<span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>max<span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>min<span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>prod<span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">#累乘</span><span class="token keyword">print</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>std<span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true">#标准差</span><span class="token keyword">print</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>var<span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true">#方差</span><span class="token keyword">print</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>median<span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">#中位数</span><span class="token operator">>></span><span class="token operator">></span>Output<span class="token punctuation">:</span>tensor<span class="token punctuation">(</span><span class="token number">45</span><span class="token punctuation">.</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">.</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token number">9</span><span class="token punctuation">.</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token number">362880</span><span class="token punctuation">.</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token number">2.7386</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token number">7.5000</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python">b <span class="token operator">=</span> a<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>b<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>max<span class="token punctuation">(</span>b<span class="token punctuation">,</span>dim <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>max<span class="token punctuation">(</span>b<span class="token punctuation">,</span>dim <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span>Output<span class="token punctuation">:</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">7</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>torch<span class="token punctuation">.</span>return_types<span class="token punctuation">.</span>max<span class="token punctuation">(</span>values<span class="token operator">=</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">7</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>indices<span class="token operator">=</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>torch<span class="token punctuation">.</span>return_types<span class="token punctuation">.</span>max<span class="token punctuation">(</span>values<span class="token operator">=</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>indices<span class="token operator">=</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python">a <span class="token operator">=</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>cumsum<span class="token punctuation">(</span>a<span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>cumprod<span class="token punctuation">(</span>a<span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>cummax<span class="token punctuation">(</span>a<span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>values<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>cummax<span class="token punctuation">(</span>a<span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>indices<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>cummin<span class="token punctuation">(</span>a<span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span>Output<span class="token punctuation">:</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span> <span class="token number">1</span><span class="token punctuation">,</span>  <span class="token number">3</span><span class="token punctuation">,</span>  <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">15</span><span class="token punctuation">,</span> <span class="token number">21</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">36</span><span class="token punctuation">,</span> <span class="token number">45</span><span class="token punctuation">]</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span>     <span class="token number">1</span><span class="token punctuation">,</span>      <span class="token number">2</span><span class="token punctuation">,</span>      <span class="token number">6</span><span class="token punctuation">,</span>     <span class="token number">24</span><span class="token punctuation">,</span>    <span class="token number">120</span><span class="token punctuation">,</span>    <span class="token number">720</span><span class="token punctuation">,</span>   <span class="token number">5040</span><span class="token punctuation">,</span>  <span class="token number">40320</span><span class="token punctuation">,</span> <span class="token number">362880</span><span class="token punctuation">]</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">]</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">]</span><span class="token punctuation">)</span>torch<span class="token punctuation">.</span>return_types<span class="token punctuation">.</span>cummin<span class="token punctuation">(</span>values<span class="token operator">=</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>indices<span class="token operator">=</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><code>torch.sort()</code>和<code>torch.topk()</code>可以对张量排序。利用<code>torch.topk()</code>可以在Pytorch中实现KNN算法。</p><pre class="line-numbers language-python"><code class="language-python">a <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">9</span><span class="token punctuation">,</span><span class="token number">7</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>float<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>topk<span class="token punctuation">(</span>a<span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span>dim <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token string">"\n"</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>topk<span class="token punctuation">(</span>a<span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span>dim <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token string">"\n"</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>sort<span class="token punctuation">(</span>a<span class="token punctuation">,</span>dim <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token string">"\n"</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span>Output<span class="token punctuation">:</span>torch<span class="token punctuation">.</span>return_types<span class="token punctuation">.</span>topk<span class="token punctuation">(</span>values<span class="token operator">=</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">9</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>indices<span class="token operator">=</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span> torch<span class="token punctuation">.</span>return_types<span class="token punctuation">.</span>topk<span class="token punctuation">(</span>values<span class="token operator">=</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">9</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">6</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>indices<span class="token operator">=</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span> torch<span class="token punctuation">.</span>return_types<span class="token punctuation">.</span>sort<span class="token punctuation">(</span>values<span class="token operator">=</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">7</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>indices<span class="token operator">=</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="矩阵运算"><a href="#矩阵运算" class="headerlink" title="矩阵运算"></a>矩阵运算</h4><p>矩阵必须是二维的。<br>矩阵运算包括：矩阵乘法，矩阵转置，矩阵逆，矩阵求迹，矩阵范数，矩阵行列式，矩阵求特征值，矩阵分解等运算。</p><pre class="line-numbers language-python"><code class="language-python">a <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>b <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 下列均等价</span>torch<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>a<span class="token punctuation">,</span>b<span class="token punctuation">)</span>torch<span class="token punctuation">.</span>mm<span class="token punctuation">(</span>a<span class="token punctuation">,</span>b<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>a@b<span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span>Output<span class="token punctuation">:</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python">a <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1.0</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token punctuation">.</span>t<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span>Output<span class="token punctuation">:</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>矩阵求逆必须是浮点数类型。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 必须为浮点类型</span>a <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1.0</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>inverse<span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span>Output<span class="token punctuation">:</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">2.0000</span><span class="token punctuation">,</span>  <span class="token number">1.0000</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">1.5000</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.5000</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python">a <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1.0</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>trace<span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span>Output<span class="token punctuation">:</span>tensor<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python">a <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1.0</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>norm<span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span>Output<span class="token punctuation">:</span>tensor<span class="token punctuation">(</span><span class="token number">5.4772</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python">a <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1.0</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>det<span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span>Output<span class="token punctuation">:</span>tensor<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">2.0000</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python">a <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1.0</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>dtype <span class="token operator">=</span> torch<span class="token punctuation">.</span>float<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>eig<span class="token punctuation">(</span>a<span class="token punctuation">,</span>eigenvectors<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 两个特征值分别是 -2.5+2.7839j, 2.5-2.7839j </span><span class="token operator">>></span><span class="token operator">></span>Output<span class="token punctuation">:</span>torch<span class="token punctuation">.</span>return_types<span class="token punctuation">.</span>eig<span class="token punctuation">(</span>eigenvalues<span class="token operator">=</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">2.5000</span><span class="token punctuation">,</span>  <span class="token number">2.7839</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">2.5000</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">2.7839</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>eigenvectors<span class="token operator">=</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0.2535</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.4706</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">0.8452</span><span class="token punctuation">,</span>  <span class="token number">0.0000</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>矩阵QR分解，将一个方阵分解为一个正交矩阵q和上三角矩阵r。<br>QR分解实际上是对矩阵a实施Schmidt正交化得到q。</p><pre class="line-numbers language-python"><code class="language-python">a <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1.0</span><span class="token punctuation">,</span><span class="token number">2.0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">3.0</span><span class="token punctuation">,</span><span class="token number">4.0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>q<span class="token punctuation">,</span>r <span class="token operator">=</span> torch<span class="token punctuation">.</span>qr<span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>q<span class="token punctuation">,</span><span class="token string">"\n"</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>r<span class="token punctuation">,</span><span class="token string">"\n"</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>q@r<span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span>Output<span class="token punctuation">:</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.3162</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.9487</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.9487</span><span class="token punctuation">,</span>  <span class="token number">0.3162</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span> tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">3.1623</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">4.4272</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span> <span class="token number">0.0000</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.6325</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span> tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1.0000</span><span class="token punctuation">,</span> <span class="token number">2.0000</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">3.0000</span><span class="token punctuation">,</span> <span class="token number">4.0000</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>矩阵svd分解，svd分解可以将任意一个矩阵分解为一个正交矩阵u，一个对角阵s和一个正交矩阵<code>v.t()</code>的乘积。svd常用于矩阵压缩和降维，利用svd分解可以在Pytorch中实现主成分分析降维。</p><pre class="line-numbers language-python"><code class="language-python">a<span class="token operator">=</span>torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1.0</span><span class="token punctuation">,</span><span class="token number">2.0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">3.0</span><span class="token punctuation">,</span><span class="token number">4.0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">5.0</span><span class="token punctuation">,</span><span class="token number">6.0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>u<span class="token punctuation">,</span>s<span class="token punctuation">,</span>v <span class="token operator">=</span> torch<span class="token punctuation">.</span>svd<span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>u<span class="token punctuation">,</span><span class="token string">"\n"</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>s<span class="token punctuation">,</span><span class="token string">"\n"</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>v<span class="token punctuation">,</span><span class="token string">"\n"</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>u@torch<span class="token punctuation">.</span>diag<span class="token punctuation">(</span>s<span class="token punctuation">)</span>@v<span class="token punctuation">.</span>t<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span>Output<span class="token punctuation">:</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.2298</span><span class="token punctuation">,</span>  <span class="token number">0.8835</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.5247</span><span class="token punctuation">,</span>  <span class="token number">0.2408</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.8196</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.4019</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span> tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">9.5255</span><span class="token punctuation">,</span> <span class="token number">0.5143</span><span class="token punctuation">]</span><span class="token punctuation">)</span> tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.6196</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.7849</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.7849</span><span class="token punctuation">,</span>  <span class="token number">0.6196</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span> tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1.0000</span><span class="token punctuation">,</span> <span class="token number">2.0000</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">3.0000</span><span class="token punctuation">,</span> <span class="token number">4.0000</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">5.0000</span><span class="token punctuation">,</span> <span class="token number">6.0000</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="广播机制"><a href="#广播机制" class="headerlink" title="广播机制"></a>广播机制</h4><p>Pytorch的广播规则和numpy是一样的:</p><ol><li>如果张量的维度不同，将维度较小的张量进行扩展，直到两个张量的维度都一样。</li><li>如果两个张量在某个维度上的长度是相同的，或者其中一个张量在该维度上的长度为1，那么我们就说这两个张量在该维度上是相容的。</li><li>如果两个张量在所有维度上都是相容的，它们就能使用广播。</li><li>广播之后，每个维度的长度将取两个张量在该维度长度的较大值。</li><li>在任何一个维度上，如果一个张量的长度为1，另一个张量长度大于1，那么在该维度上，就好像是对第一个张量进行了复制。</li></ol><p><code>torch.broadcast_tensors()</code>可以将多个张量根据广播规则转换成相同的维度。</p><pre class="line-numbers language-python"><code class="language-python">a <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>b <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>b <span class="token operator">+</span> a<span class="token punctuation">)</span> a_broad<span class="token punctuation">,</span>b_broad <span class="token operator">=</span> torch<span class="token punctuation">.</span>broadcast_tensors<span class="token punctuation">(</span>a<span class="token punctuation">,</span>b<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>a_broad<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>b_broad<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>a_broad <span class="token operator">+</span> b_broad<span class="token punctuation">)</span> <span class="token operator">>></span><span class="token operator">></span>Output<span class="token punctuation">:</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span> tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span> tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> Pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 基础知识 </tag>
            
            <tag> Pytorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Pytorch训练代码模板</title>
      <link href="/2023/03/23/pytorch-ji-chu-zhi-shi/shen-du-xue-xi-xun-lian-dai-ma-mo-ban/"/>
      <url>/2023/03/23/pytorch-ji-chu-zhi-shi/shen-du-xue-xi-xun-lian-dai-ma-mo-ban/</url>
      
        <content type="html"><![CDATA[<h1 id="Pytorch训练代码模板"><a href="#Pytorch训练代码模板" class="headerlink" title="Pytorch训练代码模板"></a>Pytorch训练代码模板</h1><p>从参数定义，到网络模型定义，再到训练步骤，验证步骤，测试步骤，本文总结了一套较为直观的代码模板。目录如下：</p><ol><li>导入包以及设置随机种子</li><li>以类的方式定义超参数</li><li>定义自己的模型</li><li>定义早停类(此步骤可以省略)</li><li>定义自己的数据集Dataset,DataLoader</li><li>实例化模型，设置loss，优化器等</li><li>开始训练以及调整lr</li><li>绘图</li><li>预测</li></ol><h2 id="导入包以及设置随机种子"><a href="#导入包以及设置随机种子" class="headerlink" title="导入包以及设置随机种子"></a>导入包以及设置随机种子</h2><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">import</span> torch<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader<span class="token punctuation">,</span> Dataset<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> train_test_split<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt<span class="token keyword">import</span> randomseed <span class="token operator">=</span> <span class="token number">42</span>random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span>seed<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># seed for module random</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span>seed<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># seed for numpy</span>torch<span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span>seed<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># seed for PyTorch CPU</span>torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span>seed<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># seed for current PyTorch GPU</span>torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>manual_seed_all<span class="token punctuation">(</span>seed<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># seed for all PyTorch GPUs</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="以类的方式定义超参数"><a href="#以类的方式定义超参数" class="headerlink" title="以类的方式定义超参数"></a>以类的方式定义超参数</h2><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">argparse</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">pass</span>args <span class="token operator">=</span> argparse<span class="token punctuation">(</span><span class="token punctuation">)</span>args<span class="token punctuation">.</span>epochs<span class="token punctuation">,</span> args<span class="token punctuation">.</span>learning_rate<span class="token punctuation">,</span> args<span class="token punctuation">.</span>patience <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">30</span><span class="token punctuation">,</span> <span class="token number">0.001</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span>args<span class="token punctuation">.</span>hidden_size<span class="token punctuation">,</span> args<span class="token punctuation">.</span>input_size<span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">40</span><span class="token punctuation">,</span> <span class="token number">30</span><span class="token punctuation">]</span>args<span class="token punctuation">.</span>device<span class="token punctuation">,</span> <span class="token operator">=</span> <span class="token punctuation">[</span>torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">"cuda:0"</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">"cpu"</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="定义模型"><a href="#定义模型" class="headerlink" title="定义模型"></a>定义模型</h2><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Your_model</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>Your_model<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">pass</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">pass</span>        <span class="token keyword">return</span> x<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="定义早停类-可选"><a href="#定义早停类-可选" class="headerlink" title="定义早停类(可选)"></a>定义早停类(可选)</h2><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">EarlyStopping</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> patience<span class="token operator">=</span><span class="token number">7</span><span class="token punctuation">,</span> verbose<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> delta<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>patience <span class="token operator">=</span> patience        self<span class="token punctuation">.</span>verbose <span class="token operator">=</span> verbose        self<span class="token punctuation">.</span>counter <span class="token operator">=</span> <span class="token number">0</span>        self<span class="token punctuation">.</span>best_score <span class="token operator">=</span> None        self<span class="token punctuation">.</span>early_stop <span class="token operator">=</span> <span class="token boolean">False</span>        self<span class="token punctuation">.</span>val_loss_min <span class="token operator">=</span> np<span class="token punctuation">.</span>Inf        self<span class="token punctuation">.</span>delta <span class="token operator">=</span> delta            <span class="token keyword">def</span> <span class="token function">__call__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> val_loss<span class="token punctuation">,</span> model<span class="token punctuation">,</span> path<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"val_loss={}"</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>val_loss<span class="token punctuation">)</span><span class="token punctuation">)</span>        score <span class="token operator">=</span> <span class="token operator">-</span>val_loss        <span class="token keyword">if</span> self<span class="token punctuation">.</span>best_score <span class="token keyword">is</span> None<span class="token punctuation">:</span>            self<span class="token punctuation">.</span>best_score <span class="token operator">=</span> score            self<span class="token punctuation">.</span>save_checkpoint<span class="token punctuation">(</span>val_loss<span class="token punctuation">,</span> model<span class="token punctuation">,</span>path<span class="token punctuation">)</span>        <span class="token keyword">elif</span> score <span class="token operator">&lt;</span> self<span class="token punctuation">.</span>best_score<span class="token operator">+</span>self<span class="token punctuation">.</span>delta<span class="token punctuation">:</span>            self<span class="token punctuation">.</span>counter<span class="token operator">+=</span><span class="token number">1</span>            <span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">'EarlyStopping counter: {self.counter} out of {self.patience}'</span><span class="token punctuation">)</span>            <span class="token keyword">if</span> self<span class="token punctuation">.</span>counter<span class="token operator">>=</span>self<span class="token punctuation">.</span>patience<span class="token punctuation">:</span>                self<span class="token punctuation">.</span>early_stop <span class="token operator">=</span> <span class="token boolean">True</span>        <span class="token keyword">else</span><span class="token punctuation">:</span>            self<span class="token punctuation">.</span>best_score <span class="token operator">=</span> score            self<span class="token punctuation">.</span>save_checkpoint<span class="token punctuation">(</span>val_loss<span class="token punctuation">,</span> model<span class="token punctuation">,</span>path<span class="token punctuation">)</span>            self<span class="token punctuation">.</span>counter <span class="token operator">=</span> <span class="token number">0</span>                <span class="token keyword">def</span> <span class="token function">save_checkpoint</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> val_loss<span class="token punctuation">,</span>model<span class="token punctuation">,</span> path<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">if</span> self<span class="token punctuation">.</span>verbose<span class="token punctuation">:</span>            <span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...'</span><span class="token punctuation">)</span>        torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>model<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> path<span class="token operator">+</span><span class="token string">'/'</span><span class="token operator">+</span><span class="token string">'model_checkpoint.pth'</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>val_loss_min <span class="token operator">=</span> val_loss<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="定义数据集Dataset-DataLoader"><a href="#定义数据集Dataset-DataLoader" class="headerlink" title="定义数据集Dataset,DataLoader"></a>定义数据集Dataset,DataLoader</h2><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Dataset_name</span><span class="token punctuation">(</span>Dataset<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> flag<span class="token operator">=</span><span class="token string">'train'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">assert</span> flag <span class="token keyword">in</span> <span class="token punctuation">[</span><span class="token string">'train'</span><span class="token punctuation">,</span> <span class="token string">'test'</span><span class="token punctuation">,</span> <span class="token string">'valid'</span><span class="token punctuation">]</span>        self<span class="token punctuation">.</span>flag <span class="token operator">=</span> flag        self<span class="token punctuation">.</span>__load_data__<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">__getitem__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> index<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">pass</span>    <span class="token keyword">def</span> <span class="token function">__len__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">pass</span>    <span class="token keyword">def</span> <span class="token function">__load_data__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> csv_paths<span class="token punctuation">:</span> list<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">pass</span>        <span class="token keyword">print</span><span class="token punctuation">(</span>            <span class="token string">"train_X.shape:{}\ntrain_Y.shape:{}\nvalid_X.shape:{}\nvalid_Y.shape:{}\n"</span>            <span class="token punctuation">.</span>format<span class="token punctuation">(</span>self<span class="token punctuation">.</span>train_X<span class="token punctuation">.</span>shape<span class="token punctuation">,</span> self<span class="token punctuation">.</span>train_Y<span class="token punctuation">.</span>shape<span class="token punctuation">,</span> self<span class="token punctuation">.</span>valid_X<span class="token punctuation">.</span>shape<span class="token punctuation">,</span> self<span class="token punctuation">.</span>valid_Y<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token punctuation">)</span>train_dataset <span class="token operator">=</span> Dataset_name<span class="token punctuation">(</span>flag<span class="token operator">=</span><span class="token string">'train'</span><span class="token punctuation">)</span>train_dataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>dataset<span class="token operator">=</span>train_dataset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>valid_dataset <span class="token operator">=</span> Dataset_name<span class="token punctuation">(</span>flag<span class="token operator">=</span><span class="token string">'valid'</span><span class="token punctuation">)</span>valid_dataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>dataset<span class="token operator">=</span>valid_dataset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="实例化模型，设置loss，优化器等"><a href="#实例化模型，设置loss，优化器等" class="headerlink" title="实例化模型，设置loss，优化器等"></a>实例化模型，设置loss，优化器等</h2><pre class="line-numbers language-python"><code class="language-python">model <span class="token operator">=</span> Your_model<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>args<span class="token punctuation">.</span>device<span class="token punctuation">)</span>criterion <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>MSELoss<span class="token punctuation">(</span><span class="token punctuation">)</span>optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>Your_model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>args<span class="token punctuation">.</span>learning_rate<span class="token punctuation">)</span>train_loss <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>valid_loss <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>train_epochs_loss <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>valid_epochs_loss <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>early_stopping <span class="token operator">=</span> EarlyStopping<span class="token punctuation">(</span>patience<span class="token operator">=</span>args<span class="token punctuation">.</span>patience<span class="token punctuation">,</span> verbose<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="开始训练以及调整lr"><a href="#开始训练以及调整lr" class="headerlink" title="开始训练以及调整lr"></a>开始训练以及调整lr</h2><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">for</span> epoch <span class="token keyword">in</span> range<span class="token punctuation">(</span>args<span class="token punctuation">.</span>epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>    Your_model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>    train_epoch_loss <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    <span class="token keyword">for</span> idx<span class="token punctuation">,</span><span class="token punctuation">(</span>data_x<span class="token punctuation">,</span>data_y<span class="token punctuation">)</span> <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>train_dataloader<span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        data_x <span class="token operator">=</span> data_x<span class="token punctuation">.</span>to<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>args<span class="token punctuation">.</span>device<span class="token punctuation">)</span>        data_y <span class="token operator">=</span> data_y<span class="token punctuation">.</span>to<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>args<span class="token punctuation">.</span>device<span class="token punctuation">)</span>                outputs <span class="token operator">=</span> Your_model<span class="token punctuation">(</span>data_x<span class="token punctuation">)</span>                optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>        loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>data_y<span class="token punctuation">,</span> outputs<span class="token punctuation">)</span>        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>                train_epoch_loss<span class="token punctuation">.</span>append<span class="token punctuation">(</span>loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        train_loss<span class="token punctuation">.</span>append<span class="token punctuation">(</span>loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">if</span> idx<span class="token operator">%</span><span class="token punctuation">(</span>len<span class="token punctuation">(</span>train_dataloader<span class="token punctuation">)</span><span class="token operator">//</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token operator">==</span><span class="token number">0</span><span class="token punctuation">:</span>            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"epoch={}/{},{}/{}of train, loss={}"</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>                epoch<span class="token punctuation">,</span> args<span class="token punctuation">.</span>epochs<span class="token punctuation">,</span> idx<span class="token punctuation">,</span> len<span class="token punctuation">(</span>train_dataloader<span class="token punctuation">)</span><span class="token punctuation">,</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    train_epochs_loss<span class="token punctuation">.</span>append<span class="token punctuation">(</span>np<span class="token punctuation">.</span>average<span class="token punctuation">(</span>train_epoch_loss<span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">#=====================valid============================</span>    Your_model<span class="token punctuation">.</span>eval<span class="token punctuation">(</span><span class="token punctuation">)</span>    valid_epoch_loss <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    <span class="token keyword">for</span> idx<span class="token punctuation">,</span><span class="token punctuation">(</span>data_x<span class="token punctuation">,</span>data_y<span class="token punctuation">)</span> <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>valid_dataloader<span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        data_x <span class="token operator">=</span> data_x<span class="token punctuation">.</span>to<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>args<span class="token punctuation">.</span>device<span class="token punctuation">)</span>        data_y <span class="token operator">=</span> data_y<span class="token punctuation">.</span>to<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>args<span class="token punctuation">.</span>device<span class="token punctuation">)</span>        outputs <span class="token operator">=</span> Your_model<span class="token punctuation">(</span>data_x<span class="token punctuation">)</span>        loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span>data_y<span class="token punctuation">)</span>        valid_epoch_loss<span class="token punctuation">.</span>append<span class="token punctuation">(</span>loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        valid_loss<span class="token punctuation">.</span>append<span class="token punctuation">(</span>loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    valid_epochs_loss<span class="token punctuation">.</span>append<span class="token punctuation">(</span>np<span class="token punctuation">.</span>average<span class="token punctuation">(</span>valid_epoch_loss<span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">#==================early stopping======================</span>    early_stopping<span class="token punctuation">(</span>valid_epochs_loss<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> model<span class="token operator">=</span>Your_model<span class="token punctuation">,</span> path<span class="token operator">=</span>r<span class="token string">'c:\\your_model_to_save'</span><span class="token punctuation">)</span>    <span class="token keyword">if</span> early_stopping<span class="token punctuation">.</span>early_stop<span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Early stopping"</span><span class="token punctuation">)</span>        <span class="token keyword">break</span>            <span class="token comment" spellcheck="true">#====================adjust lr========================</span>    lr_adjust <span class="token operator">=</span> <span class="token punctuation">{</span>            <span class="token number">2</span><span class="token punctuation">:</span> <span class="token number">5e</span><span class="token operator">-</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">:</span> <span class="token number">1e</span><span class="token operator">-</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">:</span> <span class="token number">5e</span><span class="token operator">-</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">:</span> <span class="token number">1e</span><span class="token operator">-</span><span class="token number">6</span><span class="token punctuation">,</span>            <span class="token number">10</span><span class="token punctuation">:</span> <span class="token number">5e</span><span class="token operator">-</span><span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">15</span><span class="token punctuation">:</span> <span class="token number">1e</span><span class="token operator">-</span><span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">:</span> <span class="token number">5e</span><span class="token operator">-</span><span class="token number">8</span>        <span class="token punctuation">}</span>    <span class="token keyword">if</span> epoch <span class="token keyword">in</span> lr_adjust<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        lr <span class="token operator">=</span> lr_adjust<span class="token punctuation">[</span>epoch<span class="token punctuation">]</span>        <span class="token keyword">for</span> param_group <span class="token keyword">in</span> optimizer<span class="token punctuation">.</span>param_groups<span class="token punctuation">:</span>            param_group<span class="token punctuation">[</span><span class="token string">'lr'</span><span class="token punctuation">]</span> <span class="token operator">=</span> lr        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Updating learning rate to {}'</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>lr<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="绘图"><a href="#绘图" class="headerlink" title="绘图"></a>绘图</h2><pre class="line-numbers language-python"><code class="language-python">plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">12</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">121</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>train_loss<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">"train_loss"</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">122</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>train_epochs_loss<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token string">'-o'</span><span class="token punctuation">,</span>label<span class="token operator">=</span><span class="token string">"train_loss"</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>valid_epochs_loss<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token string">'-o'</span><span class="token punctuation">,</span>label<span class="token operator">=</span><span class="token string">"valid_loss"</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">"epochs_loss"</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="预测"><a href="#预测" class="headerlink" title="预测"></a>预测</h2><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 此处可定义一个预测集的Dataloader。也可以直接将你的预测数据reshape,添加batch_size=1</span>Your_model<span class="token punctuation">.</span>eval<span class="token punctuation">(</span><span class="token punctuation">)</span>predict <span class="token operator">=</span> Your_model<span class="token punctuation">(</span>data<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> Pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Pytorch </tag>
            
            <tag> 代码模板 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Pytorch保存和加载模型&amp;断点训练</title>
      <link href="/2023/03/23/pytorch-ji-chu-zhi-shi/bao-cun-he-jia-zai-mo-xing-duan-dian-ji-xu-xun-lian/"/>
      <url>/2023/03/23/pytorch-ji-chu-zhi-shi/bao-cun-he-jia-zai-mo-xing-duan-dian-ji-xu-xun-lian/</url>
      
        <content type="html"><![CDATA[<h1 id="Pytorch模型保存和加载"><a href="#Pytorch模型保存和加载" class="headerlink" title="Pytorch模型保存和加载"></a>Pytorch模型保存和加载</h1><p>Pytorch保存和加载模型需要掌握3个重要的函数：</p><ol><li><strong>torch.save：</strong> 将一个序列化的对象保存到磁盘。这个函数使用 Python 的 pickle 工具进行序列化。用这个函数可以保存<strong>模型 (model)<strong>、</strong>张量 (tensor)</strong> 和<strong>各种对象的字典 (dict)</strong> 。</li><li><strong>torch.load：</strong> 将 pickle 对象文件反序列化到内存，也便于将数据加载到设备中。</li><li><strong>torch.nn.Module.load_state_dict()：</strong> 加载模型的参数。</li></ol><h2 id="state-dict"><a href="#state-dict" class="headerlink" title="state_dict"></a>state_dict</h2><h3 id="state-dict-介绍"><a href="#state-dict-介绍" class="headerlink" title="state_dict 介绍"></a>state_dict 介绍</h3><p>PyTorch 中，<code>torch.nn.Module</code>里面的可学习的参数 (weights 和 biases) 都放在<code>model.parameters()</code>里面。而<code>state_dict</code>是一个Python dictionary object，将每一层映射到它的 parameter tensor 上。<br><strong>注意</strong>：只有含有可学习参数的层 (convolutional layers, linear layers)，或者含有<code>registered buffers</code>的层 (batchnorm’s running_mean) 才有 state_dict。优化器的对象 (torch.optim) 也有 state_dict，存储了优化器的状态和它的超参数。<br>因为<code>state_dict</code>是一个 Python字典对象，所以保存，加载，更新它比较容易。<br>下面我们通过一个例子直观感受下 state_dict 的用法：</p><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># Define model</span><span class="token keyword">class</span> <span class="token class-name">TheModelClass</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>TheModelClass<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>pool <span class="token operator">=</span> nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>conv2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>fc1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">16</span> <span class="token operator">*</span> <span class="token number">5</span> <span class="token operator">*</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">120</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>fc2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">120</span><span class="token punctuation">,</span> <span class="token number">84</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>fc3 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">84</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>pool<span class="token punctuation">(</span>F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>pool<span class="token punctuation">(</span>F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv2<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">16</span> <span class="token operator">*</span> <span class="token number">5</span> <span class="token operator">*</span> <span class="token number">5</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>fc1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>fc2<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>fc3<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">return</span> x<span class="token comment" spellcheck="true"># Initialize model</span>model <span class="token operator">=</span> TheModelClass<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># Initialize optimizer</span>optimizer <span class="token operator">=</span> optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.001</span><span class="token punctuation">,</span> momentum<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># Print model's state_dict</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Model's state_dict:"</span><span class="token punctuation">)</span><span class="token keyword">for</span> param_tensor <span class="token keyword">in</span> model<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>param_tensor<span class="token punctuation">,</span> <span class="token string">"\t"</span><span class="token punctuation">,</span> model<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span>param_tensor<span class="token punctuation">]</span><span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># Print optimizer's state_dict</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Optimizer's state_dict:"</span><span class="token punctuation">)</span><span class="token keyword">for</span> var_name <span class="token keyword">in</span> optimizer<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>var_name<span class="token punctuation">,</span> <span class="token string">"\t"</span><span class="token punctuation">,</span> optimizer<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span>var_name<span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>输出</p><pre class="line-numbers language-python"><code class="language-python">Model's state_dict<span class="token punctuation">:</span>conv1<span class="token punctuation">.</span>weight     torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">)</span>conv1<span class="token punctuation">.</span>bias   torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">)</span>conv2<span class="token punctuation">.</span>weight     torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">)</span>conv2<span class="token punctuation">.</span>bias   torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">16</span><span class="token punctuation">]</span><span class="token punctuation">)</span>fc1<span class="token punctuation">.</span>weight   torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">120</span><span class="token punctuation">,</span> <span class="token number">400</span><span class="token punctuation">]</span><span class="token punctuation">)</span>fc1<span class="token punctuation">.</span>bias     torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">120</span><span class="token punctuation">]</span><span class="token punctuation">)</span>fc2<span class="token punctuation">.</span>weight   torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">84</span><span class="token punctuation">,</span> <span class="token number">120</span><span class="token punctuation">]</span><span class="token punctuation">)</span>fc2<span class="token punctuation">.</span>bias     torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">84</span><span class="token punctuation">]</span><span class="token punctuation">)</span>fc3<span class="token punctuation">.</span>weight   torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">84</span><span class="token punctuation">]</span><span class="token punctuation">)</span>fc3<span class="token punctuation">.</span>bias     torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">)</span>Optimizer's state_dict<span class="token punctuation">:</span>state    <span class="token punctuation">{</span><span class="token punctuation">}</span>param_groups     <span class="token punctuation">[</span><span class="token punctuation">{</span><span class="token string">'lr'</span><span class="token punctuation">:</span> <span class="token number">0.001</span><span class="token punctuation">,</span> <span class="token string">'momentum'</span><span class="token punctuation">:</span> <span class="token number">0.9</span><span class="token punctuation">,</span> <span class="token string">'dampening'</span><span class="token punctuation">:</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token string">'weight_decay'</span><span class="token punctuation">:</span> <span class="token number">0</span><span class="token punctuation">,</span>                    <span class="token string">'nesterov'</span><span class="token punctuation">:</span> <span class="token boolean">False</span><span class="token punctuation">,</span> <span class="token string">'params'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">4675713712</span><span class="token punctuation">,</span> <span class="token number">4675713784</span><span class="token punctuation">,</span> <span class="token number">4675714000</span><span class="token punctuation">,</span>                                                  <span class="token number">4675714072</span><span class="token punctuation">,</span> <span class="token number">4675714216</span><span class="token punctuation">,</span> <span class="token number">4675714288</span><span class="token punctuation">,</span>                                                  <span class="token number">4675714432</span><span class="token punctuation">,</span> <span class="token number">4675714504</span><span class="token punctuation">,</span> <span class="token number">4675714648</span><span class="token punctuation">,</span>                                                  <span class="token number">4675714720</span><span class="token punctuation">]</span><span class="token punctuation">}</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="保存和加载模型"><a href="#保存和加载模型" class="headerlink" title="保存和加载模型"></a>保存和加载模型</h2><h3 id="保存和加载-state-dict-已经训练完，无需继续训练"><a href="#保存和加载-state-dict-已经训练完，无需继续训练" class="headerlink" title="保存和加载 state_dict (已经训练完，无需继续训练)"></a>保存和加载 state_dict (已经训练完，无需继续训练)</h3><p>保存</p><pre class="line-numbers language-python"><code class="language-python">torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>model<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> PATH<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>加载</p><pre class="line-numbers language-python"><code class="language-python">model <span class="token operator">=</span> TheModelClass<span class="token punctuation">(</span><span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span>model<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>PATH<span class="token punctuation">)</span><span class="token punctuation">)</span>model<span class="token punctuation">.</span>eval<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>一般保存为<code>.pt</code>或<code>.pth</code>格式的文件。<br>注意：</p><ol><li>可以使用<code>model.eval()</code>将 dropout 和 batch normalization 层设置成 evaluation 模式。</li><li><code>load_state_dict()</code>函数需要一个<strong>dict类型</strong>的输入，而不是保存模型的PATH。</li><li>如果你想<strong>保存验证集上表现最好的模型</strong>，那么这样<code>best_model_state=model.state_dict()</code>是错误的。因为这属于浅复制，也就是说此时这个best_model_state会随着后续的训练过程而不断被更新，最后保存的其实是个 overfit 的模型。所以正确的做法应该是<code>best_model_state=deepcopy(model.state_dict())</code>。</li></ol><h3 id="保存和加载整个模型-已经训练完，无需继续训练"><a href="#保存和加载整个模型-已经训练完，无需继续训练" class="headerlink" title="保存和加载整个模型 (已经训练完，无需继续训练)"></a>保存和加载整个模型 (已经训练完，无需继续训练)</h3><p>保存</p><pre class="line-numbers language-python"><code class="language-python">torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>model<span class="token punctuation">,</span> PATH<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>加载。注意：<strong>必须提前定义好模型的类</strong>。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># Model class must be defined somewhere</span>model <span class="token operator">=</span> torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>PATH<span class="token punctuation">)</span>model<span class="token punctuation">.</span>eval<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>一般保存为<code>.pt</code>或<code>.pth</code>格式的文件。</p><h3 id="保存和加载-state-dict-没有训练完，还会继续训练"><a href="#保存和加载-state-dict-没有训练完，还会继续训练" class="headerlink" title="保存和加载 state_dict (没有训练完，还会继续训练)"></a>保存和加载 state_dict (没有训练完，还会继续训练)</h3><p>保存。除了保存 model_state_dict 之外，还需要保存：optimizer_state_dict，epoch 和 loss，因为继续训练时要知道优化器的状态，epoch 等等。</p><pre class="line-numbers language-python"><code class="language-python">torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span><span class="token punctuation">{</span>            <span class="token string">'epoch'</span><span class="token punctuation">:</span> epoch<span class="token punctuation">,</span>            <span class="token string">'model_state_dict'</span><span class="token punctuation">:</span> model<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            <span class="token string">'optimizer_state_dict'</span><span class="token punctuation">:</span> optimizer<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            <span class="token string">'loss'</span><span class="token punctuation">:</span> loss<span class="token punctuation">,</span>            <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>            <span class="token punctuation">}</span><span class="token punctuation">,</span> PATH<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>加载。除了加载 model_state_dict 之外，还需要加载：optimizer_state_dict，epoch 和 loss。</p><pre class="line-numbers language-python"><code class="language-python">model <span class="token operator">=</span> TheModelClass<span class="token punctuation">(</span><span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span>optimizer <span class="token operator">=</span> TheOptimizerClass<span class="token punctuation">(</span><span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span>checkpoint <span class="token operator">=</span> torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>PATH<span class="token punctuation">)</span>model<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>checkpoint<span class="token punctuation">[</span><span class="token string">'model_state_dict'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>optimizer<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>checkpoint<span class="token punctuation">[</span><span class="token string">'optimizer_state_dict'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>epoch <span class="token operator">=</span> checkpoint<span class="token punctuation">[</span><span class="token string">'epoch'</span><span class="token punctuation">]</span>loss <span class="token operator">=</span> checkpoint<span class="token punctuation">[</span><span class="token string">'loss'</span><span class="token punctuation">]</span>model<span class="token punctuation">.</span>eval<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># - or -</span>model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="把多个模型存进一个文件"><a href="#把多个模型存进一个文件" class="headerlink" title="把多个模型存进一个文件"></a>把多个模型存进一个文件</h3><p>保存：把模型 A 和 B 的 state_dict 和 optimizer 都存进一个文件中。</p><pre class="line-numbers language-python"><code class="language-python">torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span><span class="token punctuation">{</span>            <span class="token string">'modelA_state_dict'</span><span class="token punctuation">:</span> modelA<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            <span class="token string">'modelB_state_dict'</span><span class="token punctuation">:</span> modelB<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            <span class="token string">'optimizerA_state_dict'</span><span class="token punctuation">:</span> optimizerA<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            <span class="token string">'optimizerB_state_dict'</span><span class="token punctuation">:</span> optimizerB<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>            <span class="token punctuation">}</span><span class="token punctuation">,</span> PATH<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>加载：</p><pre class="line-numbers language-python"><code class="language-python">modelA <span class="token operator">=</span> TheModelAClass<span class="token punctuation">(</span><span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span>modelB <span class="token operator">=</span> TheModelBClass<span class="token punctuation">(</span><span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span>optimizerA <span class="token operator">=</span> TheOptimizerAClass<span class="token punctuation">(</span><span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span>optimizerB <span class="token operator">=</span> TheOptimizerBClass<span class="token punctuation">(</span><span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span>checkpoint <span class="token operator">=</span> torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>PATH<span class="token punctuation">)</span>modelA<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>checkpoint<span class="token punctuation">[</span><span class="token string">'modelA_state_dict'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>modelB<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>checkpoint<span class="token punctuation">[</span><span class="token string">'modelB_state_dict'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>optimizerA<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>checkpoint<span class="token punctuation">[</span><span class="token string">'optimizerA_state_dict'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>optimizerB<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>checkpoint<span class="token punctuation">[</span><span class="token string">'optimizerB_state_dict'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>modelA<span class="token punctuation">.</span>eval<span class="token punctuation">(</span><span class="token punctuation">)</span>modelB<span class="token punctuation">.</span>eval<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># - or -</span>modelA<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>modelB<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h2><h3 id="使用其他模型的参数暖启动自己的模型"><a href="#使用其他模型的参数暖启动自己的模型" class="headerlink" title="使用其他模型的参数暖启动自己的模型"></a>使用其他模型的参数暖启动自己的模型</h3><p>有时候训练一个新的复杂模型时，需要加载它的一部分预训练的权重。即使只有几个可用的参数，也会有助于 warmstart 训练过程，帮助模型更快达到收敛。<br>如果手里有的这个 state_dict 缺乏一些 keys，或者多了一些 keys，只要设置<code>strict</code>参数为 False，就能够把 state_dict 能够匹配的 keys 加载进去，而忽略掉那些不匹配的 keys。<br>保存模型 A 的 state_dict ：</p><pre class="line-numbers language-python"><code class="language-python">torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>modelA<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> PATH<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>加载到模型 B：</p><pre class="line-numbers language-python"><code class="language-python">modelB <span class="token operator">=</span> TheModelBClass<span class="token punctuation">(</span><span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span>modelB<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>PATH<span class="token punctuation">)</span><span class="token punctuation">,</span> strict<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h3 id="不同设备（CPU-GPU）上保存和加载"><a href="#不同设备（CPU-GPU）上保存和加载" class="headerlink" title="不同设备（CPU&#x2F;GPU）上保存和加载"></a>不同设备（CPU&#x2F;GPU）上保存和加载</h3><p>不同设备的保存和加载需要在<code>load()</code>函数中引入一个参数<code>map_location</code>来指定需要将不同设备上保存的模型映射到同一个设备上。如果保存模型和加载模型的是<strong>相同</strong>的设备：CPU-&gt;CPU，GPU-&gt;GPU。则加载模型时可不使用<code>map_location</code>参数。如果保存模型和加载模型的是<strong>不同</strong>的设备：CPU-&gt;GPU，GPU-&gt;CPU。则加载模型时必须使用<code>map_location</code>参数。<br>上述的两种情况下，如果加载的设备是GPU，还需要使用<code>model.to(device)</code>将模型的参数张量转化为CUDA张量。<br>从CPU加载到GPU：</p><pre class="line-numbers language-python"><code class="language-python">torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>model<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> PATH<span class="token punctuation">)</span>device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">"cuda"</span><span class="token punctuation">)</span>model <span class="token operator">=</span> TheModelClass<span class="token punctuation">(</span><span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span>model<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>PATH<span class="token punctuation">,</span> map_location<span class="token operator">=</span><span class="token string">"cuda"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  model<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>从GPU加载到CPU：</p><pre class="line-numbers language-python"><code class="language-python">torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>model<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> PATH<span class="token punctuation">)</span>device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">'cpu'</span><span class="token punctuation">)</span>model <span class="token operator">=</span> TheModelClass<span class="token punctuation">(</span><span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span>model<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>PATH<span class="token punctuation">,</span> map_location<span class="token operator">=</span>device<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="断点继续训练"><a href="#断点继续训练" class="headerlink" title="断点继续训练"></a>断点继续训练</h2><p>将网络训练过程中的网络的权重，优化器的权重保存，以及epoch 保存，便于继续训练恢复。如果使用了学习率衰减，在保存网络中的训练的参数的过程中，还需要保存lr_scheduler的state_dict，然后断点继续训练的时候恢复。</p><pre class="line-numbers language-python"><code class="language-python">checkpoint <span class="token operator">=</span> <span class="token punctuation">{</span>    <span class="token string">"net"</span><span class="token punctuation">:</span> model<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    <span class="token string">'optimizer'</span><span class="token punctuation">:</span> optimizer<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    <span class="token string">"epoch"</span><span class="token punctuation">:</span> epoch<span class="token punctuation">,</span>    <span class="token string">'lr_schedule'</span><span class="token punctuation">:</span> lr_schedule<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token keyword">if</span> <span class="token operator">not</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>isdir<span class="token punctuation">(</span><span class="token string">"./model_parameter/test"</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    os<span class="token punctuation">.</span>mkdir<span class="token punctuation">(</span><span class="token string">"./model_parameter/test"</span><span class="token punctuation">)</span>torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>checkpoint<span class="token punctuation">,</span> <span class="token string">'./model_parameter/test/ckpt_best_%s.pth'</span> <span class="token operator">%</span> <span class="token punctuation">(</span>str<span class="token punctuation">(</span>epoch<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>加载恢复训练参数</p><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true">#加载恢复</span><span class="token keyword">if</span> RESUME<span class="token punctuation">:</span>    path_checkpoint <span class="token operator">=</span> <span class="token string">"./model_parameter/test/ckpt_best_50.pth"</span>  <span class="token comment" spellcheck="true"># 断点路径</span>    checkpoint <span class="token operator">=</span> torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>path_checkpoint<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 加载断点</span>    model<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>checkpoint<span class="token punctuation">[</span><span class="token string">'net'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 加载模型可学习参数</span>    optimizer<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>checkpoint<span class="token punctuation">[</span><span class="token string">'optimizer'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 加载优化器参数</span>    start_epoch <span class="token operator">=</span> checkpoint<span class="token punctuation">[</span><span class="token string">'epoch'</span><span class="token punctuation">]</span>  <span class="token comment" spellcheck="true"># 设置开始的epoch</span>    lr_schedule<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>checkpoint<span class="token punctuation">[</span><span class="token string">'lr_schedule'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#加载lr_scheduler</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> Pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Pytorch </tag>
            
            <tag> 代码模板 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Pytorch中的学习率衰减</title>
      <link href="/2023/02/21/pytorch-ji-chu-zhi-shi/xue-xi-lu-shuai-jian/"/>
      <url>/2023/02/21/pytorch-ji-chu-zhi-shi/xue-xi-lu-shuai-jian/</url>
      
        <content type="html"><![CDATA[<h1 id="学习率衰减原理"><a href="#学习率衰减原理" class="headerlink" title="学习率衰减原理"></a>学习率衰减原理</h1><p>在梯度下降算法中，学习率用来控制权重更新的步幅。学习率越大，则权重更新的步子迈得大一些，学习率越小，则权重更新的步子迈得小一些。<br>$w&#x3D;w- \alpha * \frac{\partial Loss}{\partial w}$<br>如果在训练过程中，学习率保持不变，则可能会出现下面两种情况。</p><ul><li><p>左侧是学习率较小的情况，这时权重更新步幅小，导致模型收敛很慢。</p></li><li><p>右侧是学习率较大的情况，这时权重更新步幅大，模型刚开始收敛很快，但是最终在接近目标函数极值时由于步子迈的太大，会越过极值的位置，导致模型在目标函数的极值两侧来回震荡，不能收敛到最优解。</p></li></ul><p><img src="/images/lr1.png"><img src="/images/lr3.png"><br>最好的状态是在训练初期学习率设置大一些，使模型收敛得快一些，训练后期学习率设置小一些，使模型能收敛到最优解。<br><img src="/images/lr2.png"><br>因此在训练时若模型的精度出现震荡或是Loss不再下降时，适当进行学习率衰减是一个有效的训练方法。Pytorch有两种学习率衰减的方法：</p><ol><li>一种是手动设置，</li><li>另一种使用<code>lr_scheduler()</code>提供的几种衰减函数进行设置。</li></ol><p>使用<code>lr_scheduler()</code>提供的函数进行设置时，方法都是类似的，如下面的代码模板。<code>decay_method()</code>方法就是<code>lr_scheduler()</code>提供的衰减函数。</p><pre class="line-numbers language-python"><code class="language-python">scheduler <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>lr_scheduler<span class="token punctuation">.</span>decay_method<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">for</span> epoch <span class="token keyword">in</span> range<span class="token punctuation">(</span>epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>    train<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span>    validate<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span>    scheduler<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="lr-scheduler-的学习率衰减策略"><a href="#lr-scheduler-的学习率衰减策略" class="headerlink" title="lr_scheduler()的学习率衰减策略"></a>lr_scheduler()的学习率衰减策略</h2><h3 id="等间隔调整学习率"><a href="#等间隔调整学习率" class="headerlink" title="等间隔调整学习率"></a>等间隔调整学习率</h3><pre class="line-numbers language-python"><code class="language-python">scheduler <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>lr_scheduler<span class="token punctuation">.</span>StepLR<span class="token punctuation">(</span>optimizer<span class="token punctuation">,</span> step_size<span class="token punctuation">,</span> gamma<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>该方法有3个参数：</p><ol><li>optimizer是优化器；</li><li>step_size表示间隔多少个epoch后调整学习率；</li><li>gamma表示学习率调整的倍数。</li></ol><p>该方法是每训练step_size个epoch，就将学习率调整为 lr<em>gamma。如下图step_size &#x3D; 10，gamma &#x3D; 0.8表示每间隔10个epoch将学习率调整为 lr</em>0.8。<br><img src="/images/step_LR.png"></p><h3 id="多间隔调整学习率"><a href="#多间隔调整学习率" class="headerlink" title="多间隔调整学习率"></a>多间隔调整学习率</h3><pre class="line-numbers language-python"><code class="language-python">scheduler <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>lr_scheduler<span class="token punctuation">.</span>MultiStepLR<span class="token punctuation">(</span>optimizer<span class="token punctuation">,</span> milestones<span class="token punctuation">,</span> gamma<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>该方法与StepLR()类似也是间隔调整学习率，但是<strong>间隔并不相等</strong>。它有3个参数：</p><ol><li>optimizer是优化器；</li><li>milestones是一个列表，列表中每个元素表示要调整学习率的epoch；</li><li>gamma表示学习率调整的倍数。</li></ol><p>如下图所示，milestones&#x3D; [10, 30, 90]，gamma &#x3D; 0.8表示在epoch &#x3D; 10、30、90时将学习率调整为 lr*0.8。<br><img src="/images/MultiStepLR.png"></p><h3 id="指数衰减调整学习率"><a href="#指数衰减调整学习率" class="headerlink" title="指数衰减调整学习率"></a>指数衰减调整学习率</h3><pre class="line-numbers language-python"><code class="language-python">scheduler <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>lr_scheduler<span class="token punctuation">.</span>ExponentialLR<span class="token punctuation">(</span>optimizer<span class="token punctuation">,</span> gamma<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>该方法与前两种不同，是<strong>每个epoch都调整学习率</strong>，学习率调整为<br>$lr* gamma^{epoch}$。<br>它有两个参数：</p><ol><li>optimizer是优化器；</li><li>gamma是调整学习率的底数，指数为epoch。</li></ol><p>如下图，gamma &#x3D; 0.8。<br><img src="/images/ELR.png"></p><h3 id="余弦退火函数调整学习率"><a href="#余弦退火函数调整学习率" class="headerlink" title="余弦退火函数调整学习率"></a>余弦退火函数调整学习率</h3><pre class="line-numbers language-python"><code class="language-python">scheduler <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>lr_scheduler<span class="token punctuation">.</span>CosineAnnealingLR<span class="token punctuation">(</span>optimizer<span class="token punctuation">,</span> T_max<span class="token punctuation">,</span> eta_min<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>该方法使得<strong>学习率呈Cos型衰减</strong>，T_max表示0.5个余弦函数周期，也<strong>表示学习率调整为最小时的epoch数值，eta_min表示学习率调整的最小值</strong>，默认为0。如下所示，T_max &#x3D; 100, eta_min&#x3D;0表示学习率呈Cos衰减，在epoch &#x3D; 100时学习率降到最低，即学习率降到0。<br><img src="/images/Cos.png"></p><h3 id="根据指标调整学习率"><a href="#根据指标调整学习率" class="headerlink" title="根据指标调整学习率"></a>根据指标调整学习率</h3><pre class="line-numbers language-python"><code class="language-python">scheduler <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>lr_sheduler<span class="token punctuation">.</span>ReduceLROnPlateau<span class="token punctuation">(</span>optimizer<span class="token punctuation">,</span> mode<span class="token operator">=</span><span class="token string">'min'</span><span class="token punctuation">,</span> factor<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">,</span>                     patience<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> verbose<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> threshold<span class="token operator">=</span><span class="token number">0.0001</span><span class="token punctuation">,</span> threshold_mode<span class="token operator">=</span><span class="token string">'rel'</span><span class="token punctuation">,</span>                     cooldown<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> min_lr<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> eps<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">08</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>该方法<strong>根据监测指标来调整学习率，如训练过程中监测Loss不再降低或是监测Acc不再上升，则调整学习率。</strong>它有如下参数：</p><ol><li><strong>mod</strong>是模式选择，其参数有两种值”min”和”max”，min表示监测指标不再降低就调整学习率，”max”表示检测指标不再上升就调整学习率。</li><li><strong>factor</strong>表示学习率调整的倍数，学习率会调整为lr*factor。</li><li><strong>patience</strong>表示监测指标经过多少个epoch没有降低或上升了，其含义是经过patience个epoch，监测指标仍然没有变化，则调整学习率。</li><li><strong>verbose</strong>表示是否打印学习率。</li><li><strong>cooldown</strong>表示调整过一次学习率后，等待一定的epoch再进行监测。</li><li><strong>min_lr</strong>表示学习率的最小值。</li><li><strong>eps</strong>表示学习率的最小变化，若新旧学习率之间的差值小于1e-8则学习率不变。</li></ol><h3 id="自定义调整学习率"><a href="#自定义调整学习率" class="headerlink" title="自定义调整学习率"></a>自定义调整学习率</h3><pre class="line-numbers language-python"><code class="language-python">scheduler <span class="token operator">=</span> lr_scheduler<span class="token punctuation">.</span>LambdaLR<span class="token punctuation">(</span>optimizer<span class="token punctuation">,</span> lr_lambda<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>该方法允许<strong>自定义学习率衰减函数</strong>，它是每个epoch调整一次学习率。<br>该方法的<code>lr_lambda</code>参数表示<strong>自定义的学习率调整函数</strong>，可以是自定义函数，也可以是lambda表达式，自定义的函数须要<strong>接收一个int参数：epoch</strong>，根据epoch定义出学习率的调整倍数。学习率调整为<br>$lr * LR_{lambda}(epoch)$<br>如下所示，自定义学习率调整函数：下面的函数是<strong>自定义的指数衰减</strong>，gamma &#x3D; 0.8。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">lr_decay</span><span class="token punctuation">(</span>epoch<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">return</span> <span class="token number">0.8</span><span class="token operator">**</span>epochscheduler <span class="token operator">=</span> lr_scheduler<span class="token punctuation">.</span>LambdaLR<span class="token punctuation">(</span>optimizer<span class="token punctuation">,</span>lr_lambda <span class="token operator">=</span> lr_decay<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>自定义lambda表达式：下面是<strong>自定义的等间隔学习率调整</strong>，间隔为10epoch。</p><pre class="line-numbers language-python"><code class="language-python">lambda1 <span class="token operator">=</span> <span class="token keyword">lambda</span> epoch<span class="token punctuation">:</span><span class="token punctuation">(</span><span class="token number">0.8</span> <span class="token operator">**</span> <span class="token punctuation">(</span>epoch <span class="token operator">//</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span>scheduler <span class="token operator">=</span> lr_scheduler<span class="token punctuation">.</span>LambdaLR<span class="token punctuation">(</span>optimizer<span class="token punctuation">,</span>lr_lambda <span class="token operator">=</span> lambda1<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h2 id="手动调整学习率"><a href="#手动调整学习率" class="headerlink" title="手动调整学习率"></a>手动调整学习率</h2><p>我们可以通过下面两种方式来访问模型中的学习率。optimizer通过<code>param_groups</code>来管理参数组，<code>param_groups</code>中保存了模型的参数组及其对应的学习率，通过<code>param_group[&#39;lr&#39;]</code>就可以访问到对应参数组的学习率。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 下面两种方式等价</span><span class="token keyword">print</span> <span class="token punctuation">(</span>optimizer<span class="token punctuation">.</span>param_groups<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'lr'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">print</span> <span class="token punctuation">(</span>optimizer<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token string">'param_groups'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'lr'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>所以<strong>通过</strong><code>**param_groups**</code><strong>来修改对应参数组的学习率</strong>。下面的代码是每10个epoch修改一次学习率，调整的学习率倍数为0.9。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">for</span> epoch <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">if</span> epoch <span class="token operator">%</span> <span class="token number">10</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>        <span class="token keyword">for</span> param_group <span class="token keyword">in</span> optimizer<span class="token punctuation">.</span>param_groups<span class="token punctuation">:</span>            param_group<span class="token punctuation">[</span><span class="token string">'lr'</span><span class="token punctuation">]</span> <span class="token operator">*=</span> <span class="token number">0.9</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>除了这种方式外，还可以<strong>通过重新定义优化器的方式修改学习率</strong>。下面的代码是每20个epoch修改一次学习率，调整的学习率倍数为0.8。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">lr_decay</span><span class="token punctuation">(</span>lr<span class="token punctuation">,</span> epoch<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">return</span> lr<span class="token operator">*</span><span class="token punctuation">(</span><span class="token number">0.8</span> <span class="token operator">**</span> <span class="token punctuation">(</span>epoch <span class="token operator">//</span> <span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">for</span> epoch <span class="token keyword">in</span> range<span class="token punctuation">(</span>epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment" spellcheck="true"># 调整学习率</span>    lr <span class="token operator">=</span> lr_decay<span class="token punctuation">(</span>lr<span class="token punctuation">,</span> epoch<span class="token punctuation">)</span>      optimizer <span class="token operator">=</span> optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>lr<span class="token punctuation">)</span>    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>    <span class="token comment" spellcheck="true"># 采用新的学习率进行参数更新</span>    optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>      <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> Pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Pytorch </tag>
            
            <tag> 代码模板 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Python的@staticmethod和@classmethod</title>
      <link href="/2023/02/17/python-zhi-shi/python-zhong-staticmethod-classmethod-fang-fa/"/>
      <url>/2023/02/17/python-zhi-shi/python-zhong-staticmethod-classmethod-fang-fa/</url>
      
        <content type="html"><![CDATA[<h1 id="Python中的类方法和静态方法"><a href="#Python中的类方法和静态方法" class="headerlink" title="Python中的类方法和静态方法"></a>Python中的类方法和静态方法</h1><p>一般来说，要使用某个类的方法，需要先实例化一个对象再调用方法。而使用<code>@staticmethod</code>或<code>@classmethod</code>，就可以不需要实例化，直接<code>类名.方法名()</code>来调用。<br>Python面向对象编程中，类中定义的方法可以是<code>@classmethod</code>装饰的<strong>类方法</strong>，也可以是<code>@staticmethod</code>装饰的<strong>静态方法</strong>，用的最多的还是不带装饰器的<strong>实例方法。</strong><br>先来看一个简单示例：</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">A</span><span class="token punctuation">(</span>object<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">def</span> <span class="token function">m1</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> n<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"self:"</span><span class="token punctuation">,</span> self<span class="token punctuation">)</span>    @classmethod    <span class="token keyword">def</span> <span class="token function">m2</span><span class="token punctuation">(</span>cls<span class="token punctuation">,</span> n<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"cls:"</span><span class="token punctuation">,</span> cls<span class="token punctuation">)</span>    @staticmethod    <span class="token keyword">def</span> <span class="token function">m3</span><span class="token punctuation">(</span>n<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">pass</span>a <span class="token operator">=</span> A<span class="token punctuation">(</span><span class="token punctuation">)</span>a<span class="token punctuation">.</span>m1<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># self: &lt;__main__.A object at 0x000001E596E41A90></span>A<span class="token punctuation">.</span>m2<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># cls: &lt;class '__main__.A'></span>A<span class="token punctuation">.</span>m3<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>在类中一共定义了3个方法，m1 是<strong>实例方法</strong>，第一个参数必须是<code>self</code>（约定俗成的）。m2 是<strong>类方法</strong>，第一个参数必须是<code>cls</code>（同样是约定俗成），m3 是<strong>静态方法</strong>，参数根据业务需求定，可有可无。<br>当程序运行时，大概发生了这么几件事（结合下面的图来看）：</p><ul><li>第一步：代码从第一行开始执行 class 命令，此时会创建一个类 A 对象（<mark>类也是对象</mark>，一切皆对象嘛）同时初始化类里面的属性和方法；记住，此刻实例对象还没创建出来。</li><li>第二、三步：接着执行 a&#x3D;A()，系统自动调用类的构造器，构造出实例对象 a。</li><li>第四步：接着调用<code>a.m1(1)</code>，m1 是实例方法，<strong>内部会自动把</strong><mark>实例对象</mark>传递给 self 参数进行绑定**，也就是说， self 和 a 指向的都是同一个实例对象。</li><li>第五步：调用A.m2(1)时，<strong>python内部隐式地把</strong><mark>类对象</mark><strong>传递给 cls 参数</strong>，cls 和 A 都指向类对象。</li></ul><p><img src="/images/python_class.png"><br>严格意义上来说，左边的都是变量名，是对象的引用，右边才是真正的对像</p><h2 id="几个方法的介绍和区别"><a href="#几个方法的介绍和区别" class="headerlink" title="几个方法的介绍和区别"></a>几个方法的介绍和区别</h2><h3 id="实例方法"><a href="#实例方法" class="headerlink" title="实例方法"></a>实例方法</h3><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">print</span><span class="token punctuation">(</span>A<span class="token punctuation">.</span>m1<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># A.m1在py2中显示为&lt;unbound method A.m1></span><span class="token operator">&lt;</span>function A<span class="token punctuation">.</span>m1 at <span class="token number">0x000002BF7FF9A488</span><span class="token operator">></span><span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token punctuation">.</span>m1<span class="token punctuation">)</span><span class="token operator">&lt;</span>bound method A<span class="token punctuation">.</span>m1 of <span class="token operator">&lt;</span>__main__<span class="token punctuation">.</span>A object at <span class="token number">0x000002BF7FFA2BE0</span><span class="token operator">>></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><code>A.m1</code>是一个还没有绑定实例对象的方法，对于未绑定方法，调用<code>A.m1</code>时必须显示地传入一个实例对象进去，而<code>a.m1</code>是已经绑定了实例的方法，python隐式地把对象传递给了self参数，所以不再手动传递参数，这是调用实例方法的过程。</p><pre class="line-numbers language-python"><code class="language-python">A<span class="token punctuation">.</span>m1<span class="token punctuation">(</span>a<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 等价于</span>a<span class="token punctuation">.</span>m1<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p><strong>如果未绑定的方法</strong><code>**A.m1**</code><strong>不传实例对象给 self 时，就会报参数缺失错误</strong></p><h3 id="类方法"><a href="#类方法" class="headerlink" title="类方法"></a>类方法</h3><p>m2是<strong>类方法</strong>，不管是<code>A.m2</code>还是<code>a.m2</code>，都是已经自动绑定了类对象A的方法，对于<code>a.m2</code>，因为python可以通过实例对象a找到它所属的类是A，找到A之后自动绑定到 cls。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">print</span><span class="token punctuation">(</span>A<span class="token punctuation">.</span>m2<span class="token punctuation">)</span><span class="token operator">&lt;</span>bound method A<span class="token punctuation">.</span>m2 of <span class="token operator">&lt;</span><span class="token keyword">class</span> <span class="token string">'__main__.A'</span><span class="token operator">>></span><span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token punctuation">.</span>m2<span class="token punctuation">)</span><span class="token operator">&lt;</span>bound method A<span class="token punctuation">.</span>m2 of <span class="token operator">&lt;</span><span class="token keyword">class</span> <span class="token string">'__main__.A'</span><span class="token operator">>></span>A<span class="token punctuation">.</span>m2<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 等价于</span>a<span class="token punctuation">.</span>m2<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>这使得我们可以在实例方法中通过使用<code>self.m2()</code>这种方式来调用类方法和静态方法。<br>类方法只能访问类变量，不能访问实例变量，也就是跟类有关，跟实例无关。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">m1</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> n<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"self:"</span><span class="token punctuation">,</span> self<span class="token punctuation">)</span>    self<span class="token punctuation">.</span>m2<span class="token punctuation">(</span>n<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h3 id="静态方法"><a href="#静态方法" class="headerlink" title="静态方法"></a>静态方法</h3><p>m3是类里面的一个<strong>静态方法</strong>，跟普通函数没什么区别，<strong>与类和实例都没有所谓的绑定关系</strong>，它只不过是碰巧存在类中的一个函数而已。<strong>不论是通过类还是实例都可以引用该方法</strong>。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">print</span><span class="token punctuation">(</span>A<span class="token punctuation">.</span>m3<span class="token punctuation">)</span><span class="token operator">&lt;</span>function A<span class="token punctuation">.</span>m3 at <span class="token number">0x000002BF7FF9A840</span><span class="token operator">></span><span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token punctuation">.</span>m3<span class="token punctuation">)</span><span class="token operator">&lt;</span>function A<span class="token punctuation">.</span>m3 at <span class="token number">0x000002BF7FF9A840</span><span class="token operator">></span>A<span class="token punctuation">.</span>m3<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 等价于</span>a<span class="token punctuation">.</span>m3<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ul><li>可以看成是静态方法已经跟这个类没关系了，相当于已经脱离了这个类，是一个完全独立的函数，只是调用的时候必须通过这个类，或者为了规范代码而将函数放到类中</li><li>当类中的该方法不涉及对该类属性的操作，建议声明为@staticmethod，面向对象思想体现</li></ul><h2 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h2><p>静态方法的使用场景： 如果在方法中不需要访问任何实例方法和属性，纯粹地通过传入参数并返回数据的功能性方法，那么它就适合用静态方法来定义，它节省了实例化对象的开销成本，往往这种方法放在类外面的模块层作为一个函数存在也是没问题的，而放在类中，仅为这个类服务。例如下面是微信公众号开发中验证微信签名的一个例子，它没有引用任何类或者实例相关的属性和方法。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> hashlib <span class="token keyword">import</span> sha1<span class="token keyword">import</span> tornado<span class="token punctuation">.</span>web<span class="token keyword">class</span> <span class="token class-name">SignatureHandler</span><span class="token punctuation">(</span>tornado<span class="token punctuation">.</span>web<span class="token punctuation">.</span>RequestHandler<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">get</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""         根据签名判断请求是否来自微信        """</span>        signature <span class="token operator">=</span> self<span class="token punctuation">.</span>get_query_argument<span class="token punctuation">(</span><span class="token string">"signature"</span><span class="token punctuation">,</span> None<span class="token punctuation">)</span>        echostr <span class="token operator">=</span> self<span class="token punctuation">.</span>get_query_argument<span class="token punctuation">(</span><span class="token string">"echostr"</span><span class="token punctuation">,</span> None<span class="token punctuation">)</span>        timestamp <span class="token operator">=</span> self<span class="token punctuation">.</span>get_query_argument<span class="token punctuation">(</span><span class="token string">"timestamp"</span><span class="token punctuation">,</span> None<span class="token punctuation">)</span>        nonce <span class="token operator">=</span> self<span class="token punctuation">.</span>get_query_argument<span class="token punctuation">(</span><span class="token string">"nonce"</span><span class="token punctuation">,</span> None<span class="token punctuation">)</span>        <span class="token keyword">if</span> self<span class="token punctuation">.</span>_check_sign<span class="token punctuation">(</span>TOKEN<span class="token punctuation">,</span> timestamp<span class="token punctuation">,</span> nonce<span class="token punctuation">,</span> signature<span class="token punctuation">)</span><span class="token punctuation">:</span>            logger<span class="token punctuation">.</span>info<span class="token punctuation">(</span><span class="token string">"微信签名校验成功"</span><span class="token punctuation">)</span>            self<span class="token punctuation">.</span>write<span class="token punctuation">(</span>echostr<span class="token punctuation">)</span>        <span class="token keyword">else</span><span class="token punctuation">:</span>            self<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">"你不是微信发过来的请求"</span><span class="token punctuation">)</span>    @staticmethod    <span class="token keyword">def</span> <span class="token function">_check_sign</span><span class="token punctuation">(</span>token<span class="token punctuation">,</span> timestamp<span class="token punctuation">,</span> nonce<span class="token punctuation">,</span> signature<span class="token punctuation">)</span><span class="token punctuation">:</span>        sign <span class="token operator">=</span> <span class="token punctuation">[</span>token<span class="token punctuation">,</span> timestamp<span class="token punctuation">,</span> nonce<span class="token punctuation">]</span>        sign<span class="token punctuation">.</span>sort<span class="token punctuation">(</span><span class="token punctuation">)</span>        sign <span class="token operator">=</span> <span class="token string">""</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>sign<span class="token punctuation">)</span>        sign <span class="token operator">=</span> sha1<span class="token punctuation">(</span>sign<span class="token punctuation">)</span><span class="token punctuation">.</span>hexdigest<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> sign <span class="token operator">==</span> signature<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>类方法的使用场景有：作为工厂方法创建实例对象，例如内置模块 datetime.date 类中就有大量使用类方法作为工厂方法，以此来创建date对象。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">date</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__new__</span><span class="token punctuation">(</span>cls<span class="token punctuation">,</span> year<span class="token punctuation">,</span> month<span class="token operator">=</span>None<span class="token punctuation">,</span> day<span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token punctuation">:</span>        self <span class="token operator">=</span> object<span class="token punctuation">.</span>__new__<span class="token punctuation">(</span>cls<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>_year <span class="token operator">=</span> year        self<span class="token punctuation">.</span>_month <span class="token operator">=</span> month        self<span class="token punctuation">.</span>_day <span class="token operator">=</span> day        <span class="token keyword">return</span> self    @classmethod    <span class="token keyword">def</span> <span class="token function">fromtimestamp</span><span class="token punctuation">(</span>cls<span class="token punctuation">,</span> t<span class="token punctuation">)</span><span class="token punctuation">:</span>        y<span class="token punctuation">,</span> m<span class="token punctuation">,</span> d<span class="token punctuation">,</span> hh<span class="token punctuation">,</span> mm<span class="token punctuation">,</span> ss<span class="token punctuation">,</span> weekday<span class="token punctuation">,</span> jday<span class="token punctuation">,</span> dst <span class="token operator">=</span> _time<span class="token punctuation">.</span>localtime<span class="token punctuation">(</span>t<span class="token punctuation">)</span>        <span class="token keyword">return</span> cls<span class="token punctuation">(</span>y<span class="token punctuation">,</span> m<span class="token punctuation">,</span> d<span class="token punctuation">)</span>    @classmethod    <span class="token keyword">def</span> <span class="token function">today</span><span class="token punctuation">(</span>cls<span class="token punctuation">)</span><span class="token punctuation">:</span>        t <span class="token operator">=</span> _time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> cls<span class="token punctuation">.</span>fromtimestamp<span class="token punctuation">(</span>t<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>如果希望在方法裡面调用静态类，那么把方法定义成类方法是合适的，因为要是定义成静态方法，那么你就要显示地引用类A，这对继承来说可不是一件好事情。<br>如果在@staticmethod中要调用到这个类的一些属性方法，只能直接<code>类名.属性名</code>或<code>类名.方法名</code>。而@classmethod因为持有cls参数，可以来调用类的属性，类的方法，实例化对象等，避免硬编码。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">A</span><span class="token punctuation">:</span>    @staticmethod    <span class="token keyword">def</span> <span class="token function">m1</span><span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">pass</span>    @staticmethod    <span class="token keyword">def</span> <span class="token function">m2</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        A<span class="token punctuation">.</span>m1<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># bad</span>    @classmethod    <span class="token keyword">def</span> <span class="token function">m3</span><span class="token punctuation">(</span>cls<span class="token punctuation">)</span><span class="token punctuation">:</span>        cls<span class="token punctuation">.</span>m1<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># good</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>在上述的例子中，有的返回的是 function 类型，有的返回的是 method 类型，function类型是函数，method类型是方法。他们的主要区别在于，函数的传参都是显式传递的；而方法传参往往都会有隐式传递的，具体根据于调用方。隐式传递 self 或者cls数据。</p><ul><li><strong>@staticmethod 的效果是让类对象与实例对象的调用都返回函数。</strong></li><li><strong>@staticmethod不需要表示自身对象的self和自身类的cls参数，就跟使用函数一样。</strong></li><li><strong>@classmethod 则是要让类对象与实例对象的调用都返回方法，并且传递隐式参数 cls</strong></li><li><strong>@classmethod的第一个参数需要是表示自身类的cls参数。</strong></li></ul><p>classmethod主要用途是作为构造函数：</p><ul><li>Python只有一个构造函数__new__，如果想要多种构造函数就很不方便。只能在new里面写一堆if isinstance 。有classmethod之后就可以用classmethod来写不同的构造函数。</li></ul><p>staticmethod主要用途是限定Namespace：</p><ul><li>也就是说这个函数虽然是个普通的function，但是它只有这个class会用到，不适合作为module level的function，这时候就把它作为staticmethod。如果不考虑namespace的问题的话直接在module里面def function就行了。</li></ul><p>staticmethod 和 classmethod 都运用了描述符的机制，学习描述符不仅能提供接触到更多工具集的方法，还能更深地理解 Python 工作的原理并更加体会到其设计的优雅性。</p>]]></content>
      
      
      <categories>
          
          <category> 编程语言 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 基础知识 </tag>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Python的装饰器</title>
      <link href="/2023/02/17/python-zhi-shi/python-zhuang-shi-qi/"/>
      <url>/2023/02/17/python-zhi-shi/python-zhuang-shi-qi/</url>
      
        <content type="html"><![CDATA[<h1 id="Python的装饰器"><a href="#Python的装饰器" class="headerlink" title="Python的装饰器"></a>Python的装饰器</h1><p>装饰器是Python语法糖，装饰器是可调用的对象，可以像常规的可调用对象那样调用，特殊的地方是装饰器的参数是一个函数。<br>装饰器的使用场景：</p><ol><li>增强被装饰函数的行为</li><li>提高代码复用</li></ol><p>一个良好的装饰器必须要遵守<strong>两个原则</strong>：</p><ul><li>不能修改被装饰函数的代码</li><li>不能修改被装饰函数的调用方式</li></ul><h2 id="装饰器理解基础"><a href="#装饰器理解基础" class="headerlink" title="装饰器理解基础"></a>装饰器理解基础</h2><p>如果想要很好的理解装饰器，那下面的两个内容需要先有所认知。</p><ul><li>函数名可以赋值给变量</li><li>高阶函数</li></ul><h3 id="函数名可以赋值给变量"><a href="#函数名可以赋值给变量" class="headerlink" title="函数名可以赋值给变量"></a>函数名可以赋值给变量</h3><p>看下这个例子：</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">func</span><span class="token punctuation">(</span>name<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'我是{}！慌的一逼！'</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>name<span class="token punctuation">)</span><span class="token punctuation">)</span>    func<span class="token punctuation">(</span><span class="token string">'梅西'</span><span class="token punctuation">)</span>y <span class="token operator">=</span> funcy<span class="token punctuation">(</span><span class="token string">'勒夫'</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> Output<span class="token punctuation">:</span><span class="token comment" spellcheck="true"># 我是梅西！慌的一逼！</span><span class="token comment" spellcheck="true"># 我是勒夫！慌的一逼！</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>代码中我们首先定义了函数<code>func</code>，并调用了<code>func</code>函数，并且把<code>func</code>赋值给y。<code>y = func</code>表明了：<strong>函数名可以赋值给变量，并且不影响调用</strong>。</p><h3 id="高阶函数"><a href="#高阶函数" class="headerlink" title="高阶函数"></a>高阶函数</h3><p>高阶函数满足如下两个条件中的任意一个：</p><ol><li>可以接收函数名作为实参；</li><li>返回值中可以包含函数名。</li></ol><p>在 Python 标准库中的 map 和 filter 等函数就是高阶函数—函数名作为参数。</p><pre class="line-numbers language-python"><code class="language-python">l <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span>r <span class="token operator">=</span> map<span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> x<span class="token operator">*</span><span class="token number">3</span><span class="token punctuation">,</span> l<span class="token punctuation">)</span><span class="token keyword">for</span> i <span class="token keyword">in</span> r<span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'当前天台人数：'</span><span class="token punctuation">,</span> i<span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> Output<span class="token punctuation">:</span><span class="token comment" spellcheck="true"># 当前天台人数： 3</span><span class="token comment" spellcheck="true"># 当前天台人数： 6</span><span class="token comment" spellcheck="true"># 当前天台人数： 12</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>自定义一个能返回函数的函数，也是高阶函数：</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">f</span><span class="token punctuation">(</span>l<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">return</span> map<span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> x<span class="token operator">*</span><span class="token number">5</span><span class="token punctuation">,</span> l<span class="token punctuation">)</span>a <span class="token operator">=</span> f<span class="token punctuation">(</span>l<span class="token punctuation">)</span><span class="token keyword">for</span> i <span class="token keyword">in</span> a<span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'当前天台人数：'</span><span class="token punctuation">,</span> i<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="实现一个类似的装饰器"><a href="#实现一个类似的装饰器" class="headerlink" title="实现一个类似的装饰器"></a>实现一个类似的装饰器</h2><p>现在已经知道了<strong>函数名赋值</strong>和<strong>高阶函数</strong>，有了这两个基础，就可以尝试实现一个类似的装饰器。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">status</span><span class="token punctuation">(</span>func<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'慌的一逼！'</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> func    <span class="token keyword">def</span> <span class="token function">name</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'我是梅西！'</span><span class="token punctuation">)</span>    temp <span class="token operator">=</span> status<span class="token punctuation">(</span>name<span class="token punctuation">)</span>temp<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> Output<span class="token punctuation">:</span><span class="token comment" spellcheck="true"># 慌的一逼！</span><span class="token comment" spellcheck="true"># 我是梅西！</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>在这个例子中我们定义了一个 status 函数，status 接收一个函数名然后直接返回该函数名。这样我们实现了不修改原函数 name，并且添加了一个新功能的需求。但是这里有个<strong>缺陷就是函数的调用方式改变了</strong>。即不是原本的 name，而是 temp。<br>要解决这个问题很简单，相信 a &#x3D; a*3 这样的表达式大家都见过，那么上述代码中的 temp &#x3D; status(name) 同样可以修改为 name &#x3D; status(name)，这样我们就完美的解决了问题：<strong>既添加新功能又没有修改原函数和其调用方式</strong>。修改后的代码如下：</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">status</span><span class="token punctuation">(</span>func<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'慌的一逼！'</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> func    <span class="token keyword">def</span> <span class="token function">name</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'我是梅西！'</span><span class="token punctuation">)</span>    name <span class="token operator">=</span> status<span class="token punctuation">(</span>name<span class="token punctuation">)</span>name<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>但这样的代码却有个不便之处，即每次使用这样的装饰器，我们都要写类似 name &#x3D; status(name) 的代码。在 python 中为了简化这种情况，提供了一个语法糖 @，<strong>在每个被装饰的函数上方使用这个语法糖</strong>就可以省掉这一句代码 name &#x3D; status(name)，最后的代码如下：</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">status</span><span class="token punctuation">(</span>func<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'慌的一逼！'</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> func    @status<span class="token keyword">def</span> <span class="token function">name</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'我是梅西！'</span><span class="token punctuation">)</span>    name<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>这样我们就弄清楚了装饰器的工作原理：</p><ul><li><strong>写一个高阶函数</strong>，即参数是函数，返回的也是函数。</li><li>在<strong>利用语法糖@，简化赋值操作</strong>。</li></ul><h2 id="装饰器进阶"><a href="#装饰器进阶" class="headerlink" title="装饰器进阶"></a>装饰器进阶</h2><p>能够处理返回值的装饰器：</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">guess_win</span><span class="token punctuation">(</span>func<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">rooftop_status</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        result <span class="token operator">=</span> func<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'天台已满，请排队！'</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> result    <span class="token keyword">return</span> rooftop_status@guess_win<span class="token keyword">def</span> <span class="token function">german_team</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'德国必胜！'</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> <span class="token string">'赢了会所嫩模！输了下海干活！'</span>x <span class="token operator">=</span> german_team<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> Output<span class="token punctuation">:</span><span class="token comment" spellcheck="true"># 德国必胜！</span><span class="token comment" spellcheck="true"># 天台已满，请排队！</span><span class="token comment" spellcheck="true"># 赢了会所嫩模！输了下海干活！</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>能够处理参数的装饰器：</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">guess_win</span><span class="token punctuation">(</span>func<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">rooftop_status</span><span class="token punctuation">(</span><span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>        result <span class="token operator">=</span> func<span class="token punctuation">(</span><span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'天台已满，请排队！'</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> result    <span class="token keyword">return</span> rooftop_status@guess_win<span class="token keyword">def</span> <span class="token function">german_team</span><span class="token punctuation">(</span>arg<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'{}必胜！'</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>arg<span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> <span class="token string">'赢了会所嫩模！输了下海干活！'</span>x <span class="token operator">=</span> german_team<span class="token punctuation">(</span><span class="token string">'德国'</span><span class="token punctuation">)</span>y <span class="token operator">=</span> german_team<span class="token punctuation">(</span><span class="token string">'西班牙'</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> Output<span class="token punctuation">:</span><span class="token comment" spellcheck="true"># 德国必胜！</span><span class="token comment" spellcheck="true"># 天台已满，请排队！</span><span class="token comment" spellcheck="true"># 西班牙必胜！</span><span class="token comment" spellcheck="true"># 天台已满，请排队！</span><span class="token comment" spellcheck="true"># 赢了会所嫩模！输了下海干活！</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>装饰器的<strong>本质是函数</strong>，<strong>其参数是另一个函数（被装饰的函数）</strong>。装饰器通常会额外处理被装饰的函数，然后把它返回，或者将其替换成另一个函数或可调用对象。行为良好的装饰器可以重用，以减少代码量。<br>代码运行的理解通式：</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">xxx</span><span class="token punctuation">(</span>func<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">return</span> func@xxx<span class="token keyword">def</span> <span class="token function">yyy</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">pass</span>yyy<span class="token punctuation">(</span><span class="token punctuation">)</span>等价于下面的方式yyy <span class="token operator">=</span> xxx<span class="token punctuation">(</span>yyy<span class="token punctuation">)</span>yyy<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> 编程语言 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 基础知识 </tag>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深度学习的优化算法</title>
      <link href="/2023/02/15/suan-fa/shen-du-xue-xi-you-hua-suan-fa/"/>
      <url>/2023/02/15/suan-fa/shen-du-xue-xi-you-hua-suan-fa/</url>
      
        <content type="html"><![CDATA[<h1 id="深度学习的优化算法"><a href="#深度学习的优化算法" class="headerlink" title="深度学习的优化算法"></a>深度学习的优化算法</h1><p>炼丹师的日常：拿来药材（数据），架起八卦炉（模型），点着六味真火（优化算法），就摇着蒲扇等着丹药出炉了。不过，同样的食材，同样的菜谱，但火候不一样了，这出来的口味可是千差万别。火小了夹生，火大了易糊，火不匀则半生半糊。</p><h2 id="简单回顾优化算法的发展"><a href="#简单回顾优化算法的发展" class="headerlink" title="简单回顾优化算法的发展"></a>简单回顾优化算法的发展</h2><p>深度学习优化算法经历了 SGD -&gt; SGDM -&gt; NAG -&gt;AdaGrad -&gt; AdaDelta -&gt; Adam -&gt; Nadam 这样的发展历程。<br>首先定义待优化参数$w$，目标函数$f(w)$，初始学习率$\alpha$。<br>开始进行迭代优化，在每个 epoch $t$ 中：</p><ol><li>计算目标函数关于当前参数的梯度：$g_t&#x3D;\frac{\partial f(w)}{\partial w}$</li><li>根据历史梯度计算一阶动量和二阶动量：$m_t&#x3D;\phi(g_1, g_2, g_3, … , g_t)$；$V_t&#x3D;\psi(g_1, g_2, g_3, … , g_t)$</li><li>计算当前时刻的下降梯度：$\eta_t&#x3D;\alpha \times m_t &#x2F; \sqrt[2]{V_t}$</li><li>根据下降梯度进行更新：$w_{t+1}&#x3D;w_t- \eta_t$</li></ol><p>上面4个步骤就是优化算法的通式。</p><h3 id="SGD算法"><a href="#SGD算法" class="headerlink" title="SGD算法"></a>SGD算法</h3><p>SGD没有动量的概念，因此：<br>$m_t&#x3D;g_t; V_t&#x3D;I^2$<br>代入步骤3中，可以看到下降梯度就是最简单的<br>$\eta_t&#x3D;\alpha \cdot g_t$<br>SGD最大的缺点是下降速度慢，而且可能会在沟壑的两边持续震荡，停留在一个局部最优点。</p><h3 id="SGDM算法"><a href="#SGDM算法" class="headerlink" title="SGDM算法"></a>SGDM算法</h3><p>SGDM全称是SGD with Momentum，在SGD基础上引入了一阶动量。为了抑制SGD的震荡，SGDM认为梯度下降过程可以加入惯性。下坡的时候，如果发现是陡坡，那就利用惯性跑的快一些。引入的一阶动量为：<br>$m_t&#x3D;\beta_1 \cdot m_{t-1} + (1 - \beta_1) \cdot g_t$<br>一阶动量是各个时刻梯度方向的指数移动平均值，也即梯度的动量更新。约等于最近$1 &#x2F; (1-\beta_1)$个时刻的梯度向量和的平均值。<br>也就是说，$t$时刻的下降方向，不仅由当前点的梯度方向决定，而且由此前累积的下降方向决定。$\beta_1$的经验值为0.9，这就意味着下降方向主要是此前累积的下降方向，并略微偏向当前时刻的下降方向。想象高速公路上汽车转弯，在高速向前的同时略微偏向，急转弯可是要出事的。</p><h3 id="NGA算法"><a href="#NGA算法" class="headerlink" title="NGA算法"></a>NGA算法</h3><p>SGD 还有一个问题是困在局部最优的沟壑里面震荡。想象一下你走到一个盆地，四周都是略高的小山，你觉得没有下坡的方向，那就只能待在这里了。可是如果你爬上高地，就会发现外面的世界还很广阔。因此，我们不能停留在当前位置去观察未来的方向，而要向前一步、多看一步、看远一些。<br>NAG全称Nesterov Accelerated Gradient，是在SGD、SGDM的基础上的进一步改进，改进点在于步骤1。我们知道在时刻$t$的主要下降方向是由累积动量决定的，自己的梯度方向说了也不算，那与其看当前梯度方向，不如先看看如果跟着累积动量走了一步，那个时候再怎么走。因此，NAG在步骤1，<strong>不计算当前位置的梯度方向，而是计算如果按照累积动量走了一步，那个时候的下降方向</strong>：<br>$g_t&#x3D;\nabla f(w_t - \alpha \cdot m_{t-1} &#x2F; \sqrt{V_{t-1}})$<br>然后用下一个点的梯度方向，与历史累积动量相结合，计算步骤2中当前时刻的累积动量。</p><h3 id="AdaGrad算法"><a href="#AdaGrad算法" class="headerlink" title="AdaGrad算法"></a>AdaGrad算法</h3><p>二阶动量的出现，才意味着自适应学习优化算法时代的到来。<br>SGD及其变种以同样的学习率更新每个参数，但深度神经网络往往包含大量的参数，这些参数并不是总会用得到（想想大规模的embedding）。<strong>对于经常更新的参数，我们已经积累了大量关于它的知识，不希望被单个样本影响太大，希望学习速率慢一些；对于偶尔更新的参数，我们了解的信息太少，希望能从每个偶然出现的样本身上多学一些，即学习速率大一些</strong>。<br>怎么样去度量历史更新频率呢？那就是二阶动量——该维度上，迄今为止所有梯度值的平方和：<br>$V_t&#x3D;\sum_{\tau &#x3D;1}^{t} g_{\tau}^2$<br>步骤3中下降的梯度为：<br>$\eta_t&#x3D;\alpha \times m_t &#x2F; \sqrt{V_t}$<br>可以看出，此时实质上的学习率由$\alpha$变成了$\alpha &#x2F; \sqrt{V_t}$。一般为了避免分母为0，会在分母上加一个小的平滑项。因此$\sqrt{V_t}$是恒大于0的，而且参数更新越频繁，二阶动量越大，学习率就越小。<br>这一方法在稀疏数据场景下表现非常好。但也存在一些问题：因为$\sqrt{V_t}$是单调递增的，会使得学习率单调递减至0，可能会使得训练过程提前结束，即便后续还有数据也无法学到必要的知识。</p><h3 id="AdaDelta-RMSProp算法"><a href="#AdaDelta-RMSProp算法" class="headerlink" title="AdaDelta&#x2F;RMSProp算法"></a>AdaDelta&#x2F;RMSProp算法</h3><p>由于AdaGrad单调递减的学习率变化过于激进，我们考虑一个改变二阶动量计算方法的策略：不累积全部历史梯度，而只关注过去一段时间窗口的下降梯度。这也就是AdaDelta名称中Delta的来历。<br>修改的思路很简单。前面我们讲到，指数移动平均值大约就是过去一段时间的平均值，因此我们用这一方法来计算二阶累积动量：<br>$V_t&#x3D;\beta_2 \cdot V_{t-1} + (1- \beta_2)g_t^2$<br>这就避免了二阶动量持续累积、导致训练过程提前结束的问题了。</p><h3 id="Adam算法"><a href="#Adam算法" class="headerlink" title="Adam算法"></a>Adam算法</h3><p>Adam是前述方法的集大成者。我们看到，SGDM在SGD基础上增加了一阶动量，AdaGrad和AdaDelta在SGD基础上增加了二阶动量。把一阶动量和二阶动量都用起来，就是Adam了——Adaptive + Momentum。<br>SGD的一阶动量：<br>$$m_t&#x3D;\beta_1 \cdot m_{t-1} + (1 - \beta_1) \cdot g_t$$<br>加上AdaDelta的二阶动量：<br>$V_t&#x3D;\beta_2 \cdot V_{t-1} + (1- \beta_2)g_t^2$<br>优化算法里最常见的两个超参数$\beta_1$和$\beta_2$都在这里了，前者控制一阶动量，后者控制二阶动量。</p><h3 id="Nadam算法"><a href="#Nadam算法" class="headerlink" title="Nadam算法"></a>Nadam算法</h3><p>我们说Adam是集大成者，但它居然遗漏了Nesterov，这还能忍？必须给它加上，按照NAG的步骤1：<br>$g_t&#x3D;\nabla f(w_t - \alpha \cdot m_{t-1} &#x2F; \sqrt{V_{t-1}})$<br>这就是Nesterov + Adam &#x3D; Nadam了。</p><h2 id="指数移动平均值的偏差修正"><a href="#指数移动平均值的偏差修正" class="headerlink" title="指数移动平均值的偏差修正"></a>指数移动平均值的偏差修正</h2><p>一阶动量和二阶动量都是按照指数移动平均值进行计算的：<br>$m_t&#x3D;\beta_1 \cdot m_{t-1} + (1 - \beta_1) \cdot g_t$<br>$V_t&#x3D;\beta_2 \cdot V_{t-1} + (1- \beta_2)g_t^2$<br>参数的经验值是$\beta_1&#x3D;0.9$；$\beta_2&#x3D;0.999$。初始化：$m_0&#x3D;0$；$V_0&#x3D;0$。<br>这个时候我们看到，在初期$m_t$和$V_t$都会接近于0，这个估计是有问题的。因此我们常常根据下式进行误差修正：<br>$\widetilde{m_t}&#x3D;m_t&#x2F;(1-\beta_1^t)$<br>$\widetilde{V_t}&#x3D;V_t&#x2F;(1-\beta_2^t)$</p><h2 id="Adam-SGD-组合策略"><a href="#Adam-SGD-组合策略" class="headerlink" title="Adam+SGD 组合策略"></a>Adam+SGD 组合策略</h2><p>不同优化算法的优劣依然是未有定论的争议话题。主流的观点认为：Adam等自适应学习率算法对于稀疏数据具有优势，且收敛速度很快；但精调参数的SGD（+Momentum）往往能够取得更好的最终结果。<br>可不可以把这两者结合起来，<strong>先用Adam快速下降，再用SGD调优</strong>，一举两得？思路简单，但里面有两个技术问题：</p><ol><li><strong>什么时候切换优化算法？</strong>——如果切换太晚，Adam可能已经跑到自己的盆地里去了，SGD再怎么好也跑不出来了。</li><li><strong>切换算法以后用什么样的学习率？</strong>——Adam用的是自适应学习率，依赖的是二阶动量的累积，SGD接着训练的话，用什么样的学习率？</li></ol><h3 id="切换之后用什么样的学习率"><a href="#切换之后用什么样的学习率" class="headerlink" title="切换之后用什么样的学习率"></a><strong>切换之后用什么样的学习率</strong></h3><p>Adam的下降方向是$\eta_t^{Adam}&#x3D;(\alpha &#x2F; \sqrt{V_t}) \cdot m_t$，SGD的下降方向是$\eta_t^{SGD}&#x3D;\alpha^{SGD} \cdot g_t$。<br>$\eta_t^{SGD}$必定可以分解为$\eta_t^{Adam}$所在方向及其正交方向上的两个方向之和，那么其在$\eta_t^{Adam}$方向上的投影就意味着SGD在Adam算法决定的下降方向上前进的距离，而在$\eta_t^{Adam}$的正交方向上的投影是 SGD 在自己选择的修正方向上前进的距离。这里p为Adam下降方向，g为梯度方向，γ为SGD的学习率。<br><img src="/images/yuque_mind.jpeg"><br>如果SGD要走完Adam未走完的路，那就首先要接过Adam的大旗——沿着$\eta_t^{Adam}$方向走一步，而后在沿着其正交方向走相应的一步。这样我们就知道该如何确定SGD的步长（学习率）了——<strong>SGD在Adam下降方向上的正交投影，应该正好等于Adam的下降方向（含步长）</strong>。也即：<br>$proj_{\eta_t^{SGD}}&#x3D;\eta_t^{Adam}$<br>解这个方程，我们就可以得到接续进行SGD的学习率：<br>$\alpha_t^{SGD}&#x3D;((\eta_t^{Adam})^T \eta_t^{Adam}) &#x2F; ((\eta_t^{Adam})^T g_t)$<br>为了减少噪声影响，作者使用移动平均值来修正对学习率的估计：<br>$\lambda_t^{SGD}&#x3D;\beta_2 \cdot \lambda_{t-1}^{SGD}+(1-\beta_2) \cdot \alpha_t^{SGD}$<br>$\widetilde{\lambda_t^{SGD}}&#x3D;\lambda_t^{SGD}&#x2F;(1-\beta_2^t)$<br>这里直接复用了Adam的$\beta_2$参数。</p><h3 id="何时进行算法的切换"><a href="#何时进行算法的切换" class="headerlink" title="何时进行算法的切换"></a><strong>何时进行算法的切换</strong></h3><p>当 SGD的相应学习率的移动平均值基本不变的时候，即：<br>$|\widetilde{\lambda_t^{SGD}}-\alpha_t^{SGD}|&lt; \epsilon$<br>每次迭代完都计算一下SGD接班人的相应学习率，如果发现基本稳定了，那就SGD以$\widetilde{\lambda_t^{SGD}}$为学习率接班前进。</p><h2 id="优化算法的常用tricks"><a href="#优化算法的常用tricks" class="headerlink" title="优化算法的常用tricks"></a>优化算法的常用tricks</h2><ol><li>首先，各大算法孰优孰劣并无定论。如果是刚入门，<strong>优先考虑 SGD+Nesterov Momentum或者Adam。</strong>（Standford 231n : _The two recommended updates to use are either SGD+Nesterov Momentum or Adam_）</li><li><strong>选择你熟悉的算法</strong>——这样你可以更加熟练地利用你的经验进行调参。</li><li><strong>充分了解你的数据</strong>——如果模型是非常稀疏的，那么优先考虑自适应学习率的算法。</li><li><strong>根据你的需求来选择</strong>——在模型设计实验过程中，要快速验证新模型的效果，可以先用Adam进行快速实验优化；在模型上线或者结果发布前，可以用精调的SGD进行模型的极致优化。</li><li><strong>先用小数据集进行实验。</strong> 有论文研究指出，随机梯度下降算法的收敛速度和数据集的大小的关系不大。（_The mathematics of stochastic gradient descent are amazingly independent of the training set size. In particular, the asymptotic SGD convergence rates are independent from the sample size_）因此可以先用一个具有代表性的小数据集进行实验，测试一下最好的优化算法，并通过参数搜索来寻找最优的训练参数。</li><li><strong>考虑不同算法的组合。</strong> 先用Adam进行快速下降，而后再换到SGD进行充分的调优。切换策略可以参考本文介绍的方法。</li><li><strong>数据集一定要充分的打散（shuffle）。</strong> 这样在使用自适应学习率算法的时候，可以避免某些特征集中出现，而导致的有时学习过度、有时学习不足，使得下降方向出现偏差的问题。</li><li>训练过程中<strong>持续监控训练数据和验证数据</strong>上的目标函数值以及精度或者AUC等指标的变化情况。对训练数据的监控是要保证模型进行了充分的训练——下降方向正确，且学习率足够高；对验证数据的监控是为了避免出现过拟合。</li><li><strong>制定一个合适的学习率衰减策略。</strong> 可以使用定期衰减策略，比如每过多少个epoch就衰减一次；或者利用精度或者AUC等性能指标来监控，当测试集上的指标不变或者下跌时，就降低学习率。</li></ol>]]></content>
      
      
      <categories>
          
          <category> 算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 基础知识 </tag>
            
            <tag> 优化算法 </tag>
            
            <tag> 数学 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hexo项目部署|PUSH到Github有各种问题</title>
      <link href="/2022/12/05/ji-lu-yi-ci-hexo-xiang-mu-bu-shu-de-debug-guo-cheng/"/>
      <url>/2022/12/05/ji-lu-yi-ci-hexo-xiang-mu-bu-shu-de-debug-guo-cheng/</url>
      
        <content type="html"><![CDATA[<blockquote><p>关注公众号【惜学塔】，每日知识干货马上就来！</p></blockquote><p><img src="/medias/contact.jpg"></p><h1 id="正常部署方式"><a href="#正常部署方式" class="headerlink" title="正常部署方式"></a>正常部署方式</h1><p>当github仓库、git、Hexo准备就绪，想把自己的内容推送到Github上时，通过GitHub网址 ，<a href="https://jlcxxzj.github.io/" target="_blank" rel="noopener">可见jlcxxzj</a>,就可以愉快的访问时，一切都是那么简单，只需要：</p><h2 id="一、建立本地项目和Github的连接"><a href="#一、建立本地项目和Github的连接" class="headerlink" title="一、建立本地项目和Github的连接"></a>一、建立本地项目和Github的连接</h2><ol><li>打开Hexo项目根目录，右键打开git bash，然后输入自己的github账号信息命令：<pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">git</span> config --global user.name <span class="token string">"jlcxxzj"</span><span class="token function">git</span> config --global user.email <span class="token string">"2541597473@qq.com"</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></li><li>没有报错就说明用户信息是正确的，如果报错去Github设置看看自己的用户名和邮箱；接下来生成密钥SSH key，首先是确定要生成密钥的账户：<pre class="line-numbers language-bash"><code class="language-bash">ssh-keygen -t rsa -C <span class="token string">"2541597473@qq.com"</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre> 继续输入下面命令，会产生一个密钥，也可在本地的用户根目录下**.ssh**文件夹找到产生的密钥：<pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">cat</span> ~/.ssh/id_rsa.pub<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li><li>生成密钥成功以后，打开<a href="https://github.com/jlcxxzj">github</a>，在右上角头像下面点击<code>settings</code>，再点击<code>SSH and GPG keys</code>，新建一个SSH，名字任意，可按项目名称来，将第2步产生的密钥复制到框中，点击确定保存。</li><li>在第1步右键打开的git bash下输入<code>ssh -T git@github.com</code>，如果没有报错，出现你的用户名，那就成功了。</li></ol><h1 id="内网穿透"><a href="#内网穿透" class="headerlink" title="内网穿透"></a>内网穿透</h1><p>由于本机属于内网，互联网是没有办法直接访问的，因此需要使用内网穿透来使得其他设备可以访问到<br><a href="https://cloud.tencent.com/developer/article/2126247" target="_blank" rel="noopener">https://cloud.tencent.com/developer/article/2126247</a><br>主机IP可通过CMD输入ipconfig或者ipconfig&#x2F;all来查看<br>选择https方式</p><h2 id="二、将自己的Hexo博客上传到github页面，不用搭服务器或者内网穿透就能远程访问"><a href="#二、将自己的Hexo博客上传到github页面，不用搭服务器或者内网穿透就能远程访问" class="headerlink" title="二、将自己的Hexo博客上传到github页面，不用搭服务器或者内网穿透就能远程访问"></a>二、将自己的Hexo博客上传到github页面，不用搭服务器或者内网穿透就能远程访问</h2><ol><li>首先修改一下Hexo博客更目录下的_config.yml配置文件(注意，不是主题下面的_config.yml),修改一下部署的配置信息，repository修改为自己的github项目地址：<pre class="line-numbers language-bash"><code class="language-bash">deploy:    type: <span class="token function">git</span>    repository: https://github.com/jlcxxzj/jlcxxzj.github.io.git    branch: master<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></li><li>正常情况下以下3步就可以部署到github页面访问1. <code>hexo clean</code>、<code>hexo g</code>、<code>hexo d</code></li><li>github访问地址 <a href="https://github.com/jlcxxzj/jlcxxzj.github.io.git%EF%BC%8C%E5%9C%A8%E5%85%B7%E4%BD%93%E7%9A%84%E9%A1%B9%E7%9B%AE%E8%AE%BE%E7%BD%AE%E4%B8%AD%EF%BC%8C%E5%8F%AF%E4%BB%A5%E6%A0%B9%E6%9C%AC%E6%9B%B4%E6%94%B9%E9%BB%98%E8%AE%A4%E5%88%86%E6%94%AF%EF%BC%8C%E8%AE%BF%E9%97%AE%E7%9A%84%E8%AF%9D%E4%B9%9F%E6%98%AF%E8%AE%BF%E9%97%AE%E9%BB%98%E8%AE%A4%E7%9A%84%E5%88%86%E6%94%AF">https://github.com/jlcxxzj/jlcxxzj.github.io.git，在具体的项目设置中，可以根本更改默认分支，访问的话也是访问默认的分支</a></li><li>也可以本地访问， <code>hexo clean</code>、<code>hexo g</code>、<code>hexo s</code>，默认4000端口可访问，<a href="http://localhost:4000/" target="_blank" rel="noopener">http://localhost:4000</a></li></ol><h1 id="各种意外情况"><a href="#各种意外情况" class="headerlink" title="各种意外情况"></a>各种意外情况</h1><h2 id="部署出现错误err-Error-Spawn-failed"><a href="#部署出现错误err-Error-Spawn-failed" class="headerlink" title="部署出现错误err: Error: Spawn failed"></a>部署出现错误err: Error: Spawn failed</h2><pre class="line-numbers language-bash"><code class="language-bash"><span class="token comment" spellcheck="true">##进入站点根目录</span><span class="token function">cd</span> /usr/local/src/hexo/hanyubolg/<span class="token comment" spellcheck="true">##删除git提交内容文件夹</span><span class="token function">rm</span> -rf .deploy_git/<span class="token comment" spellcheck="true">##执行</span><span class="token function">git</span> config --global core.autocrlf <span class="token boolean">false</span><span class="token comment" spellcheck="true">##最后</span>hexo clean <span class="token operator">&amp;&amp;</span> hexo g <span class="token operator">&amp;&amp;</span> hexo d<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="Git出错：error-RPC-failed-curl-56-OpenSSL-SSL-read-Connection-was-reset-errno-10054"><a href="#Git出错：error-RPC-failed-curl-56-OpenSSL-SSL-read-Connection-was-reset-errno-10054" class="headerlink" title="Git出错：error: RPC failed; curl 56 OpenSSL SSL_read: Connection was reset, errno 10054"></a>Git出错：error: RPC failed; curl 56 OpenSSL SSL_read: Connection was reset, errno 10054</h2><p>出现这种原因的可能有好几种</p><h3 id="fatal-The-remote-end-hung-up-unexpectedly"><a href="#fatal-The-remote-end-hung-up-unexpectedly" class="headerlink" title="fatal: The remote end hung up unexpectedly"></a>fatal: The remote end hung up unexpectedly</h3><p><img src="https://upload-images.jianshu.io/upload_images/20074990-37e315ab227b135e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/566/format/webp"></p><ol><li>整体文件太大，修改文件大小的上限：<br><code>git config --global http.postBuffer 524288000</code><br>也可在项目中的.git文件夹，直接修改；通过下面命令查看是否修改成功：<br><code>git config --list</code></li><li>单个文件<strong>超过100M</strong>是不能上传的，部署的时候需要注意</li></ol><h3 id="error-failed-to-push-some-refs-to-git"><a href="#error-failed-to-push-some-refs-to-git" class="headerlink" title="error: failed to push some refs to *.git"></a>error: failed to push some refs to *.git</h3><p>之前这种操作属于常规操作，没想到这次出了问题，感觉问题应该出在了工程创建方式上。我在 git 后台创建工程时勾选了自动添加 README.md 文件，可能导致了后续一系列问题。</p><h2 id="部署的时候一直卡着不动的原因"><a href="#部署的时候一直卡着不动的原因" class="headerlink" title="部署的时候一直卡着不动的原因"></a>部署的时候一直卡着不动的原因</h2><p><a href="https://blog.csdn.net/qq_25333681/article/details/80879500" target="_blank" rel="noopener">https://blog.csdn.net/qq_25333681/article/details/80879500</a></p><h2 id="需要修改展示的branch分支页面时"><a href="#需要修改展示的branch分支页面时" class="headerlink" title="需要修改展示的branch分支页面时"></a>需要修改展示的branch分支页面时</h2><p>点击settings，在Pages的 <strong>Build and deployment</strong>修改<strong>Branch</strong>，需要等一会重新输入<a href="https://jlcxxzj.github.io/" target="_blank" rel="noopener">项目地址</a>，就能访问分支下的页面了。<br><img src="/%E8%AE%B0%E5%BD%95%E4%B8%80%E6%AC%A1hexo%E9%A1%B9%E7%9B%AE%E9%83%A8%E7%BD%B2%E7%9A%84Debug%E8%BF%87%E7%A8%8B_md_files/00d68c60-745b-11ed-aa4d-fdeb71e777c3.jpeg?v=1&type=image"></p><h2 id="Debug链接"><a href="#Debug链接" class="headerlink" title="Debug链接"></a>Debug链接</h2><p><a href="https://blog.csdn.net/u013250071/article/details/81203900" target="_blank" rel="noopener">修改.git文件夹</a></p>]]></content>
      
      
      <categories>
          
          <category> 计算机基础 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> github项目部署 </tag>
            
            <tag> hexo博客 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
